[{"content":"POD 运行POD # 命令格式： kubectl run (pod控制器名称) [参数] # --image 指定Pod的镜像 # --port 指定端口 # --namespace 指定namespace kubectl run nginx --image=nginx:latest --port=80 --namespace dev 查看POD信息 # 查看Pod基本信息 [root@master ~]# kubectl get pods -n dev NAME READY STATUS RESTARTS AGE nginx 1/1 Running 0 43s # 查看Pod的详细信息 [root@master ~]# kubectl describe pod nginx -n dev 删除POD kubectl delete pod nginx -n dev 配置操作 创建一个pod-nginx.yaml，内容如下：\napiVersion: v1 kind: Pod metadata: name: nginx namespace: dev spec: containers: - image: nginx:latest name: pod ports: - name: nginx-port containerPort: 80 protocol: TCP ConfigMap 创建ConfigMap对象的方法有两种\n命令式命令\n1.字面量：kubectl create configmap NAME --from-literal=key1=value1 2.从文件加载：kubectl create configmap NAME --from-file=[key=]/PATH/TO/FILE 3.从目录加载： kubectl create configmap NAME --from-file=[key=]/PATH/TO/DIR/ 配置文件\n1.命令式：kubectl create -f 2.声明式：kubectl apply -f 提示：基于文件内容生成时，可以使用命令式命令以dry-run模式生成并保存\n查看帮助\nkubectl create configmap -h 案例1：\nkubectl create configmap my-cm --from-literal=\u0026#39;test.html\u0026#39;=\u0026#39;this is nignx\u0026#39; --dry-run=client -o yaml \u0026gt; my-cm.yaml 文件内容\napiVersion: v1 data: test.html: this is nignx kind: ConfigMap metadata: creationTimestamp: null name: my-cm 案例2：\nkubectl create cm my-cm2 --from-file=./map.txt --dry-run=client -o yaml \u0026gt;my-cm2.yaml 文件内容\napiVersion: v1 data: map.txt: | configmap kind: ConfigMap metadata: creationTimestamp: null name: my-cm2 引用ConfigMap对象 ConfigMap资源对象中以key-value保存的数据，在Pod中引用的方式通常有两种\n环境变量 1.引用ConfigMap对象上特定的key，以valueFrom赋值给Pod上指定的环境变量 2.在Pod上使用envFrom一次性导入ConfigMap对象上的所有key-value，key（也可以统一附加特定前缀）即为环境变量名，value自动成为相应的变量值 configMap卷 1.在Pod上将ConfigMap对象引用为存储卷，而后整体由容器mount至某个目录下;key转为文件名，value即为相应的文件内容 2.在Pod上定义configMap卷时，仅引用其中的部分key，而后由容器mount至目录下 3.在容器上仅mount configMap卷上指定的key 在Pod上配置使用ConfigMap示例 1.通过存储卷引用\napiVersion: apps/v1 kind: Deployment metadata: labels: app: my-dep name: my-dep spec: replicas: 1 selector: matchLabels: app: my-dep template: metadata: labels: app: my-dep spec: containers: - image: nginx:latest name: nginx ports: - containerPort: 80 volumeMounts: - name: my-cm-configmap # 卷名称 mountPath: /usr/share/nginx/html/ # 容器内挂载路径 readOnly: true # 只读 否 volumes: - name: my-cm-configmap # 卷名称 configMap: name: my-cm # configmap名称 optional: false 2.通过环境变量引用\napiVersion: apps/v1 kind: Deployment metadata: labels: app: my-dep name: my-dep spec: replicas: 1 selector: matchLabels: app: my-dep template: metadata: labels: app: my-dep spec: containers: - image: nginx:latest name: nginx ports: - containerPort: 80 env: - name: PORT valueFrom: configMapKeyRef: name: my-cm key: \u0026#39;test.html\u0026#39; optional: false Secret secret资源 1.Secret主要用于存储密钥、OAuth令牌和 SSH 密钥等敏感信息，这些敏感信息采用base64编码保存，略好于明文存储\n2.Secret根据其用途等，还有类型上的区分\n创建Secret资源 支持类似于ConfigMap的创建方式，但Secret有类型子命令，而且不同类型在data或stringData字段中支持嵌套使用的key亦会有所有同\n命令式命令\n#generic 1.kubectl create secret generic NAME [--type=string] [--from-file=[key=]source] [--from-literal=key1=value1] 2.除了后面docker-registry和tls命令之外的其它类型，都可以使用该命令中的--type选项进行定义，但有些类型有key的特定要求 #tls 1.kubectl create secret tls NAME --cert=path/to/cert/file --key=path/to/key/file 2.通常，其保存cert文件内容的key为tls.crt，而保存private key的key为tls.key #docker-registry 1.kubectl create secret docker-registry NAME --docker-username=user --docker-password=password --docker-email=email [--docker-server=string] [--from-file=[key=]source] 2.通常，从已有的json格式的文件加载生成的就是dockerconfigjson类型，命令行直接量生成的也是该类型 资源示例 命令式 kubectl create secret generic mysql-root-auth --from-literal=username=root --from-literal=passwd=123456 --dry-run=client -o yaml kubectl create secret tls my-tls --cert=./itshare.crt --key=./itshare.key --dry-run=client -o yaml 配置文件 apiVersion: v1 data: passwd: MTIzNDU2 username: cm9vdA== kind: Secret metadata: name: mysql-root-auth apiVersion: v1 data: tls.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURFVENDQWZrQ0ZEVjRpUFhjNlNIelR4a2NzdEwzTFUxRFRzTmNNQTBHQ1NxR1NJYjNEUUVCQ3dVQU1FVXgKQ3pBSkJnTlZCQVlUQWtGVk1STXdFUVlEVlFRSURBcFRiMjFsTFZOMFlYUmxNU0V3SHdZRFZRUUtEQmhKYm5SbApjbTVsZENCWGFXUm5hWFJ6SUZCMGVTQk1kR1F3SGhjTk1qTXdOakl6TVRZeU1qQTJXaGNOTWpRd05qSXlNVFl5Ck1qQTJXakJGTVFzd0NRWURWUVFHRXdKQlZURVRNQkVHQTFVRUNBd0tVMjl0WlMxVGRHRjBaVEVoTUI4R0ExVUUKQ2d3WVNXNTBaWEp1WlhRZ1YybGtaMmwwY3lCUWRIa2dUSFJrTUlJQklqQU5CZ2txaGtpRzl3MEJBUUVGQUFPQwpBUThBTUlJQkNnS0NBUUVBelFPZEZodlNlejJVNEZVK3lIaU1qT3BCWHhVd0RiV1NScW5GaUFMenc3OFk0bmx1Cmw3MFFzeGlTNEdndFJKK1JwZlRuSEF5RTVmNUxnS2lCc0U1WS9IdlQ5NDZSWEZZYVEyOTBNYTNSbFY3b3V3ODMKUmVTZmg0ZWI2cmlKVW00eVBYaUxUZHRmNXF2K2FuZGtFdVZ1VlFaMUpOVUxoRFF0dzRFQ1J4eURvc0s1R1VHVApmYVpGczByVUdMQTV1Ui8zVHM2b1hxWnowUkZYVC9lU29JbEFnMVplckpHd0FlNTNhWllvdm9ERi9Ja2lubldOCjB3Y2dQSWl4R1RtdU9iQ0NPS3k1bk8xMnJ5NGtFa3djRWRkSkQ2S3JKYkdYNkg3VWNXV3VvQkxUUDhoVEgxTjEKNUtIVmtJZ0U2a3h4RHpVeUtNb3FhekZ3M0MrVUp5U0pEZHVnb3dJREFRQUJNQTBHQ1NxR1NJYjNEUUVCQ3dVQQpBNElCQVFBcE40OHlWTml3RnR4TEZ5V3ZVTmdQRWZLc0c1M3M2bGR4RjRLNk84Wm44ODAzR2tUR0o3MnkrSFVICjJTZkpPV3hyRnVzdysrZ2ZONjBPV0FZbnF5RzkvREttczJsUTFabmw1QU8wUWpxM0NqZkl2ODV4Q2VuQWVsdngKYktrZjFPR1lSNTBHZFl4TGYwMEFaVzhBSFBvOFkvRDBEL2phVXN1OEhsVnFhSWF6SmpTSldpZkFWcFh0cXpaeQp2ZDVWTWRST3diNWdhWWZhRjJVWDZLSlFpemF1K2hzV2ZWOGkzRnNMY2w1YWJmYnkyNUROTlUwVHZYU3V3ckVwCnZBSDNMU2hJeGtRQzU0REc3TDM0WFJ6Q1hkN3U4QkR3U1JaczQzSkxwQ1JKR1RGc0hvNnFPaFdEVFBSa0xDcTUKbGt4bG5FbUNTMFdPWHhRVGRGYUdpN0ZIMVBSLwotLS0tLUVORCBDRVJUSUZJQ0FURS0tLS0tCg== tls.key: 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 kind: Secret metadata: creationTimestamp: null name: my-tls type: kubernetes.io/tls 引用Secret对象 Secret资源在Pod中引用的方式同样有两种\n环境变量 1.引用Secret对象上特定的key，以valueFrom赋值给Pod上指定的环境变量 2.在Pod上使用envFrom一次性导入Secret对象上的所有key-value，key（也可以统一附加特定前缀）即为环境变量名，value自动成为相应的变量值 secret卷 1.在Pod上将Secret对象引用为存储卷，而后整体由容器mount至某个目录下key转为文件名，value即为相应的文件内容 2.在Pod上定义Secret卷时，仅引用其中的部分key，而后由容器mount至目录下 3.在容器上仅mount Secret卷上指定的key 注意：容器很可能会将环境变量打印到日志中，因而不建议以环境变量方式引用Secret中的数据\n在Pod上引用Secret的示例 在Pod上引用Secret资源 apiVersion: apps/v1 kind: Deployment metadata: labels: app: my-dep name: my-dep spec: replicas: 1 selector: matchLabels: app: my-dep template: metadata: labels: app: my-dep spec: containers: - image: nginx:latest name: nginx ports: - containerPort: 80 volumeMounts: - name: my-secret mountPath: /etc/nginx/certs/ readOnly: true volumes: - name: my-secret secret: secretName: my-tls # secret 名称 ","permalink":"https://xyenvy.github.io/posts/k8sactualcombat/","summary":"POD 运行POD # 命令格式： kubectl run (pod控制器名称) [参数] # --image 指定Pod的镜像 # --port 指定端口 # --namespace 指定namespace kubectl run nginx --image=nginx:latest --port=80 --namespace dev 查看POD信息 # 查看Pod基本信息 [root@master ~]# kubectl get pods -n dev NAME READY STATUS RESTARTS AGE nginx 1/1 Running 0 43s # 查看Pod的详细信息 [root@master ~]# kubectl describe pod nginx -n dev 删除POD kubectl delete pod nginx -n dev 配置操作 创建一个pod-","title":"kubernetes实战"},{"content":"Pod资源对象yaml详解 apiVersion: apps/v1 #必选，版本号，例如v1 kind: Pod #必选，指定创建资源的角色/类型 metadata: #必选，资源的元数据/属性 name: string #必选，资源的名字，在同一个namespace中必须唯一 namespace: string #必选，Pod所属的命名空间 labels: #自定义标签,使这个标签在service网络中备案，以便被获知 - name: string #自定义标签名字 annotations: #设置自定义注解列表 - name: \u0026#34;string\u0026#34; #设置自定义注解名字 spec: #必选，设置该资源的详细定义 containers: #必选，Pod中容器列表 - name: string #必选，容器名称 image: string #必选，容器的镜像名称 imagePullPolicy: [Always | Never | IfNotPresent] #获取镜像的策略 Alawys表示下载镜像 IfnotPresent表示优先使用本地镜像，否则下载镜像，Nerver表示仅使用本地镜像 command: [string] #容器的启动命令列表，如不指定，使用打包时使用的启动命令 args: [string] #容器的启动命令参数列表 workingDir: string #容器的工作目录 volumeMounts: #挂载到容器内部的存储卷配置 - name: string #引用pod定义的共享存储卷的名称，需用volumes[]部分定义的的卷名 mountPath: string #存储卷在容器内mount的绝对路径，应少于512字符 readOnly: boolean #是否为只读模式 ports: #需要暴露的端口库号列表 - name: string #端口号名称 containerPort: int #容器需要监听的端口号 hostPort: int #容器所在主机需要监听的端口号，默认与Container相同 protocol: string #端口协议，支持TCP和UDP，默认TCP env: #容器运行前需设置的环境变量列表 - name: string #环境变量名称 value: string #环境变量的值 resources: #资源限制和请求的设置 limits: #资源限制的设置 cpu: string #Cpu的限制，单位为core数，将用于docker run --cpu-shares参数 memory: string #内存限制，单位可以为Mib/Gib，将用于docker run --memory参数 requests: #资源请求的设置 cpu: string #Cpu请求，容器启动的初始可用数量 memory: string #内存清楚，容器启动的初始可用数量 livenessProbe: #对Pod内个容器健康检查的设置，当探测无响应几次后将自动重启该容器，检查方法有exec、httpGet和tcpSocket，对一个容器只需设置其中一种方法即可 exec: #对Pod容器内检查方式设置为exec方式 command: [string] #exec方式需要制定的命令或脚本 httpGet: #对Pod内个容器健康检查方法设置为HttpGet，需要制定Path、port path: string port: number host: string scheme: string HttpHeaders: - name: string value: string tcpSocket: #对Pod内个容器健康检查方式设置为tcpSocket方式 port: number initialDelaySeconds: 0 #容器启动完成后首次探测的时间，单位为秒 timeoutSeconds: 0 #对容器健康检查探测等待响应的超时时间，单位秒，默认1秒 periodSeconds: 0 #对容器监控检查的定期探测时间设置，单位秒，默认10秒一次 successThreshold: 0 failureThreshold: 0 securityContext: privileged:false restartPolicy: [Always | Never | OnFailure]#Pod的重启策略，Always表示一旦不管以何种方式终止运行，kubelet都将重启，OnFailure表示只有Pod以非0退出码退出才重启，Nerver表示不再重启该Pod nodeSelector: obeject #设置NodeSelector表示将该Pod调度到包含这个label的node上，以key：value的格式指定 imagePullSecrets: #Pull镜像时使用的secret名称，以key：secretkey格式指定 - name: string hostNetwork: false #是否使用主机网络模式，默认为false，如果设置为true，表示使用宿主机网络 volumes: #在该pod上定义共享存储卷列表 - name: string #共享存储卷名称 （volumes类型有很多种） emptyDir: {} #类型为emtyDir的存储卷，与Pod同生命周期的一个临时目录。为空值 hostPath: string #类型为hostPath的存储卷，表示挂载Pod所在宿主机的目录 path: /root/data #Pod所在宿主机的目录，将被用于同期中mount的目录 secret: #类型为secret的存储卷，挂载集群与定义的secre对象到容器内部 scretname: string items: - key: string path: string configMap: #类型为configMap的存储卷，挂载预定义的configMap对象到容器内部 name: string items: - key: string path: string点 Deployment资源对象yaml详解 apiVersion: apps/v1 kind: Deployment metadata: #元数据 annotations: #注释信息 deployment.kubernetes.io/revision: \u0026#39;1\u0026#39; k8s.kuboard.cn/ingress: \u0026#39;false\u0026#39; k8s.kuboard.cn/service: NodePort k8s.kuboard.cn/workload: nextcloud labels: #标签信息 k8s.kuboard.cn/layer: \u0026#39;\u0026#39; k8s.kuboard.cn/name: nextcloud name: nextcloud #名称 namespace: nextcloud #命名空间 spec: #定义容器模板，该模板可以包含多个容器 replicas: 3 #副本数量 selector: #标签选择器 matchLabels: k8s.kuboard.cn/layer: \u0026#39;\u0026#39; k8s.kuboard.cn/name: nextcloud strategy: #滚动升级策略 type: RollingUpdate #类型 rollingUpdate: #由于replicas为3,则整个升级,pod个数在2-4个之间 maxSurge: 25% #滚动升级时会先启动25%pod maxUnavailable: 25% #滚动升级时允许的最大Unavailable的pod个数 template: #镜像模板 metadata: #元数据 labels: #标签 k8s.kuboard.cn/layer: \u0026#39;\u0026#39; k8s.kuboard.cn/name: nextcloud spec: #定义容器模板，该模板可以包含多个容器 containers: #容器信息 - name: nextcloud #容器名称 image: \u0026#39;172.16.20.100/library/nextcloud:yan\u0026#39; #镜像名称 imagePullPolicy: Always #镜像下载策略 ports: - name: http containerPort: 80 protocol: TCP env: resources: #CPU内存限制 limits: #限制cpu内存 cpu: 200m memory: 200m requests: #请求cpu内存 cpu: 100m memory: 100m securityContext: #-------------------------#安全设定 privileged: true #-----------------------#开启享有特权 volumeMounts: #----------------------------#挂载volumes中定义的磁盘 - name: html #---------------------------#挂载容器1 mountPath: /var/www/html - name: session #------------------------#挂载容器1 mountPath: /var/lib/php/session volumes: #在该pod上定义共享存储卷列表 - name: html #-------------------------------#共享存储卷名称 （volumes类型有很多种） persistentVolumeClaim: #-------------------#volumes类型为pvc claimName: html #-----------------------#关联pvc名称 - name: session persistentVolumeClaim: claimName: session restartPolicy: Always #------------------------#Pod的重启策略 #Always表示一旦不管以何种方式终止运行，kubelet都将重启， #OnFailure表示只有Pod以非0退出码退出才重启， #Nerver表示不再重启该Pod schedulerName: default-scheduler #指定pod调度到节点 Service资源对象yaml详解 apiVersion: v1 kind: Service metadata: #---------------------------------#元数据 annotations: #-----------------------------#注释信息 k8s.kuboard.cn/workload: nextcloud labels: #----------------------------------#标签信息 k8s.kuboard.cn/layer: \u0026#39;\u0026#39; k8s.kuboard.cn/name: nextcloud name: nextcloud #--------------------------#名称 namespace: nextcloud #---------------------#命名空间 spec: #--------------------------------------#定义Service模板 clusterIP: 10.0.181.206 #------------------#指定svcip地址 不指定则随机 #NodePort类型：集群外网络 type: NodePort #---------------------------#类型为NodePort ports: - name: mnwwwp nodePort: 30001 #----------------------#当type = NodePort时，指定映射到物理机的端口号 port: 80 #-----------------------------#服务监听的端口号 protocol: TCP #------------------------#端口协议，支持TCP和UDP，默认TCP targetPort: 80 #-----------------------#需要转发到后端Pod的端口号 #ClusterIP类型：集群内网络 # type: ClusterIP # - name: mnwwwp # port: 80 # protocol: TCP # targetPort: 80 # - name: j5smwx # port: 22 # protocol: TCP # targetPort: 22 selector: #-------------------------------#label selector配置，将选择具有label标签的Pod作为管理 k8s.kuboard.cn/layer: \u0026#39;\u0026#39; k8s.kuboard.cn/name: nextcloud sessionAffinity: None #--------------------#是否支持session ","permalink":"https://xyenvy.github.io/posts/k8srresourceddetails/","summary":"Pod资源对象yaml详解 apiVersion: apps/v1 #必选，版本号，例如v1 kind: Pod #必选，指定创建资源的角色/类型 metadata: #必选，资源的元数据/属性 name: string #必选，资源的名字，在同一个namespace中必须唯一 namespace: string #必选，Pod所属的命名空间 labels: #自定义标签,使这个标签在service网络中备案，以便被获知 - name: string","title":"kubernetes常见yaml资源详解"},{"content":"开源和跨平台性 Tabby 远程是一款开源的软件，这意味着它的源代码对公众开放，任何人都可以查看、使用和修改。开源性带来了以下优势：\n透明性：开源使得软件的开发和运行过程更加透明。用户可以查看源代码，了解软件的实现方式，并确保其中没有隐藏的恶意代码或漏洞。 可靠性：由于开源软件的源代码可以被广泛审查和测试，它通常具有更高的可靠性和稳定性。开源社区中的开发者和用户可以共同改进软件，并修复可能存在的问题。 灵活性：开源软件通常提供了更大的灵活性。用户可以根据自己的需求自由地修改和定制软件，以适应特定的环境和用例。 Tabby 远程也具有跨平台性，它可以在多个操作系统上运行，包括但不限于 Windows、MacOS 和 Linux。这意味着无论您使用哪种操作系统，都可以使用 Tabby 远程来进行远程连接和管理。这种跨平台性使得 Tabby 远程成为一个广泛适用的工具，可以满足不同用户的需求和偏好。\n下载和安装 要安装 Tabby 远程，您可以按照以下步骤进行操作：\n1.访问 Tabby github地址github下载地址\n2.根据您的操作系统选择适当的版本（Windows、MacOS 或 Linux）下载\n3.下载完成，您可以根据操作系统的要求进行安装。安装过程通常非常简单，并且在几分钟内即可完成\n常用功能简介 远程连接管理：Tabby 远程允许您创建、管理和切换多个远程连接。您可以轻松地在不同的标签页之间切换，以便同时访问多个远程服务器。 多种连接类型：Tabby 远程支持多种连接类型，包括 SSH、Telnet、Serial 和 Raw。这意味着您可以连接到各种不同类型的设备和服务器。 会话持久化：Tabby 远程具有会话持久化功能，即使您断开连接或关闭应用程序，也能够保持会话的状态。这样，您可以随时重新连接并恢复之前的工作。 文件传输：Tabby 远程允许您在本地计算机和远程服务器之间进行文件传输。您可以方便地上传和下载文件，以及在两者之间进行复制和粘贴操作。 多窗口和标签页：Tabby 远程支持多窗口和标签页功能，使您可以同时在多个终端窗口中进行工作。这样，您可以更高效地管理和组织不同的连接和任务。 远程命令执行：通过 Tabby 远程，您可以在远程服务器上执行命令并查看命令的输出。这使得远程管理和维护变得更加方便和灵活。 配置管理：Tabby 远程允许您保存和管理连接的配置，包括服务器地址、端口、用户名、密码和密钥等。这样，您可以快速访问并连接到事先配置好的服务器。 自定义设置：Tabby 远程提供了许多自定义设置选项，使您可以根据个人喜好和需求进行界面和行为上的调整。您可以更改配色方案、字体、键盘快捷键等。 安全性：Tabby 远程支持加密连接，确保您的远程通信和数据传输的安全性。它使用 SSH 协议和其他安全性措施来保护您的连接和数据。 功能较多，本文只举例常用的几个功能讲解\n添加ssh链接 首页进行语言的切换，将语言切换为中文\n点击首页的 『Setting』进入设置页面，在 『Application』中点击 『Language』将语言切换为中文，然后重启tabby工具\n除了打开本地终端，终端模拟器更多是用来连接远程服务器。以连接我本地虚拟机为例，先添加一个 SSH 连接。\n点击首页的 『设置』进入设置页面，在 『配置和连接』中点击 『+ 新配置』：\n在弹窗中选择ssh链接\n填写名称、主机地址、端口、用户名，登录验证支持密码和密钥，填写完毕后点击保存即可\n可以看到 SSH 连接已添加成功，点击按钮进行连接：\nSFTP 传输文件 对于经常使用终端的小伙伴而言，文件传输肯定是个刚需。Tabby 集成了 SFTP，所以传输大文件时，我们不用再安装其他软件了。\n点击终端上方的 SFTP 按钮，可以将文件直接拖曳到目录下，还是挺方便的\n修改配色方案 如果你不满意终端显示的配色，可以选择其它的配色方案。Tabby 内部集成了非常多的配色方案，总有一款适合你。\n配色方案可以到『配色方案』界面中挑选，这里我选择了『base2tone-lake-dark』：\n","permalink":"https://xyenvy.github.io/posts/tabby/","summary":"开源和跨平台性 Tabby 远程是一款开源的软件，这意味着它的源代码对公众开放，任何人都可以查看、使用和修改。开源性带来了以下优势： 透明性：开源使得软件的开发和运行过程更加透明。用户可以查看源代码，了解软件的实现方式，并确保其中没有隐藏的恶意代码或漏洞。 可靠性：由于开源软件的源代码可以被广泛","title":"Tabby 一款强大而美观的跨平台终端神器"},{"content":"Kubernetes详细教程 1. Kubernetes介绍 1.1 应用部署方式演变 在部署应用程序的方式上，主要经历了三个时代：\n传统部署：互联网早期，会直接将应用程序部署在物理机上\n优点：简单，不需要其它技术的参与\n缺点：不能为应用程序定义资源使用边界，很难合理地分配计算资源，而且程序之间容易产生影响\n虚拟化部署：可以在一台物理机上运行多个虚拟机，每个虚拟机都是独立的一个环境\n优点：程序环境不会相互产生影响，提供了一定程度的安全性\n缺点：增加了操作系统，浪费了部分资源\n容器化部署：与虚拟化类似，但是共享了操作系统\n优点：\n可以保证每个容器拥有自己的文件系统、CPU、内存、进程空间等\n运行应用程序所需要的资源都被容器包装，并和底层基础架构解耦\n容器化的应用程序可以跨云服务商、跨Linux操作系统发行版进行部署\n容器化部署方式给带来很多的便利，但是也会出现一些问题，比如说：\n一个容器故障停机了，怎么样让另外一个容器立刻启动去替补停机的容器 当并发访问量变大的时候，怎么样做到横向扩展容器数量 这些容器管理的问题统称为容器编排问题，为了解决这些容器编排问题，就产生了一些容器编排的软件：\nSwarm：Docker自己的容器编排工具 Mesos：Apache的一个资源统一管控的工具，需要和Marathon结合使用 Kubernetes：Google开源的的容器编排工具 1.2 kubernetes简介 kubernetes，是一个全新的基于容器技术的分布式架构领先方案，是谷歌严格保密十几年的秘密武器\u0026mdash;-Borg系统的一个开源版本，于2014年9月发布第一个版本，2015年7月发布第一个正式版本。\nkubernetes的本质是一组服务器集群，它可以在集群的每个节点上运行特定的程序，来对节点中的容器进行管理。目的是实现资源管理的自动化，主要提供了如下的主要功能：\n自我修复：一旦某一个容器崩溃，能够在1秒中左右迅速启动新的容器 弹性伸缩：可以根据需要，自动对集群中正在运行的容器数量进行调整 服务发现：服务可以通过自动发现的形式找到它所依赖的服务 负载均衡：如果一个服务起动了多个容器，能够自动实现请求的负载均衡 版本回退：如果发现新发布的程序版本有问题，可以立即回退到原来的版本 存储编排：可以根据容器自身的需求自动创建存储卷 1.3 kubernetes组件 一个kubernetes集群主要是由控制节点(master)、工作节点(node)构成，每个节点上都会安装不同的组件。\nmaster：集群的控制平面，负责集群的决策 ( 管理 )\nApiServer : 资源操作的唯一入口，接收用户输入的命令，提供认证、授权、API注册和发现等机制\nScheduler : 负责集群资源调度，按照预定的调度策略将Pod调度到相应的node节点上\nControllerManager : 负责维护集群的状态，比如程序部署安排、故障检测、自动扩展、滚动更新等\nEtcd ：负责存储集群中各种资源对象的信息\nnode：集群的数据平面，负责为容器提供运行环境 ( 干活 )\nKubelet : 负责维护容器的生命周期，即通过控制docker，来创建、更新、销毁容器\nKubeProxy : 负责提供集群内部的服务发现和负载均衡\nDocker : 负责节点上容器的各种操作\n下面，以部署一个nginx服务来说明kubernetes系统各个组件调用关系：\n首先要明确，一旦kubernetes环境启动之后，master和node都会将自身的信息存储到etcd数据库中\n一个nginx服务的安装请求会首先被发送到master节点的apiServer组件\napiServer组件会调用scheduler组件来决定到底应该把这个服务安装到哪个node节点上\n在此时，它会从etcd中读取各个node节点的信息，然后按照一定的算法进行选择，并将结果告知apiServer\napiServer调用controller-manager去调度Node节点安装nginx服务\nkubelet接收到指令后，会通知docker，然后由docker来启动一个nginx的pod\npod是kubernetes的最小操作单元，容器必须跑在pod中至此，\n一个nginx服务就运行了，如果需要访问nginx，就需要通过kube-proxy来对pod产生访问的代理\n这样，外界用户就可以访问集群中的nginx服务了\n1.4 kubernetes概念 Master：集群控制节点，每个集群需要至少一个master节点负责集群的管控\nNode：工作负载节点，由master分配容器到这些node工作节点上，然后node节点上的docker负责容器的运行\nPod：kubernetes的最小控制单元，容器都是运行在pod中的，一个pod中可以有1个或者多个容器\nController：控制器，通过它来实现对pod的管理，比如启动pod、停止pod、伸缩pod的数量等等\nService：pod对外服务的统一入口，下面可以维护者同一类的多个pod\nLabel：标签，用于对pod进行分类，同一类pod会拥有相同的标签\nNameSpace：命名空间，用来隔离pod的运行环境\n2. kubernetes集群环境搭建 2.1 前置知识点 目前生产部署Kubernetes 集群主要有两种方式：\nkubeadm\nKubeadm 是一个K8s 部署工具，提供kubeadm init 和kubeadm join，用于快速部署Kubernetes 集群。\n官方地址：https:/kubernetes.io/docs/reference/setup-tools/kubeadm/kubeadm/\n二进制包\n从github 下载发行版的二进制包，手动部署每个组件，组成Kubernetes 集群。\nKubeadm 降低部署门槛，但屏蔽了很多细节，遇到问题很难排查。如果想更容易可控，推荐使用二进制包部署Kubernetes 集群，虽然手动部署麻烦点，期间可以学习很多工作原理，也利于后期维护。\n2.2 kubeadm 部署方式介绍 kubeadm 是官方社区推出的一个用于快速部署kubernetes 集群的工具，这个工具能通过两条指令完成一个kubernetes 集群的部署：\n创建一个Master 节点kubeadm init 将Node 节点加入到当前集群中$ kubeadm join \u0026lt;Master 节点的IP 和端口\u0026gt; 2.3 安装要求 在开始之前，部署Kubernetes 集群机器需要满足以下几个条件：\n一台或多台机器，操作系统CentOS7.x-86_x64 硬件配置：2GB 或更多RAM，2 个CPU 或更多CPU，硬盘30GB 或更多 集群中所有机器之间网络互通 可以访问外网，需要拉取镜像 禁止swap 分区 2.4 最终目标 在所有节点上安装Docker 和kubeadm 部署Kubernetes Master 部署容器网络插件 部署Kubernetes Node，将节点加入Kubernetes 集群中 部署Dashboard Web 页面，可视化查看Kubernetes 资源 2.5 准备环境 角色 IP地址 组件 master01 192.168.90.100 docker，kubectl，kubeadm，kubelet node01 192.168.90.106 docker，kubectl，kubeadm，kubelet node02 192.168.90.107 docker，kubectl，kubeadm，kubelet 2.6 环境初始化 2.6.1 检查操作系统的版本 # 此方式下安装kubernetes集群要求Centos版本要在7.5或之上 [root@master ~]# cat /etc/redhat-release Centos Linux 7.5.1804 (Core) 2.6.2 主机名解析 为了方便集群节点间的直接调用，在这个配置一下主机名解析，企业中推荐使用内部DNS服务器\n# 主机名成解析 编辑三台服务器的/etc/hosts文件，添加下面内容 192.168.90.100 master 192.168.90.106 node1 192.168.90.107 node2 2.6.3 时间同步 kubernetes要求集群中的节点时间必须精确一直，这里使用chronyd服务从网络同步时间\n企业中建议配置内部的会见同步服务器\n# 启动chronyd服务 [root@master ~]# systemctl start chronyd [root@master ~]# systemctl enable chronyd [root@master ~]# date 2.6.4 禁用iptable和firewalld服务 kubernetes和docker 在运行的中会产生大量的iptables规则，为了不让系统规则跟它们混淆，直接关闭系统的规则\n# 1 关闭firewalld服务 [root@master ~]# systemctl stop firewalld [root@master ~]# systemctl disable firewalld # 2 关闭iptables服务 [root@master ~]# systemctl stop iptables [root@master ~]# systemctl disable iptables 2.6.5 禁用selinux selinux是linux系统下的一个安全服务，如果不关闭它，在安装集群中会产生各种各样的奇葩问题\n# 编辑 /etc/selinux/config 文件，修改SELINUX的值为disable # 注意修改完毕之后需要重启linux服务 SELINUX=disabled 2.6.6 禁用swap分区 swap分区指的是虚拟内存分区，它的作用是物理内存使用完，之后将磁盘空间虚拟成内存来使用，启用swap设备会对系统的性能产生非常负面的影响，因此kubernetes要求每个节点都要禁用swap设备，但是如果因为某些原因确实不能关闭swap分区，就需要在集群安装过程中通过明确的参数进行配置说明\n# 编辑分区配置文件/etc/fstab，注释掉swap分区一行 # 注意修改完毕之后需要重启linux服务 vim /etc/fstab 注释掉 /dev/mapper/centos-swap swap # /dev/mapper/centos-swap swap 2.6.7 修改linux的内核参数 # 修改linux的内核采纳数，添加网桥过滤和地址转发功能 # 编辑/etc/sysctl.d/kubernetes.conf文件，添加如下配置： net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 net.ipv4.ip_forward = 1 # 重新加载配置 [root@master ~]# sysctl -p # 加载网桥过滤模块 [root@master ~]# modprobe br_netfilter # 查看网桥过滤模块是否加载成功 [root@master ~]# lsmod | grep br_netfilter 2.6.8 配置ipvs功能 在Kubernetes中Service有两种带来模型，一种是基于iptables的，一种是基于ipvs的两者比较的话，ipvs的性能明显要高一些，但是如果要使用它，需要手动载入ipvs模块\n# 1.安装ipset和ipvsadm [root@master ~]# yum install ipset ipvsadm -y # 2.添加需要加载的模块写入脚本文件 [root@master ~]# cat \u0026lt;\u0026lt;EOF\u0026gt; /etc/sysconfig/modules/ipvs.modules #!/bin/bash modprobe -- ip_vs modprobe -- ip_vs_rr modprobe -- ip_vs_wrr modprobe -- ip_vs_sh modprobe -- nf_conntrack_ipv4 EOF # 3.为脚本添加执行权限 [root@master ~]# chmod +x /etc/sysconfig/modules/ipvs.modules # 4.执行脚本文件 [root@master ~]# /bin/bash /etc/sysconfig/modules/ipvs.modules # 5.查看对应的模块是否加载成功 [root@master ~]# lsmod | grep -e ip_vs -e nf_conntrack_ipv4 2.6.9 安装docker # 1、切换镜像源 [root@master ~]# wget https:/mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo -O /etc/yum.repos.d/docker-ce.repo # 2、查看当前镜像源中支持的docker版本 [root@master ~]# yum list docker-ce --showduplicates # 3、安装特定版本的docker-ce # 必须制定--setopt=obsoletes=0，否则yum会自动安装更高版本 [root@master ~]# yum install --setopt=obsoletes=0 docker-ce-18.06.3.ce-3.el7 -y # 4、添加一个配置文件 #Docker 在默认情况下使用Vgroup Driver为cgroupfs，而Kubernetes推荐使用systemd来替代cgroupfs [root@master ~]# mkdir /etc/docker [root@master ~]# cat \u0026lt;\u0026lt;EOF\u0026gt; /etc/docker/daemon.json { \u0026#34;exec-opts\u0026#34;: [\u0026#34;native.cgroupdriver=systemd\u0026#34;], \u0026#34;registry-mirrors\u0026#34;: [\u0026#34;https:/kn0t2bca.mirror.aliyuncs.com\u0026#34;] } EOF # 5、启动dokcer [root@master ~]# systemctl restart docker [root@master ~]# systemctl enable docker 2.6.10 安装Kubernetes组件 # 1、由于kubernetes的镜像在国外，速度比较慢，这里切换成国内的镜像源 # 2、编辑/etc/yum.repos.d/kubernetes.repo,添加下面的配置 [kubernetes] name=Kubernetes baseurl=http:/mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64 enabled=1 gpgchech=0 repo_gpgcheck=0 gpgkey=http:/mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg http:/mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg # 3、安装kubeadm、kubelet和kubectl [root@master ~]# yum install --setopt=obsoletes=0 kubeadm-1.17.4-0 kubelet-1.17.4-0 kubectl-1.17.4-0 -y # 4、配置kubelet的cgroup #编辑/etc/sysconfig/kubelet, 添加下面的配置 KUBELET_CGROUP_ARGS=\u0026#34;--cgroup-driver=systemd\u0026#34; KUBE_PROXY_MODE=\u0026#34;ipvs\u0026#34; # 5、设置kubelet开机自启 [root@master ~]# systemctl enable kubelet 2.6.11 准备集群镜像 # 在安装kubernetes集群之前，必须要提前准备好集群需要的镜像，所需镜像可以通过下面命令查看 [root@master ~]# kubeadm config /kubernetes.images list # 下载镜像 # 此镜像kubernetes的仓库中，由于网络原因，无法连接，下面提供了一种替换方案 /kubernetes.images=( kube-apiserver:v1.17.4 kube-controller-manager:v1.17.4 kube-scheduler:v1.17.4 kube-proxy:v1.17.4 pause:3.1 etcd:3.4.3-0 coredns:1.6.5 ) for imageName in ${/kubernetes.images[@]};do docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/$imageName docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/$imageName k8s.gcr.io/$imageName docker rmi registry.cn-hangzhou.aliyuncs.com/google_containers/$imageName done 2.6.11 集群初始化 下面的操作只需要在master节点上执行即可\n# 创建集群 [root@master ~]# kubeadm init \\ --apiserver-advertise-address=192.168.90.100 \\ --image-repository registry.aliyuncs.com/google_containers \\ --kubernetes-version=v1.17.4 \\ --service-cidr=10.96.0.0/12 \\ --pod-network-cidr=10.244.0.0/16 # 创建必要文件 [root@master ~]# mkdir -p $HOME/.kube [root@master ~]# sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config [root@master ~]# sudo chown $(id -u):$(id -g) $HOME/.kube/config 下面的操作只需要在node节点上执行即可\nkubeadm join 192.168.0.100:6443 --token awk15p.t6bamck54w69u4s8 \\ --discovery-token-ca-cert-hash sha256:a94fa09562466d32d29523ab6cff122186f1127599fa4dcd5fa0152694f17117 在master上查看节点信息\n[root@master ~]# kubectl get nodes NAME STATUS ROLES AGE VERSION master NotReady master 6m v1.17.4 node1 NotReady \u0026lt;none\u0026gt; 22s v1.17.4 node2 NotReady \u0026lt;none\u0026gt; 19s v1.17.4 2.6.13 安装网络插件，只在master节点操作即可 wget https:/raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml 由于外网不好访问，如果出现无法访问的情况，可以直接用下面的 记得文件名是kube-flannel.yml，位置：/root/kube-flannel.yml内容：\nhttps:/github.com/flannel-io/flannel/tree/master/Documentation/kube-flannel.yml 也可手动拉取指定版本 docker pull quay.io/coreos/flannel:v0.14.0 #拉取flannel网络，三台主机 docker /kubernetes.images #查看仓库是否拉去下来\n个人笔记 若是集群状态一直是 notready,用下面语句查看原因， journalctl -f -u kubelet.service 若原因是： cni.go:237] Unable to update cni config: no networks found in /etc/cni/net.d mkdir -p /etc/cni/net.d #创建目录给flannel做配置文件 vim /etc/cni/net.d/10-flannel.conf #编写配置文件\n{ \u0026#34;name\u0026#34;:\u0026#34;cbr0\u0026#34;, \u0026#34;cniVersion\u0026#34;:\u0026#34;0.3.1\u0026#34;, \u0026#34;type\u0026#34;:\u0026#34;flannel\u0026#34;, \u0026#34;deledate\u0026#34;:{ \u0026#34;hairpinMode\u0026#34;:true, \u0026#34;isDefaultGateway\u0026#34;:true } } 2.6.14 使用kubeadm reset重置集群 #在master节点之外的节点进行操作 kubeadm reset systemctl stop kubelet systemctl stop docker rm -rf /var/lib/cni/ rm -rf /var/lib/kubelet/* rm -rf /etc/cni/ ifconfig cni0 down ifconfig flannel.1 down ifconfig docker0 down ip link delete cni0 ip link delete flannel.1 ##重启kubelet systemctl restart kubelet ##重启docker systemctl restart docker 2.6.15 重启kubelet和docker # 重启kubelet systemctl restart kubelet # 重启docker systemctl restart docker 使用配置文件启动fannel\nkubectl apply -f kube-flannel.yml 等待它安装完毕 发现已经是 集群的状态已经是Ready\n2.6.16 kubeadm中的命令 # 生成 新的token [root@master ~]# kubeadm token create --print-join-command 2.7 集群测试 2.7.1 创建一个nginx服务 kubectl create deployment nginx --image=nginx:1.14-alpine 2.7.2 暴露端口 kubectl expose deploy nginx --port=80 --target-port=80 --type=NodePort 2.7.3 查看服务 kubectl get pod,svc 2.7.4 查看pod 浏览器测试结果：\n3. 资源管理 3.1 资源管理介绍 在kubernetes中，所有的内容都抽象为资源，用户需要通过操作资源来管理kubernetes。\nkubernetes的本质上就是一个集群系统，用户可以在集群中部署各种服务，所谓的部署服务，其实就是在kubernetes集群中运行一个个的容器，并将指定的程序跑在容器中。\nkubernetes的最小管理单元是pod而不是容器，所以只能将容器放在Pod中，而kubernetes一般也不会直接管理Pod，而是通过Pod控制器来管理Pod的。\nPod可以提供服务之后，就要考虑如何访问Pod中服务，kubernetes提供了Service资源实现这个功能。\n当然，如果Pod中程序的数据需要持久化，kubernetes还提供了各种存储系统。\n学习kubernetes的核心，就是学习如何对集群上的Pod、Pod控制器、Service、存储等各种资源进行操作\n3.2 YAML语言介绍 YAML是一个类似 XML、JSON 的标记性语言。它强调以数据为中心，并不是以标识语言为重点。因而YAML本身的定义比较简单，号称\u0026quot;一种人性化的数据格式语言\u0026quot;。\n\u0026lt;heima\u0026gt; \u0026lt;age\u0026gt;15\u0026lt;/age\u0026gt; \u0026lt;address\u0026gt;Beijing\u0026lt;/address\u0026gt; \u0026lt;/heima\u0026gt; heima: age: 15 address: Beijing YAML的语法比较简单，主要有下面几个：\n大小写敏感 使用缩进表示层级关系 缩进不允许使用tab，只允许空格( 低版本限制 ) 缩进的空格数不重要，只要相同层级的元素左对齐即可 \u0026lsquo;#\u0026lsquo;表示注释 YAML支持以下几种数据类型：\n纯量：单个的、不可再分的值 对象：键值对的集合，又称为映射（mapping）/ 哈希（hash） / 字典（dictionary） 数组：一组按次序排列的值，又称为序列（sequence） / 列表（list） # 纯量, 就是指的一个简单的值，字符串、布尔值、整数、浮点数、Null、时间、日期 # 1 布尔类型 c1: true (或者True) # 2 整型 c2: 234 # 3 浮点型 c3: 3.14 # 4 null类型 c4: ~ # 使用~表示null # 5 日期类型 c5: 2018-02-17 # 日期必须使用ISO 8601格式，即yyyy-MM-dd # 6 时间类型 c6: 2018-02-17T15:02:31+08:00 # 时间使用ISO 8601格式，时间和日期之间使用T连接，最后使用+代表时区 # 7 字符串类型 c7: heima # 简单写法，直接写值 , 如果字符串中间有特殊字符，必须使用双引号或者单引号包裹 c8: line1 line2 # 字符串过多的情况可以拆成多行，每一行会被转化成一个空格 # 对象 # 形式一(推荐): heima: age: 15 address: Beijing # 形式二(了解): heima: {age: 15,address: Beijing} # 数组 # 形式一(推荐): address: - 顺义 - 昌平 # 形式二(了解): address: [顺义,昌平] 小提示：\n1 书写yaml切记: 后面要加一个空格\n2 如果需要将多段yaml配置放在一个文件中，中间要使用---分隔\n3 下面是一个yaml转json的网站，可以通过它验证yaml是否书写正确 https:/www.json2yaml.com/convert-yaml-to-json\n3.3 资源管理方式 命令式对象管理：直接使用命令去操作kubernetes资源\nkubectl run nginx-pod --image=nginx:1.17.1 --port=80 命令式对象配置：通过命令配置和配置文件去操作kubernetes资源\nkubectl create/patch -f nginx-pod.yaml 声明式对象配置：通过apply命令和配置文件去操作kubernetes资源\nkubectl apply -f nginx-pod.yaml 类型 操作对象 适用环境 优点 缺点 命令式对象管理 对象 测试 简单 只能操作活动对象，无法审计、跟踪 命令式对象配置 文件 开发 可以审计、跟踪 项目大时，配置文件多，操作麻烦 声明式对象配置 目录 开发 支持目录操作 意外情况下难以调试 3.3.1 命令式对象管理 kubectl命令\nkubectl是kubernetes集群的命令行工具，通过它能够对集群本身进行管理，并能够在集群上进行容器化应用的安装部署。kubectl命令的语法如下：\nkubectl [command] [type] [name] [flags] comand：指定要对资源执行的操作，例如create、get、delete\ntype：指定资源类型，比如deployment、pod、service\nname：指定资源的名称，名称大小写敏感\nflags：指定额外的可选参数\n# 查看所有pod kubectl get pod # 查看某个pod kubectl get pod pod_name # 查看某个pod,以yaml格式展示结果 kubectl get pod pod_name -o yaml 资源类型\nkubernetes中所有的内容都抽象为资源，可以通过下面的命令进行查看:\nkubectl api-resources 经常使用的资源有下面这些：\n资源分类 资源名称 缩写 资源作用 集群级别资源 nodes no 集群组成部分 namespaces ns 隔离Pod pod资源 pods po 装载容器 pod资源控制器 replicationcontrollers rc 控制pod资源 replicasets rs 控制pod资源 deployments deploy 控制pod资源 daemonsets ds 控制pod资源 jobs 控制pod资源 cronjobs cj 控制pod资源 horizontalpodautoscalers hpa 控制pod资源 statefulsets sts 控制pod资源 服务发现资源 services svc 统一pod对外接口 ingress ing 统一pod对外接口 存储资源 volumeattachments 存储 persistentvolumes pv 存储 persistentvolumeclaims pvc 存储 配置资源 configmaps cm 配置 secrets 配置 操作\nkubernetes允许对资源进行多种操作，可以通过\u0026ndash;help查看详细的操作命令\nkubectl --help 经常使用的操作有下面这些：\n命令分类 命令 翻译 命令作用 基本命令 create 创建 创建一个资源 edit 编辑 编辑一个资源 get 获取 获取一个资源 patch 更新 更新一个资源 delete 删除 删除一个资源 explain 解释 展示资源文档 运行和调试 run 运行 在集群中运行一个指定的镜像 expose 暴露 暴露资源为Service describe 描述 显示资源内部信息 logs 日志输出容器在 pod 中的日志 输出容器在 pod 中的日志 attach 缠绕进入运行中的容器 进入运行中的容器 exec 执行容器中的一个命令 执行容器中的一个命令 cp 复制 在Pod内外复制文件 rollout 首次展示 管理资源的发布 scale 规模 扩(缩)容Pod的数量 autoscale 自动调整 自动调整Pod的数量 高级命令 apply rc 通过文件对资源进行配置 label 标签 更新资源上的标签 其他命令 cluster-info 集群信息 显示集群信息 version 版本 显示当前Server和Client的版本 下面以一个namespace / pod的创建和删除简单演示下命令的使用：\n# 创建一个namespace [root@master ~]# kubectl create namespace dev namespace/dev created # 获取namespace [root@master ~]# kubectl get ns NAME STATUS AGE default Active 21h dev Active 21s kube-node-lease Active 21h kube-public Active 21h kube-system Active 21h # 在此namespace下创建并运行一个nginx的Pod [root@master ~]# kubectl run pod --image=nginx:latest -n dev kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead. deployment.apps/pod created # 查看新创建的pod [root@master ~]# kubectl get pod -n dev NAME READY STATUS RESTARTS AGE pod 1/1 Running 0 21s # 删除指定的pod [root@master ~]# kubectl delete pod pod-864f9875b9-pcw7x pod \u0026#34;pod\u0026#34; deleted # 删除指定的namespace [root@master ~]# kubectl delete ns dev namespace \u0026#34;dev\u0026#34; deleted 3.3.2 命令式对象配置 命令式对象配置就是使用命令配合配置文件一起来操作kubernetes资源。\n1） 创建一个nginxpod.yaml，内容如下：\napiVersion: v1 kind: Namespace metadata: name: dev --- apiVersion: v1 kind: Pod metadata: name: nginxpod namespace: dev spec: containers: - name: nginx-containers image: nginx:latest 2）执行create命令，创建资源：\n[root@master ~]# kubectl create -f nginxpod.yaml namespace/dev created pod/nginxpod created 此时发现创建了两个资源对象，分别是namespace和pod\n3）执行get命令，查看资源：\n[root@master ~]# kubectl get -f nginxpod.yaml NAME STATUS AGE namespace/dev Active 18s NAME READY STATUS RESTARTS AGE pod/nginxpod 1/1 Running 0 17s 这样就显示了两个资源对象的信息\n4）执行delete命令，删除资源：\n[root@master ~]# kubectl delete -f nginxpod.yaml namespace \u0026#34;dev\u0026#34; deleted pod \u0026#34;nginxpod\u0026#34; deleted 此时发现两个资源对象被删除了\n总结: 命令式对象配置的方式操作资源，可以简单的认为：命令 + yaml配置文件（里面是命令需要的各种参数） 3.3.3 声明式对象配置 声明式对象配置跟命令式对象配置很相似，但是它只有一个命令apply。\n# 首先执行一次kubectl apply -f yaml文件，发现创建了资源 [root@master ~]# kubectl apply -f nginxpod.yaml namespace/dev created pod/nginxpod created # 再次执行一次kubectl apply -f yaml文件，发现说资源没有变动 [root@master ~]# kubectl apply -f nginxpod.yaml namespace/dev unchanged pod/nginxpod unchanged 总结: 其实声明式对象配置就是使用apply描述一个资源最终的状态（在yaml中定义状态） 使用apply操作资源： 如果资源不存在，就创建，相当于 kubectl create 如果资源已存在，就更新，相当于 kubectl patch 扩展：kubectl可以在node节点上运行吗 ?\nkubectl的运行是需要进行配置的，它的配置文件是$HOME/.kube，如果想要在node节点运行此命令，需要将master上的.kube文件复制到node节点上，即在master节点上执行下面操作：\nscp -r HOME/.kube node1: HOME/ 使用推荐: 三种方式应该怎么用 ?\n创建/更新资源 使用声明式对象配置 kubectl apply -f XXX.yaml\n删除资源 使用命令式对象配置 kubectl delete -f XXX.yaml\n查询资源 使用命令式对象管理 kubectl get(describe) 资源名称\n4. 实战入门 本章节将介绍如何在kubernetes集群中部署一个nginx服务，并且能够对其进行访问。\n4.1 Namespace Namespace是kubernetes系统中的一种非常重要资源，它的主要作用是用来实现多套环境的资源隔离或者多租户的资源隔离。\n默认情况下，kubernetes集群中的所有的Pod都是可以相互访问的。但是在实际中，可能不想让两个Pod之间进行互相的访问，那此时就可以将两个Pod划分到不同的namespace下。kubernetes通过将集群内部的资源分配到不同的Namespace中，可以形成逻辑上的\u0026quot;组\u0026quot;，以方便不同的组的资源进行隔离使用和管理。\n可以通过kubernetes的授权机制，将不同的namespace交给不同租户进行管理，这样就实现了多租户的资源隔离。此时还能结合kubernetes的资源配额机制，限定不同租户能占用的资源，例如CPU使用量、内存使用量等等，来实现租户可用资源的管理。\nkubernetes在集群启动之后，会默认创建几个namespace\n[root@master ~]# kubectl get namespace NAME STATUS AGE default Active 45h # 所有未指定Namespace的对象都会被分配在default命名空间 kube-node-lease Active 45h # 集群节点之间的心跳维护，v1.13开始引入 kube-public Active 45h # 此命名空间下的资源可以被所有人访问（包括未认证用户） kube-system Active 45h # 所有由Kubernetes系统创建的资源都处于这个命名空间 下面来看namespace资源的具体操作：\n4.1.1 查看 # 1 查看所有的ns 命令：kubectl get ns [root@master ~]# kubectl get ns NAME STATUS AGE default Active 45h kube-node-lease Active 45h kube-public Active 45h kube-system Active 45h # 2 查看指定的ns 命令：kubectl get ns ns名称 [root@master ~]# kubectl get ns default NAME STATUS AGE default Active 45h # 3 指定输出格式 命令：kubectl get ns ns名称 -o 格式参数 # kubernetes支持的格式有很多，比较常见的是wide、json、yaml [root@master ~]# kubectl get ns default -o yaml apiVersion: v1 kind: Namespace metadata: creationTimestamp: \u0026#34;2021-05-08T04:44:16Z\u0026#34; name: default resourceVersion: \u0026#34;151\u0026#34; selfLink: /api/v1/namespaces/default uid: 7405f73a-e486-43d4-9db6-145f1409f090 spec: finalizers: - kubernetes status: phase: Active # 4 查看ns详情 命令：kubectl describe ns ns名称 [root@master ~]# kubectl describe ns default Name: default Labels: \u0026lt;none\u0026gt; Annotations: \u0026lt;none\u0026gt; Status: Active # Active 命名空间正在使用中 Terminating 正在删除命名空间 # ResourceQuota 针对namespace做的资源限制 # LimitRange针对namespace中的每个组件做的资源限制 No resource quota. No LimitRange resource. 4.1.2 创建 # 创建namespace [root@master ~]# kubectl create ns dev namespace/dev created 4.1.3 删除 # 删除namespace [root@master ~]# kubectl delete ns dev namespace \u0026#34;dev\u0026#34; deleted 4.1.4 配置方式 首先准备一个yaml文件：ns-dev.yaml\napiVersion: v1 kind: Namespace metadata: name: dev 然后就可以执行对应的创建和删除命令了：\n创建：kubectl create -f ns-dev.yaml\n删除：kubectl delete -f ns-dev.yaml\n4.2 Pod Pod是kubernetes集群进行管理的最小单元，程序要运行必须部署在容器中，而容器必须存在于Pod中。\nPod可以认为是容器的封装，一个Pod中可以存在一个或者多个容器。\nkubernetes在集群启动之后，集群中的各个组件也都是以Pod方式运行的。可以通过下面命令查看：\n[root@master ~]# kubectl get pod -n kube-system NAMESPACE NAME READY STATUS RESTARTS AGE kube-system coredns-6955765f44-68g6v 1/1 Running 0 2d1h kube-system coredns-6955765f44-cs5r8 1/1 Running 0 2d1h kube-system etcd-master 1/1 Running 0 2d1h kube-system kube-apiserver-master 1/1 Running 0 2d1h kube-system kube-controller-manager-master 1/1 Running 0 2d1h kube-system kube-flannel-ds-amd64-47r25 1/1 Running 0 2d1h kube-system kube-flannel-ds-amd64-ls5lh 1/1 Running 0 2d1h kube-system kube-proxy-685tk 1/1 Running 0 2d1h kube-system kube-proxy-87spt 1/1 Running 0 2d1h kube-system kube-scheduler-master 1/1 Running 0 2d1h 4.2.1 创建并运行 kubernetes没有提供单独运行Pod的命令，都是通过Pod控制器来实现的\n# 命令格式： kubectl run (pod控制器名称) [参数] # --image 指定Pod的镜像 # --port 指定端口 # --namespace 指定namespace [root@master ~]# kubectl run nginx --image=nginx:latest --port=80 --namespace dev deployment.apps/nginx created 4.2.2 查看pod信息 # 查看Pod基本信息 [root@master ~]# kubectl get pods -n dev NAME READY STATUS RESTARTS AGE nginx 1/1 Running 0 43s # 查看Pod的详细信息 [root@master ~]# kubectl describe pod nginx -n dev Name: nginx Namespace: dev Priority: 0 Node: node1/192.168.5.4 Start Time: Wed, 08 May 2021 09:29:24 +0800 Labels: pod-template-hash=5ff7956ff6 run=nginx Annotations: \u0026lt;none\u0026gt; Status: Running IP: 10.244.1.23 IPs: IP: 10.244.1.23 Controlled By: ReplicaSet/nginx Containers: nginx: Container ID: docker:/4c62b8c0648d2512380f4ffa5da2c99d16e05634979973449c98e9b829f6253c Image: nginx:latest Image ID: docker-pullable:/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 Port: 80/TCP Host Port: 0/TCP State: Running Started: Wed, 08 May 2021 09:30:01 +0800 Ready: True Restart Count: 0 Environment: \u0026lt;none\u0026gt; Mounts: /var/run/secrets/kubernetes.io/serviceaccount from default-token-hwvvw (ro) Conditions: Type Status Initialized True Ready True ContainersReady True PodScheduled True Volumes: default-token-hwvvw: Type: Secret (a volume populated by a Secret) SecretName: default-token-hwvvw Optional: false QoS Class: BestEffort Node-Selectors: \u0026lt;none\u0026gt; Tolerations: node.kubernetes.io/not-ready:NoExecute for 300s node.kubernetes.io/unreachable:NoExecute for 300s Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled \u0026lt;unknown\u0026gt; default-scheduler Successfully assigned dev/nginx-5ff7956ff6-fg2db to node1 Normal Pulling 4m11s kubelet, node1 Pulling image \u0026#34;nginx:latest\u0026#34; Normal Pulled 3m36s kubelet, node1 Successfully pulled image \u0026#34;nginx:latest\u0026#34; Normal Created 3m36s kubelet, node1 Created container nginx Normal Started 3m36s kubelet, node1 Started container nginx 4.2.3 访问Pod # 获取podIP [root@master ~]# kubectl get pods -n dev -o wide NAME READY STATUS RESTARTS AGE IP NODE ... nginx 1/1 Running 0 190s 10.244.1.23 node1 ... #访问POD [root@master ~]# curl http:/10.244.1.23:80 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;Welcome to nginx!\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;\u0026lt;em\u0026gt;Thank you for using nginx.\u0026lt;/em\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 4.2.4 删除指定Pod # 删除指定Pod [root@master ~]# kubectl delete pod nginx -n dev pod \u0026#34;nginx\u0026#34; deleted # 此时，显示删除Pod成功，但是再查询，发现又新产生了一个 [root@master ~]# kubectl get pods -n dev NAME READY STATUS RESTARTS AGE nginx 1/1 Running 0 21s # 这是因为当前Pod是由Pod控制器创建的，控制器会监控Pod状况，一旦发现Pod死亡，会立即重建 # 此时要想删除Pod，必须删除Pod控制器 # 先来查询一下当前namespace下的Pod控制器 [root@master ~]# kubectl get deploy -n dev NAME READY UP-TO-DATE AVAILABLE AGE nginx 1/1 1 1 9m7s # 接下来，删除此PodPod控制器 [root@master ~]# kubectl delete deploy nginx -n dev deployment.apps \u0026#34;nginx\u0026#34; deleted # 稍等片刻，再查询Pod，发现Pod被删除了 [root@master ~]# kubectl get pods -n dev No resources found in dev namespace. 4.2.5 配置操作 创建一个pod-nginx.yaml，内容如下：\napiVersion: v1 kind: Pod metadata: name: nginx namespace: dev spec: containers: - image: nginx:latest name: pod ports: - name: nginx-port containerPort: 80 protocol: TCP 然后就可以执行对应的创建和删除命令了：\n创建：kubectl create -f pod-nginx.yaml\n删除：kubectl delete -f pod-nginx.yaml\n4.3 Label Label是kubernetes系统中的一个重要概念。它的作用就是在资源上添加标识，用来对它们进行区分和选择。\nLabel的特点：\n一个Label会以key/value键值对的形式附加到各种对象上，如Node、Pod、Service等等 一个资源对象可以定义任意数量的Label ，同一个Label也可以被添加到任意数量的资源对象上去 Label通常在资源对象定义时确定，当然也可以在对象创建后动态添加或者删除 可以通过Label实现资源的多维度分组，以便灵活、方便地进行资源分配、调度、配置、部署等管理工作。\n一些常用的Label 示例如下：\n版本标签：\u0026ldquo;version\u0026rdquo;:\u0026ldquo;release\u0026rdquo;, \u0026ldquo;version\u0026rdquo;:\u0026ldquo;stable\u0026rdquo;\u0026hellip;\u0026hellip; 环境标签：\u0026ldquo;environment\u0026rdquo;:\u0026ldquo;dev\u0026rdquo;，\u0026ldquo;environment\u0026rdquo;:\u0026ldquo;test\u0026rdquo;，\u0026ldquo;environment\u0026rdquo;:\u0026ldquo;pro\u0026rdquo; 架构标签：\u0026ldquo;tier\u0026rdquo;:\u0026ldquo;frontend\u0026rdquo;，\u0026ldquo;tier\u0026rdquo;:\u0026ldquo;backend\u0026rdquo; 标签定义完毕之后，还要考虑到标签的选择，这就要使用到Label Selector，即：\nLabel用于给某个资源对象定义标识\nLabel Selector用于查询和筛选拥有某些标签的资源对象\n当前有两种Label Selector：\n基于等式的Label Selector\nname = slave: 选择所有包含Label中key=\u0026ldquo;name\u0026quot;且value=\u0026ldquo;slave\u0026quot;的对象\nenv != production: 选择所有包括Label中的key=\u0026ldquo;env\u0026quot;且value不等于\u0026quot;production\u0026quot;的对象\n基于集合的Label Selector\nname in (master, slave): 选择所有包含Label中的key=\u0026ldquo;name\u0026quot;且value=\u0026ldquo;master\u0026quot;或\u0026quot;slave\u0026quot;的对象\nname not in (frontend): 选择所有包含Label中的key=\u0026ldquo;name\u0026quot;且value不等于\u0026quot;frontend\u0026quot;的对象\n标签的选择条件可以使用多个，此时将多个Label Selector进行组合，使用逗号\u0026rdquo;,\u0026ldquo;进行分隔即可。例如：\nname=slave，env!=production\nname not in (frontend)，env!=production\n4.3.1 命令方式 # 为pod资源打标签 [root@master ~]# kubectl label pod nginx-pod version=1.0 -n dev pod/nginx-pod labeled # 为pod资源更新标签 [root@master ~]# kubectl label pod nginx-pod version=2.0 -n dev --overwrite pod/nginx-pod labeled # 查看标签 [root@master ~]# kubectl get pod nginx-pod -n dev --show-labels NAME READY STATUS RESTARTS AGE LABELS nginx-pod 1/1 Running 0 10m version=2.0 # 筛选标签 [root@master ~]# kubectl get pod -n dev -l version=2.0 --show-labels NAME READY STATUS RESTARTS AGE LABELS nginx-pod 1/1 Running 0 17m version=2.0 [root@master ~]# kubectl get pod -n dev -l version!=2.0 --show-labels No resources found in dev namespace. #删除标签 [root@master ~]# kubectl label pod nginx-pod -n dev tier- pod/nginx unlabeled 4.3.2 配置方式 apiVersion: v1 kind: Pod metadata: name: nginx namespace: dev labels: version: \u0026#34;3.0\u0026#34; env: \u0026#34;test\u0026#34; spec: containers: - image: nginx:latest name: pod ports: - name: nginx-port containerPort: 80 protocol: TCP 然后就可以执行对应的更新命令了：kubectl apply -f pod-nginx.yaml\n4.4 Deployment 在kubernetes中，Pod是最小的控制单元，但是kubernetes很少直接控制Pod，一般都是通过Pod控制器来完成的。Pod控制器用于pod的管理，确保pod资源符合预期的状态，当pod的资源出现故障时，会尝试进行重启或重建pod。\n在kubernetes中Pod控制器的种类有很多，本章节只介绍一种：Deployment。\n4.4.1 命令操作 # 命令格式: kubectl create deployment 名称 [参数] # --image 指定pod的镜像 # --port 指定端口 # --replicas 指定创建pod数量 # --namespace 指定namespace [root@master ~]# kubectl run nginx --image=nginx:latest --port=80 --replicas=3 -n dev deployment.apps/nginx created # 查看创建的Pod [root@master ~]# kubectl get pods -n dev NAME READY STATUS RESTARTS AGE nginx-5ff7956ff6-6k8cb 1/1 Running 0 19s nginx-5ff7956ff6-jxfjt 1/1 Running 0 19s nginx-5ff7956ff6-v6jqw 1/1 Running 0 19s # 查看deployment的信息 [root@master ~]# kubectl get deploy -n dev NAME READY UP-TO-DATE AVAILABLE AGE nginx 3/3 3 3 2m42s # UP-TO-DATE：成功升级的副本数量 # AVAILABLE：可用副本的数量 [root@master ~]# kubectl get deploy -n dev -o wide NAME READY UP-TO-DATE AVAILABLE AGE CONTAINERS IMAGES SELECTOR nginx 3/3 3 3 2m51s nginx nginx:latest run=nginx # 查看deployment的详细信息 [root@master ~]# kubectl describe deploy nginx -n dev Name: nginx Namespace: dev CreationTimestamp: Wed, 08 May 2021 11:14:14 +0800 Labels: run=nginx Annotations: deployment.kubernetes.io/revision: 1 Selector: run=nginx Replicas: 3 desired | 3 updated | 3 total | 3 available | 0 unavailable StrategyType: RollingUpdate MinReadySeconds: 0 RollingUpdateStrategy: 25% max unavailable, 25% max 违规词汇 Pod Template: Labels: run=nginx Containers: nginx: Image: nginx:latest Port: 80/TCP Host Port: 0/TCP Environment: \u0026lt;none\u0026gt; Mounts: \u0026lt;none\u0026gt; Volumes: \u0026lt;none\u0026gt; Conditions: Type Status Reason ---- ------ ------ Available True MinimumReplicasAvailable Progressing True NewReplicaSetAvailable OldReplicaSets: \u0026lt;none\u0026gt; NewReplicaSet: nginx-5ff7956ff6 (3/3 replicas created) Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal ScalingReplicaSet 5m43s deployment-controller Scaled up replicaset nginx-5ff7956ff6 to 3 # 删除 [root@master ~]# kubectl delete deploy nginx -n dev deployment.apps \u0026#34;nginx\u0026#34; deleted 4.4.2 配置操作 创建一个deploy-nginx.yaml，内容如下：\napiVersion: apps/v1 kind: Deployment metadata: name: nginx namespace: dev spec: replicas: 3 selector: matchLabels: run: nginx template: metadata: labels: run: nginx spec: containers: - image: nginx:latest name: nginx ports: - containerPort: 80 protocol: TCP 然后就可以执行对应的创建和删除命令了：\n创建：kubectl create -f deploy-nginx.yaml\n删除：kubectl delete -f deploy-nginx.yaml\n4.5 Service 通过上节课的学习，已经能够利用Deployment来创建一组Pod来提供具有高可用性的服务。\n虽然每个Pod都会分配一个单独的Pod IP，然而却存在如下两问题：\nPod IP 会随着Pod的重建产生变化 Pod IP 仅仅是集群内可见的虚拟IP，外部无法访问 这样对于访问这个服务带来了难度。因此，kubernetes设计了Service来解决这个问题。\nService可以看作是一组同类Pod对外的访问接口。借助Service，应用可以方便地实现服务发现和负载均衡。\n4.5.1 创建集群内部可访问的Service # 暴露Service [root@master ~]# kubectl expose deploy nginx --name=svc-nginx1 --type=ClusterIP --port=80 --target-port=80 -n dev service/svc-nginx1 exposed # 查看service [root@master ~]# kubectl get svc svc-nginx1 -n dev -o wide NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE SELECTOR svc-nginx1 ClusterIP 10.109.179.231 \u0026lt;none\u0026gt; 80/TCP 3m51s run=nginx # 这里产生了一个CLUSTER-IP，这就是service的IP，在Service的生命周期中，这个地址是不会变动的 # 可以通过这个IP访问当前service对应的POD [root@master ~]# curl 10.109.179.231:80 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;Welcome to nginx!\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;Welcome to nginx!\u0026lt;/h1\u0026gt; ....... \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 4.5.2 创建集群外部也可访问的Service # 上面创建的Service的type类型为ClusterIP，这个ip地址只用集群内部可访问 # 如果需要创建外部也可以访问的Service，需要修改type为NodePort [root@master ~]# kubectl expose deploy nginx --name=svc-nginx2 --type=NodePort --port=80 --target-port=80 -n dev service/svc-nginx2 exposed # 此时查看，会发现出现了NodePort类型的Service，而且有一对Port（80:31928/TC） [root@master ~]# kubectl get svc svc-nginx2 -n dev -o wide NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE SELECTOR svc-nginx2 NodePort 10.100.94.0 \u0026lt;none\u0026gt; 80:31928/TCP 9s run=nginx # 接下来就可以通过集群外的主机访问 节点IP:31928访问服务了 # 例如在的电脑主机上通过浏览器访问下面的地址 http:/192.168.90.100:31928/ 4.5.3 删除Service [root@master ~]# kubectl delete svc svc-nginx-1 -n dev service \u0026#34;svc-nginx-1\u0026#34; deleted 4.5.4 配置方式 创建一个svc-nginx.yaml，内容如下：\napiVersion: v1 kind: Service metadata: name: svc-nginx namespace: dev spec: clusterIP: 10.109.179.231 #固定svc的内网ip ports: - port: 80 protocol: TCP targetPort: 80 selector: run: nginx type: ClusterIP 然后就可以执行对应的创建和删除命令了：\n创建：kubectl create -f svc-nginx.yaml\n删除：kubectl delete -f svc-nginx.yaml\n小结\n至此，已经掌握了Namespace、Pod、Deployment、Service资源的基本操作，有了这些操作，就可以在kubernetes集群中实现一个服务的简单部署和访问了，但是如果想要更好的使用kubernetes，就需要深入学习这几种资源的细节和原理。\n5. Pod详解 5.1 Pod介绍 5.1.1 Pod结构 每个Pod中都可以包含一个或者多个容器，这些容器可以分为两类：\n用户程序所在的容器，数量可多可少\nPause容器，这是每个Pod都会有的一个根容器，它的作用有两个：\n可以以它为依据，评估整个Pod的健康状态\n可以在根容器上设置Ip地址，其它容器都此Ip（Pod IP），以实现Pod内部的网路通信\n这里是Pod内部的通讯，Pod的之间的通讯采用虚拟二层网络技术来实现，我们当前环境用的是Flannel 5.1.2 Pod定义 下面是Pod的资源清单：\napiVersion: v1 #必选，版本号，例如v1 kind: Pod #必选，资源类型，例如 Pod metadata: #必选，元数据 name: string #必选，Pod名称 namespace: string #Pod所属的命名空间,默认为\u0026#34;default\u0026#34; labels: #自定义标签列表 - name: string spec: #必选，Pod中容器的详细定义 containers: #必选，Pod中容器列表 - name: string #必选，容器名称 image: string #必选，容器的镜像名称 imagePullPolicy: [ Always|Never|IfNotPresent ] #获取镜像的策略 command: [string] #容器的启动命令列表，如不指定，使用打包时使用的启动命令 args: [string] #容器的启动命令参数列表 workingDir: string #容器的工作目录 volumeMounts: #挂载到容器内部的存储卷配置 - name: string #引用pod定义的共享存储卷的名称，需用volumes[]部分定义的的卷名 mountPath: string #存储卷在容器内mount的绝对路径，应少于512字符 readOnly: boolean #是否为只读模式 ports: #需要暴露的端口库号列表 - name: string #端口的名称 containerPort: int #容器需要监听的端口号 hostPort: int #容器所在主机需要监听的端口号，默认与Container相同 protocol: string #端口协议，支持TCP和UDP，默认TCP env: #容器运行前需设置的环境变量列表 - name: string #环境变量名称 value: string #环境变量的值 resources: #资源限制和请求的设置 limits: #资源限制的设置 cpu: string #Cpu的限制，单位为core数，将用于docker run --cpu-shares参数 memory: string #内存限制，单位可以为Mib/Gib，将用于docker run --memory参数 requests: #资源请求的设置 cpu: string #Cpu请求，容器启动的初始可用数量 memory: string #内存请求,容器启动的初始可用数量 lifecycle: #生命周期钩子 postStart: #容器启动后立即执行此钩子,如果执行失败,会根据重启策略进行重启 preStop: #容器终止前执行此钩子,无论结果如何,容器都会终止 livenessProbe: #对Pod内各容器健康检查的设置，当探测无响应几次后将自动重启该容器 exec: #对Pod容器内检查方式设置为exec方式 command: [string] #exec方式需要制定的命令或脚本 httpGet: #对Pod内个容器健康检查方法设置为HttpGet，需要制定Path、port path: string port: number host: string scheme: string HttpHeaders: - name: string value: string tcpSocket: #对Pod内个容器健康检查方式设置为tcpSocket方式 port: number initialDelaySeconds: 0 #容器启动完成后首次探测的时间，单位为秒 timeoutSeconds: 0 #对容器健康检查探测等待响应的超时时间，单位秒，默认1秒 periodSeconds: 0 #对容器监控检查的定期探测时间设置，单位秒，默认10秒一次 successThreshold: 0 failureThreshold: 0 securityContext: privileged: false restartPolicy: [Always | Never | OnFailure] #Pod的重启策略 nodeName: \u0026lt;string\u0026gt; #设置NodeName表示将该Pod调度到指定到名称的node节点上 nodeSelector: obeject #设置NodeSelector表示将该Pod调度到包含这个label的node上 imagePullSecrets: #Pull镜像时使用的secret名称，以key：secretkey格式指定 - name: string hostNetwork: false #是否使用主机网络模式，默认为false，如果设置为true，表示使用宿主机网络 volumes: #在该pod上定义共享存储卷列表 - name: string #共享存储卷名称 （volumes类型有很多种） emptyDir: {} #类型为emtyDir的存储卷，与Pod同生命周期的一个临时目录。为空值 hostPath: string #类型为hostPath的存储卷，表示挂载Pod所在宿主机的目录 path: string #Pod所在宿主机的目录，将被用于同期中mount的目录 secret: #类型为secret的存储卷，挂载集群与定义的secret对象到容器内部 scretname: string items: - key: string path: string configMap: #类型为configMap的存储卷，挂载预定义的configMap对象到容器内部 name: string items: - key: string path: string #小提示： # 在这里，可通过一个命令来查看每种资源的可配置项 # kubectl explain 资源类型 查看某种资源可以配置的一级属性 # kubectl explain 资源类型.属性 查看属性的子属性 [root@k8s-master01 ~]# kubectl explain pod KIND: Pod VERSION: v1 FIELDS: apiVersion \u0026lt;string\u0026gt; kind \u0026lt;string\u0026gt; metadata \u0026lt;Object\u0026gt; spec \u0026lt;Object\u0026gt; status \u0026lt;Object\u0026gt; [root@k8s-master01 ~]# kubectl explain pod.metadata KIND: Pod VERSION: v1 RESOURCE: metadata \u0026lt;Object\u0026gt; FIELDS: annotations \u0026lt;map[string]string\u0026gt; clusterName \u0026lt;string\u0026gt; creationTimestamp \u0026lt;string\u0026gt; deletionGracePeriodSeconds \u0026lt;integer\u0026gt; deletionTimestamp \u0026lt;string\u0026gt; finalizers \u0026lt;[]string\u0026gt; generateName \u0026lt;string\u0026gt; generation \u0026lt;integer\u0026gt; labels \u0026lt;map[string]string\u0026gt; managedFields \u0026lt;[]Object\u0026gt; name \u0026lt;string\u0026gt; namespace \u0026lt;string\u0026gt; ownerReferences \u0026lt;[]Object\u0026gt; resourceVersion \u0026lt;string\u0026gt; selfLink \u0026lt;string\u0026gt; uid \u0026lt;string\u0026gt; 在kubernetes中基本所有资源的一级属性都是一样的，主要包含5部分：\n- apiVersion \u0026lt;string\u0026gt; 版本，由kubernetes内部定义，版本号必须可以用 kubectl api-versions 查询到 - kind \u0026lt;string\u0026gt; 类型，由kubernetes内部定义，版本号必须可以用 kubectl api-resources 查询到 - metadata \u0026lt;Object\u0026gt; 元数据，主要是资源标识和说明，常用的有name、namespace、labels等 - spec \u0026lt;Object\u0026gt; 描述，这是配置中最重要的一部分，里面是对各种资源配置的详细描述 - status \u0026lt;Object\u0026gt; 状态信息，里面的内容不需要定义，由kubernetes自动生成 在上面的属性中，spec是接下来研究的重点，继续看下它的常见子属性:\n- containers \u0026lt;[]Object\u0026gt; 容器列表，用于定义容器的详细信息 - nodeName \u0026lt;String\u0026gt; 根据nodeName的值将pod调度到指定的Node节点上 - nodeSelector \u0026lt;map[]\u0026gt; 根据NodeSelector中定义的信息选择将该Pod调度到包含这些label的Node 上 - hostNetwork \u0026lt;boolean\u0026gt; 是否使用主机网络模式，默认为false，如果设置为true，表示使用宿主机网络 - volumes \u0026lt;[]Object\u0026gt; 存储卷，用于定义Pod上面挂在的存储信息 - restartPolicy \u0026lt;string\u0026gt; 重启策略，表示Pod在遇到故障的时候的处理策略 5.2 Pod配置 本小节主要来研究pod.spec.containers属性，这也是pod配置中最为关键的一项配置。\n[root@k8s-master01 ~]# kubectl explain pod.spec.containers KIND: Pod VERSION: v1 RESOURCE: containers \u0026lt;[]Object\u0026gt; # 数组，代表可以有多个容器 FIELDS: name \u0026lt;string\u0026gt; # 容器名称 image \u0026lt;string\u0026gt; # 容器需要的镜像地址 imagePullPolicy \u0026lt;string\u0026gt; # 镜像拉取策略 command \u0026lt;[]string\u0026gt; # 容器的启动命令列表，如不指定，使用打包时使用的启动命令 args \u0026lt;[]string\u0026gt; # 容器的启动命令需要的参数列表 env \u0026lt;[]Object\u0026gt; # 容器环境变量的配置 ports \u0026lt;[]Object\u0026gt; # 容器需要暴露的端口号列表 resources \u0026lt;Object\u0026gt; # 资源限制和资源请求的设置 5.2.1 基本配置 创建pod-base.yaml文件，内容如下：\napiVersion: v1 kind: Pod metadata: name: pod-base namespace: dev labels: user: heima spec: containers: - name: nginx image: nginx:1.17.1 - name: busybox image: busybox:1.30 上面定义了一个比较简单Pod的配置，里面有两个容器：\nnginx：用1.17.1版本的nginx镜像创建，（nginx是一个轻量级web容器） busybox：用1.30版本的busybox镜像创建，（busybox是一个小巧的linux命令集合） # 创建Pod [root@k8s-master01 pod]# kubectl apply -f pod-base.yaml pod/pod-base created # 查看Pod状况 # READY 1/2 : 表示当前Pod中有2个容器，其中1个准备就绪，1个未就绪 # RESTARTS : 重启次数，因为有1个容器故障了，Pod一直在重启试图恢复它 [root@k8s-master01 pod]# kubectl get pod -n dev NAME READY STATUS RESTARTS AGE pod-base 1/2 Running 4 95s # 可以通过describe查看内部的详情 # 此时已经运行起来了一个基本的Pod，虽然它暂时有问题 [root@k8s-master01 pod]# kubectl describe pod pod-base -n dev 5.2.2 镜像拉取 创建pod-imagepullpolicy.yaml文件，内容如下：\napiVersion: v1 kind: Pod metadata: name: pod-imagepullpolicy namespace: dev spec: containers: - name: nginx image: nginx:1.17.1 imagePullPolicy: Never # 用于设置镜像拉取策略 - name: busybox image: busybox:1.30 imagePullPolicy，用于设置镜像拉取策略，kubernetes支持配置三种拉取策略：\nAlways：总是从远程仓库拉取镜像（一直远程下载） IfNotPresent：本地有则使用本地镜像，本地没有则从远程仓库拉取镜像（本地有就本地 本地没远程下载） Never：只使用本地镜像，从不去远程仓库拉取，本地没有就报错 （一直使用本地） 默认值说明：\n如果镜像tag为具体版本号， 默认策略是：IfNotPresent\n如果镜像tag为：latest（最终版本） ，默认策略是always\n# 创建Pod [root@k8s-master01 pod]# kubectl create -f pod-imagepullpolicy.yaml pod/pod-imagepullpolicy created # 查看Pod详情 # 此时明显可以看到nginx镜像有一步Pulling image \u0026#34;nginx:1.17.1\u0026#34;的过程 [root@k8s-master01 pod]# kubectl describe pod pod-imagepullpolicy -n dev ...... Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled \u0026lt;unknown\u0026gt; default-scheduler Successfully assigned dev/pod-imagePullPolicy to node1 Normal Pulling 32s kubelet, node1 Pulling image \u0026#34;nginx:1.17.1\u0026#34; Normal Pulled 26s kubelet, node1 Successfully pulled image \u0026#34;nginx:1.17.1\u0026#34; Normal Created 26s kubelet, node1 Created container nginx Normal Started 25s kubelet, node1 Started container nginx Normal Pulled 7s (x3 over 25s) kubelet, node1 Container image \u0026#34;busybox:1.30\u0026#34; already present on machine Normal Created 7s (x3 over 25s) kubelet, node1 Created container busybox Normal Started 7s (x3 over 25s) kubelet, node1 Started container busybox 5.2.3 启动命令 在前面的案例中，一直有一个问题没有解决，就是的busybox容器一直没有成功运行，那么到底是什么原因导致这个容器的故障呢？\n原来busybox并不是一个程序，而是类似于一个工具类的集合，kubernetes集群启动管理后，它会自动关闭。解决方法就是让其一直在运行，这就用到了command配置。\n创建pod-command.yaml文件，内容如下：\napiVersion: v1 kind: Pod metadata: name: pod-command namespace: dev spec: containers: - name: nginx image: nginx:1.17.1 - name: busybox image: busybox:1.30 command: [\u0026#34;/bin/sh\u0026#34;,\u0026#34;-c\u0026#34;,\u0026#34;touch /tmp/hello.txt;while true;do /bin/echo $(date +%T) \u0026gt;\u0026gt; /tmp/hello.txt; sleep 3; done;\u0026#34;] command，用于在pod中的容器初始化完毕之后运行一个命令。\n稍微解释下上面命令的意思：\n\u0026ldquo;/bin/sh\u0026rdquo;,\u0026quot;-c\u0026rdquo;, 使用sh执行命令\ntouch /tmp/hello.txt; 创建一个/tmp/hello.txt 文件\nwhile true;do /bin/echo $(date +%T) \u0026raquo; /tmp/hello.txt; sleep 3; done; 每隔3秒向文件中写入当前时间\n# 创建Pod [root@k8s-master01 pod]# kubectl create -f pod-command.yaml pod/pod-command created # 查看Pod状态 # 此时发现两个pod都正常运行了 [root@k8s-master01 pod]# kubectl get pods pod-command -n dev NAME READY STATUS RESTARTS AGE pod-command 2/2 Runing 0 2s # 进入pod中的busybox容器，查看文件内容 # 补充一个命令: kubectl exec pod名称 -n 命名空间 -it -c 容器名称 /bin/sh 在容器内部执行命令 # 使用这个命令就可以进入某个容器的内部，然后进行相关操作了 # 比如，可以查看txt文件的内容 [root@k8s-master01 pod]# kubectl exec pod-command -n dev -it -c busybox /bin/sh / # tail -f /tmp/hello.txt 14:44:19 14:44:22 14:44:25 特别说明： 通过上面发现command已经可以完成启动命令和传递参数的功能，为什么这里还要提供一个args选项，用于传递参数呢?这其实跟docker有点关系，kubernetes中的command、args两项其实是实现覆盖Dockerfile中ENTRYPOINT的功能。 1 如果command和args均没有写，那么用Dockerfile的配置。 2 如果command写了，但args没有写，那么Dockerfile默认的配置会被忽略，执行输入的command 3 如果command没写，但args写了，那么Dockerfile中配置的ENTRYPOINT的命令会被执行，使用当前args的参数 4 如果command和args都写了，那么Dockerfile的配置被忽略，执行command并追加上args参数 5.2.4 环境变量 创建pod-env.yaml文件，内容如下：\napiVersion: v1 kind: Pod metadata: name: pod-env namespace: dev spec: containers: - name: busybox image: busybox:1.30 command: [\u0026#34;/bin/sh\u0026#34;,\u0026#34;-c\u0026#34;,\u0026#34;while true;do /bin/echo $(date +%T);sleep 60; done;\u0026#34;] env: # 设置环境变量列表 - name: \u0026#34;username\u0026#34; value: \u0026#34;admin\u0026#34; - name: \u0026#34;password\u0026#34; value: \u0026#34;123456\u0026#34; env，环境变量，用于在pod中的容器设置环境变量。\n# 创建Pod [root@k8s-master01 ~]# kubectl create -f pod-env.yaml pod/pod-env created # 进入容器，输出环境变量 [root@k8s-master01 ~]# kubectl exec pod-env -n dev -c busybox -it /bin/sh / # echo $username admin / # echo $password 123456 这种方式不是很推荐，推荐将这些配置单独存储在配置文件中，这种方式将在后面介绍。\n5.2.5 端口设置 本小节来介绍容器的端口设置，也就是containers的ports选项。\n首先看下ports支持的子选项：\n[root@k8s-master01 ~]# kubectl explain pod.spec.containers.ports KIND: Pod VERSION: v1 RESOURCE: ports \u0026lt;[]Object\u0026gt; FIELDS: name \u0026lt;string\u0026gt; # 端口名称，如果指定，必须保证name在pod中是唯一的 containerPort\u0026lt;integer\u0026gt; # 容器要监听的端口(0\u0026lt;x\u0026lt;65536) hostPort \u0026lt;integer\u0026gt; # 容器要在主机上公开的端口，如果设置，主机上只能运行容器的一个副本(一般省略) hostIP \u0026lt;string\u0026gt; # 要将外部端口绑定到的主机IP(一般省略) protocol \u0026lt;string\u0026gt; # 端口协议。必须是UDP、TCP或SCTP。默认为“TCP”。 接下来，编写一个测试案例，创建pod-ports.yaml\napiVersion: v1 kind: Pod metadata: name: pod-ports namespace: dev spec: containers: - name: nginx image: nginx:1.17.1 ports: # 设置容器暴露的端口列表 - name: nginx-port containerPort: 80 protocol: TCP # 创建Pod [root@k8s-master01 ~]# kubectl create -f pod-ports.yaml pod/pod-ports created # 查看pod # 在下面可以明显看到配置信息 [root@k8s-master01 ~]# kubectl get pod pod-ports -n dev -o yaml ...... spec: containers: - image: nginx:1.17.1 imagePullPolicy: IfNotPresent name: nginx ports: - containerPort: 80 name: nginx-port protocol: TCP ...... 访问容器中的程序需要使用的是Podip:containerPort\n5.2.6 资源配额 容器中的程序要运行，肯定是要占用一定资源的，比如cpu和内存等，如果不对某个容器的资源做限制，那么它就可能吃掉大量资源，导致其它容器无法运行。针对这种情况，kubernetes提供了对内存和cpu的资源进行配额的机制，这种机制主要通过resources选项实现，他有两个子选项：\nlimits：用于限制运行时容器的最大占用资源，当容器占用资源超过limits时会被终止，并进行重启 requests ：用于设置容器需要的最小资源，如果环境资源不够，容器将无法启动 可以通过上面两个选项设置资源的上下限。\n接下来，编写一个测试案例，创建pod-resources.yaml\napiVersion: v1 kind: Pod metadata: name: pod-resources namespace: dev spec: containers: - name: nginx image: nginx:1.17.1 resources: # 资源配额 limits: # 限制资源（上限） cpu: \u0026#34;2\u0026#34; # CPU限制，单位是core数 memory: \u0026#34;10Gi\u0026#34; # 内存限制 requests: # 请求资源（下限） cpu: \u0026#34;1\u0026#34; # CPU限制，单位是core数 memory: \u0026#34;10Mi\u0026#34; # 内存限制 在这对cpu和memory的单位做一个说明：\ncpu：core数，可以为整数或小数 memory： 内存大小，可以使用Gi、Mi、G、M等形式 # 运行Pod [root@k8s-master01 ~]# kubectl create -f pod-resources.yaml pod/pod-resources created # 查看发现pod运行正常 [root@k8s-master01 ~]# kubectl get pod pod-resources -n dev NAME READY STATUS RESTARTS AGE pod-resources 1/1 Running 0 39s # 接下来，停止Pod [root@k8s-master01 ~]# kubectl delete -f pod-resources.yaml pod \u0026#34;pod-resources\u0026#34; deleted # 编辑pod，修改resources.requests.memory的值为10Gi [root@k8s-master01 ~]# vim pod-resources.yaml # 再次启动pod [root@k8s-master01 ~]# kubectl create -f pod-resources.yaml pod/pod-resources created # 查看Pod状态，发现Pod启动失败 [root@k8s-master01 ~]# kubectl get pod pod-resources -n dev -o wide NAME READY STATUS RESTARTS AGE pod-resources 0/1 Pending 0 20s # 查看pod详情会发现，如下提示 [root@k8s-master01 ~]# kubectl describe pod pod-resources -n dev ...... Warning FailedScheduling 35s default-scheduler 0/3 nodes are available: 1 node(s) had taint {node-role.kubernetes.io/master: }, that the pod didn\u0026#39;t tolerate, 2 Insufficient memory.(内存不足) 5.3 Pod生命周期 我们一般将pod对象从创建至终的这段时间范围称为pod的生命周期，它主要包含下面的过程：\npod创建过程 运行初始化容器（init container）过程 运行主容器（main container） 容器启动后钩子（post start）、容器终止前钩子（pre stop） 容器的存活性探测（liveness probe）、就绪性探测（readiness probe） pod终止过程 在整个生命周期中，Pod会出现5种状态（相位），分别如下：\n挂起（Pending）：apiserver已经创建了pod资源对象，但它尚未被调度完成或者仍处于下载镜像的过程中 运行中（Running）：pod已经被调度至某节点，并且所有容器都已经被kubelet创建完成 成功（Succeeded）：pod中的所有容器都已经成功终止并且不会被重启 失败（Failed）：所有容器都已经终止，但至少有一个容器终止失败，即容器返回了非0值的退出状态 未知（Unknown）：apiserver无法正常获取到pod对象的状态信息，通常由网络通信失败所导致 5.3.1 创建和终止 pod的创建过程\n用户通过kubectl或其他api客户端提交需要创建的pod信息给apiServer\napiServer开始生成pod对象的信息，并将信息存入etcd，然后返回确认信息至客户端\napiServer开始反映etcd中的pod对象的变化，其它组件使用watch机制来跟踪检查apiServer上的变动\nscheduler发现有新的pod对象要创建，开始为Pod分配主机并将结果信息更新至apiServer\nnode节点上的kubelet发现有pod调度过来，尝试调用docker启动容器，并将结果回送至apiServer\napiServer将接收到的pod状态信息存入etcd中\npod的终止过程\n用户向apiServer发送删除pod对象的命令 apiServcer中的pod对象信息会随着时间的推移而更新，在宽限期内（默认30s），pod被视为dead 将pod标记为terminating状态 kubelet在监控到pod对象转为terminating状态的同时启动pod关闭过程 端点控制器监控到pod对象的关闭行为时将其从所有匹配到此端点的service资源的端点列表中移除 如果当前pod对象定义了preStop钩子处理器，则在其标记为terminating后即会以同步的方式启动执行 pod对象中的容器进程收到停止信号 宽限期结束后，若pod中还存在仍在运行的进程，那么pod对象会收到立即终止的信号 kubelet请求apiServer将此pod资源的宽限期设置为0从而完成删除操作，此时pod对于用户已不可见 5.3.2 初始化容器 初始化容器是在pod的主容器启动之前要运行的容器，主要是做一些主容器的前置工作，它具有两大特征：\n初始化容器必须运行完成直至结束，若某初始化容器运行失败，那么kubernetes需要重启它直到成功完成 初始化容器必须按照定义的顺序执行，当且仅当前一个成功之后，后面的一个才能运行 初始化容器有很多的应用场景，下面列出的是最常见的几个：\n提供主容器镜像中不具备的工具程序或自定义代码 初始化容器要先于应用容器串行启动并运行完成，因此可用于延后应用容器的启动直至其依赖的条件得到满足 接下来做一个案例，模拟下面这个需求：\n假设要以主容器来运行nginx，但是要求在运行nginx之前先要能够连接上mysql和redis所在服务器\n为了简化测试，事先规定好mysql(192.168.90.14)和redis(192.168.90.15)服务器的地址\n创建pod-initcontainer.yaml，内容如下：\napiVersion: v1 kind: Pod metadata: name: pod-initcontainer namespace: dev spec: containers: - name: main-container image: nginx:1.17.1 ports: - name: nginx-port containerPort: 80 initContainers: - name: test-mysql image: busybox:1.30 command: [\u0026#39;sh\u0026#39;, \u0026#39;-c\u0026#39;, \u0026#39;until ping 192.168.90.14 -c 1 ; do echo waiting for mysql...; sleep 2; done;\u0026#39;] - name: test-redis image: busybox:1.30 command: [\u0026#39;sh\u0026#39;, \u0026#39;-c\u0026#39;, \u0026#39;until ping 192.168.90.15 -c 1 ; do echo waiting for reids...; sleep 2; done;\u0026#39;] # 创建pod [root@k8s-master01 ~]# kubectl create -f pod-initcontainer.yaml pod/pod-initcontainer created # 查看pod状态 # 发现pod卡在启动第一个初始化容器过程中，后面的容器不会运行 root@k8s-master01 ~]# kubectl describe pod pod-initcontainer -n dev ........ Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled 49s default-scheduler Successfully assigned dev/pod-initcontainer to node1 Normal Pulled 48s kubelet, node1 Container image \u0026#34;busybox:1.30\u0026#34; already present on machine Normal Created 48s kubelet, node1 Created container test-mysql Normal Started 48s kubelet, node1 Started container test-mysql # 动态查看pod [root@k8s-master01 ~]# kubectl get pods pod-initcontainer -n dev -w NAME READY STATUS RESTARTS AGE pod-initcontainer 0/1 Init:0/2 0 15s pod-initcontainer 0/1 Init:1/2 0 52s pod-initcontainer 0/1 Init:1/2 0 53s pod-initcontainer 0/1 PodInitializing 0 89s pod-initcontainer 1/1 Running 0 90s # 接下来新开一个shell，为当前服务器新增两个ip，观察pod的变化 [root@k8s-master01 ~]# ifconfig ens33:1 192.168.90.14 netmask 255.255.255.0 up [root@k8s-master01 ~]# ifconfig ens33:2 192.168.90.15 netmask 255.255.255.0 up 5.3.3 钩子函数 钩子函数能够感知自身生命周期中的事件，并在相应的时刻到来时运行用户指定的程序代码。\nkubernetes在主容器的启动之后和停止之前提供了两个钩子函数：\npost start：容器创建之后执行，如果失败了会重启容器 pre stop ：容器终止之前执行，执行完成之后容器将成功终止，在其完成之前会阻塞删除容器的操作 钩子处理器支持使用下面三种方式定义动作：\nExec命令：在容器内执行一次命令\n…… lifecycle: postStart: exec: command: - cat - /tmp/healthy …… TCPSocket：在当前容器尝试访问指定的socket\n…… lifecycle: postStart: tcpSocket: port: 8080 …… HTTPGet：在当前容器中向某url发起http请求\n…… lifecycle: postStart: httpGet: path: / #URI地址 port: 80 #端口号 host: 192.168.5.3 #主机地址 scheme: HTTP #支持的协议，http或者https …… 接下来，以exec方式为例，演示下钩子函数的使用，创建pod-hook-exec.yaml文件，内容如下：\napiVersion: v1 kind: Pod metadata: name: pod-hook-exec namespace: dev spec: containers: - name: main-container image: nginx:1.17.1 ports: - name: nginx-port containerPort: 80 lifecycle: postStart: exec: # 在容器启动的时候执行一个命令，修改掉nginx的默认首页内容 command: [\u0026#34;/bin/sh\u0026#34;, \u0026#34;-c\u0026#34;, \u0026#34;echo postStart... \u0026gt; /usr/share/nginx/html/index.html\u0026#34;] preStop: exec: # 在容器停止之前停止nginx服务 command: [\u0026#34;/usr/sbin/nginx\u0026#34;,\u0026#34;-s\u0026#34;,\u0026#34;quit\u0026#34;] # 创建pod [root@k8s-master01 ~]# kubectl create -f pod-hook-exec.yaml pod/pod-hook-exec created # 查看pod [root@k8s-master01 ~]# kubectl get pods pod-hook-exec -n dev -o wide NAME READY STATUS RESTARTS AGE IP NODE pod-hook-exec 1/1 Running 0 29s 10.244.2.48 node2 # 访问pod [root@k8s-master01 ~]# curl 10.244.2.48 postStart... 5.3.4 容器探测 容器探测用于检测容器中的应用实例是否正常工作，是保障业务可用性的一种传统机制。如果经过探测，实例的状态不符合预期，那么kubernetes就会把该问题实例\u0026rdquo; 摘除 \u0026ldquo;，不承担业务流量。kubernetes提供了两种探针来实现容器探测，分别是：\nliveness probes：存活性探针，用于检测应用实例当前是否处于正常运行状态，如果不是，k8s会重启容器 readiness probes：就绪性探针，用于检测应用实例当前是否可以接收请求，如果不能，k8s不会转发流量 livenessProbe 决定是否重启容器，readinessProbe 决定是否将请求转发给容器。\n上面两种探针目前均支持三种探测方式：\nExec命令：在容器内执行一次命令，如果命令执行的退出码为0，则认为程序正常，否则不正常\n…… livenessProbe: exec: command: - cat - /tmp/healthy …… TCPSocket：将会尝试访问一个用户容器的端口，如果能够建立这条连接，则认为程序正常，否则不正常\n…… livenessProbe: tcpSocket: port: 8080 …… HTTPGet：调用容器内Web应用的URL，如果返回的状态码在200和399之间，则认为程序正常，否则不正常\n…… livenessProbe: httpGet: path: / #URI地址 port: 80 #端口号 host: 127.0.0.1 #主机地址 scheme: HTTP #支持的协议，http或者https …… 下面以liveness probes为例，做几个演示：\n方式一：Exec\n创建pod-liveness-exec.yaml\napiVersion: v1 kind: Pod metadata: name: pod-liveness-exec namespace: dev spec: containers: - name: nginx image: nginx:1.17.1 ports: - name: nginx-port containerPort: 80 livenessProbe: exec: command: [\u0026#34;/bin/cat\u0026#34;,\u0026#34;/tmp/hello.txt\u0026#34;] # 执行一个查看文件的命令 创建pod，观察效果\n# 创建Pod [root@k8s-master01 ~]# kubectl create -f pod-liveness-exec.yaml pod/pod-liveness-exec created # 查看Pod详情 [root@k8s-master01 ~]# kubectl describe pods pod-liveness-exec -n dev ...... Normal Created 20s (x2 over 50s) kubelet, node1 Created container nginx Normal Started 20s (x2 over 50s) kubelet, node1 Started container nginx Normal Killing 20s kubelet, node1 Container nginx failed liveness probe, will be restarted Warning Unhealthy 0s (x5 over 40s) kubelet, node1 Liveness probe failed: cat: can\u0026#39;t open \u0026#39;/tmp/hello11.txt\u0026#39;: No such file or directory # 观察上面的信息就会发现nginx容器启动之后就进行了健康检查 # 检查失败之后，容器被kill掉，然后尝试进行重启（这是重启策略的作用，后面讲解） # 稍等一会之后，再观察pod信息，就可以看到RESTARTS不再是0，而是一直增长 [root@k8s-master01 ~]# kubectl get pods pod-liveness-exec -n dev NAME READY STATUS RESTARTS AGE pod-liveness-exec 0/1 CrashLoopBackOff 2 3m19s # 当然接下来，可以修改成一个存在的文件，比如/tmp/hello.txt，再试，结果就正常了...... 方式二：TCPSocket\n创建pod-liveness-tcpsocket.yaml\napiVersion: v1 kind: Pod metadata: name: pod-liveness-tcpsocket namespace: dev spec: containers: - name: nginx image: nginx:1.17.1 ports: - name: nginx-port containerPort: 80 livenessProbe: tcpSocket: port: 8080 # 尝试访问8080端口 创建pod，观察效果\n# 创建Pod [root@k8s-master01 ~]# kubectl create -f pod-liveness-tcpsocket.yaml pod/pod-liveness-tcpsocket created # 查看Pod详情 [root@k8s-master01 ~]# kubectl describe pods pod-liveness-tcpsocket -n dev ...... Normal Scheduled 31s default-scheduler Successfully assigned dev/pod-liveness-tcpsocket to node2 Normal Pulled \u0026lt;invalid\u0026gt; kubelet, node2 Container image \u0026#34;nginx:1.17.1\u0026#34; already present on machine Normal Created \u0026lt;invalid\u0026gt; kubelet, node2 Created container nginx Normal Started \u0026lt;invalid\u0026gt; kubelet, node2 Started container nginx Warning Unhealthy \u0026lt;invalid\u0026gt; (x2 over \u0026lt;invalid\u0026gt;) kubelet, node2 Liveness probe failed: dial tcp 10.244.2.44:8080: connect: connection refused # 观察上面的信息，发现尝试访问8080端口,但是失败了 # 稍等一会之后，再观察pod信息，就可以看到RESTARTS不再是0，而是一直增长 [root@k8s-master01 ~]# kubectl get pods pod-liveness-tcpsocket -n dev NAME READY STATUS RESTARTS AGE pod-liveness-tcpsocket 0/1 CrashLoopBackOff 2 3m19s # 当然接下来，可以修改成一个可以访问的端口，比如80，再试，结果就正常了...... 方式三：HTTPGet\n创建pod-liveness-httpget.yaml\napiVersion: v1 kind: Pod metadata: name: pod-liveness-httpget namespace: dev spec: containers: - name: nginx image: nginx:1.17.1 ports: - name: nginx-port containerPort: 80 livenessProbe: httpGet: # 其实就是访问http:/127.0.0.1:80/hello scheme: HTTP #支持的协议，http或者https port: 80 #端口号 path: /hello #URI地址 创建pod，观察效果\n# 创建Pod [root@k8s-master01 ~]# kubectl create -f pod-liveness-httpget.yaml pod/pod-liveness-httpget created # 查看Pod详情 [root@k8s-master01 ~]# kubectl describe pod pod-liveness-httpget -n dev ....... Normal Pulled 6s (x3 over 64s) kubelet, node1 Container image \u0026#34;nginx:1.17.1\u0026#34; already present on machine Normal Created 6s (x3 over 64s) kubelet, node1 Created container nginx Normal Started 6s (x3 over 63s) kubelet, node1 Started container nginx Warning Unhealthy 6s (x6 over 56s) kubelet, node1 Liveness probe failed: HTTP probe failed with statuscode: 404 Normal Killing 6s (x2 over 36s) kubelet, node1 Container nginx failed liveness probe, will be restarted # 观察上面信息，尝试访问路径，但是未找到,出现404错误 # 稍等一会之后，再观察pod信息，就可以看到RESTARTS不再是0，而是一直增长 [root@k8s-master01 ~]# kubectl get pod pod-liveness-httpget -n dev NAME READY STATUS RESTARTS AGE pod-liveness-httpget 1/1 Running 5 3m17s # 当然接下来，可以修改成一个可以访问的路径path，比如/，再试，结果就正常了...... 至此，已经使用liveness Probe演示了三种探测方式，但是查看livenessProbe的子属性，会发现除了这三种方式，还有一些其他的配置，在这里一并解释下：\n[root@k8s-master01 ~]# kubectl explain pod.spec.containers.livenessProbe FIELDS: exec \u0026lt;Object\u0026gt; tcpSocket \u0026lt;Object\u0026gt; httpGet \u0026lt;Object\u0026gt; initialDelaySeconds \u0026lt;integer\u0026gt; # 容器启动后等待多少秒执行第一次探测 timeoutSeconds \u0026lt;integer\u0026gt; # 探测超时时间。默认1秒，最小1秒 periodSeconds \u0026lt;integer\u0026gt; # 执行探测的频率。默认是10秒，最小1秒 failureThreshold \u0026lt;integer\u0026gt; # 连续探测失败多少次才被认定为失败。默认是3。最小值是1 successThreshold \u0026lt;integer\u0026gt; # 连续探测成功多少次才被认定为成功。默认是1 下面稍微配置两个，演示下效果即可：\n[root@k8s-master01 ~]# more pod-liveness-httpget.yaml apiVersion: v1 kind: Pod metadata: name: pod-liveness-httpget namespace: dev spec: containers: - name: nginx image: nginx:1.17.1 ports: - name: nginx-port containerPort: 80 livenessProbe: httpGet: scheme: HTTP port: 80 path: / initialDelaySeconds: 30 # 容器启动后30s开始探测 timeoutSeconds: 5 # 探测超时时间为5s 5.3.5 重启策略 在上一节中，一旦容器探测出现了问题，kubernetes就会对容器所在的Pod进行重启，其实这是由pod的重启策略决定的，pod的重启策略有 3 种，分别如下：\nAlways ：容器失效时，自动重启该容器，这也是默认值。 OnFailure ： 容器终止运行且退出码不为0时重启 Never ： 不论状态为何，都不重启该容器 重启策略适用于pod对象中的所有容器，首次需要重启的容器，将在其需要时立即进行重启，随后再次需要重启的操作将由kubelet延迟一段时间后进行，且反复的重启操作的延迟时长以此为10s、20s、40s、80s、160s和300s，300s是最大延迟时长。\n创建pod-restartpolicy.yaml：\napiVersion: v1 kind: Pod metadata: name: pod-restartpolicy namespace: dev spec: containers: - name: nginx image: nginx:1.17.1 ports: - name: nginx-port containerPort: 80 livenessProbe: httpGet: scheme: HTTP port: 80 path: /hello restartPolicy: Never # 设置重启策略为Never 运行Pod测试\n# 创建Pod [root@k8s-master01 ~]# kubectl create -f pod-restartpolicy.yaml pod/pod-restartpolicy created # 查看Pod详情，发现nginx容器失败 [root@k8s-master01 ~]# kubectl describe pods pod-restartpolicy -n dev ...... Warning Unhealthy 15s (x3 over 35s) kubelet, node1 Liveness probe failed: HTTP probe failed with statuscode: 404 Normal Killing 15s kubelet, node1 Container nginx failed liveness probe # 多等一会，再观察pod的重启次数，发现一直是0，并未重启 [root@k8s-master01 ~]# kubectl get pods pod-restartpolicy -n dev NAME READY STATUS RESTARTS AGE pod-restartpolicy 0/1 Running 0 5min42s 5.4 Pod调度 在默认情况下，一个Pod在哪个Node节点上运行，是由Scheduler组件采用相应的算法计算出来的，这个过程是不受人工控制的。但是在实际使用中，这并不满足的需求，因为很多情况下，我们想控制某些Pod到达某些节点上，那么应该怎么做呢？这就要求了解kubernetes对Pod的调度规则，kubernetes提供了四大类调度方式：\n自动调度：运行在哪个节点上完全由Scheduler经过一系列的算法计算得出 定向调度：NodeName、NodeSelector 亲和性调度：NodeAffinity、PodAffinity、PodAntiAffinity 污点（容忍）调度：Taints、Toleration 5.4.1 定向调度 定向调度，指的是利用在pod上声明nodeName或者nodeSelector，以此将Pod调度到期望的node节点上。注意，这里的调度是强制的，这就意味着即使要调度的目标Node不存在，也会向上面进行调度，只不过pod运行失败而已。\nNodeName\nNodeName用于强制约束将Pod调度到指定的Name的Node节点上。这种方式，其实是直接跳过Scheduler的调度逻辑，直接将Pod调度到指定名称的节点。\n接下来，实验一下：创建一个pod-nodename.yaml文件\napiVersion: v1 kind: Pod metadata: name: pod-nodename namespace: dev spec: containers: - name: nginx image: nginx:1.17.1 nodeName: node1 # 指定调度到node1节点上 #创建Pod [root@k8s-master01 ~]# kubectl create -f pod-nodename.yaml pod/pod-nodename created #查看Pod调度到NODE属性，确实是调度到了node1节点上 [root@k8s-master01 ~]# kubectl get pods pod-nodename -n dev -o wide NAME READY STATUS RESTARTS AGE IP NODE ...... pod-nodename 1/1 Running 0 56s 10.244.1.87 node1 ...... # 接下来，删除pod，修改nodeName的值为node3（并没有node3节点） [root@k8s-master01 ~]# kubectl delete -f pod-nodename.yaml pod \u0026#34;pod-nodename\u0026#34; deleted [root@k8s-master01 ~]# vim pod-nodename.yaml [root@k8s-master01 ~]# kubectl create -f pod-nodename.yaml pod/pod-nodename created #再次查看，发现已经向Node3节点调度，但是由于不存在node3节点，所以pod无法正常运行 [root@k8s-master01 ~]# kubectl get pods pod-nodename -n dev -o wide NAME READY STATUS RESTARTS AGE IP NODE ...... pod-nodename 0/1 Pending 0 6s \u0026lt;none\u0026gt; node3 ...... NodeSelector\nNodeSelector用于将pod调度到添加了指定标签的node节点上。它是通过kubernetes的label-selector机制实现的，也就是说，在pod创建之前，会由scheduler使用MatchNodeSelector调度策略进行label匹配，找出目标node，然后将pod调度到目标节点，该匹配规则是强制约束。\n接下来，实验一下：\n1 首先分别为node节点添加标签\n[root@k8s-master01 ~]# kubectl label nodes node1 nodeenv=pro node/node2 labeled [root@k8s-master01 ~]# kubectl label nodes node2 nodeenv=test node/node2 labeled 2 创建一个pod-nodeselector.yaml文件，并使用它创建Pod\napiVersion: v1 kind: Pod metadata: name: pod-nodeselector namespace: dev spec: containers: - name: nginx image: nginx:1.17.1 nodeSelector: nodeenv: pro # 指定调度到具有nodeenv=pro标签的节点上 #创建Pod [root@k8s-master01 ~]# kubectl create -f pod-nodeselector.yaml pod/pod-nodeselector created #查看Pod调度到NODE属性，确实是调度到了node1节点上 [root@k8s-master01 ~]# kubectl get pods pod-nodeselector -n dev -o wide NAME READY STATUS RESTARTS AGE IP NODE ...... pod-nodeselector 1/1 Running 0 47s 10.244.1.87 node1 ...... # 接下来，删除pod，修改nodeSelector的值为nodeenv: xxxx（不存在打有此标签的节点） [root@k8s-master01 ~]# kubectl delete -f pod-nodeselector.yaml pod \u0026#34;pod-nodeselector\u0026#34; deleted [root@k8s-master01 ~]# vim pod-nodeselector.yaml [root@k8s-master01 ~]# kubectl create -f pod-nodeselector.yaml pod/pod-nodeselector created #再次查看，发现pod无法正常运行,Node的值为none [root@k8s-master01 ~]# kubectl get pods -n dev -o wide NAME READY STATUS RESTARTS AGE IP NODE pod-nodeselector 0/1 Pending 0 2m20s \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; # 查看详情,发现node selector匹配失败的提示 [root@k8s-master01 ~]# kubectl describe pods pod-nodeselector -n dev ....... Events: Type Reason Age From Message ---- ------ ---- ---- ------- Warning FailedScheduling \u0026lt;unknown\u0026gt; default-scheduler 0/3 nodes are available: 3 node(s) didn\u0026#39;t match node selector. 5.4.2 亲和性调度 上一节，介绍了两种定向调度的方式，使用起来非常方便，但是也有一定的问题，那就是如果没有满足条件的Node，那么Pod将不会被运行，即使在集群中还有可用Node列表也不行，这就限制了它的使用场景。\n基于上面的问题，kubernetes还提供了一种亲和性调度（Affinity）。它在NodeSelector的基础之上的进行了扩展，可以通过配置的形式，实现优先选择满足条件的Node进行调度，如果没有，也可以调度到不满足条件的节点上，使调度更加灵活。\nAffinity主要分为三类：\nnodeAffinity(node亲和性）: 以node为目标，解决pod可以调度到哪些node的问题 podAffinity(pod亲和性) : 以pod为目标，解决pod可以和哪些已存在的pod部署在同一个拓扑域中的问题 podAntiAffinity(pod反亲和性) : 以pod为目标，解决pod不能和哪些已存在pod部署在同一个拓扑域中的问题 关于亲和性(反亲和性)使用场景的说明：\n亲和性：如果两个应用频繁交互，那就有必要利用亲和性让两个应用的尽可能的靠近，这样可以减少因网络通信而带来的性能损耗。\n反亲和性：当应用的采用多副本部署时，有必要采用反亲和性让各个应用实例打散分布在各个node上，这样可以提高服务的高可用性。\nNodeAffinity\n首先来看一下NodeAffinity的可配置项：\npod.spec.affinity.nodeAffinity requiredDuringSchedulingIgnoredDuringExecution Node节点必须满足指定的所有规则才可以，相当于硬限制 nodeSelectorTerms 节点选择列表 matchFields 按节点字段列出的节点选择器要求列表 matchExpressions 按节点标签列出的节点选择器要求列表(推荐) key 键 values 值 operat or 关系符 支持Exists, DoesNotExist, In, NotIn, Gt, Lt preferredDuringSchedulingIgnoredDuringExecution 优先调度到满足指定的规则的Node，相当于软限制 (倾向) preference 一个节点选择器项，与相应的权重相关联 matchFields 按节点字段列出的节点选择器要求列表 matchExpressions 按节点标签列出的节点选择器要求列表(推荐) key 键 values 值 operator 关系符 支持In, NotIn, Exists, DoesNotExist, Gt, Lt weight 倾向权重，在范围1-100。 关系符的使用说明: - matchExpressions: - key: nodeenv # 匹配存在标签的key为nodeenv的节点 operator: Exists - key: nodeenv # 匹配标签的key为nodeenv,且value是\u0026#34;xxx\u0026#34;或\u0026#34;yyy\u0026#34;的节点 operator: In values: [\u0026#34;xxx\u0026#34;,\u0026#34;yyy\u0026#34;] - key: nodeenv # 匹配标签的key为nodeenv,且value大于\u0026#34;xxx\u0026#34;的节点 operator: Gt values: \u0026#34;xxx\u0026#34; 接下来首先演示一下requiredDuringSchedulingIgnoredDuringExecution ,\n创建pod-nodeaffinity-required.yaml\napiVersion: v1 kind: Pod metadata: name: pod-nodeaffinity-required namespace: dev spec: containers: - name: nginx image: nginx:1.17.1 affinity: #亲和性设置 nodeAffinity: #设置node亲和性 requiredDuringSchedulingIgnoredDuringExecution: # 硬限制 nodeSelectorTerms: - matchExpressions: # 匹配env的值在[\u0026#34;xxx\u0026#34;,\u0026#34;yyy\u0026#34;]中的标签 - key: nodeenv operator: In values: [\u0026#34;xxx\u0026#34;,\u0026#34;yyy\u0026#34;] # 创建pod [root@k8s-master01 ~]# kubectl create -f pod-nodeaffinity-required.yaml pod/pod-nodeaffinity-required created # 查看pod状态 （运行失败） [root@k8s-master01 ~]# kubectl get pods pod-nodeaffinity-required -n dev -o wide NAME READY STATUS RESTARTS AGE IP NODE ...... pod-nodeaffinity-required 0/1 Pending 0 16s \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; ...... # 查看Pod的详情 # 发现调度失败，提示node选择失败 [root@k8s-master01 ~]# kubectl describe pod pod-nodeaffinity-required -n dev ...... Warning FailedScheduling \u0026lt;unknown\u0026gt; default-scheduler 0/3 nodes are available: 3 node(s) didn\u0026#39;t match node selector. Warning FailedScheduling \u0026lt;unknown\u0026gt; default-scheduler 0/3 nodes are available: 3 node(s) didn\u0026#39;t match node selector. #接下来，停止pod [root@k8s-master01 ~]# kubectl delete -f pod-nodeaffinity-required.yaml pod \u0026#34;pod-nodeaffinity-required\u0026#34; deleted # 修改文件，将values: [\u0026#34;xxx\u0026#34;,\u0026#34;yyy\u0026#34;]------\u0026gt; [\u0026#34;pro\u0026#34;,\u0026#34;yyy\u0026#34;] [root@k8s-master01 ~]# vim pod-nodeaffinity-required.yaml # 再次启动 [root@k8s-master01 ~]# kubectl create -f pod-nodeaffinity-required.yaml pod/pod-nodeaffinity-required created # 此时查看，发现调度成功，已经将pod调度到了node1上 [root@k8s-master01 ~]# kubectl get pods pod-nodeaffinity-required -n dev -o wide NAME READY STATUS RESTARTS AGE IP NODE ...... pod-nodeaffinity-required 1/1 Running 0 11s 10.244.1.89 node1 ...... 接下来再演示一下requiredDuringSchedulingIgnoredDuringExecution ,\n创建pod-nodeaffinity-preferred.yaml\napiVersion: v1 kind: Pod metadata: name: pod-nodeaffinity-preferred namespace: dev spec: containers: - name: nginx image: nginx:1.17.1 affinity: #亲和性设置 nodeAffinity: #设置node亲和性 preferredDuringSchedulingIgnoredDuringExecution: # 软限制 - weight: 1 preference: matchExpressions: # 匹配env的值在[\u0026#34;xxx\u0026#34;,\u0026#34;yyy\u0026#34;]中的标签(当前环境没有) - key: nodeenv operator: In values: [\u0026#34;xxx\u0026#34;,\u0026#34;yyy\u0026#34;] # 创建pod [root@k8s-master01 ~]# kubectl create -f pod-nodeaffinity-preferred.yaml pod/pod-nodeaffinity-preferred created # 查看pod状态 （运行成功） [root@k8s-master01 ~]# kubectl get pod pod-nodeaffinity-preferred -n dev NAME READY STATUS RESTARTS AGE pod-nodeaffinity-preferred 1/1 Running 0 40s NodeAffinity规则设置的注意事项： 1 如果同时定义了nodeSelector和nodeAffinity，那么必须两个条件都得到满足，Pod才能运行在指定的Node上 2 如果nodeAffinity指定了多个nodeSelectorTerms，那么只需要其中一个能够匹配成功即可 3 如果一个nodeSelectorTerms中有多个matchExpressions ，则一个节点必须满足所有的才能匹配成功 4 如果一个pod所在的Node在Pod运行期间其标签发生了改变，不再符合该Pod的节点亲和性需求，则系统将忽略此变化 PodAffinity\nPodAffinity主要实现以运行的Pod为参照，实现让新创建的Pod跟参照pod在一个区域的功能。\n首先来看一下PodAffinity的可配置项：\npod.spec.affinity.podAffinity requiredDuringSchedulingIgnoredDuringExecution 硬限制 namespaces 指定参照pod的namespace topologyKey 指定调度作用域 labelSelector 标签选择器 matchExpressions 按节点标签列出的节点选择器要求列表(推荐) key 键 values 值 operator 关系符 支持In, NotIn, Exists, DoesNotExist. matchLabels 指多个matchExpressions映射的内容 preferredDuringSchedulingIgnoredDuringExecution 软限制 podAffinityTerm 选项 namespaces topologyKey labelSelector matchExpressions key 键 values 值 operator matchLabels weight 倾向权重，在范围1-100 topologyKey用于指定调度时作用域,例如: 如果指定为kubernetes.io/hostname，那就是以Node节点为区分范围 如果指定为beta.kubernetes.io/os,则以Node节点的操作系统类型来区分 接下来，演示下requiredDuringSchedulingIgnoredDuringExecution,\n1）首先创建一个参照Pod，pod-podaffinity-target.yaml：\napiVersion: v1 kind: Pod metadata: name: pod-podaffinity-target namespace: dev labels: podenv: pro #设置标签 spec: containers: - name: nginx image: nginx:1.17.1 nodeName: node1 # 将目标pod名确指定到node1上 # 启动目标pod [root@k8s-master01 ~]# kubectl create -f pod-podaffinity-target.yaml pod/pod-podaffinity-target created # 查看pod状况 [root@k8s-master01 ~]# kubectl get pods pod-podaffinity-target -n dev NAME READY STATUS RESTARTS AGE pod-podaffinity-target 1/1 Running 0 4s 2）创建pod-podaffinity-required.yaml，内容如下：\napiVersion: v1 kind: Pod metadata: name: pod-podaffinity-required namespace: dev spec: containers: - name: nginx image: nginx:1.17.1 affinity: #亲和性设置 podAffinity: #设置pod亲和性 requiredDuringSchedulingIgnoredDuringExecution: # 硬限制 - labelSelector: matchExpressions: # 匹配env的值在[\u0026#34;xxx\u0026#34;,\u0026#34;yyy\u0026#34;]中的标签 - key: podenv operator: In values: [\u0026#34;xxx\u0026#34;,\u0026#34;yyy\u0026#34;] topologyKey: kubernetes.io/hostname 上面配置表达的意思是：新Pod必须要与拥有标签nodeenv=xxx或者nodeenv=yyy的pod在同一Node上，显然现在没有这样pod，接下来，运行测试一下。\n# 启动pod [root@k8s-master01 ~]# kubectl create -f pod-podaffinity-required.yaml pod/pod-podaffinity-required created # 查看pod状态，发现未运行 [root@k8s-master01 ~]# kubectl get pods pod-podaffinity-required -n dev NAME READY STATUS RESTARTS AGE pod-podaffinity-required 0/1 Pending 0 9s # 查看详细信息 [root@k8s-master01 ~]# kubectl describe pods pod-podaffinity-required -n dev ...... Events: Type Reason Age From Message ---- ------ ---- ---- ------- Warning FailedScheduling \u0026lt;unknown\u0026gt; default-scheduler 0/3 nodes are available: 2 node(s) didn\u0026#39;t match pod affinity rules, 1 node(s) had taints that the pod didn\u0026#39;t tolerate. # 接下来修改 values: [\u0026#34;xxx\u0026#34;,\u0026#34;yyy\u0026#34;]-----\u0026gt;values:[\u0026#34;pro\u0026#34;,\u0026#34;yyy\u0026#34;] # 意思是：新Pod必须要与拥有标签nodeenv=xxx或者nodeenv=yyy的pod在同一Node上 [root@k8s-master01 ~]# vim pod-podaffinity-required.yaml # 然后重新创建pod，查看效果 [root@k8s-master01 ~]# kubectl delete -f pod-podaffinity-required.yaml pod \u0026#34;pod-podaffinity-required\u0026#34; de leted [root@k8s-master01 ~]# kubectl create -f pod-podaffinity-required.yaml pod/pod-podaffinity-required created # 发现此时Pod运行正常 [root@k8s-master01 ~]# kubectl get pods pod-podaffinity-required -n dev NAME READY STATUS RESTARTS AGE LABELS pod-podaffinity-required 1/1 Running 0 6s \u0026lt;none\u0026gt; 关于PodAffinity的 preferredDuringSchedulingIgnoredDuringExecution，这里不再演示。\nPodAntiAffinity\nPodAntiAffinity主要实现以运行的Pod为参照，让新创建的Pod跟参照pod不在一个区域中的功能。\n它的配置方式和选项跟PodAffinty是一样的，这里不再做详细解释，直接做一个测试案例。\n1）继续使用上个案例中目标pod\n[root@k8s-master01 ~]# kubectl get pods -n dev -o wide --show-labels NAME READY STATUS RESTARTS AGE IP NODE LABELS pod-podaffinity-required 1/1 Running 0 3m29s 10.244.1.38 node1 \u0026lt;none\u0026gt; pod-podaffinity-target 1/1 Running 0 9m25s 10.244.1.37 node1 podenv=pro 2）创建pod-podantiaffinity-required.yaml，内容如下：\napiVersion: v1 kind: Pod metadata: name: pod-podantiaffinity-required namespace: dev spec: containers: - name: nginx image: nginx:1.17.1 affinity: #亲和性设置 podAntiAffinity: #设置pod亲和性 requiredDuringSchedulingIgnoredDuringExecution: # 硬限制 - labelSelector: matchExpressions: # 匹配podenv的值在[\u0026#34;pro\u0026#34;]中的标签 - key: podenv operator: In values: [\u0026#34;pro\u0026#34;] topologyKey: kubernetes.io/hostname 上面配置表达的意思是：新Pod必须要与拥有标签nodeenv=pro的pod不在同一Node上，运行测试一下。\n# 创建pod [root@k8s-master01 ~]# kubectl create -f pod-podantiaffinity-required.yaml pod/pod-podantiaffinity-required created # 查看pod # 发现调度到了node2上 [root@k8s-master01 ~]# kubectl get pods pod-podantiaffinity-required -n dev -o wide NAME READY STATUS RESTARTS AGE IP NODE .. pod-podantiaffinity-required 1/1 Running 0 30s 10.244.1.96 node2 .. 5.4.3 污点和容忍 污点（Taints）\n前面的调度方式都是站在Pod的角度上，通过在Pod上添加属性，来确定Pod是否要调度到指定的Node上，其实我们也可以站在Node的角度上，通过在Node上添加污点属性，来决定是否允许Pod调度过来。\nNode被设置上污点之后就和Pod之间存在了一种相斥的关系，进而拒绝Pod调度进来，甚至可以将已经存在的Pod驱逐出去。\n污点的格式为：key=value:effect, key和value是污点的标签，effect描述污点的作用，支持如下三个选项：\nPreferNoSchedule：kubernetes将尽量避免把Pod调度到具有该污点的Node上，除非没有其他节点可调度 NoSchedule：kubernetes将不会把Pod调度到具有该污点的Node上，但不会影响当前Node上已存在的Pod NoExecute：kubernetes将不会把Pod调度到具有该污点的Node上，同时也会将Node上已存在的Pod驱离 使用kubectl设置和去除污点的命令示例如下：\n# 设置污点 kubectl taint nodes node1 key=value:effect # 去除污点 kubectl taint nodes node1 key:effect- # 去除所有污点 kubectl taint nodes node1 key- 接下来，演示下污点的效果：\n准备节点node1（为了演示效果更加明显，暂时停止node2节点） 为node1节点设置一个污点: tag=heima:PreferNoSchedule；然后创建pod1( pod1 可以 ) 修改为node1节点设置一个污点: tag=heima:NoSchedule；然后创建pod2( pod1 正常 pod2 失败 ) 修改为node1节点设置一个污点: tag=heima:NoExecute；然后创建pod3 ( 3个pod都失败 ) # 为node1设置污点(PreferNoSchedule) [root@k8s-master01 ~]# kubectl taint nodes node1 tag=heima:PreferNoSchedule # 创建pod1 [root@k8s-master01 ~]# kubectl run taint1 --image=nginx:1.17.1 -n dev [root@k8s-master01 ~]# kubectl get pods -n dev -o wide NAME READY STATUS RESTARTS AGE IP NODE taint1-7665f7fd85-574h4 1/1 Running 0 2m24s 10.244.1.59 node1 # 为node1设置污点(取消PreferNoSchedule，设置NoSchedule) [root@k8s-master01 ~]# kubectl taint nodes node1 tag:PreferNoSchedule- [root@k8s-master01 ~]# kubectl taint nodes node1 tag=heima:NoSchedule # 创建pod2 [root@k8s-master01 ~]# kubectl run taint2 --image=nginx:1.17.1 -n dev [root@k8s-master01 ~]# kubectl get pods taint2 -n dev -o wide NAME READY STATUS RESTARTS AGE IP NODE taint1-7665f7fd85-574h4 1/1 Running 0 2m24s 10.244.1.59 node1 taint2-544694789-6zmlf 0/1 Pending 0 21s \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; # 为node1设置污点(取消NoSchedule，设置NoExecute) [root@k8s-master01 ~]# kubectl taint nodes node1 tag:NoSchedule- [root@k8s-master01 ~]# kubectl taint nodes node1 tag=heima:NoExecute # 创建pod3 [root@k8s-master01 ~]# kubectl run taint3 --image=nginx:1.17.1 -n dev [root@k8s-master01 ~]# kubectl get pods -n dev -o wide NAME READY STATUS RESTARTS AGE IP NODE NOMINATED taint1-7665f7fd85-htkmp 0/1 Pending 0 35s \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; taint2-544694789-bn7wb 0/1 Pending 0 35s \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; taint3-6d78dbd749-tktkq 0/1 Pending 0 6s \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; 小提示： 使用kubeadm搭建的集群，默认就会给master节点添加一个污点标记,所以pod就不会调度到master节点上. 容忍（Toleration）\n上面介绍了污点的作用，我们可以在node上添加污点用于拒绝pod调度上来，但是如果就是想将一个pod调度到一个有污点的node上去，这时候应该怎么做呢？这就要使用到容忍。\n污点就是拒绝，容忍就是忽略，Node通过污点拒绝pod调度上去，Pod通过容忍忽略拒绝\n下面先通过一个案例看下效果：\n上一小节，已经在node1节点上打上了NoExecute的污点，此时pod是调度不上去的 本小节，可以通过给pod添加容忍，然后将其调度上去 创建pod-toleration.yaml,内容如下\napiVersion: v1 kind: Pod metadata: name: pod-toleration namespace: dev spec: containers: - name: nginx image: nginx:1.17.1 tolerations: # 添加容忍 - key: \u0026#34;tag\u0026#34; # 要容忍的污点的key operator: \u0026#34;Equal\u0026#34; # 操作符 value: \u0026#34;heima\u0026#34; # 容忍的污点的value effect: \u0026#34;NoExecute\u0026#34; # 添加容忍的规则，这里必须和标记的污点规则相同 # 添加容忍之前的pod [root@k8s-master01 ~]# kubectl get pods -n dev -o wide NAME READY STATUS RESTARTS AGE IP NODE NOMINATED pod-toleration 0/1 Pending 0 3s \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; # 添加容忍之后的pod [root@k8s-master01 ~]# kubectl get pods -n dev -o wide NAME READY STATUS RESTARTS AGE IP NODE NOMINATED pod-toleration 1/1 Running 0 3s 10.244.1.62 node1 \u0026lt;none\u0026gt; 下面看一下容忍的详细配置:\n[root@k8s-master01 ~]# kubectl explain pod.spec.tolerations ...... FIELDS: key # 对应着要容忍的污点的键，空意味着匹配所有的键 value # 对应着要容忍的污点的值 operator # key-value的运算符，支持Equal和Exists（默认） effect # 对应污点的effect，空意味着匹配所有影响 tolerationSeconds # 容忍时间, 当effect为NoExecute时生效，表示pod在Node上的停留时间 6. Pod控制器详解 6.1 Pod控制器介绍 Pod是kubernetes的最小管理单元，在kubernetes中，按照pod的创建方式可以将其分为两类：\n自主式pod：kubernetes直接创建出来的Pod，这种pod删除后就没有了，也不会重建 控制器创建的pod：kubernetes通过控制器创建的pod，这种pod删除了之后还会自动重建 什么是Pod控制器\nPod控制器是管理pod的中间层，使用Pod控制器之后，只需要告诉Pod控制器，想要多少个什么样的Pod就可以了，它会创建出满足条件的Pod并确保每一个Pod资源处于用户期望的目标状态。如果Pod资源在运行中出现故障，它会基于指定策略重新编排Pod。\n在kubernetes中，有很多类型的pod控制器，每种都有自己的适合的场景，常见的有下面这些：\nReplicationController：比较原始的pod控制器，已经被废弃，由ReplicaSet替代 ReplicaSet：保证副本数量一直维持在期望值，并支持pod数量扩缩容，镜像版本升级 Deployment：通过控制ReplicaSet来控制Pod，并支持滚动升级、回退版本 Horizontal Pod Autoscaler：可以根据集群负载自动水平调整Pod的数量，实现削峰填谷 DaemonSet：在集群中的指定Node上运行且仅运行一个副本，一般用于守护进程类的任务 Job：它创建出来的pod只要完成任务就立即退出，不需要重启或重建，用于执行一次性任务 Cronjob：它创建的Pod负责周期性任务控制，不需要持续后台运行 StatefulSet：管理有状态应用 6.2 ReplicaSet(RS) ReplicaSet的主要作用是保证一定数量的pod正常运行，它会持续监听这些Pod的运行状态，一旦Pod发生故障，就会重启或重建。同时它还支持对pod数量的扩缩容和镜像版本的升降级。\nReplicaSet的资源清单文件：\napiVersion: apps/v1 # 版本号 kind: ReplicaSet # 类型 metadata: # 元数据 name: # rs名称 namespace: # 所属命名空间 labels: #标签 controller: rs spec: # 详情描述 replicas: 3 # 副本数量 selector: # 选择器，通过它指定该控制器管理哪些pod matchLabels: # Labels匹配规则 app: nginx-pod matchExpressions: # Expressions匹配规则 - {key: app, operator: In, values: [nginx-pod]} template: # 模板，当副本数量不足时，会根据下面的模板创建pod副本 metadata: labels: app: nginx-pod spec: containers: - name: nginx image: nginx:1.17.1 ports: - containerPort: 80 在这里面，需要新了解的配置项就是spec下面几个选项：\nreplicas：指定副本数量，其实就是当前rs创建出来的pod的数量，默认为1\nselector：选择器，它的作用是建立pod控制器和pod之间的关联关系，采用的Label Selector机制\n在pod模板上定义label，在控制器上定义选择器，就可以表明当前控制器能管理哪些pod了\ntemplate：模板，就是当前控制器创建pod所使用的模板板，里面其实就是前一章学过的pod的定义\n创建ReplicaSet\n创建pc-replicaset.yaml文件，内容如下：\napiVersion: apps/v1 kind: ReplicaSet metadata: name: pc-replicaset namespace: dev spec: replicas: 3 selector: matchLabels: app: nginx-pod template: metadata: labels: app: nginx-pod spec: containers: - name: nginx image: nginx:1.17.1 # 创建rs [root@k8s-master01 ~]# kubectl create -f pc-replicaset.yaml replicaset.apps/pc-replicaset created # 查看rs # DESIRED:期望副本数量 # CURRENT:当前副本数量 # READY:已经准备好提供服务的副本数量 [root@k8s-master01 ~]# kubectl get rs pc-replicaset -n dev -o wide NAME DESIRED CURRENT READY AGE CONTAINERS IMAGES SELECTOR pc-replicaset 3 3 3 22s nginx nginx:1.17.1 app=nginx-pod # 查看当前控制器创建出来的pod # 这里发现控制器创建出来的pod的名称是在控制器名称后面拼接了-xxxxx随机码 [root@k8s-master01 ~]# kubectl get pod -n dev NAME READY STATUS RESTARTS AGE pc-replicaset-6vmvt 1/1 Running 0 54s pc-replicaset-fmb8f 1/1 Running 0 54s pc-replicaset-snrk2 1/1 Running 0 54s 扩缩容\n# 编辑rs的副本数量，修改spec:replicas: 6即可 [root@k8s-master01 ~]# kubectl edit rs pc-replicaset -n dev replicaset.apps/pc-replicaset edited # 查看pod [root@k8s-master01 ~]# kubectl get pods -n dev NAME READY STATUS RESTARTS AGE pc-replicaset-6vmvt 1/1 Running 0 114m pc-replicaset-cftnp 1/1 Running 0 10s pc-replicaset-fjlm6 1/1 Running 0 10s pc-replicaset-fmb8f 1/1 Running 0 114m pc-replicaset-s2whj 1/1 Running 0 10s pc-replicaset-snrk2 1/1 Running 0 114m # 当然也可以直接使用命令实现 # 使用scale命令实现扩缩容， 后面--replicas=n直接指定目标数量即可 [root@k8s-master01 ~]# kubectl scale rs pc-replicaset --replicas=2 -n dev replicaset.apps/pc-replicaset scaled # 命令运行完毕，立即查看，发现已经有4个开始准备退出了 [root@k8s-master01 ~]# kubectl get pods -n dev NAME READY STATUS RESTARTS AGE pc-replicaset-6vmvt 0/1 Terminating 0 118m pc-replicaset-cftnp 0/1 Terminating 0 4m17s pc-replicaset-fjlm6 0/1 Terminating 0 4m17s pc-replicaset-fmb8f 1/1 Running 0 118m pc-replicaset-s2whj 0/1 Terminating 0 4m17s pc-replicaset-snrk2 1/1 Running 0 118m #稍等片刻，就只剩下2个了 [root@k8s-master01 ~]# kubectl get pods -n dev NAME READY STATUS RESTARTS AGE pc-replicaset-fmb8f 1/1 Running 0 119m pc-replicaset-snrk2 1/1 Running 0 119m 镜像升级\n# 编辑rs的容器镜像 - image: nginx:1.17.2 [root@k8s-master01 ~]# kubectl edit rs pc-replicaset -n dev replicaset.apps/pc-replicaset edited # 再次查看，发现镜像版本已经变更了 [root@k8s-master01 ~]# kubectl get rs -n dev -o wide NAME DESIRED CURRENT READY AGE CONTAINERS IMAGES ... pc-replicaset 2 2 2 140m nginx nginx:1.17.2 ... # 同样的道理，也可以使用命令完成这个工作 # kubectl set image rs rs名称 容器=镜像版本 -n namespace [root@k8s-master01 ~]# kubectl set image rs pc-replicaset nginx=nginx:1.17.1 -n dev replicaset.apps/pc-replicaset image updated # 再次查看，发现镜像版本已经变更了 [root@k8s-master01 ~]# kubectl get rs -n dev -o wide NAME DESIRED CURRENT READY AGE CONTAINERS IMAGES ... pc-replicaset 2 2 2 145m nginx nginx:1.17.1 ... 删除ReplicaSet\n# 使用kubectl delete命令会删除此RS以及它管理的Pod # 在kubernetes删除RS前，会将RS的replicasclear调整为0，等待所有的Pod被删除后，在执行RS对象的删除 [root@k8s-master01 ~]# kubectl delete rs pc-replicaset -n dev replicaset.apps \u0026#34;pc-replicaset\u0026#34; deleted [root@k8s-master01 ~]# kubectl get pod -n dev -o wide No resources found in dev namespace. # 如果希望仅仅删除RS对象（保留Pod），可以使用kubectl delete命令时添加--cascade=false选项（不推荐）。 [root@k8s-master01 ~]# kubectl delete rs pc-replicaset -n dev --cascade=false replicaset.apps \u0026#34;pc-replicaset\u0026#34; deleted [root@k8s-master01 ~]# kubectl get pods -n dev NAME READY STATUS RESTARTS AGE pc-replicaset-cl82j 1/1 Running 0 75s pc-replicaset-dslhb 1/1 Running 0 75s # 也可以使用yaml直接删除(推荐) [root@k8s-master01 ~]# kubectl delete -f pc-replicaset.yaml replicaset.apps \u0026#34;pc-replicaset\u0026#34; deleted 6.3 Deployment(Deploy) 为了更好的解决服务编排的问题，kubernetes在V1.2版本开始，引入了Deployment控制器。值得一提的是，这种控制器并不直接管理pod，而是通过管理ReplicaSet来简介管理Pod，即：Deployment管理ReplicaSet，ReplicaSet管理Pod。所以Deployment比ReplicaSet功能更加强大。\nDeployment主要功能有下面几个：\n支持ReplicaSet的所有功能 支持发布的停止、继续 支持滚动升级和回滚版本 Deployment的资源清单文件：\napiVersion: apps/v1 # 版本号 kind: Deployment # 类型 metadata: # 元数据 name: # rs名称 namespace: # 所属命名空间 labels: #标签 controller: deploy spec: # 详情描述 replicas: 3 # 副本数量 revisionHistoryLimit: 3 # 保留历史版本 paused: false # 暂停部署，默认是false progressDeadlineSeconds: 600 # 部署超时时间（s），默认是600 strategy: # 策略 type: RollingUpdate # 滚动更新策略 rollingUpdate: # 滚动更新 max违规词汇: 30% # 最大额外可以存在的副本数，可以为百分比，也可以为整数 maxUnavailable: 30% # 最大不可用状态的 Pod 的最大值，可以为百分比，也可以为整数 selector: # 选择器，通过它指定该控制器管理哪些pod matchLabels: # Labels匹配规则 app: nginx-pod matchExpressions: # Expressions匹配规则 - {key: app, operator: In, values: [nginx-pod]} template: # 模板，当副本数量不足时，会根据下面的模板创建pod副本 metadata: labels: app: nginx-pod spec: containers: - name: nginx image: nginx:1.17.1 ports: - containerPort: 80 6.3.1 创建deployment 创建pc-deployment.yaml，内容如下：\napiVersion: apps/v1 kind: Deployment metadata: name: pc-deployment namespace: dev spec: replicas: 3 selector: matchLabels: app: nginx-pod template: metadata: labels: app: nginx-pod spec: containers: - name: nginx image: nginx:1.17.1 # 创建deployment [root@k8s-master01 ~]# kubectl create -f pc-deployment.yaml --record=true deployment.apps/pc-deployment created # 查看deployment # UP-TO-DATE 最新版本的pod的数量 # AVAILABLE 当前可用的pod的数量 [root@k8s-master01 ~]# kubectl get deploy pc-deployment -n dev NAME READY UP-TO-DATE AVAILABLE AGE pc-deployment 3/3 3 3 15s # 查看rs # 发现rs的名称是在原来deployment的名字后面添加了一个10位数的随机串 [root@k8s-master01 ~]# kubectl get rs -n dev NAME DESIRED CURRENT READY AGE pc-deployment-6696798b78 3 3 3 23s # 查看pod [root@k8s-master01 ~]# kubectl get pods -n dev NAME READY STATUS RESTARTS AGE pc-deployment-6696798b78-d2c8n 1/1 Running 0 107s pc-deployment-6696798b78-smpvp 1/1 Running 0 107s pc-deployment-6696798b78-wvjd8 1/1 Running 0 107s 6.3.2 扩缩容 # 变更副本数量为5个 [root@k8s-master01 ~]# kubectl scale deploy pc-deployment --replicas=5 -n dev deployment.apps/pc-deployment scaled # 查看deployment [root@k8s-master01 ~]# kubectl get deploy pc-deployment -n dev NAME READY UP-TO-DATE AVAILABLE AGE pc-deployment 5/5 5 5 2m # 查看pod [root@k8s-master01 ~]# kubectl get pods -n dev NAME READY STATUS RESTARTS AGE pc-deployment-6696798b78-d2c8n 1/1 Running 0 4m19s pc-deployment-6696798b78-jxmdq 1/1 Running 0 94s pc-deployment-6696798b78-mktqv 1/1 Running 0 93s pc-deployment-6696798b78-smpvp 1/1 Running 0 4m19s pc-deployment-6696798b78-wvjd8 1/1 Running 0 4m19s # 编辑deployment的副本数量，修改spec:replicas: 4即可 [root@k8s-master01 ~]# kubectl edit deploy pc-deployment -n dev deployment.apps/pc-deployment edited # 查看pod [root@k8s-master01 ~]# kubectl get pods -n dev NAME READY STATUS RESTARTS AGE pc-deployment-6696798b78-d2c8n 1/1 Running 0 5m23s pc-deployment-6696798b78-jxmdq 1/1 Running 0 2m38s pc-deployment-6696798b78-smpvp 1/1 Running 0 5m23s pc-deployment-6696798b78-wvjd8 1/1 Running 0 5m23s 镜像更新\ndeployment支持两种更新策略:重建更新和滚动更新,可以通过strategy指定策略类型,支持两个属性:\nstrategy：指定新的Pod替换旧的Pod的策略， 支持两个属性： type：指定策略类型，支持两种策略 Recreate：在创建出新的Pod之前会先杀掉所有已存在的Pod RollingUpdate：滚动更新，就是杀死一部分，就启动一部分，在更新过程中，存在两个版本Pod rollingUpdate：当type为RollingUpdate时生效，用于为RollingUpdate设置参数，支持两个属性： maxUnavailable：用来指定在升级过程中不可用Pod的最大数量，默认为25%。 max违规词汇： 用来指定在升级过程中可以超过期望的Pod的最大数量，默认为25%。 重建更新\n编辑pc-deployment.yaml,在spec节点下添加更新策略 spec: strategy: # 策略 type: Recreate # 重建更新 创建deploy进行验证\n# 变更镜像 [root@k8s-master01 ~]# kubectl set image deployment pc-deployment nginx=nginx:1.17.2 -n dev deployment.apps/pc-deployment image updated # 观察升级过程 [root@k8s-master01 ~]# kubectl get pods -n dev -w NAME READY STATUS RESTARTS AGE pc-deployment-5d89bdfbf9-65qcw 1/1 Running 0 31s pc-deployment-5d89bdfbf9-w5nzv 1/1 Running 0 31s pc-deployment-5d89bdfbf9-xpt7w 1/1 Running 0 31s pc-deployment-5d89bdfbf9-xpt7w 1/1 Terminating 0 41s pc-deployment-5d89bdfbf9-65qcw 1/1 Terminating 0 41s pc-deployment-5d89bdfbf9-w5nzv 1/1 Terminating 0 41s pc-deployment-675d469f8b-grn8z 0/1 Pending 0 0s pc-deployment-675d469f8b-hbl4v 0/1 Pending 0 0s pc-deployment-675d469f8b-67nz2 0/1 Pending 0 0s pc-deployment-675d469f8b-grn8z 0/1 ContainerCreating 0 0s pc-deployment-675d469f8b-hbl4v 0/1 ContainerCreating 0 0s pc-deployment-675d469f8b-67nz2 0/1 ContainerCreating 0 0s pc-deployment-675d469f8b-grn8z 1/1 Running 0 1s pc-deployment-675d469f8b-67nz2 1/1 Running 0 1s pc-deployment-675d469f8b-hbl4v 1/1 Running 0 2s 滚动更新\n编辑pc-deployment.yaml,在spec节点下添加更新策略 spec: strategy: # 策略 type: RollingUpdate # 滚动更新策略 rollingUpdate: max违规词汇: 25% maxUnavailable: 25% 创建deploy进行验证\n# 变更镜像 [root@k8s-master01 ~]# kubectl set image deployment pc-deployment nginx=nginx:1.17.3 -n dev deployment.apps/pc-deployment image updated # 观察升级过程 [root@k8s-master01 ~]# kubectl get pods -n dev -w NAME READY STATUS RESTARTS AGE pc-deployment-c848d767-8rbzt 1/1 Running 0 31m pc-deployment-c848d767-h4p68 1/1 Running 0 31m pc-deployment-c848d767-hlmz4 1/1 Running 0 31m pc-deployment-c848d767-rrqcn 1/1 Running 0 31m pc-deployment-966bf7f44-226rx 0/1 Pending 0 0s pc-deployment-966bf7f44-226rx 0/1 ContainerCreating 0 0s pc-deployment-966bf7f44-226rx 1/1 Running 0 1s pc-deployment-c848d767-h4p68 0/1 Terminating 0 34m pc-deployment-966bf7f44-cnd44 0/1 Pending 0 0s pc-deployment-966bf7f44-cnd44 0/1 ContainerCreating 0 0s pc-deployment-966bf7f44-cnd44 1/1 Running 0 2s pc-deployment-c848d767-hlmz4 0/1 Terminating 0 34m pc-deployment-966bf7f44-px48p 0/1 Pending 0 0s pc-deployment-966bf7f44-px48p 0/1 ContainerCreating 0 0s pc-deployment-966bf7f44-px48p 1/1 Running 0 0s pc-deployment-c848d767-8rbzt 0/1 Terminating 0 34m pc-deployment-966bf7f44-dkmqp 0/1 Pending 0 0s pc-deployment-966bf7f44-dkmqp 0/1 ContainerCreating 0 0s pc-deployment-966bf7f44-dkmqp 1/1 Running 0 2s pc-deployment-c848d767-rrqcn 0/1 Terminating 0 34m # 至此，新版本的pod创建完毕，就版本的pod销毁完毕 # 中间过程是滚动进行的，也就是边销毁边创建 滚动更新的过程：\n镜像更新中rs的变化\n# 查看rs,发现原来的rs的依旧存在，只是pod数量变为了0，而后又新产生了一个rs，pod数量为4 # 其实这就是deployment能够进行版本回退的奥妙所在，后面会详细解释 [root@k8s-master01 ~]# kubectl get rs -n dev NAME DESIRED CURRENT READY AGE pc-deployment-6696798b78 0 0 0 7m37s pc-deployment-6696798b11 0 0 0 5m37s pc-deployment-c848d76789 4 4 4 72s 6.3.3 版本回退 deployment支持版本升级过程中的暂停、继续功能以及版本回退等诸多功能，下面具体来看.\nkubectl rollout： 版本升级相关功能，支持下面的选项：\nstatus 显示当前升级状态 history 显示 升级历史记录 pause 暂停版本升级过程 resume 继续已经暂停的版本升级过程 restart 重启版本升级过程 undo 回滚到上一级版本（可以使用\u0026ndash;to-revision回滚到指定版本） # 查看当前升级版本的状态 [root@k8s-master01 ~]# kubectl rollout status deploy pc-deployment -n dev deployment \u0026#34;pc-deployment\u0026#34; successfully rolled out # 查看升级历史记录 [root@k8s-master01 ~]# kubectl rollout history deploy pc-deployment -n dev deployment.apps/pc-deployment REVISION CHANGE-CAUSE 1 kubectl create --filename=pc-deployment.yaml --record=true 2 kubectl create --filename=pc-deployment.yaml --record=true 3 kubectl create --filename=pc-deployment.yaml --record=true # 可以发现有三次版本记录，说明完成过两次升级 # 版本回滚 # 这里直接使用--to-revision=1回滚到了1版本， 如果省略这个选项，就是回退到上个版本，就是2版本 [root@k8s-master01 ~]# kubectl rollout undo deployment pc-deployment --to-revision=1 -n dev deployment.apps/pc-deployment rolled back # 查看发现，通过nginx镜像版本可以发现到了第一版 [root@k8s-master01 ~]# kubectl get deploy -n dev -o wide NAME READY UP-TO-DATE AVAILABLE AGE CONTAINERS IMAGES pc-deployment 4/4 4 4 74m nginx nginx:1.17.1 # 查看rs，发现第一个rs中有4个pod运行，后面两个版本的rs中pod为运行 # 其实deployment之所以可是实现版本的回滚，就是通过记录下历史rs来实现的， # 一旦想回滚到哪个版本，只需要将当前版本pod数量降为0，然后将回滚版本的pod提升为目标数量就可以了 [root@k8s-master01 ~]# kubectl get rs -n dev NAME DESIRED CURRENT READY AGE pc-deployment-6696798b78 4 4 4 78m pc-deployment-966bf7f44 0 0 0 37m pc-deployment-c848d767 0 0 0 71m 6.3.4 金丝雀发布 Deployment控制器支持控制更新过程中的控制，如“暂停(pause)”或“继续(resume)”更新操作。\n比如有一批新的Pod资源创建完成后立即暂停更新过程，此时，仅存在一部分新版本的应用，主体部分还是旧的版本。然后，再筛选一小部分的用户请求路由到新版本的Pod应用，继续观察能否稳定地按期望的方式运行。确定没问题之后再继续完成余下的Pod资源滚动更新，否则立即回滚更新操作。这就是所谓的金丝雀发布。\n# 更新deployment的版本，并配置暂停deployment [root@k8s-master01 ~]# kubectl set image deploy pc-deployment nginx=nginx:1.17.4 -n dev \u0026amp;\u0026amp; kubectl rollout pause deployment pc-deployment -n dev deployment.apps/pc-deployment image updated deployment.apps/pc-deployment paused #观察更新状态 [root@k8s-master01 ~]# kubectl rollout status deploy pc-deployment -n dev　Waiting for deployment \u0026#34;pc-deployment\u0026#34; rollout to finish: 2 out of 4 new replicas have been updated... # 监控更新的过程，可以看到已经新增了一个资源，但是并未按照预期的状态去删除一个旧的资源，就是因为使用了pause暂停命令 [root@k8s-master01 ~]# kubectl get rs -n dev -o wide NAME DESIRED CURRENT READY AGE CONTAINERS IMAGES pc-deployment-5d89bdfbf9 3 3 3 19m nginx nginx:1.17.1 pc-deployment-675d469f8b 0 0 0 14m nginx nginx:1.17.2 pc-deployment-6c9f56fcfb 2 2 2 3m16s nginx nginx:1.17.4 [root@k8s-master01 ~]# kubectl get pods -n dev NAME READY STATUS RESTARTS AGE pc-deployment-5d89bdfbf9-rj8sq 1/1 Running 0 7m33s pc-deployment-5d89bdfbf9-ttwgg 1/1 Running 0 7m35s pc-deployment-5d89bdfbf9-v4wvc 1/1 Running 0 7m34s pc-deployment-6c9f56fcfb-996rt 1/1 Running 0 3m31s pc-deployment-6c9f56fcfb-j2gtj 1/1 Running 0 3m31s # 确保更新的pod没问题了，继续更新 [root@k8s-master01 ~]# kubectl rollout resume deploy pc-deployment -n dev deployment.apps/pc-deployment resumed # 查看最后的更新情况 [root@k8s-master01 ~]# kubectl get rs -n dev -o wide NAME DESIRED CURRENT READY AGE CONTAINERS IMAGES pc-deployment-5d89bdfbf9 0 0 0 21m nginx nginx:1.17.1 pc-deployment-675d469f8b 0 0 0 16m nginx nginx:1.17.2 pc-deployment-6c9f56fcfb 4 4 4 5m11s nginx nginx:1.17.4 [root@k8s-master01 ~]# kubectl get pods -n dev NAME READY STATUS RESTARTS AGE pc-deployment-6c9f56fcfb-7bfwh 1/1 Running 0 37s pc-deployment-6c9f56fcfb-996rt 1/1 Running 0 5m27s pc-deployment-6c9f56fcfb-j2gtj 1/1 Running 0 5m27s pc-deployment-6c9f56fcfb-rf84v 1/1 Running 0 37s 删除Deployment\n# 删除deployment，其下的rs和pod也将被删除 [root@k8s-master01 ~]# kubectl delete -f pc-deployment.yaml deployment.apps \u0026#34;pc-deployment\u0026#34; deleted 6.4 Horizontal Pod Autoscaler(HPA) 在前面的课程中，我们已经可以实现通过手工执行kubectl scale命令实现Pod扩容或缩容，但是这显然不符合Kubernetes的定位目标\u0026ndash;自动化、智能化。 Kubernetes期望可以实现通过监测Pod的使用情况，实现pod数量的自动调整，于是就产生了Horizontal Pod Autoscaler（HPA）这种控制器。\nHPA可以获取每个Pod利用率，然后和HPA中定义的指标进行对比，同时计算出需要伸缩的具体值，最后实现Pod的数量的调整。其实HPA与之前的Deployment一样，也属于一种Kubernetes资源对象，它通过追踪分析RC控制的所有目标Pod的负载变化情况，来确定是否需要针对性地调整目标Pod的副本数，这是HPA的实现原理。\n接下来，我们来做一个实验\n6.4.1 安装metrics-server metrics-server可以用来收集集群中的资源使用情况\n# 安装git [root@k8s-master01 ~]# yum install git -y # 获取metrics-server, 注意使用的版本 [root@k8s-master01 ~]# git clone -b v0.3.6 https:/github.com/kubernetes-incubator/metrics-server # 修改deployment, 注意修改的是镜像和初始化参数 [root@k8s-master01 ~]# cd /root/metrics-server/deploy/1.8+/ [root@k8s-master01 1.8+]# vim metrics-server-deployment.yaml 按图中添加下面选项 hostNetwork: true image: registry.cn-hangzhou.aliyuncs.com/google_containers/metrics-server-amd64:v0.3.6 args: - --kubelet-insecure-tls - --kubelet-preferred-address-types=InternalIP,Hostname,InternalDNS,ExternalDNS,ExternalIP # 安装metrics-server [root@k8s-master01 1.8+]# kubectl apply -f ./ # 查看pod运行情况 [root@k8s-master01 1.8+]# kubectl get pod -n kube-system metrics-server-6b976979db-2xwbj 1/1 Running 0 90s # 使用kubectl top node 查看资源使用情况 [root@k8s-master01 1.8+]# kubectl top node NAME CPU(cores) CPU% MEMORY(bytes) MEMORY% k8s-master01 289m 14% 1582Mi 54% k8s-node01 81m 4% 1195Mi 40% k8s-node02 72m 3% 1211Mi 41% [root@k8s-master01 1.8+]# kubectl top pod -n kube-system NAME CPU(cores) MEMORY(bytes) coredns-6955765f44-7ptsb 3m 9Mi coredns-6955765f44-vcwr5 3m 8Mi etcd-master 14m 145Mi ... # 至此,metrics-server安装完成 6.4.2 准备deployment和servie 创建pc-hpa-pod.yaml文件，内容如下：\napiVersion: apps/v1 kind: Deployment metadata: name: nginx namespace: dev spec: strategy: # 策略 type: RollingUpdate # 滚动更新策略 replicas: 1 selector: matchLabels: app: nginx-pod template: metadata: labels: app: nginx-pod spec: containers: - name: nginx image: nginx:1.17.1 resources: # 资源配额 limits: # 限制资源（上限） cpu: \u0026#34;1\u0026#34; # CPU限制，单位是core数 requests: # 请求资源（下限） cpu: \u0026#34;100m\u0026#34; # CPU限制，单位是core数 # 创建deployment [root@k8s-master01 1.8+]# kubectl run nginx --image=nginx:1.17.1 --requests=cpu=100m -n dev # 创建service [root@k8s-master01 1.8+]# kubectl expose deployment nginx --type=NodePort --port=80 -n dev # 查看 [root@k8s-master01 1.8+]# kubectl get deployment,pod,svc -n dev NAME READY UP-TO-DATE AVAILABLE AGE deployment.apps/nginx 1/1 1 1 47s NAME READY STATUS RESTARTS AGE pod/nginx-7df9756ccc-bh8dr 1/1 Running 0 47s NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/nginx NodePort 10.101.18.29 \u0026lt;none\u0026gt; 80:31830/TCP 35s 6.4.3 部署HPA 创建pc-hpa.yaml文件，内容如下：\napiVersion: autoscaling/v1 kind: HorizontalPodAutoscaler metadata: name: pc-hpa namespace: dev spec: minReplicas: 1 #最小pod数量 maxReplicas: 10 #最大pod数量 targetCPUUtilizationPercentage: 3 # CPU使用率指标 scaleTargetRef: # 指定要控制的nginx信息 apiVersion: /v1 kind: Deployment name: nginx # 创建hpa [root@k8s-master01 1.8+]# kubectl create -f pc-hpa.yaml horizontalpodautoscaler.autoscaling/pc-hpa created # 查看hpa [root@k8s-master01 1.8+]# kubectl get hpa -n dev NAME REFERENCE TARGETS MINPODS MAXPODS REPLICAS AGE pc-hpa Deployment/nginx 0%/3% 1 10 1 62s 6.4.4 测试 使用压测工具对service地址192.168.5.4:31830进行压测，然后通过控制台查看hpa和pod的变化\nhpa变化\n[root@k8s-master01 ~]# kubectl get hpa -n dev -w NAME REFERENCE TARGETS MINPODS MAXPODS REPLICAS AGE pc-hpa Deployment/nginx 0%/3% 1 10 1 4m11s pc-hpa Deployment/nginx 0%/3% 1 10 1 5m19s pc-hpa Deployment/nginx 22%/3% 1 10 1 6m50s pc-hpa Deployment/nginx 22%/3% 1 10 4 7m5s pc-hpa Deployment/nginx 22%/3% 1 10 8 7m21s pc-hpa Deployment/nginx 6%/3% 1 10 8 7m51s pc-hpa Deployment/nginx 0%/3% 1 10 8 9m6s pc-hpa Deployment/nginx 0%/3% 1 10 8 13m pc-hpa Deployment/nginx 0%/3% 1 10 1 14m deployment变化\n[root@k8s-master01 ~]# kubectl get deployment -n dev -w NAME READY UP-TO-DATE AVAILABLE AGE nginx 1/1 1 1 11m nginx 1/4 1 1 13m nginx 1/4 1 1 13m nginx 1/4 1 1 13m nginx 1/4 4 1 13m nginx 1/8 4 1 14m nginx 1/8 4 1 14m nginx 1/8 4 1 14m nginx 1/8 8 1 14m nginx 2/8 8 2 14m nginx 3/8 8 3 14m nginx 4/8 8 4 14m nginx 5/8 8 5 14m nginx 6/8 8 6 14m nginx 7/8 8 7 14m nginx 8/8 8 8 15m nginx 8/1 8 8 20m nginx 8/1 8 8 20m nginx 1/1 1 1 20m pod变化\n[root@k8s-master01 ~]# kubectl get pods -n dev -w NAME READY STATUS RESTARTS AGE nginx-7df9756ccc-bh8dr 1/1 Running 0 11m nginx-7df9756ccc-cpgrv 0/1 Pending 0 0s nginx-7df9756ccc-8zhwk 0/1 Pending 0 0s nginx-7df9756ccc-rr9bn 0/1 Pending 0 0s nginx-7df9756ccc-cpgrv 0/1 ContainerCreating 0 0s nginx-7df9756ccc-8zhwk 0/1 ContainerCreating 0 0s nginx-7df9756ccc-rr9bn 0/1 ContainerCreating 0 0s nginx-7df9756ccc-m9gsj 0/1 Pending 0 0s nginx-7df9756ccc-g56qb 0/1 Pending 0 0s nginx-7df9756ccc-sl9c6 0/1 Pending 0 0s nginx-7df9756ccc-fgst7 0/1 Pending 0 0s nginx-7df9756ccc-g56qb 0/1 ContainerCreating 0 0s nginx-7df9756ccc-m9gsj 0/1 ContainerCreating 0 0s nginx-7df9756ccc-sl9c6 0/1 ContainerCreating 0 0s nginx-7df9756ccc-fgst7 0/1 ContainerCreating 0 0s nginx-7df9756ccc-8zhwk 1/1 Running 0 19s nginx-7df9756ccc-rr9bn 1/1 Running 0 30s nginx-7df9756ccc-m9gsj 1/1 Running 0 21s nginx-7df9756ccc-cpgrv 1/1 Running 0 47s nginx-7df9756ccc-sl9c6 1/1 Running 0 33s nginx-7df9756ccc-g56qb 1/1 Running 0 48s nginx-7df9756ccc-fgst7 1/1 Running 0 66s nginx-7df9756ccc-fgst7 1/1 Terminating 0 6m50s nginx-7df9756ccc-8zhwk 1/1 Terminating 0 7m5s nginx-7df9756ccc-cpgrv 1/1 Terminating 0 7m5s nginx-7df9756ccc-g56qb 1/1 Terminating 0 6m50s nginx-7df9756ccc-rr9bn 1/1 Terminating 0 7m5s nginx-7df9756ccc-m9gsj 1/1 Terminating 0 6m50s nginx-7df9756ccc-sl9c6 1/1 Terminating 0 6m50s 6.5 DaemonSet(DS) DaemonSet类型的控制器可以保证在集群中的每一台（或指定）节点上都运行一个副本。一般适用于日志收集、节点监控等场景。也就是说，如果一个Pod提供的功能是节点级别的（每个节点都需要且只需要一个），那么这类Pod就适合使用DaemonSet类型的控制器创建。\nDaemonSet控制器的特点：\n每当向集群中添加一个节点时，指定的 Pod 副本也将添加到该节点上 当节点从集群中移除时，Pod 也就被垃圾回收了 下面先来看下DaemonSet的资源清单文件\napiVersion: apps/v1 # 版本号 kind: DaemonSet # 类型 metadata: # 元数据 name: # rs名称 namespace: # 所属命名空间 labels: #标签 controller: daemonset spec: # 详情描述 revisionHistoryLimit: 3 # 保留历史版本 updateStrategy: # 更新策略 type: RollingUpdate # 滚动更新策略 rollingUpdate: # 滚动更新 maxUnavailable: 1 # 最大不可用状态的 Pod 的最大值，可以为百分比，也可以为整数 selector: # 选择器，通过它指定该控制器管理哪些pod matchLabels: # Labels匹配规则 app: nginx-pod matchExpressions: # Expressions匹配规则 - {key: app, operator: In, values: [nginx-pod]} template: # 模板，当副本数量不足时，会根据下面的模板创建pod副本 metadata: labels: app: nginx-pod spec: containers: - name: nginx image: nginx:1.17.1 ports: - containerPort: 80 创建pc-daemonset.yaml，内容如下：\napiVersion: apps/v1 kind: DaemonSet metadata: name: pc-daemonset namespace: dev spec: selector: matchLabels: app: nginx-pod template: metadata: labels: app: nginx-pod spec: containers: - name: nginx image: nginx:1.17.1 # 创建daemonset [root@k8s-master01 ~]# kubectl create -f pc-daemonset.yaml daemonset.apps/pc-daemonset created # 查看daemonset [root@k8s-master01 ~]# kubectl get ds -n dev -o wide NAME DESIRED CURRENT READY UP-TO-DATE AVAILABLE AGE CONTAINERS IMAGES pc-daemonset 2 2 2 2 2 24s nginx nginx:1.17.1 # 查看pod,发现在每个Node上都运行一个pod [root@k8s-master01 ~]# kubectl get pods -n dev -o wide NAME READY STATUS RESTARTS AGE IP NODE pc-daemonset-9bck8 1/1 Running 0 37s 10.244.1.43 node1 pc-daemonset-k224w 1/1 Running 0 37s 10.244.2.74 node2 # 删除daemonset [root@k8s-master01 ~]# kubectl delete -f pc-daemonset.yaml daemonset.apps \u0026#34;pc-daemonset\u0026#34; deleted 6.6 Job Job，主要用于负责批量处理(一次要处理指定数量任务)短暂的一次性(每个任务仅运行一次就结束)任务。Job特点如下：\n当Job创建的pod执行成功结束时，Job将记录成功结束的pod数量 当成功结束的pod达到指定的数量时，Job将完成执行 Job的资源清单文件：\napiVersion: batch/v1 # 版本号 kind: Job # 类型 metadata: # 元数据 name: # rs名称 namespace: # 所属命名空间 labels: #标签 controller: job spec: # 详情描述 completions: 1 # 指定job需要成功运行Pods的次数。默认值: 1 parallelism: 1 # 指定job在任一时刻应该并发运行Pods的数量。默认值: 1 activeDeadlineSeconds: 30 # 指定job可运行的时间期限，超过时间还未结束，系统将会尝试进行终止。 backoffLimit: 6 # 指定job失败后进行重试的次数。默认是6 manualSelector: true # 是否可以使用selector选择器选择pod，默认是false selector: # 选择器，通过它指定该控制器管理哪些pod matchLabels: # Labels匹配规则 app: counter-pod matchExpressions: # Expressions匹配规则 - {key: app, operator: In, values: [counter-pod]} template: # 模板，当副本数量不足时，会根据下面的模板创建pod副本 metadata: labels: app: counter-pod spec: restartPolicy: Never # 重启策略只能设置为Never或者OnFailure containers: - name: counter image: busybox:1.30 command: [\u0026#34;bin/sh\u0026#34;,\u0026#34;-c\u0026#34;,\u0026#34;for i in 9 8 7 6 5 4 3 2 1; do echo $i;sleep 2;done\u0026#34;] 关于重启策略设置的说明： 如果指定为OnFailure，则job会在pod出现故障时重启容器，而不是创建pod，failed次数不变 如果指定为Never，则job会在pod出现故障时创建新的pod，并且故障pod不会消失，也不会重启，failed次数加1 如果指定为Always的话，就意味着一直重启，意味着job任务会重复去执行了，当然不对，所以不能设置为Always 创建pc-job.yaml，内容如下：\napiVersion: batch/v1 kind: Job metadata: name: pc-job namespace: dev spec: manualSelector: true selector: matchLabels: app: counter-pod template: metadata: labels: app: counter-pod spec: restartPolicy: Never containers: - name: counter image: busybox:1.30 command: [\u0026#34;bin/sh\u0026#34;,\u0026#34;-c\u0026#34;,\u0026#34;for i in 9 8 7 6 5 4 3 2 1; do echo $i;sleep 3;done\u0026#34;] # 创建job [root@k8s-master01 ~]# kubectl create -f pc-job.yaml job.batch/pc-job created # 查看job [root@k8s-master01 ~]# kubectl get job -n dev -o wide -w NAME COMPLETIONS DURATION AGE CONTAINERS IMAGES SELECTOR pc-job 0/1 21s 21s counter busybox:1.30 app=counter-pod pc-job 1/1 31s 79s counter busybox:1.30 app=counter-pod # 通过观察pod状态可以看到，pod在运行完毕任务后，就会变成Completed状态 [root@k8s-master01 ~]# kubectl get pods -n dev -w NAME READY STATUS RESTARTS AGE pc-job-rxg96 1/1 Running 0 29s pc-job-rxg96 0/1 Completed 0 33s # 接下来，调整下pod运行的总数量和并行数量 即：在spec下设置下面两个选项 # completions: 6 # 指定job需要成功运行Pods的次数为6 # parallelism: 3 # 指定job并发运行Pods的数量为3 # 然后重新运行job，观察效果，此时会发现，job会每次运行3个pod，总共执行了6个pod [root@k8s-master01 ~]# kubectl get pods -n dev -w NAME READY STATUS RESTARTS AGE pc-job-684ft 1/1 Running 0 5s pc-job-jhj49 1/1 Running 0 5s pc-job-pfcvh 1/1 Running 0 5s pc-job-684ft 0/1 Completed 0 11s pc-job-v7rhr 0/1 Pending 0 0s pc-job-v7rhr 0/1 Pending 0 0s pc-job-v7rhr 0/1 ContainerCreating 0 0s pc-job-jhj49 0/1 Completed 0 11s pc-job-fhwf7 0/1 Pending 0 0s pc-job-fhwf7 0/1 Pending 0 0s pc-job-pfcvh 0/1 Completed 0 11s pc-job-5vg2j 0/1 Pending 0 0s pc-job-fhwf7 0/1 ContainerCreating 0 0s pc-job-5vg2j 0/1 Pending 0 0s pc-job-5vg2j 0/1 ContainerCreating 0 0s pc-job-fhwf7 1/1 Running 0 2s pc-job-v7rhr 1/1 Running 0 2s pc-job-5vg2j 1/1 Running 0 3s pc-job-fhwf7 0/1 Completed 0 12s pc-job-v7rhr 0/1 Completed 0 12s pc-job-5vg2j 0/1 Completed 0 12s # 删除job [root@k8s-master01 ~]# kubectl delete -f pc-job.yaml job.batch \u0026#34;pc-job\u0026#34; deleted 6.7 CronJob(CJ) CronJob控制器以 Job控制器资源为其管控对象，并借助它管理pod资源对象，Job控制器定义的作业任务在其控制器资源创建之后便会立即执行，但CronJob可以以类似于Linux操作系统的周期性任务作业计划的方式控制其运行时间点及重复运行的方式。也就是说，CronJob可以在特定的时间点(反复的)去运行job任务。\nCronJob的资源清单文件：\napiVersion: batch/v1beta1 # 版本号 kind: CronJob # 类型 metadata: # 元数据 name: # rs名称 namespace: # 所属命名空间 labels: #标签 controller: cronjob spec: # 详情描述 schedule: # cron格式的作业调度运行时间点,用于控制任务在什么时间执行 concurrencyPolicy: # 并发执行策略，用于定义前一次作业运行尚未完成时是否以及如何运行后一次的作业 failedJobHistoryLimit: # 为失败的任务执行保留的历史记录数，默认为1 successfulJobHistoryLimit: # 为成功的任务执行保留的历史记录数，默认为3 startingDeadlineSeconds: # 启动作业错误的超时时长 jobTemplate: # job控制器模板，用于为cronjob控制器生成job对象;下面其实就是job的定义 metadata: spec: completions: 1 parallelism: 1 activeDeadlineSeconds: 30 backoffLimit: 6 manualSelector: true selector: matchLabels: app: counter-pod matchExpressions: 规则 - {key: app, operator: In, values: [counter-pod]} template: metadata: labels: app: counter-pod spec: restartPolicy: Never containers: - name: counter image: busybox:1.30 command: [\u0026#34;bin/sh\u0026#34;,\u0026#34;-c\u0026#34;,\u0026#34;for i in 9 8 7 6 5 4 3 2 1; do echo $i;sleep 20;done\u0026#34;] 需要重点解释的几个选项： schedule: cron表达式，用于指定任务的执行时间 */1 * * * * \u0026lt;分钟\u0026gt; \u0026lt;小时\u0026gt; \u0026lt;日\u0026gt; \u0026lt;月份\u0026gt; \u0026lt;星期\u0026gt; 分钟 值从 0 到 59. 小时 值从 0 到 23. 日 值从 1 到 31. 月 值从 1 到 12. 星期 值从 0 到 6, 0 代表星期日 多个时间可以用逗号隔开； 范围可以用连字符给出；*可以作为通配符； /表示每... concurrencyPolicy: Allow: 允许Jobs并发运行(默认) Forbid: 禁止并发运行，如果上一次运行尚未完成，则跳过下一次运行 Replace: 替换，取消当前正在运行的作业并用新作业替换它 创建pc-cronjob.yaml，内容如下：\napiVersion: batch/v1beta1 kind: CronJob metadata: name: pc-cronjob namespace: dev labels: controller: cronjob spec: schedule: \u0026#34;*/1 * * * *\u0026#34; jobTemplate: metadata: spec: template: spec: restartPolicy: Never containers: - name: counter image: busybox:1.30 command: [\u0026#34;bin/sh\u0026#34;,\u0026#34;-c\u0026#34;,\u0026#34;for i in 9 8 7 6 5 4 3 2 1; do echo $i;sleep 3;done\u0026#34;] # 创建cronjob [root@k8s-master01 ~]# kubectl create -f pc-cronjob.yaml cronjob.batch/pc-cronjob created # 查看cronjob [root@k8s-master01 ~]# kubectl get cronjobs -n dev NAME SCHEDULE SUSPEND ACTIVE LAST SCHEDULE AGE pc-cronjob */1 * * * * False 0 \u0026lt;none\u0026gt; 6s # 查看job [root@k8s-master01 ~]# kubectl get jobs -n dev NAME COMPLETIONS DURATION AGE pc-cronjob-1592587800 1/1 28s 3m26s pc-cronjob-1592587860 1/1 28s 2m26s pc-cronjob-1592587920 1/1 28s 86s # 查看pod [root@k8s-master01 ~]# kubectl get pods -n dev pc-cronjob-1592587800-x4tsm 0/1 Completed 0 2m24s pc-cronjob-1592587860-r5gv4 0/1 Completed 0 84s pc-cronjob-1592587920-9dxxq 1/1 Running 0 24s # 删除cronjob [root@k8s-master01 ~]# kubectl delete -f pc-cronjob.yaml cronjob.batch \u0026#34;pc-cronjob\u0026#34; deleted 7. Service详解 7.1 Service介绍 在kubernetes中，pod是应用程序的载体，我们可以通过pod的ip来访问应用程序，但是pod的ip地址不是固定的，这也就意味着不方便直接采用pod的ip对服务进行访问。\n为了解决这个问题，kubernetes提供了Service资源，Service会对提供同一个服务的多个pod进行聚合，并且提供一个统一的入口地址。通过访问Service的入口地址就能访问到后面的pod服务。\nService在很多情况下只是一个概念，真正起作用的其实是kube-proxy服务进程，每个Node节点上都运行着一个kube-proxy服务进程。当创建Service的时候会通过api-server向etcd写入创建的service的信息，而kube-proxy会基于监听的机制发现这种Service的变动，然后它会将最新的Service信息转换成对应的访问规则。\n# 10.97.97.97:80 是service提供的访问入口 # 当访问这个入口的时候，可以发现后面有三个pod的服务在等待调用， # kube-proxy会基于rr（轮询）的策略，将请求分发到其中一个pod上去 # 这个规则会同时在集群内的所有节点上都生成，所以在任何一个节点上，都可以访问。 [root@node1 ~]# ipvsadm -Ln IP Virtual Server version 1.2.1 (size=4096) Prot LocalAddress:Port Scheduler Flags -\u0026gt; RemoteAddress:Port Forward Weight ActiveConn InActConn TCP 10.97.97.97:80 rr -\u0026gt; 10.244.1.39:80 Masq 1 0 0 -\u0026gt; 10.244.1.40:80 Masq 1 0 0 -\u0026gt; 10.244.2.33:80 Masq 1 0 0 kube-proxy目前支持三种工作模式:\n7.1.1 userspace 模式 userspace模式下，kube-proxy会为每一个Service创建一个监听端口，发向Cluster IP的请求被Iptables规则重定向到kube-proxy监听的端口上，kube-proxy根据LB算法选择一个提供服务的Pod并和其建立链接，以将请求转发到Pod上。 该模式下，kube-proxy充当了一个四层负责均衡器的角色。由于kube-proxy运行在userspace中，在进行转发处理时会增加内核和用户空间之间的数据拷贝，虽然比较稳定，但是效率比较低。\n7.1.2 iptables 模式 iptables模式下，kube-proxy为service后端的每个Pod创建对应的iptables规则，直接将发向Cluster IP的请求重定向到一个Pod IP。 该模式下kube-proxy不承担四层负责均衡器的角色，只负责创建iptables规则。该模式的优点是较userspace模式效率更高，但不能提供灵活的LB策略，当后端Pod不可用时也无法进行重试。\n7.1.3 ipvs 模式 ipvs模式和iptables类似，kube-proxy监控Pod的变化并创建相应的ipvs规则。ipvs相对iptables转发效率更高。除此以外，ipvs支持更多的LB算法。\n# 此模式必须安装ipvs内核模块，否则会降级为iptables # 开启ipvs [root@k8s-master01 ~]# kubectl edit cm kube-proxy -n kube-system # 修改mode: \u0026#34;ipvs\u0026#34; [root@k8s-master01 ~]# kubectl delete pod -l k8s-app=kube-proxy -n kube-system [root@node1 ~]# ipvsadm -Ln IP Virtual Server version 1.2.1 (size=4096) Prot LocalAddress:Port Scheduler Flags -\u0026gt; RemoteAddress:Port Forward Weight ActiveConn InActConn TCP 10.97.97.97:80 rr -\u0026gt; 10.244.1.39:80 Masq 1 0 0 -\u0026gt; 10.244.1.40:80 Masq 1 0 0 -\u0026gt; 10.244.2.33:80 Masq 1 0 0 7.2 Service类型 Service的资源清单文件：\nkind: Service # 资源类型 apiVersion: v1 # 资源版本 metadata: # 元数据 name: service # 资源名称 namespace: dev # 命名空间 spec: # 描述 selector: # 标签选择器，用于确定当前service代理哪些pod app: nginx type: # Service类型，指定service的访问方式 clusterIP: # 虚拟服务的ip地址 sessionAffinity: # session亲和性，支持ClientIP、None两个选项 ports: # 端口信息 - protocol: TCP port: 3017 # service端口 targetPort: 5003 # pod端口 nodePort: 31122 # 主机端口 ClusterIP：默认值，它是Kubernetes系统自动分配的虚拟IP，只能在集群内部访问 NodePort：将Service通过指定的Node上的端口暴露给外部，通过此方法，就可以在集群外部访问服务 LoadBalancer：使用外接负载均衡器完成到服务的负载分发，注意此模式需要外部云环境支持 ExternalName： 把集群外部的服务引入集群内部，直接使用 7.3 Service使用 7.3.1 实验环境准备 在使用service之前，首先利用Deployment创建出3个pod，注意要为pod设置app=nginx-pod的标签\n创建deployment.yaml，内容如下：\napiVersion: apps/v1 kind: Deployment metadata: name: pc-deployment namespace: dev spec: replicas: 3 selector: matchLabels: app: nginx-pod template: metadata: labels: app: nginx-pod spec: containers: - name: nginx image: nginx:1.17.1 ports: - containerPort: 80 [root@k8s-master01 ~]# kubectl create -f deployment.yaml deployment.apps/pc-deployment created # 查看pod详情 [root@k8s-master01 ~]# kubectl get pods -n dev -o wide --show-labels NAME READY STATUS IP NODE LABELS pc-deployment-66cb59b984-8p84h 1/1 Running 10.244.1.39 node1 app=nginx-pod pc-deployment-66cb59b984-vx8vx 1/1 Running 10.244.2.33 node2 app=nginx-pod pc-deployment-66cb59b984-wnncx 1/1 Running 10.244.1.40 node1 app=nginx-pod # 为了方便后面的测试，修改下三台nginx的index.html页面（三台修改的IP地址不一致） # kubectl exec -it pc-deployment-66cb59b984-8p84h -n dev /bin/sh # echo \u0026#34;10.244.1.39\u0026#34; \u0026gt; /usr/share/nginx/html/index.html #修改完毕之后，访问测试 [root@k8s-master01 ~]# curl 10.244.1.39 10.244.1.39 [root@k8s-master01 ~]# curl 10.244.2.33 10.244.2.33 [root@k8s-master01 ~]# curl 10.244.1.40 10.244.1.40 7.3.2 ClusterIP类型的Service 创建service-clusterip.yaml文件\napiVersion: v1 kind: Service metadata: name: service-clusterip namespace: dev spec: selector: app: nginx-pod clusterIP: 10.97.97.97 # service的ip地址，如果不写，默认会生成一个 type: ClusterIP ports: - port: 80 # Service端口 targetPort: 80 # pod端口 # 创建service [root@k8s-master01 ~]# kubectl create -f service-clusterip.yaml service/service-clusterip created # 查看service [root@k8s-master01 ~]# kubectl get svc -n dev -o wide NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE SELECTOR service-clusterip ClusterIP 10.97.97.97 \u0026lt;none\u0026gt; 80/TCP 13s app=nginx-pod # 查看service的详细信息 # 在这里有一个Endpoints列表，里面就是当前service可以负载到的服务入口 [root@k8s-master01 ~]# kubectl describe svc service-clusterip -n dev Name: service-clusterip Namespace: dev Labels: \u0026lt;none\u0026gt; Annotations: \u0026lt;none\u0026gt; Selector: app=nginx-pod Type: ClusterIP IP: 10.97.97.97 Port: \u0026lt;unset\u0026gt; 80/TCP TargetPort: 80/TCP Endpoints: 10.244.1.39:80,10.244.1.40:80,10.244.2.33:80 Session Affinity: None Events: \u0026lt;none\u0026gt; # 查看ipvs的映射规则 [root@k8s-master01 ~]# ipvsadm -Ln TCP 10.97.97.97:80 rr -\u0026gt; 10.244.1.39:80 Masq 1 0 0 -\u0026gt; 10.244.1.40:80 Masq 1 0 0 -\u0026gt; 10.244.2.33:80 Masq 1 0 0 # 访问10.97.97.97:80观察效果 [root@k8s-master01 ~]# curl 10.97.97.97:80 10.244.2.33 7.3.3 Endpoint Endpoint是kubernetes中的一个资源对象，存储在etcd中，用来记录一个service对应的所有pod的访问地址，它是根据service配置文件中selector描述产生的。\n一个Service由一组Pod组成，这些Pod通过Endpoints暴露出来，Endpoints是实现实际服务的端点集合。换句话说，service和pod之间的联系是通过endpoints实现的。\n负载分发策略\n对Service的访问被分发到了后端的Pod上去，目前kubernetes提供了两种负载分发策略：\n如果不定义，默认使用kube-proxy的策略，比如随机、轮询\n基于客户端地址的会话保持模式，即来自同一个客户端发起的所有请求都会转发到固定的一个Pod上\n此模式可以使在spec中添加sessionAffinity:ClientIP选项\n# 查看ipvs的映射规则【rr 轮询】 [root@k8s-master01 ~]# ipvsadm -Ln TCP 10.97.97.97:80 rr -\u0026gt; 10.244.1.39:80 Masq 1 0 0 -\u0026gt; 10.244.1.40:80 Masq 1 0 0 -\u0026gt; 10.244.2.33:80 Masq 1 0 0 # 循环访问测试 [root@k8s-master01 ~]# while true;do curl 10.97.97.97:80; sleep 5; done; 10.244.1.40 10.244.1.39 10.244.2.33 10.244.1.40 10.244.1.39 10.244.2.33 # 修改分发策略----sessionAffinity:ClientIP # 查看ipvs规则【persistent 代表持久】 [root@k8s-master01 ~]# ipvsadm -Ln TCP 10.97.97.97:80 rr persistent 10800 -\u0026gt; 10.244.1.39:80 Masq 1 0 0 -\u0026gt; 10.244.1.40:80 Masq 1 0 0 -\u0026gt; 10.244.2.33:80 Masq 1 0 0 # 循环访问测试 [root@k8s-master01 ~]# while true;do curl 10.97.97.97; sleep 5; done; 10.244.2.33 10.244.2.33 10.244.2.33 # 删除service [root@k8s-master01 ~]# kubectl delete -f service-clusterip.yaml service \u0026#34;service-clusterip\u0026#34; deleted 7.3.4 HeadLiness类型的Service 在某些场景中，开发人员可能不想使用Service提供的负载均衡功能，而希望自己来控制负载均衡策略，针对这种情况，kubernetes提供了HeadLiness Service，这类Service不会分配Cluster IP，如果想要访问service，只能通过service的域名进行查询。\n创建service-headliness.yaml\napiVersion: v1 kind: Service metadata: name: service-headliness namespace: dev spec: selector: app: nginx-pod clusterIP: None # 将clusterIP设置为None，即可创建headliness Service type: ClusterIP ports: - port: 80 targetPort: 80 # 创建service [root@k8s-master01 ~]# kubectl create -f service-headliness.yaml service/service-headliness created # 获取service， 发现CLUSTER-IP未分配 [root@k8s-master01 ~]# kubectl get svc service-headliness -n dev -o wide NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE SELECTOR service-headliness ClusterIP None \u0026lt;none\u0026gt; 80/TCP 11s app=nginx-pod # 查看service详情 [root@k8s-master01 ~]# kubectl describe svc service-headliness -n dev Name: service-headliness Namespace: dev Labels: \u0026lt;none\u0026gt; Annotations: \u0026lt;none\u0026gt; Selector: app=nginx-pod Type: ClusterIP IP: None Port: \u0026lt;unset\u0026gt; 80/TCP TargetPort: 80/TCP Endpoints: 10.244.1.39:80,10.244.1.40:80,10.244.2.33:80 Session Affinity: None Events: \u0026lt;none\u0026gt; # 查看域名的解析情况 [root@k8s-master01 ~]# kubectl exec -it pc-deployment-66cb59b984-8p84h -n dev /bin/sh / # cat /etc/resolv.conf nameserver 10.96.0.10 search dev.svc.cluster.local svc.cluster.local cluster.local [root@k8s-master01 ~]# dig @10.96.0.10 service-headliness.dev.svc.cluster.local service-headliness.dev.svc.cluster.local. 30 IN A 10.244.1.40 service-headliness.dev.svc.cluster.local. 30 IN A 10.244.1.39 service-headliness.dev.svc.cluster.local. 30 IN A 10.244.2.33 7.3.5 NodePort类型的Service 在之前的样例中，创建的Service的ip地址只有集群内部才可以访问，如果希望将Service暴露给集群外部使用，那么就要使用到另外一种类型的Service，称为NodePort类型。NodePort的工作原理其实就是将service的端口映射到Node的一个端口上，然后就可以通过NodeIp:NodePort来访问service了。\n创建service-nodeport.yaml\napiVersion: v1 kind: Service metadata: name: service-nodeport namespace: dev spec: selector: app: nginx-pod type: NodePort # service类型 ports: - port: 80 nodePort: 30002 # 指定绑定的node的端口(默认的取值范围是：30000-32767), 如果不指定，会默认分配 targetPort: 80 # 创建service [root@k8s-master01 ~]# kubectl create -f service-nodeport.yaml service/service-nodeport created # 查看service [root@k8s-master01 ~]# kubectl get svc -n dev -o wide NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) SELECTOR service-nodeport NodePort 10.105.64.191 \u0026lt;none\u0026gt; 80:30002/TCP app=nginx-pod # 接下来可以通过电脑主机的浏览器去访问集群中任意一个nodeip的30002端口，即可访问到pod 7.3.6 LoadBalancer类型的Service LoadBalancer和NodePort很相似，目的都是向外部暴露一个端口，区别在于LoadBalancer会在集群的外部再来做一个负载均衡设备，而这个设备需要外部环境支持的，外部服务发送到这个设备上的请求，会被设备负载之后转发到集群中。\n7.3.7 ExternalName类型的Service ExternalName类型的Service用于引入集群外部的服务，它通过externalName属性指定外部一个服务的地址，然后在集群内部访问此service就可以访问到外部的服务了。\napiVersion: v1 kind: Service metadata: name: service-externalname namespace: dev spec: type: ExternalName # service类型 externalName: www.baidu.com #改成ip地址也可以 # 创建service [root@k8s-master01 ~]# kubectl create -f service-externalname.yaml service/service-externalname created # 域名解析 [root@k8s-master01 ~]# dig @10.96.0.10 service-externalname.dev.svc.cluster.local service-externalname.dev.svc.cluster.local. 30 IN CNAME www.baidu.com. www.baidu.com. 30 IN CNAME www.a.shifen.com. www.a.shifen.com. 30 IN A 39.156.66.18 www.a.shifen.com. 30 IN A 39.156.66.14 7.4 Ingress介绍 在前面课程中已经提到，Service对集群之外暴露服务的主要方式有两种：NotePort和LoadBalancer，但是这两种方式，都有一定的缺点：\nNodePort方式的缺点是会占用很多集群机器的端口，那么当集群服务变多的时候，这个缺点就愈发明显 LB方式的缺点是每个service需要一个LB，浪费、麻烦，并且需要kubernetes之外设备的支持 基于这种现状，kubernetes提供了Ingress资源对象，Ingress只需要一个NodePort或者一个LB就可以满足暴露多个Service的需求。工作机制大致如下图表示：\n实际上，Ingress相当于一个7层的负载均衡器，是kubernetes对反向代理的一个抽象，它的工作原理类似于Nginx，可以理解成在Ingress里建立诸多映射规则，Ingress Controller通过监听这些配置规则并转化成Nginx的反向代理配置 , 然后对外部提供服务。在这里有两个核心概念：\ningress：kubernetes中的一个对象，作用是定义请求如何转发到service的规则 ingress controller：具体实现反向代理及负载均衡的程序，对ingress定义的规则进行解析，根据配置的规则来实现请求转发，实现方式有很多，比如Nginx, Contour, Haproxy等等 Ingress（以Nginx为例）的工作原理如下：\n用户编写Ingress规则，说明哪个域名对应kubernetes集群中的哪个Service Ingress控制器动态感知Ingress服务规则的变化，然后生成一段对应的Nginx反向代理配置 Ingress控制器会将生成的Nginx配置写入到一个运行着的Nginx服务中，并动态更新 到此为止，其实真正在工作的就是一个Nginx了，内部配置了用户定义的请求转发规则 7.5 Ingress使用 7.5.1 环境准备 搭建ingress环境 # 创建文件夹 [root@k8s-master01 ~]# mkdir ingress-controller [root@k8s-master01 ~]# cd ingress-controller/ # 获取ingress-nginx，本次案例使用的是0.30版本 [root@k8s-master01 ingress-controller]# wget https:/raw.githubusercontent.com/kubernetes/ingress-nginx/nginx-0.30.0/deploy/static/mandatory.yaml [root@k8s-master01 ingress-controller]# wget https:/raw.githubusercontent.com/kubernetes/ingress-nginx/nginx-0.30.0/deploy/static/provider/baremetal/service-nodeport.yaml # 修改mandatory.yaml文件中的仓库 # 修改quay.io/kubernetes-ingress-controller/nginx-ingress-controller:0.30.0 # 为quay-mirror.qiniu.com/kubernetes-ingress-controller/nginx-ingress-controller:0.30.0 # 创建ingress-nginx [root@k8s-master01 ingress-controller]# kubectl apply -f ./ # 查看ingress-nginx [root@k8s-master01 ingress-controller]# kubectl get pod -n ingress-nginx NAME READY STATUS RESTARTS AGE pod/nginx-ingress-controller-fbf967dd5-4qpbp 1/1 Running 0 12h # 查看service [root@k8s-master01 ingress-controller]# kubectl get svc -n ingress-nginx NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE ingress-nginx NodePort 10.98.75.163 \u0026lt;none\u0026gt; 80:32240/TCP,443:31335/TCP 11h 7.5.2 准备service和pod 为了后面的实验比较方便，创建如下图所示的模型\n创建tomcat-nginx.yaml\napiVersion: apps/v1 kind: Deployment metadata: name: nginx-deployment namespace: dev spec: replicas: 3 selector: matchLabels: app: nginx-pod template: metadata: labels: app: nginx-pod spec: containers: - name: nginx image: nginx:1.17.1 ports: - containerPort: 80 --- apiVersion: apps/v1 kind: Deployment metadata: name: tomcat-deployment namespace: dev spec: replicas: 3 selector: matchLabels: app: tomcat-pod template: metadata: labels: app: tomcat-pod spec: containers: - name: tomcat image: tomcat:8.5-jre10-slim ports: - containerPort: 8080 --- apiVersion: v1 kind: Service metadata: name: nginx-service namespace: dev spec: selector: app: nginx-pod clusterIP: None type: ClusterIP ports: - port: 80 targetPort: 80 --- apiVersion: v1 kind: Service metadata: name: tomcat-service namespace: dev spec: selector: app: tomcat-pod clusterIP: None type: ClusterIP ports: - port: 8080 targetPort: 8080 # 创建 [root@k8s-master01 ~]# kubectl create -f tomcat-nginx.yaml # 查看 [root@k8s-master01 ~]# kubectl get svc -n dev NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE nginx-service ClusterIP None \u0026lt;none\u0026gt; 80/TCP 48s tomcat-service ClusterIP None \u0026lt;none\u0026gt; 8080/TCP 48s 7.5.3 Http代理 创建ingress-http.yaml\napiVersion: extensions/v1beta1 kind: Ingress metadata: name: ingress-http namespace: dev spec: rules: - host: nginx.itheima.com http: paths: - path: / backend: serviceName: nginx-service servicePort: 80 - host: tomcat.itheima.com http: paths: - path: / backend: serviceName: tomcat-service servicePort: 8080 # 创建 [root@k8s-master01 ~]# kubectl create -f ingress-http.yaml ingress.extensions/ingress-http created # 查看 [root@k8s-master01 ~]# kubectl get ing ingress-http -n dev NAME HOSTS ADDRESS PORTS AGE ingress-http nginx.itheima.com,tomcat.itheima.com 80 22s # 查看详情 [root@k8s-master01 ~]# kubectl describe ing ingress-http -n dev ... Rules: Host Path Backends ---- ---- -------- nginx.itheima.com / nginx-service:80 (10.244.1.96:80,10.244.1.97:80,10.244.2.112:80) tomcat.itheima.com / tomcat-service:8080(10.244.1.94:8080,10.244.1.95:8080,10.244.2.111:8080) ... # 接下来,在本地电脑上配置host文件,解析上面的两个域名到192.168.109.100(master)上 # 然后,就可以分别访问tomcat.itheima.com:32240 和 nginx.itheima.com:32240 查看效果了 7.5.4 Https代理 创建证书\n# 生成证书 openssl req -x509 -sha256 -nodes -days 365 -newkey rsa:2048 -keyout tls.key -out tls.crt -subj \u0026#34;/C=CN/ST=BJ/L=BJ/O=nginx/CN=itheima.com\u0026#34; # 创建密钥 kubectl create secret tls tls-secret --key tls.key --cert tls.crt 创建ingress-https.yaml\napiVersion: extensions/v1beta1 kind: Ingress metadata: name: ingress-https namespace: dev spec: tls: - hosts: - nginx.itheima.com - tomcat.itheima.com secretName: tls-secret # 指定秘钥 rules: - host: nginx.itheima.com http: paths: - path: / backend: serviceName: nginx-service servicePort: 80 - host: tomcat.itheima.com http: paths: - path: / backend: serviceName: tomcat-service servicePort: 8080 # 创建 [root@k8s-master01 ~]# kubectl create -f ingress-https.yaml ingress.extensions/ingress-https created # 查看 [root@k8s-master01 ~]# kubectl get ing ingress-https -n dev NAME HOSTS ADDRESS PORTS AGE ingress-https nginx.itheima.com,tomcat.itheima.com 10.104.184.38 80, 443 2m42s # 查看详情 [root@k8s-master01 ~]# kubectl describe ing ingress-https -n dev ... TLS: tls-secret terminates nginx.itheima.com,tomcat.itheima.com Rules: Host Path Backends ---- ---- -------- nginx.itheima.com / nginx-service:80 (10.244.1.97:80,10.244.1.98:80,10.244.2.119:80) tomcat.itheima.com / tomcat-service:8080(10.244.1.99:8080,10.244.2.117:8080,10.244.2.120:8080) ... # 下面可以通过浏览器访问https:/nginx.itheima.com:31335 和 https:/tomcat.itheima.com:31335来查看了 8. 数据存储 在前面已经提到，容器的生命周期可能很短，会被频繁地创建和销毁。那么容器在销毁时，保存在容器中的数据也会被清除。这种结果对用户来说，在某些情况下是不乐意看到的。为了持久化保存容器的数据，kubernetes引入了Volume的概念。\nVolume是Pod中能够被多个容器访问的共享目录，它被定义在Pod上，然后被一个Pod里的多个容器挂载到具体的文件目录下，kubernetes通过Volume实现同一个Pod中不同容器之间的数据共享以及数据的持久化存储。Volume的生命容器不与Pod中单个容器的生命周期相关，当容器终止或者重启时，Volume中的数据也不会丢失。\nkubernetes的Volume支持多种类型，比较常见的有下面几个：\n简单存储：EmptyDir、HostPath、NFS 高级存储：PV、PVC 配置存储：ConfigMap、Secret 8.1 基本存储 8.1.1 EmptyDir EmptyDir是最基础的Volume类型，一个EmptyDir就是Host上的一个空目录。\nEmptyDir是在Pod被分配到Node时创建的，它的初始内容为空，并且无须指定宿主机上对应的目录文件，因为kubernetes会自动分配一个目录，当Pod销毁时， EmptyDir中的数据也会被永久删除。 EmptyDir用途如下：\n临时空间，例如用于某些应用程序运行时所需的临时目录，且无须永久保留 一个容器需要从另一个容器中获取数据的目录（多容器共享目录） 接下来，通过一个容器之间文件共享的案例来使用一下EmptyDir。\n在一个Pod中准备两个容器nginx和busybox，然后声明一个Volume分别挂在到两个容器的目录中，然后nginx容器负责向Volume中写日志，busybox中通过命令将日志内容读到控制台。\n创建一个volume-emptydir.yaml\napiVersion: v1 kind: Pod metadata: name: volume-emptydir namespace: dev spec: containers: - name: nginx image: nginx:1.17.1 ports: - containerPort: 80 volumeMounts: # 将logs-volume挂在到nginx容器中，对应的目录为 /var/log/nginx - name: logs-volume mountPath: /var/log/nginx - name: busybox image: busybox:1.30 command: [\u0026#34;/bin/sh\u0026#34;,\u0026#34;-c\u0026#34;,\u0026#34;tail -f /logs/access.log\u0026#34;] # 初始命令，动态读取指定文件中内容 volumeMounts: # 将logs-volume 挂在到busybox容器中，对应的目录为 /logs - name: logs-volume mountPath: /logs volumes: # 声明volume， name为logs-volume，类型为emptyDir - name: logs-volume emptyDir: {} # 创建Pod [root@k8s-master01 ~]# kubectl create -f volume-emptydir.yaml pod/volume-emptydir created # 查看pod [root@k8s-master01 ~]# kubectl get pods volume-emptydir -n dev -o wide NAME READY STATUS RESTARTS AGE IP NODE ...... volume-emptydir 2/2 Running 0 97s 10.42.2.9 node1 ...... # 通过podIp访问nginx [root@k8s-master01 ~]# curl 10.42.2.9 ...... # 通过kubectl logs命令查看指定容器的标准输出 [root@k8s-master01 ~]# kubectl logs -f volume-emptydir -n dev -c busybox 10.42.1.0 - - [27/Jun/2021:15:08:54 +0000] \u0026#34;GET / HTTP/1.1\u0026#34; 200 612 \u0026#34;-\u0026#34; \u0026#34;curl/7.29.0\u0026#34; \u0026#34;-\u0026#34; 8.1.2 HostPath 上节课提到，EmptyDir中数据不会被持久化，它会随着Pod的结束而销毁，如果想简单的将数据持久化到主机中，可以选择HostPath。\nHostPath就是将Node主机中一个实际目录挂在到Pod中，以供容器使用，这样的设计就可以保证Pod销毁了，但是数据依据可以存在于Node主机上。\n创建一个volume-hostpath.yaml：\napiVersion: v1 kind: Pod metadata: name: volume-hostpath namespace: dev spec: containers: - name: nginx image: nginx:1.17.1 ports: - containerPort: 80 volumeMounts: - name: logs-volume mountPath: /var/log/nginx - name: busybox image: busybox:1.30 command: [\u0026#34;/bin/sh\u0026#34;,\u0026#34;-c\u0026#34;,\u0026#34;tail -f /logs/access.log\u0026#34;] volumeMounts: - name: logs-volume mountPath: /logs volumes: - name: logs-volume hostPath: path: /root/logs type: DirectoryOrCreate # 目录存在就使用，不存在就先创建后使用 关于type的值的一点说明： DirectoryOrCreate 目录存在就使用，不存在就先创建后使用 Directory 目录必须存在 FileOrCreate 文件存在就使用，不存在就先创建后使用 File 文件必须存在 Socket unix套接字必须存在 CharDevice 字符设备必须存在 BlockDevice 块设备必须存在 # 创建Pod [root@k8s-master01 ~]# kubectl create -f volume-hostpath.yaml pod/volume-hostpath created # 查看Pod [root@k8s-master01 ~]# kubectl get pods volume-hostpath -n dev -o wide NAME READY STATUS RESTARTS AGE IP NODE ...... pod-volume-hostpath 2/2 Running 0 16s 10.42.2.10 node1 ...... #访问nginx [root@k8s-master01 ~]# curl 10.42.2.10 [root@k8s-master01 ~]# kubectl logs -f volume-emptydir -n dev -c busybox # 接下来就可以去host的/root/logs目录下查看存储的文件了 ### 注意: 下面的操作需要到Pod所在的节点运行（案例中是node1） [root@node1 ~]# ls /root/logs/ access.log error.log # 同样的道理，如果在此目录下创建一个文件，到容器中也是可以看到的 8.1.3 NFS HostPath可以解决数据持久化的问题，但是一旦Node节点故障了，Pod如果转移到了别的节点，又会出现问题了，此时需要准备单独的网络存储系统，比较常用的用NFS、CIFS。\nNFS是一个网络文件存储系统，可以搭建一台NFS服务器，然后将Pod中的存储直接连接到NFS系统上，这样的话，无论Pod在节点上怎么转移，只要Node跟NFS的对接没问题，数据就可以成功访问。\n1）首先要准备nfs的服务器，这里为了简单，直接是master节点做nfs服务器\n# 在nfs上安装nfs服务 [root@nfs ~]# yum install nfs-utils -y # 准备一个共享目录 [root@nfs ~]# mkdir /root/data/nfs -pv # 将共享目录以读写权限暴露给192.168.5.0/24网段中的所有主机 [root@nfs ~]# vim /etc/exports [root@nfs ~]# more /etc/exports /root/data/nfs 192.168.5.0/24(rw,no_root_squash) # 启动nfs服务 [root@nfs ~]# systemctl restart nfs 2）接下来，要在的每个node节点上都安装下nfs，这样的目的是为了node节点可以驱动nfs设备\n# 在node上安装nfs服务，注意不需要启动 [root@k8s-master01 ~]# yum install nfs-utils -y 3）接下来，就可以编写pod的配置文件了，创建volume-nfs.yaml\napiVersion: v1 kind: Pod metadata: name: volume-nfs namespace: dev spec: containers: - name: nginx image: nginx:1.17.1 ports: - containerPort: 80 volumeMounts: - name: logs-volume mountPath: /var/log/nginx - name: busybox image: busybox:1.30 command: [\u0026#34;/bin/sh\u0026#34;,\u0026#34;-c\u0026#34;,\u0026#34;tail -f /logs/access.log\u0026#34;] volumeMounts: - name: logs-volume mountPath: /logs volumes: - name: logs-volume nfs: server: 192.168.5.6 #nfs服务器地址 path: /root/data/nfs #共享文件路径 4）最后，运行下pod，观察结果\n# 创建pod [root@k8s-master01 ~]# kubectl create -f volume-nfs.yaml pod/volume-nfs created # 查看pod [root@k8s-master01 ~]# kubectl get pods volume-nfs -n dev NAME READY STATUS RESTARTS AGE volume-nfs 2/2 Running 0 2m9s # 查看nfs服务器上的共享目录，发现已经有文件了 [root@k8s-master01 ~]# ls /root/data/ access.log error.log 8.2 高级存储 前面已经学习了使用NFS提供存储，此时就要求用户会搭建NFS系统，并且会在yaml配置nfs。由于kubernetes支持的存储系统有很多，要求客户全都掌握，显然不现实。为了能够屏蔽底层存储实现的细节，方便用户使用， kubernetes引入PV和PVC两种资源对象。\nPV（Persistent Volume）是持久化卷的意思，是对底层的共享存储的一种抽象。一般情况下PV由kubernetes管理员进行创建和配置，它与底层具体的共享存储技术有关，并通过插件完成与共享存储的对接。\nPVC（Persistent Volume Claim）是持久卷声明的意思，是用户对于存储需求的一种声明。换句话说，PVC其实就是用户向kubernetes系统发出的一种资源需求申请。\n使用了PV和PVC之后，工作可以得到进一步的细分：\n存储：存储工程师维护 PV： kubernetes管理员维护 PVC：kubernetes用户维护 8.2.1 PV PV是存储资源的抽象，下面是资源清单文件:\napiVersion: v1 kind: PersistentVolume metadata: name: pv2 spec: nfs: # 存储类型，与底层真正存储对应 capacity: # 存储能力，目前只支持存储空间的设置 storage: 2Gi accessModes: # 访问模式 storageClassName: # 存储类别 persistentVolumeReclaimPolicy: # 回收策略 PV 的关键配置参数说明：\n存储类型\n底层实际存储的类型，kubernetes支持多种存储类型，每种存储类型的配置都有所差异\n存储能力（capacity）\n目前只支持存储空间的设置( storage=1Gi )，不过未来可能会加入IOPS、吞吐量等指标的配置\n访问模式（accessModes）\n用于描述用户应用对存储资源的访问权限，访问权限包括下面几种方式：\nReadWriteOnce（RWO）：读写权限，但是只能被单个节点挂载 ReadOnlyMany（ROX）： 只读权限，可以被多个节点挂载 ReadWriteMany（RWX）：读写权限，可以被多个节点挂载 需要注意的是，底层不同的存储类型可能支持的访问模式不同\n回收策略（persistentVolumeReclaimPolicy）\n当PV不再被使用了之后，对其的处理方式。目前支持三种策略：\nRetain （保留） 保留数据，需要管理员手工清理数据 Recycle（回收） 清除 PV 中的数据，效果相当于执行 rm -rf /thevolume/* Delete （删除） 与 PV 相连的后端存储完成 volume 的删除操作，当然这常见于云服务商的存储服务 需要注意的是，底层不同的存储类型可能支持的回收策略不同\n存储类别\nPV可以通过storageClassName参数指定一个存储类别\n具有特定类别的PV只能与请求了该类别的PVC进行绑定 未设定类别的PV则只能与不请求任何类别的PVC进行绑定 状态（status）\n一个 PV 的生命周期中，可能会处于4中不同的阶段：\nAvailable（可用）： 表示可用状态，还未被任何 PVC 绑定 Bound（已绑定）： 表示 PV 已经被 PVC 绑定 Released（已释放）： 表示 PVC 被删除，但是资源还未被集群重新声明 Failed（失败）： 表示该 PV 的自动回收失败 实验\n使用NFS作为存储，来演示PV的使用，创建3个PV，对应NFS中的3个暴露的路径。\n准备NFS环境 # 创建目录 [root@nfs ~]# mkdir /root/data/{pv1,pv2,pv3} -pv # 暴露服务 [root@nfs ~]# more /etc/exports /root/data/pv1 192.168.5.0/24(rw,no_root_squash) /root/data/pv2 192.168.5.0/24(rw,no_root_squash) /root/data/pv3 192.168.5.0/24(rw,no_root_squash) # 重启服务 [root@nfs ~]# systemctl restart nfs 创建pv.yaml\napiVersion: v1 kind: PersistentVolume metadata: name: pv1 spec: capacity: storage: 1Gi accessModes: - ReadWriteMany persistentVolumeReclaimPolicy: Retain nfs: path: /root/data/pv1 server: 192.168.5.6 --- apiVersion: v1 kind: PersistentVolume metadata: name: pv2 spec: capacity: storage: 2Gi accessModes: - ReadWriteMany persistentVolumeReclaimPolicy: Retain nfs: path: /root/data/pv2 server: 192.168.5.6 --- apiVersion: v1 kind: PersistentVolume metadata: name: pv3 spec: capacity: storage: 3Gi accessModes: - ReadWriteMany persistentVolumeReclaimPolicy: Retain nfs: path: /root/data/pv3 server: 192.168.5.6 # 创建 pv [root@k8s-master01 ~]# kubectl create -f pv.yaml persistentvolume/pv1 created persistentvolume/pv2 created persistentvolume/pv3 created # 查看pv [root@k8s-master01 ~]# kubectl get pv -o wide NAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS AGE VOLUMEMODE pv1 1Gi RWX Retain Available 10s Filesystem pv2 2Gi RWX Retain Available 10s Filesystem pv3 3Gi RWX Retain Available 9s Filesystem 8.2.2 PVC PVC是资源的申请，用来声明对存储空间、访问模式、存储类别需求信息。下面是资源清单文件:\napiVersion: v1 kind: PersistentVolumeClaim metadata: name: pvc namespace: dev spec: accessModes: # 访问模式 selector: # 采用标签对PV选择 storageClassName: # 存储类别 resources: # 请求空间 requests: storage: 5Gi PVC 的关键配置参数说明：\n访问模式（accessModes） 用于描述用户应用对存储资源的访问权限\n选择条件（selector）\n通过Label Selector的设置，可使PVC对于系统中己存在的PV进行筛选\n存储类别（storageClassName）\nPVC在定义时可以设定需要的后端存储的类别，只有设置了该class的pv才能被系统选出\n资源请求（Resources ）\n描述对存储资源的请求\n实验\n创建pvc.yaml，申请pv apiVersion: v1 kind: PersistentVolumeClaim metadata: name: pvc1 namespace: dev spec: accessModes: - ReadWriteMany resources: requests: storage: 1Gi --- apiVersion: v1 kind: PersistentVolumeClaim metadata: name: pvc2 namespace: dev spec: accessModes: - ReadWriteMany resources: requests: storage: 1Gi --- apiVersion: v1 kind: PersistentVolumeClaim metadata: name: pvc3 namespace: dev spec: accessModes: - ReadWriteMany resources: requests: storage: 1Gi # 创建pvc [root@k8s-master01 ~]# kubectl create -f pvc.yaml persistentvolumeclaim/pvc1 created persistentvolumeclaim/pvc2 created persistentvolumeclaim/pvc3 created # 查看pvc [root@k8s-master01 ~]# kubectl get pvc -n dev -o wide NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE VOLUMEMODE pvc1 Bound pv1 1Gi RWX 15s Filesystem pvc2 Bound pv2 2Gi RWX 15s Filesystem pvc3 Bound pv3 3Gi RWX 15s Filesystem # 查看pv [root@k8s-master01 ~]# kubectl get pv -o wide NAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM AGE VOLUMEMODE pv1 1Gi RWx Retain Bound dev/pvc1 3h37m Filesystem pv2 2Gi RWX Retain Bound dev/pvc2 3h37m Filesystem pv3 3Gi RWX Retain Bound dev/pvc3 3h37m Filesystem 创建pods.yaml, 使用pv\napiVersion: v1 kind: Pod metadata: name: pod1 namespace: dev spec: containers: - name: busybox image: busybox:1.30 command: [\u0026#34;/bin/sh\u0026#34;,\u0026#34;-c\u0026#34;,\u0026#34;while true;do echo pod1 \u0026gt;\u0026gt; /root/out.txt; sleep 10; done;\u0026#34;] volumeMounts: - name: volume mountPath: /root/ volumes: - name: volume persistentVolumeClaim: claimName: pvc1 readOnly: false --- apiVersion: v1 kind: Pod metadata: name: pod2 namespace: dev spec: containers: - name: busybox image: busybox:1.30 command: [\u0026#34;/bin/sh\u0026#34;,\u0026#34;-c\u0026#34;,\u0026#34;while true;do echo pod2 \u0026gt;\u0026gt; /root/out.txt; sleep 10; done;\u0026#34;] volumeMounts: - name: volume mountPath: /root/ volumes: - name: volume persistentVolumeClaim: claimName: pvc2 readOnly: false # 创建pod [root@k8s-master01 ~]# kubectl create -f pods.yaml pod/pod1 created pod/pod2 created # 查看pod [root@k8s-master01 ~]# kubectl get pods -n dev -o wide NAME READY STATUS RESTARTS AGE IP NODE pod1 1/1 Running 0 14s 10.244.1.69 node1 pod2 1/1 Running 0 14s 10.244.1.70 node1 # 查看pvc [root@k8s-master01 ~]# kubectl get pvc -n dev -o wide NAME STATUS VOLUME CAPACITY ACCESS MODES AGE VOLUMEMODE pvc1 Bound pv1 1Gi RWX 94m Filesystem pvc2 Bound pv2 2Gi RWX 94m Filesystem pvc3 Bound pv3 3Gi RWX 94m Filesystem # 查看pv [root@k8s-master01 ~]# kubectl get pv -n dev -o wide NAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM AGE VOLUMEMODE pv1 1Gi RWX Retain Bound dev/pvc1 5h11m Filesystem pv2 2Gi RWX Retain Bound dev/pvc2 5h11m Filesystem pv3 3Gi RWX Retain Bound dev/pvc3 5h11m Filesystem # 查看nfs中的文件存储 [root@nfs ~]# more /root/data/pv1/out.txt node1 node1 [root@nfs ~]# more /root/data/pv2/out.txt node2 node2 8.2.3 生命周期 PVC和PV是一一对应的，PV和PVC之间的相互作用遵循以下生命周期：\n资源供应：管理员手动创建底层存储和PV\n资源绑定：用户创建PVC，kubernetes负责根据PVC的声明去寻找PV，并绑定\n在用户定义好PVC之后，系统将根据PVC对存储资源的请求在已存在的PV中选择一个满足条件的\n一旦找到，就将该PV与用户定义的PVC进行绑定，用户的应用就可以使用这个PVC了 如果找不到，PVC则会无限期处于Pending状态，直到等到系统管理员创建了一个符合其要求的PV PV一旦绑定到某个PVC上，就会被这个PVC独占，不能再与其他PVC进行绑定了\n资源使用：用户可在pod中像volume一样使用pvc\nPod使用Volume的定义，将PVC挂载到容器内的某个路径进行使用。\n资源释放：用户删除pvc来释放pv\n当存储资源使用完毕后，用户可以删除PVC，与该PVC绑定的PV将会被标记为“已释放”，但还不能立刻与其他PVC进行绑定。通过之前PVC写入的数据可能还被留在存储设备上，只有在清除之后该PV才能再次使用。\n资源回收：kubernetes根据pv设置的回收策略进行资源的回收\n对于PV，管理员可以设定回收策略，用于设置与之绑定的PVC释放资源之后如何处理遗留数据的问题。只有PV的存储空间完成回收，才能供新的PVC绑定和使用\n8.3 配置存储 8.3.1 ConfigMap ConfigMap是一种比较特殊的存储卷，它的主要作用是用来存储配置信息的。\n创建configmap.yaml，内容如下：\napiVersion: v1 kind: ConfigMap metadata: name: configmap namespace: dev data: info: | username:admin password:123456 接下来，使用此配置文件创建configmap\n# 创建configmap [root@k8s-master01 ~]# kubectl create -f configmap.yaml configmap/configmap created # 查看configmap详情 [root@k8s-master01 ~]# kubectl describe cm configmap -n dev Name: configmap Namespace: dev Labels: \u0026lt;none\u0026gt; Annotations: \u0026lt;none\u0026gt; Data ==== info: ---- username:admin password:123456 Events: \u0026lt;none\u0026gt; 接下来创建一个pod-configmap.yaml，将上面创建的configmap挂载进去\napiVersion: v1 kind: Pod metadata: name: pod-configmap namespace: dev spec: containers: - name: nginx image: nginx:1.17.1 volumeMounts: # 将configmap挂载到目录 - name: config mountPath: /configmap/config volumes: # 引用configmap - name: config configMap: name: configmap # 创建pod [root@k8s-master01 ~]# kubectl create -f pod-configmap.yaml pod/pod-configmap created # 查看pod [root@k8s-master01 ~]# kubectl get pod pod-configmap -n dev NAME READY STATUS RESTARTS AGE pod-configmap 1/1 Running 0 6s #进入容器 [root@k8s-master01 ~]# kubectl exec -it pod-configmap -n dev /bin/sh # cd /configmap/config/ # ls info # more info username:admin password:123456 # 可以看到映射已经成功，每个configmap都映射成了一个目录 # key---\u0026gt;文件 value----\u0026gt;文件中的内容 # 此时如果更新configmap的内容, 容器中的值也会动态更新 8.3.2 Secret 在kubernetes中，还存在一种和ConfigMap非常类似的对象，称为Secret对象。它主要用于存储敏感信息，例如密码、秘钥、证书等等。\n首先使用base64对数据进行编码 [root@k8s-master01 ~]# echo -n \u0026#39;admin\u0026#39; | base64 #准备username YWRtaW4= [root@k8s-master01 ~]# echo -n \u0026#39;123456\u0026#39; | base64 #准备password MTIzNDU2 接下来编写secret.yaml，并创建Secret\napiVersion: v1 kind: Secret metadata: name: secret namespace: dev type: Opaque data: username: YWRtaW4= password: MTIzNDU2 # 创建secret [root@k8s-master01 ~]# kubectl create -f secret.yaml secret/secret created # 查看secret详情 [root@k8s-master01 ~]# kubectl describe secret secret -n dev Name: secret Namespace: dev Labels: \u0026lt;none\u0026gt; Annotations: \u0026lt;none\u0026gt; Type: Opaque Data ==== password: 6 bytes username: 5 bytes 创建pod-secret.yaml，将上面创建的secret挂载进去：\napiVersion: v1 kind: Pod metadata: name: pod-secret namespace: dev spec: containers: - name: nginx image: nginx:1.17.1 volumeMounts: # 将secret挂载到目录 - name: config mountPath: /secret/config volumes: - name: config secret: secretName: secret # 创建pod [root@k8s-master01 ~]# kubectl create -f pod-secret.yaml pod/pod-secret created # 查看pod [root@k8s-master01 ~]# kubectl get pod pod-secret -n dev NAME READY STATUS RESTARTS AGE pod-secret 1/1 Running 0 2m28s # 进入容器，查看secret信息，发现已经自动解码了 [root@k8s-master01 ~]# kubectl exec -it pod-secret /bin/sh -n dev / # ls /secret/config/ password username / # more /secret/config/username admin / # more /secret/config/password 123456 至此，已经实现了利用secret实现了信息的编码。\n9. 安全认证 9.1 访问控制概述 Kubernetes作为一个分布式集群的管理工具，保证集群的安全性是其一个重要的任务。所谓的安全性其实就是保证对Kubernetes的各种客户端进行认证和鉴权操作。\n客户端\n在Kubernetes集群中，客户端通常有两类：\nUser Account：一般是独立于kubernetes之外的其他服务管理的用户账号。 Service Account：kubernetes管理的账号，用于为Pod中的服务进程在访问Kubernetes时提供身份标识。 认证、授权与准入控制\nApiServer是访问及管理资源对象的唯一入口。任何一个请求访问ApiServer，都要经过下面三个流程：\nAuthentication（认证）：身份鉴别，只有正确的账号才能够通过认证 Authorization（授权）： 判断用户是否有权限对访问的资源执行特定的动作 Admission Control（准入控制）：用于补充授权机制以实现更加精细的访问控制功能。 9.2 认证管理 Kubernetes集群安全的最关键点在于如何识别并认证客户端身份，它提供了3种客户端身份认证方式：\nHTTP Base认证：通过用户名+密码的方式认证\n这种认证方式是把“用户名:密码”用BASE64算法进行编码后的字符串放在HTTP请求中的Header Authorization域里发送给服务端。服务端收到后进行解码，获取用户名及密码，然后进行用户身份认证的过程。 HTTP Token认证：通过一个Token来识别合法用户\n这种认证方式是用一个很长的难以被模仿的字符串--Token来表明客户身份的一种方式。每个Token对应一个用户名，当客户端发起API调用请求时，需要在HTTP Header里放入Token，API Server接到Token后会跟服务器中保存的token进行比对，然后进行用户身份认证的过程。 HTTPS证书认证：基于CA根证书签名的双向数字证书认证方式\n这种认证方式是安全性最高的一种方式，但是同时也是操作起来最麻烦的一种方式。 HTTPS认证大体分为3个过程：\n证书申请和下发\nHTTPS通信双方的服务器向CA机构申请证书，CA机构下发根证书、服务端证书及私钥给申请者 客户端和服务端的双向认证\n1\u0026gt; 客户端向服务器端发起请求，服务端下发自己的证书给客户端， 客户端接收到证书后，通过私钥解密证书，在证书中获得服务端的公钥， 客户端利用服务器端的公钥认证证书中的信息，如果一致，则认可这个服务器 2\u0026gt; 客户端发送自己的证书给服务器端，服务端接收到证书后，通过私钥解密证书， 在证书中获得客户端的公钥，并用该公钥认证证书信息，确认客户端是否合法 服务器端和客户端进行通信\n服务器端和客户端协商好加密方案后，客户端会产生一个随机的秘钥并加密，然后发送到服务器端。 服务器端接收这个秘钥后，双方接下来通信的所有内容都通过该随机秘钥加密 注意: Kubernetes允许同时配置多种认证方式，只要其中任意一个方式认证通过即可\n9.3 授权管理 授权发生在认证成功之后，通过认证就可以知道请求用户是谁， 然后Kubernetes会根据事先定义的授权策略来决定用户是否有权限访问，这个过程就称为授权。\n每个发送到ApiServer的请求都带上了用户和资源的信息：比如发送请求的用户、请求的路径、请求的动作等，授权就是根据这些信息和授权策略进行比较，如果符合策略，则认为授权通过，否则会返回错误。\nAPI Server目前支持以下几种授权策略：\nAlwaysDeny：表示拒绝所有请求，一般用于测试 AlwaysAllow：允许接收所有请求，相当于集群不需要授权流程（Kubernetes默认的策略） ABAC：基于属性的访问控制，表示使用用户配置的授权规则对用户请求进行匹配和控制 Webhook：通过调用外部REST服务对用户进行授权 Node：是一种专用模式，用于对kubelet发出的请求进行访问控制 RBAC：基于角色的访问控制（kubeadm安装方式下的默认选项） RBAC(Role-Based Access Control) 基于角色的访问控制，主要是在描述一件事情：给哪些对象授予了哪些权限\n其中涉及到了下面几个概念：\n对象：User、Groups、ServiceAccount 角色：代表着一组定义在资源上的可操作动作(权限)的集合 绑定：将定义好的角色跟用户绑定在一起 RBAC引入了4个顶级资源对象：\nRole、ClusterRole：角色，用于指定一组权限 RoleBinding、ClusterRoleBinding：角色绑定，用于将角色（权限）赋予给对象 Role、ClusterRole\n一个角色就是一组权限的集合，这里的权限都是许可形式的（白名单）。\n# Role只能对命名空间内的资源进行授权，需要指定nameapce kind: Role apiVersion: rbac.authorization.k8s.io/v1beta1 metadata: namespace: dev name: authorization-role rules: - apiGroups: [\u0026#34;\u0026#34;] # 支持的API组列表,\u0026#34;\u0026#34; 空字符串，表示核心API群 resources: [\u0026#34;pods\u0026#34;] # 支持的资源对象列表 verbs: [\u0026#34;get\u0026#34;, \u0026#34;watch\u0026#34;, \u0026#34;list\u0026#34;] # 允许的对资源对象的操作方法列表 # ClusterRole可以对集群范围内资源、跨namespaces的范围资源、非资源类型进行授权 kind: ClusterRole apiVersion: rbac.authorization.k8s.io/v1beta1 metadata: name: authorization-clusterrole rules: - apiGroups: [\u0026#34;\u0026#34;] resources: [\u0026#34;pods\u0026#34;] verbs: [\u0026#34;get\u0026#34;, \u0026#34;watch\u0026#34;, \u0026#34;list\u0026#34;] 需要详细说明的是，rules中的参数：\napiGroups: 支持的API组列表\n\u0026#34;\u0026#34;,\u0026#34;apps\u0026#34;, \u0026#34;autoscaling\u0026#34;, \u0026#34;batch\u0026#34; resources：支持的资源对象列表\n\u0026#34;services\u0026#34;, \u0026#34;endpoints\u0026#34;, \u0026#34;pods\u0026#34;,\u0026#34;secrets\u0026#34;,\u0026#34;configmaps\u0026#34;,\u0026#34;crontabs\u0026#34;,\u0026#34;deployments\u0026#34;,\u0026#34;jobs\u0026#34;, \u0026#34;nodes\u0026#34;,\u0026#34;rolebindings\u0026#34;,\u0026#34;clusterroles\u0026#34;,\u0026#34;daemonsets\u0026#34;,\u0026#34;replicasets\u0026#34;,\u0026#34;statefulsets\u0026#34;, \u0026#34;horizontalpodautoscalers\u0026#34;,\u0026#34;replicationcontrollers\u0026#34;,\u0026#34;cronjobs\u0026#34; verbs：对资源对象的操作方法列表\n\u0026#34;get\u0026#34;, \u0026#34;list\u0026#34;, \u0026#34;watch\u0026#34;, \u0026#34;create\u0026#34;, \u0026#34;update\u0026#34;, \u0026#34;patch\u0026#34;, \u0026#34;delete\u0026#34;, \u0026#34;exec\u0026#34; RoleBinding、ClusterRoleBinding\n角色绑定用来把一个角色绑定到一个目标对象上，绑定目标可以是User、Group或者ServiceAccount。\n# RoleBinding可以将同一namespace中的subject绑定到某个Role下，则此subject即具有该Role定义的权限 kind: RoleBinding apiVersion: rbac.authorization.k8s.io/v1beta1 metadata: name: authorization-role-binding namespace: dev subjects: - kind: User name: heima apiGroup: rbac.authorization.k8s.io roleRef: kind: Role name: authorization-role apiGroup: rbac.authorization.k8s.io # ClusterRoleBinding在整个集群级别和所有namespaces将特定的subject与ClusterRole绑定，授予权限 kind: ClusterRoleBinding apiVersion: rbac.authorization.k8s.io/v1beta1 metadata: name: authorization-clusterrole-binding subjects: - kind: User name: heima apiGroup: rbac.authorization.k8s.io roleRef: kind: ClusterRole name: authorization-clusterrole apiGroup: rbac.authorization.k8s.io RoleBinding引用ClusterRole进行授权\nRoleBinding可以引用ClusterRole，对属于同一命名空间内ClusterRole定义的资源主体进行授权。\n一种很常用的做法就是，集群管理员为集群范围预定义好一组角色（ClusterRole），然后在多个命名空间中重复使用这些ClusterRole。这样可以大幅提高授权管理工作效率，也使得各个命名空间下的基础性授权规则与使用体验保持一致。 # 虽然authorization-clusterrole是一个集群角色，但是因为使用了RoleBinding # 所以heima只能读取dev命名空间中的资源 kind: RoleBinding apiVersion: rbac.authorization.k8s.io/v1beta1 metadata: name: authorization-role-binding-ns namespace: dev subjects: - kind: User name: heima apiGroup: rbac.authorization.k8s.io roleRef: kind: ClusterRole name: authorization-clusterrole apiGroup: rbac.authorization.k8s.io 实战：创建一个只能管理dev空间下Pods资源的账号\n创建账号 # 1) 创建证书 [root@k8s-master01 pki]# cd /etc/kubernetes/pki/ [root@k8s-master01 pki]# (umask 077;openssl genrsa -out devman.key 2048) # 2) 用apiserver的证书去签署 # 2-1) 签名申请，申请的用户是devman,组是devgroup [root@k8s-master01 pki]# openssl req -new -key devman.key -out devman.csr -subj \u0026#34;/CN=devman/O=devgroup\u0026#34; # 2-2) 签署证书 [root@k8s-master01 pki]# openssl x509 -req -in devman.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out devman.crt -days 3650 # 3) 设置集群、用户、上下文信息 [root@k8s-master01 pki]# kubectl config set-cluster kubernetes --embed-certs=true --certificate-authority=/etc/kubernetes/pki/ca.crt --server=https:/192.168.109.100:6443 [root@k8s-master01 pki]# kubectl config set-credentials devman --embed-certs=true --client-certificate=/etc/kubernetes/pki/devman.crt --client-key=/etc/kubernetes/pki/devman.key [root@k8s-master01 pki]# kubectl config set-context devman@kubernetes --cluster=kubernetes --user=devman # 切换账户到devman [root@k8s-master01 pki]# kubectl config use-context devman@kubernetes Switched to context \u0026#34;devman@kubernetes\u0026#34;. # 查看dev下pod，发现没有权限 [root@k8s-master01 pki]# kubectl get pods -n dev Error from server (Forbidden): pods is forbidden: User \u0026#34;devman\u0026#34; cannot list resource \u0026#34;pods\u0026#34; in API group \u0026#34;\u0026#34; in the namespace \u0026#34;dev\u0026#34; # 切换到admin账户 [root@k8s-master01 pki]# kubectl config use-context kubernetes-admin@kubernetes Switched to context \u0026#34;kubernetes-admin@kubernetes\u0026#34;. 2） 创建Role和RoleBinding，为devman用户授权\nkind: Role apiVersion: rbac.authorization.k8s.io/v1beta1 metadata: namespace: dev name: dev-role rules: - apiGroups: [\u0026#34;\u0026#34;] resources: [\u0026#34;pods\u0026#34;] verbs: [\u0026#34;get\u0026#34;, \u0026#34;watch\u0026#34;, \u0026#34;list\u0026#34;] --- kind: RoleBinding apiVersion: rbac.authorization.k8s.io/v1beta1 metadata: name: authorization-role-binding namespace: dev subjects: - kind: User name: devman apiGroup: rbac.authorization.k8s.io roleRef: kind: Role name: dev-role apiGroup: rbac.authorization.k8s.io [root@k8s-master01 pki]# kubectl create -f dev-role.yaml role.rbac.authorization.k8s.io/dev-role created rolebinding.rbac.authorization.k8s.io/authorization-role-binding created 切换账户，再次验证\n# 切换账户到devman [root@k8s-master01 pki]# kubectl config use-context devman@kubernetes Switched to context \u0026#34;devman@kubernetes\u0026#34;. # 再次查看 [root@k8s-master01 pki]# kubectl get pods -n dev NAME READY STATUS RESTARTS AGE nginx-deployment-66cb59b984-8wp2k 1/1 Running 0 4d1h nginx-deployment-66cb59b984-dc46j 1/1 Running 0 4d1h nginx-deployment-66cb59b984-thfck 1/1 Running 0 4d1h # 为了不影响后面的学习,切回admin账户 [root@k8s-master01 pki]# kubectl config use-context kubernetes-admin@kubernetes Switched to context \u0026#34;kubernetes-admin@kubernetes\u0026#34;. 9.4 准入控制 通过了前面的认证和授权之后，还需要经过准入控制处理通过之后，apiserver才会处理这个请求。\n准入控制是一个可配置的控制器列表，可以通过在Api-Server上通过命令行设置选择执行哪些准入控制器：\n--admission-control=NamespaceLifecycle,LimitRanger,ServiceAccount,PersistentVolumeLabel, DefaultStorageClass,ResourceQuota,DefaultTolerationSeconds 只有当所有的准入控制器都检查通过之后，apiserver才执行该请求，否则返回拒绝。\n当前可配置的Admission Control准入控制如下：\nAlwaysAdmit：允许所有请求 AlwaysDeny：禁止所有请求，一般用于测试 AlwaysPullImages：在启动容器之前总去下载镜像 DenyExecOnPrivileged：它会拦截所有想在Privileged Container上执行命令的请求 ImagePolicyWebhook：这个插件将允许后端的一个Webhook程序来完成admission controller的功能。 Service Account：实现ServiceAccount实现了自动化 SecurityContextDeny：这个插件将使用SecurityContext的Pod中的定义全部失效 ResourceQuota：用于资源配额管理目的，观察所有请求，确保在namespace上的配额不会超标 LimitRanger：用于资源限制管理，作用于namespace上，确保对Pod进行资源限制 InitialResources：为未设置资源请求与限制的Pod，根据其镜像的历史资源的使用情况进行设置 NamespaceLifecycle：如果尝试在一个不存在的namespace中创建资源对象，则该创建请求将被拒绝。当删除一个namespace时，系统将会删除该namespace中所有对象。 DefaultStorageClass：为了实现共享存储的动态供应，为未指定StorageClass或PV的PVC尝试匹配默认的StorageClass，尽可能减少用户在申请PVC时所需了解的后端存储细节 DefaultTolerationSeconds：这个插件为那些没有设置forgiveness tolerations并具有notready:NoExecute和unreachable:NoExecute两种taints的Pod设置默认的“容忍”时间，为5min PodSecurityPolicy：这个插件用于在创建或修改Pod时决定是否根据Pod的security context和可用的PodSecurityPolicy对Pod的安全策略进行控制 10. DashBoard 之前在kubernetes中完成的所有操作都是通过命令行工具kubectl完成的。其实，为了提供更丰富的用户体验，kubernetes还开发了一个基于web的用户界面（Dashboard）。用户可以使用Dashboard部署容器化的应用，还可以监控应用的状态，执行故障排查以及管理kubernetes中各种资源。\n10.1 部署Dashboard 下载yaml，并运行Dashboard # 下载yaml [root@k8s-master01 ~]# wget https:/raw.githubusercontent.com/kubernetes/dashboard/v2.0.0/aio/deploy/recommended.yaml # 修改kubernetes-dashboard的Service类型 kind: Service apiVersion: v1 metadata: labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboard namespace: kubernetes-dashboard spec: type: NodePort # 新增 ports: - port: 443 targetPort: 8443 nodePort: 30009 # 新增 selector: k8s-app: kubernetes-dashboard # 部署 [root@k8s-master01 ~]# kubectl create -f recommended.yaml # 查看namespace下的kubernetes-dashboard下的资源 [root@k8s-master01 ~]# kubectl get pod,svc -n kubernetes-dashboard NAME READY STATUS RESTARTS AGE pod/dashboard-metrics-scraper-c79c65bb7-zwfvw 1/1 Running 0 111s pod/kubernetes-dashboard-56484d4c5-z95z5 1/1 Running 0 111s NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/dashboard-metrics-scraper ClusterIP 10.96.89.218 \u0026lt;none\u0026gt; 8000/TCP 111s service/kubernetes-dashboard NodePort 10.104.178.171 \u0026lt;none\u0026gt; 443:30009/TCP 111s 2）创建访问账户，获取token\n# 创建账号 [root@k8s-master01-1 ~]# kubectl create serviceaccount dashboard-admin -n kubernetes-dashboard # 授权 [root@k8s-master01-1 ~]# kubectl create clusterrolebinding dashboard-admin-rb --clusterrole=cluster-admin --serviceaccount=kubernetes-dashboard:dashboard-admin # 获取账号token [root@k8s-master01 ~]# kubectl get secrets -n kubernetes-dashboard | grep dashboard-admin dashboard-admin-token-xbqhh kubernetes.io/service-account-token 3 2m35s [root@k8s-master01 ~]# kubectl describe secrets dashboard-admin-token-xbqhh -n kubernetes-dashboard Name: dashboard-admin-token-xbqhh Namespace: kubernetes-dashboard Labels: \u0026lt;none\u0026gt; Annotations: kubernetes.io/service-account.name: dashboard-admin kubernetes.io/service-account.uid: 95d84d80-be7a-4d10-a2e0-68f90222d039 Type: kubernetes.io/service-account-token Data ==== namespace: 20 bytes token: eyJhbGciOiJSUzI1NiIsImtpZCI6ImJrYkF4bW5XcDhWcmNGUGJtek5NODFuSXl1aWptMmU2M3o4LTY5a2FKS2cifQ.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlcm5ldGVzLWRhc2hib2FyZCIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJkYXNoYm9hcmQtYWRtaW4tdG9rZW4teGJxaGgiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC5uYW1lIjoiZGFzaGJvYXJkLWFkbWluIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQudWlkIjoiOTVkODRkODAtYmU3YS00ZDEwLWEyZTAtNjhmOTAyMjJkMDM5Iiwic3ViIjoic3lzdGVtOnNlcnZpY2VhY2NvdW50Omt1YmVybmV0ZXMtZGFzaGJvYXJkOmRhc2hib2FyZC1hZG1pbiJ9.NAl7e8ZfWWdDoPxkqzJzTB46sK9E8iuJYnUI9vnBaY3Jts7T1g1msjsBnbxzQSYgAG--cV0WYxjndzJY_UWCwaGPrQrt_GunxmOK9AUnzURqm55GR2RXIZtjsWVP2EBatsDgHRmuUbQvTFOvdJB4x3nXcYLN2opAaMqg3rnU2rr-A8zCrIuX_eca12wIp_QiuP3SF-tzpdLpsyRfegTJZl6YnSGyaVkC9id-cxZRb307qdCfXPfCHR_2rt5FVfxARgg_C0e3eFHaaYQO7CitxsnIoIXpOFNAR8aUrmopJyODQIPqBWUehb7FhlU1DCduHnIIXVC_UICZ-MKYewBDLw ca.crt: 1025 bytes 3）通过浏览器访问Dashboard的UI\n在登录页面上输入上面的token\n出现下面的页面代表成功\n10.2 使用DashBoard 本章节以Deployment为例演示DashBoard的使用\n查看\n选择指定的命名空间dev，然后点击Deployments，查看dev空间下的所有deployment\n扩缩容\n在Deployment上点击规模，然后指定目标副本数量，点击确定\n编辑\n在Deployment上点击编辑，然后修改yaml文件，点击确定\n查看Pod\n点击Pods, 查看pods列表\n操作Pod\n选中某个Pod，可以对其执行日志（logs）、进入执行（exec）、编辑、删除操作\nDashboard提供了kubectl的绝大部分功能，这里不再一一演示\n","permalink":"https://xyenvy.github.io/posts/kubernetes/","summary":"Kubernetes详细教程 1. Kubernetes介绍 1.1 应用部署方式演变 在部署应用程序的方式上，主要经历了三个时代： 传统部署：互联网早期，会直接将应用程序部署在物理机上 优点：简单，不需要其它技术的参与 缺点：不能为应用程序定义资源使用边界，很难合理地分配计算资源，而且程序之间容易产","title":"Kubernetes详细教程"},{"content":"选择服务器平台 zabbix版本 OS分布 OS版本 zabbix component 数据库 web server 5.0LTS CentOS 7 Server,Forontend,Agent MySQL Nginx 安装和配置zabbix 安装zabbix仓库 # rpm -Uvh https://repo.zabbix.com/zabbix/5.0/rhel/7/x86_64/zabbix-release-5.0-1.el7.noarch.rpm # yum clean all 安装zabbix # 安装Zabbix server，Web前端，agent # yum install zabbix-server-mysql zabbix-agent 安装Zabbix frontend 启用红帽软件集合\n# yum install centos-release-scl 编辑配置文件\n/etc/yum.repos.d/zabbix.repo and enable zabbix-frontend repository. # 修改enable的值为1 [zabbix-frontend] ... enabled=1 ... 安装Zabbix frontend 包\n# yum install zabbix-web-mysql-scl zabbix-nginx-conf-scl 创建初始数据库 注意:MySQL数据库的安装这里不做说明 在数据库主机上运行以下代码\n# mysql -uroot -p password mysql\u0026gt; create database zabbix character set utf8 collate utf8_bin; mysql\u0026gt; create user zabbix@localhost identified by \u0026#39;password\u0026#39;; mysql\u0026gt; grant all privileges on zabbix.* to zabbix@localhost; mysql\u0026gt; set global log_bin_trust_function_creators = 1; mysql\u0026gt; quit; 导入初始架构和数据\n# zcat /usr/share/doc/zabbix-server-mysql*/create.sql.gz | mysql -uzabbix -p zabbix 在导入数据库后禁用log_bin_trust_function_creators选项\n# mysql -uroot -p password mysql\u0026gt; set global log_bin_trust_function_creators = 0; mysql\u0026gt; quit; zabbix server配置数据库 编辑配置文件 /etc/zabbix/zabbix_server.conf\nDBPassword=password zabbix前端配置PHP 编辑配置文件 /etc/opt/rh/rh-nginx116/nginx/conf.d/zabbix.conf uncomment and set \u0026rsquo;listen\u0026rsquo; and \u0026lsquo;server_name\u0026rsquo; directives.\n# listen 80; # server_name example.com; 编辑配置文件 /etc/opt/rh/rh-php72/php-fpm.d/zabbix.conf add nginx to listen.acl_users directive.\nlisten.acl_users = apache,nginx 取消注释，设置正确的时区。\nphp_value[date.timezone] = Asia/Shanghai 启动Zabbix server和agent进程 # systemctl restart zabbix-server zabbix-agent rh-nginx116-nginx rh-php72-php-fpm # systemctl enable zabbix-server zabbix-agent rh-nginx116-nginx rh-php72-php-fpm 开始使用zabbix 注意：使用过程这里不叙述 ","permalink":"https://xyenvy.github.io/posts/zabbix5%E9%83%A8%E7%BD%B2%E5%AE%89%E8%A3%85/","summary":"选择服务器平台 zabbix版本 OS分布 OS版本 zabbix component 数据库 web server 5.0LTS CentOS 7 Server,Forontend,Agent MySQL Nginx 安装和配置zabbix 安装zabbix仓库 # rpm -Uvh https://repo.zabbix.com/zabbix/5.0/rhel/7/x86_64/zabbix-release-5.0-1.el7.noarch.rpm # yum clean all 安装zabbix # 安装Zabbix server，Web前端，agent # yum install zabbix-server-mysql zabbix-agent 安装Zabbix frontend 启用红帽软件集合 # yum install centos-release-scl 编辑配置文件 /etc/yum.repos.d/zabbix.repo and enable zabbix-frontend repository. # 修改","title":"zabbix5部署安装"},{"content":"搭建Kubernetes集群 部署前提 使用kubeadm部署Kubernetes集群的前提条件 支持Kubernetes运行的Linux主机，例如Debian、RedHat及其变体等 每主机2GB以上的内存，以及2颗以上的CPU 各主机间能够通过网络无障碍通信 独占的hostname、MAC地址以及product_uuid，主机名能够正常解析 放行由Kubernetes使用到的各端口，或直接禁用iptables 禁用各主机的上的Swap设备 各主机时间同步 部署环境 OS: Ubuntu 20.04.2 LTS Docker：20.10.10，CGroup Driver: systemd Kubernetes：v1.26.3, CRI: containerd, CNI: Flannel 主机 主机IP 主机名称 角色 192.168.32.200 k8s-master01.org master 192.168.32.203 k8s-node01.org node01 192.168.32.204 k8s-node02.org node02 192.168.32.205 k8s-node03.org node03 修改主机名称 # 修改192.168.32.200的主机名称为k8s-master01.org # 修改192.168.32.203的主机名称为k8s-node01.org # 修改192.168.32.204的主机名称为k8s-node02.org # 修改192.168.32.205的主机名称为k8s-node03.org 主机时间同步 在所有主机上安装 chrony\n## 所有主机上执行 root@k8s-master01:~# apt install -y chrony 建议用户配置使用本地的的时间服务器，在节点数量众多时尤其如此。存在可用的本地时间服务器时，修改节点的/etc/chrony/chrony.conf配置文件，并将时间服务器指向相应的主机即可，配置格式如下：\nserver CHRONY-SERVER-NAME-OR-IP iburst 主机名称解析 出于简化配置步骤的目的，本测试环境使用hosts文件进行各节点名称解析，文件内容如下所示。其中，我们使用kubeapi主机名作为API Server在高可用环境中的专用接入名称，也为控制平面的高可用配置留下便于配置的余地。\n# 编辑/etc/hosts文件加入如下内容 root@k8s-master01:~# vim /etc/hosts 192.168.32.200 k8s-master01.org 192.168.32.203 k8s-node01.org 192.168.32.204 k8s-node02.org 192.168.32.205 k8s-node03.org 禁用Swap设备 部署集群时，kubeadm默认会预先检查当前主机是否禁用了Swap设备，并在未禁用时强制终止部署过程。因此，在主机内存资源充裕的条件下，需要禁用所有的Swap设备，否则，就需要在后文的kubeadm init及kubeadm join命令执行时额外使用相关的选项忽略检查错误。\n关闭Swap设备，需要分两步完成。首先是关闭当前已启用的所有Swap设备：\n# 临时关闭，所有机器执行 root@k8s-master01:~# swapoff -a 而后编辑/etc/fstab配置文件，注释用于挂载Swap设备的所有行\n# 所有机器执行 root@k8s-master01:~#vim /etc/fstab # 注释如下一行 #/swap.img none swap sw 0 0 禁用默认的防火墙服务 Ubuntu和Debian等Linux发行版默认使用ufw（Uncomplicated FireWall）作为前端来简化 iptables的使用，处于启用状态时，它默认会生成一些规则以加强系统安全。出于降低配置复杂度之目的，本文选择直接将其禁用。\nroot@k8s-master01:~# ufw disable Firewall stopped and disabled on system startup root@k8s-master01:~# ufw status Status: inactive root@k8s-master01:~# 安装程序包 提示：以下操作需要在本示例中的所有四台主机上分别进行\n安装并启动docker 首先，生成docker-ce相关程序包的仓库，这里以阿里云的镜像服务器为例进行说明\ndocker-ce镜像_docker-ce下载地址_docker-ce安装教程-阿里巴巴开源镜像站 (aliyun.com)\n# step 1: 安装必要的一些系统工具 sudo apt-get update sudo apt-get -y install apt-transport-https ca-certificates curl software-properties-common # step 2: 安装GPG证书 curl -fsSL https://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo apt-key add - # Step 3: 写入软件源信息 sudo add-apt-repository \u0026#34;deb [arch=amd64] https://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs) stable\u0026#34; # Step 4: 更新并安装Docker-CE sudo apt-get -y update sudo apt-get -y install docker-ce # 安装指定版本的Docker-CE: # Step 1: 查找Docker-CE的版本: # apt-cache madison docker-ce # docker-ce | 17.03.1~ce-0~ubuntu-xenial | https://mirrors.aliyun.com/docker-ce/linux/ubuntu xenial/stable amd64 Packages # docker-ce | 17.03.0~ce-0~ubuntu-xenial | https://mirrors.aliyun.com/docker-ce/linux/ubuntu xenial/stable amd64 Packages # Step 2: 安装指定版本的Docker-CE: (VERSION例如上面的17.03.1~ce-0~ubuntu-xenial) # sudo apt-get -y install docker-ce=[VERSION] 本文以为20.10.10版本为例\nroot@k8s-node3:~# apt install docker-ce=5:20.10.10~3-0~ubuntu-focal docker-ce-cli=5:20.10.10~3-0~ubuntu-focal kubelet需要让docker容器引擎使用systemd作为CGroup的驱动，其默认值为cgroupfs，因而，我们还需要编辑docker的配置文件/etc/docker/daemon.json，添加如下内容，其中的registry-mirrors用于指明使用的镜像加速服务。\nvim /etc/docker/daemon.json { \u0026#34;registry-mirrors\u0026#34;: [ \u0026#34;https://ung2thfc.mirror.aliyuncs.com\u0026#34;, \u0026#34;https://mirror.ccs.tencentyun.com\u0026#34;, \u0026#34;https://registry.docker-cn.com\u0026#34;, \u0026#34;http://hub-mirror.c.163.com\u0026#34;, \u0026#34;https://docker.mirrors.ustc.edu.cn\u0026#34;], \u0026#34;exec-opts\u0026#34;: [\u0026#34;native.cgroupdriver=systemd\u0026#34;] } systemctl daemon-reload \u0026amp;\u0026amp; systemctl restart docker 安装cri-dockerd Kubernetes自v1.24移除了对docker-shim的支持，而Docker Engine默认又不支持CRI规范，因而二者将无法直接完成整合。为此，Mirantis和Docker联合创建了cri-dockerd项目，用于为Docker Engine提供一个能够支持到CRI规范的垫片，从而能够让Kubernetes基于CRI控制Docker 。\n项目地址\ncri-dockerd项目提供了预制的二进制格式的程序包，用户按需下载相应的系统和对应平台的版本即可完成安装，这里以Ubuntu 2004 64bits系统环境，以及cri-dockerd目前最新的程序版本v0.3.0为例。\nwget https://github.com/Mirantis/cri-dockerd/releases/download/v0.3.0/cri-dockerd_0.3.0.3-0.ubuntu-focal_amd64.deb dpkg -i cri-dockerd_0.3.0.3-0.ubuntu-focal_amd64.deb 完成安装后，相应的服务cri-dockerd.service便会自动启动。我们也可以使用如下命令进行验证，若服务处于Running状态即可进行后续步骤 。\nroot@k8s-master01:~# systemctl status cri-docker.service ● cri-docker.service - CRI Interface for Docker Application Container Engine Loaded: loaded (/lib/systemd/system/cri-docker.service; enabled; vendor preset: enabled) Active: active (running) since Tue 2023-03-21 10:59:57 CST; 1min 20s ago TriggeredBy: ● cri-docker.socket Docs: https://docs.mirantis.com Main PID: 17591 (cri-dockerd) Tasks: 7 Memory: 11.9M CGroup: /system.slice/cri-docker.service └─17591 /usr/bin/cri-dockerd --container-runtime-endpoint fd:// Mar 21 10:59:57 k8s-master01.org cri-dockerd[17591]: time=\u0026#34;2023-03-21T10:59:57+08:00\u0026#34; level=info msg=\u0026#34;Start docker client with request timeout 0s\u0026#34; Mar 21 10:59:57 k8s-master01.org cri-dockerd[17591]: time=\u0026#34;2023-03-21T10:59:57+08:00\u0026#34; level=info msg=\u0026#34;Hairpin mode is set to none\u0026#34; Mar 21 10:59:57 k8s-master01.org cri-dockerd[17591]: time=\u0026#34;2023-03-21T10:59:57+08:00\u0026#34; level=info msg=\u0026#34;Loaded network plugin cni\u0026#34; Mar 21 10:59:57 k8s-master01.org cri-dockerd[17591]: time=\u0026#34;2023-03-21T10:59:57+08:00\u0026#34; level=info msg=\u0026#34;Docker cri networking managed by network plugin cni\u0026#34; Mar 21 10:59:57 k8s-master01.org systemd[1]: Started CRI Interface for Docker Application Container Engine. Mar 21 10:59:58 k8s-master01.org cri-dockerd[17591]: time=\u0026#34;2023-03-21T10:59:57+08:00\u0026#34; level=info msg=\u0026#34;Docker Info: \u0026amp;{ID:WQBA:P7R2:H6ZI:KWU3:FVFW:MHLC:QTT7:CJCX\u0026gt; Mar 21 10:59:58 k8s-master01.org cri-dockerd[17591]: time=\u0026#34;2023-03-21T10:59:57+08:00\u0026#34; level=info msg=\u0026#34;Setting cgroupDriver cgroupfs\u0026#34; Mar 21 10:59:58 k8s-master01.org cri-dockerd[17591]: time=\u0026#34;2023-03-21T10:59:57+08:00\u0026#34; level=info msg=\u0026#34;Docker cri received runtime config \u0026amp;RuntimeConfig{Network\u0026gt; Mar 21 10:59:58 k8s-master01.org cri-dockerd[17591]: time=\u0026#34;2023-03-21T10:59:57+08:00\u0026#34; level=info msg=\u0026#34;Starting the GRPC backend for the Docker CRI interface.\u0026#34; Mar 21 10:59:58 k8s-master01.org cri-dockerd[17591]: time=\u0026#34;2023-03-21T10:59:57+08:00\u0026#34; level=info msg=\u0026#34;Start cri-dockerd grpc backend\u0026#34; lines 1-21/21 (END) 安装kubelet、kubeadm和kubectl 首先，在各主机上生成kubelet和kubeadm等相关程序包的仓库，这里以阿里云的镜像服务为例\napt-get update \u0026amp;\u0026amp; apt-get install -y apt-transport-https curl https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | apt-key add - cat \u0026lt;\u0026lt;EOF \u0026gt;/etc/apt/sources.list.d/kubernetes.list deb https://mirrors.aliyun.com/kubernetes/apt/ kubernetes-xenial main EOF apt-get update apt-get install -y kubelet kubeadm kubectl 安装完成后，要确保kubeadm等程序文件的版本，这将也是后面初始化Kubernetes集群时需要明确指定的版本号\n整合kubelet和cri-dockerd 仅支持CRI规范的kubelet需要经由遵循该规范的cri-dockerd完成与docker-ce的整合。\n配置cri-dockerd 配置cri-dockerd，确保其能够正确加载到CNI插件。编辑/usr/lib/systemd/system/cri-docker.service文件，确保其[Service]配置段中的ExecStart的值类似如下内容\nExecStart=/usr/bin/cri-dockerd --container-runtime-endpoint fd:// --network-plugin=cni --pod-infra-container-image=registry.aliyuncs.com/google_containers/pause:3.7 --cni-bin-dir=/opt/cni/bin --cni-cache-dir=/var/lib/cni/cache --cni-conf-dir=/etc/cni/net.d 需要添加的各配置参数（各参数的值要与系统部署的CNI插件的实际路径相对应）：\n\u0026ndash;network-plugin：指定网络插件规范的类型，这里要使用CNI； \u0026ndash;cni-bin-dir：指定CNI插件二进制程序文件的搜索目录； \u0026ndash;cni-cache-dir：CNI插件使用的缓存目录； \u0026ndash;cni-conf-dir：CNI插件加载配置文件的目录； 配置完成后，重载并重启cri-docker.service服务。\nroot@k8s-master01:~# systemctl daemon-reload;systemctl restart cri-docker 配置kubelet 配置kubelet，为其指定cri-dockerd在本地打开的Unix Sock文件的路径，该路径一般默认为“/run/cri-dockerd.sock“。编辑文件/etc/sysconfig/kubelet，为其添加 如下指定参数。\n提示：若/etc/sysconfig目录不存在，则需要先创建该目录。\nKUBELET_KUBEADM_ARGS=\u0026#34;--container-runtime=remote --container-runtime-endpoint=/run/cri-dockerd.sock\u0026#34; 需要说明的是，该配置也可不进行，而是直接在后面的各kubeadm命令上使用“\u0026ndash;cri-socket unix:///run/cri-dockerd.sock”选项。\n初始化第一个主节点 该步骤开始尝试构建Kubernetes集群的master节点，配置完成后，各worker节点直接加入到集群中的即可。需要特别说明的是，由kubeadm部署的Kubernetes集群上，集群核心组件kube-apiserver、kube-controller-manager、kube-scheduler和etcd等均会以静态Pod的形式运行，它们所依赖的镜像文件默认来自于registry.k8s.io这一Registry服务之上。但我们无法直接访问该服务，常用的解决办法有如下两种\n使用能够到达该服务的代理服务； 使用国内的镜像服务器上的服务，例如registry.aliyuncs.com/google_containers等。 初始化master节点（在k8s-master01上完成如下操作） 运行如下命令完成k8s-master01节点的初始化：\nkubeadm init --image-repository registry.aliyuncs.com/google_containers --kubernetes-version=v1.26.3 --pod-network-cidr=10.244.0.0/16 --service-cidr=10.96.0.0/12 --token-ttl=0 --cri-socket unix:///run/cri-dockerd.sock 命令中的各选项简单说明如下：\n\u0026ndash;image-repository：指定要使用的镜像仓库，默认为registry.k8s.io； \u0026ndash;kubernetes-version：kubernetes程序组件的版本号，它必须要与安装的kubelet程序包的版本号相同； \u0026ndash;control-plane-endpoint：控制平面的固定访问端点，可以是IP地址或DNS名称，会被用于集群管理员及集群组件的kubeconfig配置文件的API Server的访问地址；单控制平面部署时可以不使用该选项； \u0026ndash;pod-network-cidr：Pod网络的地址范围，其值为CIDR格式的网络地址，通常，Flannel网络插件的默认为10.244.0.0/16，Project Calico插件的默认值为192.168.0.0/16； \u0026ndash;service-cidr：Service的网络地址范围，其值为CIDR格式的网络地址，默认为10.96.0.0/12；通常，仅Flannel一类的网络插件需要手动指定该地址； \u0026ndash;apiserver-advertise-address：apiserver通告给其他组件的IP地址，一般应该为Master节点的用于集群内部通信的IP地址，0.0.0.0表示节点上所有可用地址； \u0026ndash;token-ttl：共享令牌（token）的过期时长，默认为24小时，0表示永不过期；为防止不安全存储等原因导致的令牌泄露危及集群安全，建议为其设定过期时长。未设定该选项时，在token过期后，若期望再向集群中加入其它节点，可以使用如下命令重新创建token，并生成节点加入命令。 初始化完成后的操作步骤 对于Kubernetes系统的新用户来说，无论使用上述哪种方法，命令运行结束后，请记录最后的kubeadm join命令输出的最后提示的操作步骤。下面的内容是需要用户记录的一个命令输出示例，它提示了后续需要的操作步骤。\n# 下面是成功完成第一个控制平面节点初始化的提示信息及后续需要完成的步骤 Your Kubernetes control-plane has initialized successfully! # 为了完成初始化操作，管理员需要额外手动完成几个必要的步骤 To start using your cluster, you need to run the following as a regular user: # 第1个步骤提示， Kubernetes集群管理员认证到Kubernetes集群时使用的kubeconfig配置文件 mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config # 我们也可以不做上述设定，而使用环境变量KUBECONFIG为kubectl等指定默认使用的kubeconfig； Alternatively, if you are the root user, you can run: export KUBECONFIG=/etc/kubernetes/admin.conf # 第2个步骤提示，为Kubernetes集群部署一个网络插件，具体选用的插件则取决于管理员； You should now deploy a pod network to the cluster. Run \u0026#34;kubectl apply -f [podnetwork].yaml\u0026#34; with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/ # 第3个步骤提示，向集群添加额外的控制平面节点，但本文会略过该步骤，并将在其它文章介绍其实现方式。 You can now join any number of the control-plane node running the following command on each as root: # 第4个步骤提示，向集群添加工作节点 Then you can join any number of worker nodes by running the following on each as root: # 在部署好kubeadm等程序包的各工作节点上以root用户运行类似如下命令； # 提示：与cri-dockerd结合使用docker-ce作为container runtime时，通常需要为下面的命令 # 额外附加“--cri-socket unix:///run/cri-dockerd.sock”选项； kubeadm join 192.168.32.200:6443 --token ivu3t7.pogk70dd5pualoz2 \\ --discovery-token-ca-cert-hash sha256:3edb3c8e3e6c944afe65b2616d46b49305c1420e6967c1fab966ddf8f149502d 设定kubectl kubectl是kube-apiserver的命令行客户端程序，实现了除系统部署之外的几乎全部的管理操作，是kubernetes管理员使用最多的命令之一。kubectl需经由API server认证及授权后方能执行相应的管理操作，kubeadm部署的集群为其生成了一个具有管理员权限的认证配置文件/etc/kubernetes/admin.conf，它可由kubectl通过默认的“$HOME/.kube/config”的路径进行加载。当然，用户也可在kubectl命令上使用\u0026ndash;kubeconfig选项指定一个别的位置。\n下面复制认证为Kubernetes系统管理员的配置文件至目标用户（例如当前用户root）的家目录下：\n~# mkdir ~/.kube\n~# cp /etc/kubernetes/admin.conf ~/.kube/config\n部署网络插件 Kubernetes系统上Pod网络的实现依赖于第三方插件进行，这类插件有近数十种之多，较为著名的有flannel、calico、canal和kube-router等，简单易用的实现是为CoreOS提供的flannel项目。下面的命令用于在线部署flannel至Kubernetes系统之上：\n首先，下载适配系统及硬件平台环境的flanneld至每个节点，并放置于/opt/bin/目录下。我们这里选用flanneld-amd64，目前最新的版本为v0.21.3，因而，我们需要在集群的每个节点上执行如下命令：\n~# mkdir /opt/cni/bin/ ~# curl -L https://github.com/flannel-io/flannel/releases/download/v0.20.2/flanneld-amd64 -o /opt/cni/bin/flanneld ~# chmod +x /opt/cni/bin/flanneld 提示：下载flanneld的地址为 https://github.com/flannel-io/flannel/releases 随后，在初始化的第一个master节点k8s-master01上运行如下命令，向Kubernetes部署kube-flannel\nkubectl apply -f https://raw.githubusercontent.com/flannel-io/flannel/v0.21.3/Documentation/kube-flannel.yml 而后使用如下命令确认其输出结果中Pod的状态为“Running”，类似如下命令及其输入的结果所示：\nroot@k8s-master01:~# kubectl get pods -n kube-flannel NAME READY STATUS RESTARTS AGE kube-flannel-ds-jgkxd 1/1 Running 0 2m59s root@k8s-master01:~# 验证master节点已经就绪 kubectl get nodes\n上述命令应该会得到类似如下输出，这表示k8s-master01节点已经就绪\nroot@k8s-master01:~# kubectl get nodes NAME STATUS ROLES AGE VERSION k8s-master01.org Ready control-plane 62m v1.26.3 root@k8s-master01:~# 添加节点到集群中 下面的两个步骤，需要分别在k8s-node01、k8s-node02和k8s-node03上各自完成。\n1、若未禁用Swap设备，编辑kubelet的配置文件/etc/default/kubelet，设置其忽略Swap启用的状态错误，内容如下：KUBELET_EXTRA_ARGS=\u0026quot;\u0026ndash;fail-swap-on=false\u0026quot;\n2、将节点加入第二步中创建的master的集群中，要使用主节点初始化过程中记录的kubeadm join命令；\nroot@k8s-node01:/opt/cni/bin# kubeadm join 192.168.32.200:6443 --token ivu3t7.pogk70dd5pualoz2 --discovery-token-ca-cert-hash sha256:3edb3c8e3e6c944afe65b2616d46b49305c1420e6967c1fab966ddf8f149502d --cri-socket unix:///run/cri-dockerd.sock 验证节点添加结果 在每个节点添加完成后，即可通过kubectl验证添加结果。下面的命令及其输出是在所有的三个节点均添加完成后运行的，其输出结果表明三个Worker Node已经准备就绪。\n~# kubectl get nodes\nroot@k8s-master01:~# kubectl get nodes NAME STATUS ROLES AGE VERSION k8s-master01.org Ready control-plane 80m v1.26.3 k8s-node01.org Ready \u0026lt;none\u0026gt; 15m v1.26.3 k8s-node2.org Ready \u0026lt;none\u0026gt; 114s v1.26.3 k8s-node3.org Ready \u0026lt;none\u0026gt; 11m v1.26.3 root@k8s-master01:~# 测试应用编排及服务访问 到此为止，一个master，并附带有三个worker的kubernetes集群基础设施已经部署完成，用户随后即可测试其核心功能。\nroot@k8s-master01:~# kubectl create deployment test-nginx --image=nginx:latest --replicas=3 deployment.apps/test-nginx created root@k8s-master01:~# root@k8s-master01:~# kubectl create service nodeport test-nginx --tcp=80:80 service/test-nginx created root@k8s-master01:~# 而后，使用如下命令了解Service对象test-nginx使用的NodePort，以便于在集群外部进行访问：\nroot@k8s-master01:~# kubectl get svc -l app=test-nginx NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE test-nginx NodePort 10.100.229.239 \u0026lt;none\u0026gt; 80:31888/TCP 50s root@k8s-master01:~# 因此，用户可以于集群外部通过\u0026#34;http://NodeIP:31888\u0026#34;这个URL访问we应用，例如于集群外通过浏览器访问\u0026#34;http://192.168.32.203:31888\u0026#34; 小结 本文给出了部署Kubernetes分布式集群的具体步骤，并在最后测试了将应用部署并运行于Kubernetes系统上的结果。在读者朋友们自行测试时，cri-dockerd、docker-ce、flannel、kubeadm、kubectl和kubelet的版本均可能存在版本上的不同，也因此可能会存在一定程度上的配置差异，具体调整方式请大家自行参考相关的文档进行\n","permalink":"https://xyenvy.github.io/posts/%E6%90%AD%E5%BB%BAkubernetes%E9%9B%86%E7%BE%A4/","summary":"搭建Kubernetes集群 部署前提 使用kubeadm部署Kubernetes集群的前提条件 支持Kubernetes运行的Linux主机，例如Debian、RedHat及其变体等 每主机2GB以上的内存，以及2颗以上的CPU 各主机间能够通过网络无障碍通信 独占的hostname、MA","title":"搭建Kubernetes集群"},{"content":"#!/bin/bash #******************************************************************** #Author: yuankun #Date: 2023-03-18 #FileName： install_zookeeper.sh #Description： The test script #Copyright (C): 2023 All rights reserved #******************************************************************** JDK_FILE=\u0026#34;jdk-8u321-linux-x64.tar.gz\u0026#34; #JDK_FILE=\u0026#34;jdk-11.0.12_linux-x64_bin.tar.gz\u0026#34; ZOOKEEPER_FILE=apache-zookeeper-3.7.1-bin TAR=tar.gz ZOOKEEPER_DIR=/usr/local/src DIR=`pwd` JDK_DIR=\u0026#34;/usr/local\u0026#34; color () { RES_COL=60 MOVE_TO_COL=\u0026#34;echo -en \\\\033[${RES_COL}G\u0026#34; SETCOLOR_SUCCESS=\u0026#34;echo -en \\\\033[1;32m\u0026#34; SETCOLOR_FAILURE=\u0026#34;echo -en \\\\033[1;31m\u0026#34; SETCOLOR_WARNING=\u0026#34;echo -en \\\\033[1;33m\u0026#34; SETCOLOR_NORMAL=\u0026#34;echo -en \\E[0m\u0026#34; echo -n \u0026#34;$2\u0026#34; \u0026amp;\u0026amp; $MOVE_TO_COL echo -n \u0026#34;[\u0026#34; if [ $1 = \u0026#34;success\u0026#34; -o $1 = \u0026#34;0\u0026#34; ] ;then ${SETCOLOR_SUCCESS} echo -n $\u0026#34; OK \u0026#34; elif [ $1 = \u0026#34;failure\u0026#34; -o $1 = \u0026#34;1\u0026#34; ] ;then ${SETCOLOR_FAILURE} echo -n $\u0026#34;FAILED\u0026#34; else ${SETCOLOR_WARNING} echo -n $\u0026#34;WARNING\u0026#34; fi ${SETCOLOR_NORMAL} echo -n \u0026#34;]\u0026#34; echo } install_jdk(){ if ! [ -f \u0026#34;$DIR/$JDK_FILE\u0026#34; ];then color 1 \u0026#34;$JDK_FILE 文件不存在\u0026#34; exit; elif [ -d $JDK_DIR/jdk ];then color 1 \u0026#34;JDK 已经安装\u0026#34; exit else [ -d \u0026#34;$JDK_DIR\u0026#34; ] || mkdir -pv $JDK_DIR fi tar xvf $DIR/$JDK_FILE -C $JDK_DIR cd $JDK_DIR \u0026amp;\u0026amp; ln -s jdk* jdk cat \u0026gt; /etc/profile.d/jdk.sh \u0026lt;\u0026lt;EOF export JAVA_HOME=$JDK_DIR/jdk #export JRE_HOME=\\$JAVA_HOME/jre #export CLASSPATH=.:\\$JAVA_HOME/lib/:\\$JRE_HOME/lib/ export PATH=\\$PATH:\\$JAVA_HOME/bin EOF . /etc/profile.d/jdk.sh java -version \u0026amp;\u0026amp; color 0 \u0026#34;JDK 安装完成\u0026#34; || { color 1 \u0026#34;JDK 安装失败\u0026#34; ; exit; } } install_zookeeper(){ cd ${DIR} if [ -f \u0026#34;${ZOOKEEPER_FILE}.${TAR}\u0026#34; ] then echo \u0026#39;正在安装zookeeper,请稍等......\u0026#39; mv ${ZOOKEEPER_FILE}.${TAR} ${ZOOKEEPER_DIR};cd ${ZOOKEEPER_DIR} tar xf ${ZOOKEEPER_FILE}.${TAR};ln -s ${ZOOKEEPER_DIR}/${ZOOKEEPER_FILE} ${ZOOKEEPER_DIR}/zookeeper rm -rf ${ZOOKEEPER_FILE}.${TAR} mkdir -p /data/zookeeper;cd ${ZOOKEEPER_DIR}/zookeeper/conf cp zoo_sample.cfg zoo.cfg;sed -i \u0026#39;s/dataDir=\\/tmp\\/zookeeper/dataDir=\\/data\\/zookeeper/\u0026#39; zoo.cfg cat \u0026gt; /usr/lib/systemd/system/zookeeper.service \u0026lt;\u0026lt;EOF [Unit] Description=Zookeeper Service unit Configuration After=network.target [Service] Type=forking Environment=JAVA_HOME=${JDK_DIR}/jdk ExecStart=${ZOOKEEPER_DIR}/zookeeper/bin/zkServer.sh start ${ZOOKEEPER_DIR}/zookeeper/conf/zoo.cfg ExecStop=${ZOOKEEPER_DIR}/zookeeper/bin/zkServer.sh stop KillMode=none Restart=on-failure [Install] WantedBy=multi-user.target EOF systemctl daemon-reload;systemctl enable --now zookeeper if [ $? -eq 0 ] then echo \u0026#39;zookeeper启动成功!安装完成\u0026#39; else echo \u0026#39;zookeeper启动失败!安装失败\u0026#39; fi else echo \u0026#39;文件不存在,退出安装!\u0026#39; exit; fi } install_jdk install_zookeeper ","permalink":"https://xyenvy.github.io/posts/zookeeper%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85%E8%84%9A%E6%9C%AC/","summary":"#!/bin/bash #******************************************************************** #Author: yuankun #Date: 2023-03-18 #FileName： install_zookeeper.sh #Description： The test script #Copyright (C): 2023 All rights reserved #******************************************************************** JDK_FILE=\u0026#34;jdk-8u321-linux-x64.tar.gz\u0026#34; #JDK_FILE=\u0026#34;jdk-11.0.12_linux-x64_bin.tar.gz\u0026#34; ZOOKEEPER_FILE=apache-zookeeper-3.7.1-bin TAR=tar.gz ZOOKEEPER_DIR=/usr/local/src DIR=`pwd` JDK_DIR=\u0026#34;/usr/local\u0026#34; color () { RES_COL=60 MOVE_TO_COL=\u0026#34;echo -en \\\\033[${RES_COL}G\u0026#34; SETCOLOR_SUCCESS=\u0026#34;echo -en \\\\033[1;32m\u0026#34; SETCOLOR_FAILURE=\u0026#34;echo -en \\\\033[1;31m\u0026#34; SETCOLOR_WARNING=\u0026#34;echo -en \\\\033[1;33m\u0026#34; SETCOLOR_NORMAL=\u0026#34;echo -en \\E[0m\u0026#34; echo -n \u0026#34;$2\u0026#34; \u0026amp;\u0026amp; $MOVE_TO_COL echo -n \u0026#34;[\u0026#34; if [ $1 = \u0026#34;success\u0026#34; -o $1 = \u0026#34;0\u0026#34; ] ;then ${SETCOLOR_SUCCESS} echo -n $\u0026#34; OK \u0026#34; elif [ $1 = \u0026#34;failure\u0026#34; -o $1 = \u0026#34;1\u0026#34; ] ;then ${SETCOLOR_FAILURE} echo -n $\u0026#34;FAILED\u0026#34; else ${SETCOLOR_WARNING} echo -n $\u0026#34;WARNING\u0026#34; fi ${SETCOLOR_NORMAL} echo -n \u0026#34;]\u0026#34; echo } install_jdk(){ if ! [ -f \u0026#34;$DIR/$JDK_FILE\u0026#34; ];then color 1 \u0026#34;$JDK_FILE 文件不存在\u0026#34; exit; elif","title":"Zookeeper离线安装脚本"},{"content":"准备部署OpenVPN环境 部署环境如下 共四台主机 1 openvpn server： CentOS 7.9 ens33:192.168.1.110/24 NAT模式,模拟公网IP ens36:172.30.0.1/24 仅主机模式,私网IP 2 内网主机两台 第一台主机 ens33172.30.0.100/24 仅主机模式,私网IP，无需网关 第二台主机 ens33172.30.0.200/24 仅主机模式,私网IP，无需网关\n3 Windows 客户端 Windows 10/11\n安装 OpenVPN 安装 OpenVPN 和证书工具 #OpenVPN服务器端 [root@openvpn-centos7 ~]#yum -y install openvpn #证书管理工具 [root@openvpn-centos7 ~]#yum -y install easy-rsa # 安装版本 [root@openvpn-centos7 ~]# yum list openvpn Loaded plugins: fastestmirror Loading mirror speeds from cached hostfile * base: mirrors.ustc.edu.cn * epel: ftp.riken.jp * extras: mirrors.163.com * updates: mirrors.ustc.edu.cn Installed Packages openvpn.x86_64 2.4.12-1.el7 @epel 准备相关配置文件 # 生成服务器配置文件 [root@openvpn-centos7 ~]# cp /usr/share/doc/openvpn-2.4.12/sample/sample-config-files/server.conf /etc/openvpn # 准备证书颁发相关文件 [root@openvpn-centos7 ~]# cp -r /usr/share/easy-rsa/ /etc/openvpn/easy-rsa-server # 准备颁发证书相关变量的配置文件 [root@openvpn-centos7 ~]# cp /usr/share/doc/easy-rsa-3.0.8/vars.example /etc/openvpn/easy-rsa-server/3/vars # 建议修改给CA和OpenVPN服务器颁发的证书的有效期,可适当加长 [root@openvpn-centos7 ~]# vim /etc/openvpn/easy-rsa-server/3/vars #CA的证书默认有效期为10年,可以适当延长,比如:36500天 #set_var EASYRSA_CA_EXPIRE 3650 set_var EASYRSA_CA_EXPIRE 36500 #服务器证书默为为825天,可适当加长,比如:3650天 #set_var EASYRSA_CERT_EXPIRE 825 #将上面行修改为下面 set_var EASYRSA_CERT_EXPIRE 3650 准备证书相关文件 初始化PKI和CA颁发机构环境 初始化PKI生成PKI相关目录和文件 # 进入该目录下 [root@openvpn-centos7 3]# pwd /etc/openvpn/easy-rsa-server/3 #初始化数据,在当前目录下生成pki目录及相关文件 [root@openvpn-centos7 3]# ./easyrsa init-pki Note: using Easy-RSA configuration from: /etc/openvpn/easy-rsa-server/3.0.8/vars init-pki complete; you may now create a CA or requests. Your newly created PKI dir is: /etc/openvpn/easy-rsa-server/3/pki [root@openvpn-centos7 3]# tree . ├── easyrsa ├── openssl-easyrsa.cnf ├── pki #生成一个新目录及相关文件 │ ├── openssl-easyrsa.cnf │ ├── private │ ├── reqs │ └── safessl-easyrsa.cnf ├── vars └── x509-types ├── ca ├── client ├── code-signing ├── COMMON ├── email ├── kdc ├── server └── serverClient 4 directories, 13 files 创建 CA 机构环境 # 进入该目录下 [root@openvpn-centos7 3]# pwd /etc/openvpn/easy-rsa-server/3 [root@openvpn-centos7 3]# tree pki/ pki/ ├── openssl-easyrsa.cnf ├── private ├── reqs └── safessl-easyrsa.cnf 2 directories, 2 files [root@openvpn-centos7 3]# ./easyrsa build-ca nopass # nopass 不需要密码 Note: using Easy-RSA configuration from: /etc/openvpn/easy-rsa-server/3.0.8/vars Using SSL: openssl OpenSSL 1.0.2k-fips 26 Jan 2017 Generating RSA private key, 2048 bit long modulus ....+++ ......+++ e is 65537 (0x10001) You are about to be asked to enter information that will be incorporated into your certificate request. What you are about to enter is what is called a Distinguished Name or a DN. There are quite a few fields but you can leave some blank For some fields there will be a default value, If you enter \u0026#39;.\u0026#39;, the field will be left blank. ----- Common Name (eg: your user, host, or server name) [Easy-RSA CA]: # 回车接受默认值 CA creation complete and you may now import and sign cert requests. Your new CA certificate file for publishing is at: /etc/openvpn/easy-rsa-server/3/pki/ca.crt #生成自签名的证书文件 [root@openvpn-centos7 3]#tree pki pki ├── ca.crt #生成的自签名的证书文件 ├── certs_by_serial ├── index.txt ├── index.txt.attr ├── issued ├── openssl-easyrsa.cnf ├── private │ └── ca.key #生成的私钥文件 ├── renewed │ ├── certs_by_serial │ ├── private_by_serial │ └── reqs_by_serial ├── reqs ├── revoked │ ├── certs_by_serial │ ├── private_by_serial │ └── reqs_by_serial ├── safessl-easyrsa.cnf └── serial 12 directories, 7 files 创建服务端证书申请 # 进入该目录 [root@openvpn-centos7 3]# pwd /etc/openvpn/easy-rsa-server/3 [root@openvpn-centos7 3]# [root@openvpn-centos7 3]# ./easyrsa gen-req server nopass Note: using Easy-RSA configuration from: /etc/openvpn/easy-rsa-server/3.0.8/vars Using SSL: openssl OpenSSL 1.0.2k-fips 26 Jan 2017 Generating a 2048 bit RSA private key ..........................................................................................................................................................+++ ......................+++ writing new private key to \u0026#39;/etc/openvpn/easy-rsa-server/3/pki/easy-rsa-1605.nDSXm1/tmp.2RnHiQ\u0026#39; ----- You are about to be asked to enter information that will be incorporated into your certificate request. What you are about to enter is what is called a Distinguished Name or a DN. There are quite a few fields but you can leave some blank For some fields there will be a default value, If you enter \u0026#39;.\u0026#39;, the field will be left blank. ----- Common Name (eg: your user, host, or server name) [server]: #接受Common Name的默认 值,直接回车 Keypair and certificate request completed. Your files are: req: /etc/openvpn/easy-rsa-server/3/pki/reqs/server.req #生成请求文件 key: /etc/openvpn/easy-rsa-server/3/pki/private/server.key #生成私钥文件 [root@openvpn-centos7 3]#tree pki pki ├── ca.crt ├── certs_by_serial ├── index.txt ├── index.txt.attr ├── issued ├── openssl-easyrsa.cnf ├── private │ ├── ca.key │ └── server.key #生成私钥文件 ├── renewed │ ├── certs_by_serial │ ├── private_by_serial │ └── reqs_by_serial ├── reqs │ └── server.req #生成请求文件 ├── revoked │ ├── certs_by_serial │ ├── private_by_serial │ └── reqs_by_serial ├── safessl-easyrsa.cnf └── serial 12 directories, 9 files 颁发服务端证书 #将上面server.req的申请,颁发server类型的证书 [root@openvpn-centos7 3]#cd /etc/openvpn/easy-rsa-server/3 #第一个server表示证书的类型,第二个server表示请求文件名的前缀 [root@openvpn-centos7 3]# ./easyrsa sign server server Note: using Easy-RSA configuration from: /etc/openvpn/easy-rsa-server/3.0.8/vars Using SSL: openssl OpenSSL 1.0.2k-fips 26 Jan 2017 You are about to sign the following certificate. Please check over the details shown below for accuracy. Note that this request has not been cryptographically verified. Please be sure it came from a trusted source or that you have verified the request checksum with the sender. Request subject, to be signed as a server certificate for 3650 days: subject= commonName = server Type the word \u0026#39;yes\u0026#39; to continue, or any other input to abort. Confirm request details: yes # 输入yes Using configuration from /etc/openvpn/easy-rsa-server/3/pki/easy-rsa-1634.ZCYI5M/tmp.2SsU9O Check that the request matches the signature Signature ok The Subject\u0026#39;s Distinguished Name is as follows commonName :ASN.1 12:\u0026#39;server\u0026#39; Certificate is to be certified until Mar 15 01:27:03 2033 GMT (3650 days) Write out database with 1 new entries Data Base Updated Certificate created at: /etc/openvpn/easy-rsa-server/3/pki/issued/server.crt #生 成服务器证书文件 验证结果 [root@openvpn-centos7 3]# tree pki/ pki/ ├── ca.crt ├── certs_by_serial │ └── EAD7A4786FA803EDD9A7166D0EC694C3.pem #生成的服务器证书文件 ├── index.txt ├── index.txt.attr ├── index.txt.attr.old ├── index.txt.old ├── issued │ └── server.crt #生成的服务器证书文件 ├── openssl-easyrsa.cnf ├── private │ ├── ca.key │ └── server.key ├── renewed │ ├── certs_by_serial │ ├── private_by_serial │ └── reqs_by_serial ├── reqs │ └── server.req ├── revoked │ ├── certs_by_serial │ ├── private_by_serial │ └── reqs_by_serial ├── safessl-easyrsa.cnf ├── serial └── serial.old 12 directories, 14 files 创建 Diffie-Hellman 密钥 [root@openvpn-centos7 3]# ./easyrsa gen-dh Note: using Easy-RSA configuration from: /etc/openvpn/easy-rsa-server/3.0.8/vars Using SSL: openssl OpenSSL 1.0.2k-fips 26 Jan 2017 Generating DH parameters, 2048 bit long safe prime, generator 2 This is going to take a long time ...............................................................................................................................................................................+. # 得等一会 DH parameters of size 2048 created at /etc/openvpn/easy-rsa-server/3/pki/dh.pem #查看生成的文件 [root@openvpn-centos7 3]# ll pki/dh.pem -rw------- 1 root root 424 Mar 18 09:34 pki/dh.pem [root@openvpn-centos7 3]# 准备客户端证书环境 上面服务端证书配置完成，下面是配置客户端证书\n[root@openvpn-centos7 /]# cp -a /usr/share/easy-rsa/ /etc/openvpn/easy-rsa-client # 进入该目录下 [root@openvpn-centos7 3]# pwd /etc/openvpn/easy-rsa-client/3 #生成证书申请所需目录pki和文件 [root@openvpn-centos7 3]# ./easyrsa init-pki init-pki complete; you may now create a CA or requests. Your newly created PKI dir is: /etc/openvpn/easy-rsa-client/3/pki 创建客户端证书申请 # 进入该目录下 [root@openvpn-centos7 3]# pwd /etc/openvpn/easy-rsa-client/3 #生成客户端用户的证书申请,dev用户 [root@openvpn-centos7 3]# ./easyrsa gen-req dev nopass Using SSL: openssl OpenSSL 1.0.2k-fips 26 Jan 2017 Generating a 2048 bit RSA private key ......................................................+++ .........................................................................................................................................................................................................+++ writing new private key to \u0026#39;/etc/openvpn/easy-rsa-client/3/pki/easy-rsa-1749.UROzYa/tmp.HqONRu\u0026#39; ----- You are about to be asked to enter information that will be incorporated into your certificate request. What you are about to enter is what is called a Distinguished Name or a DN. There are quite a few fields but you can leave some blank For some fields there will be a default value, If you enter \u0026#39;.\u0026#39;, the field will be left blank. ----- Common Name (eg: your user, host, or server name) [dev]: # 回车接受默认值 Keypair and certificate request completed. Your files are: req: /etc/openvpn/easy-rsa-client/3/pki/reqs/dev.req #私钥文件 key: /etc/openvpn/easy-rsa-client/3/pki/private/dev.key #证书申请文件 #生成两个新文件 [root@openvpn-centos7 3]# tree . ├── easyrsa ├── openssl-easyrsa.cnf ├── pki │ ├── openssl-easyrsa.cnf │ ├── private │ │ └── dev.key #私钥文件 │ ├── reqs │ │ └── dev.req #证书申请文件 │ └── safessl-easyrsa.cnf └── x509-types ├── ca ├── client ├── code-signing ├── COMMON ├── email ├── kdc ├── server └── serverClient 4 directories, 14 files 颁发客户端证书 # 进入该目录下 [root@openvpn-centos7 3]# pwd /etc/openvpn/easy-rsa-server/3 [root@openvpn-centos7 3]# [root@openvpn-centos7 3]# ./easyrsa import-req /etc/openvpn/easy-rsa-client/3/pki/reqs/dev.req dev Note: using Easy-RSA configuration from: /etc/openvpn/easy-rsa-server/3.0.8/vars Using SSL: openssl OpenSSL 1.0.2k-fips 26 Jan 2017 The request has been successfully imported with a short name of: dev You may now use this name to perform signing operations on this request. [root@openvpn-centos7 3]# tree pki/ pki/ ├── ca.crt ├── certs_by_serial │ └── EAD7A4786FA803EDD9A7166D0EC694C3.pem ├── dh.pem ├── index.txt ├── index.txt.attr ├── index.txt.attr.old ├── index.txt.old ├── issued │ └── server.crt ├── openssl-easyrsa.cnf ├── private │ ├── ca.key │ └── server.key ├── renewed │ ├── certs_by_serial │ ├── private_by_serial │ └── reqs_by_serial ├── reqs │ ├── dev.req # 导入的文件 │ └── server.req ├── revoked │ ├── certs_by_serial │ ├── private_by_serial │ └── reqs_by_serial ├── safessl-easyrsa.cnf ├── serial └── serial.old 12 directories, 16 files #修改给客户端颁发的证书的有效期 [root@openvpn-centos7 3]##vim vars #建议修改给客户端颁发证书的有效期,可适当减少,比如:90天 #set_var EASYRSA_CERT_EXPIRE 825 #将上面行修改为下面 set_var EASYRSA_CERT_EXPIRE 90 #颁发客户端证书 [root@openvpn-centos7 3]# ./easyrsa sign client dev Note: using Easy-RSA configuration from: /etc/openvpn/easy-rsa-server/3.0.8/vars Using SSL: openssl OpenSSL 1.0.2k-fips 26 Jan 2017 You are about to sign the following certificate. Please check over the details shown below for accuracy. Note that this request has not been cryptographically verified. Please be sure it came from a trusted source or that you have verified the request checksum with the sender. Request subject, to be signed as a client certificate for 3650 days: subject= commonName = dev Type the word \u0026#39;yes\u0026#39; to continue, or any other input to abort. Confirm request details: yes # 输入yes Using configuration from /etc/openvpn/easy-rsa-server/3/pki/easy-rsa-1998.yxi0PJ/tmp.IJUwSd Check that the request matches the signature Signature ok The Subject\u0026#39;s Distinguished Name is as follows commonName :ASN.1 12:\u0026#39;dev\u0026#39; Certificate is to be certified until Mar 15 01:51:32 2033 GMT (3650 days) Write out database with 1 new entries Data Base Updated Certificate created at: /etc/openvpn/easy-rsa-server/3/pki/issued/dev.crt #证书文件 将CA和服务器证书相关文件复制到服务器相应的目录 [root@openvpn-centos7 3]# mkdir /etc/openvpn/certs [root@openvpn-centos7 3]# cp /etc/openvpn/easy-rsa-server/3/pki/ca.crt /etc/openvpn/certs/ [root@openvpn-centos7 3]# cp /etc/openvpn/easy-rsa-server/3/pki/issued/server.crt /etc/openvpn/certs/ [root@openvpn-centos7 3]# cp /etc/openvpn/easy-rsa-server/3/pki/private/server.key [root@openvpn-centos7 3]# cp /etc/openvpn/easy-rsa-server/3/pki/dh.pem /etc/openvpn/certs/ [root@openvpn-centos7 3]# ll /etc/openvpn/certs/ total 20 -rw------- 1 root root 1176 Mar 18 09:54 ca.crt -rw------- 1 root root 424 Mar 18 09:57 dh.pem -rw------- 1 root root 4552 Mar 18 09:56 server.crt -rw------- 1 root root 1704 Mar 18 09:55 server.key 将客户端私钥与证书相关文件复制到服务器相关的目录 [root@openvpn-centos7 3]# mkdir /etc/openvpn/client/dev [root@openvpn-centos7 3]# cp /etc/openvpn/easy-rsa-server/3/pki/ca.crt /etc/openvpn/easy-rsa-server/3/pki/issued/dev.crt /etc/openvpn/easy-rsa-server/3/pki/reqs/dev.req /etc/openvpn/client/dev/ [root@openvpn-centos7 3]# ll /etc/openvpn/client/dev/ total 16 -rw------- 1 root root 1176 Mar 18 10:01 ca.crt -rw------- 1 root root 4425 Mar 18 10:01 dev.crt -rw------- 1 root root 883 Mar 18 10:01 dev.req [root@openvpn-centos7 3]# 准备 OpenVPN 服务器配置文件 ;local a.b.c.d #本机监听IP,默认为本机所有IP port 1194 #端口 ;proto tcp #协议,生产推荐使用TCP proto udp #默认协议udp ;dev tap #创建以太网隧道设备，tap设备实现以太网帧通过Openvpn隧道，可提供非IP协议如 IPX和AppleTalk等的支持，tap等当于一个以太网设备，它操作第二层数据包如以太网数据帧。 dev tun #创建IP路由隧道，生产推存使用tun.互联网使用tun,一个tun设备大多时候被用于基 于IP协议的通讯。tun模拟了网络层设备，操作第三层数据包比如IP数据封包。 ;dev-node MyTap #TAP-Win32的设备驱动。非windows系统不需要 ca ca.crt #ca证书文件 cert server.crt #服务器证书文件 key server.key #服务器私钥文件 dh dh2048.pem #dh参数文件 ;topology subnet server 10.8.0.0 255.255.255.0 #客户端连接后自动分配的IP网段，默认会给服务器分配此网段的第 一个IP将做为客户端的网关,注意不要和内网网段相同 ifconfig-pool-persist ipp.txt #记录客户端和虚拟ip地址分配的文件 ;server-bridge 10.8.0.4 255.255.255.0 10.8.0.50 10.8.0.100 #配置网桥模式，无需配置, 建议注释 ;server-bridge ;push \u0026#34;route 192.168.10.0 255.255.255.0\u0026#34; #推送给客户端的到达服务器后面网段的静态路由， 网关是服务器地址10.8.0.1 ;push \u0026#34;route 192.168.10.100 255.255.255.255\u0026#34; #用255.255.255.255可实现只能访问内网单个 主机的功能,比如:jumpserver ;push \u0026#34;route 192.168.20.0 255.255.255.0\u0026#34; #推送路由信息到客户端，以允许客户端能够连接到 服务器背后的其它私有网络 ;client-config-dir ccd #为特定客户端添加路由信息，此路由是客户端后面的网段而非服务端的网 段，无需设置 ;route 192.168.40.128 255.255.255.248 ;client-config-dir ccd ;route 10.9.0.0 255.255.255.252 ;learn-address ./script #指定外部脚本文件，实现创建不同组的iptables规 则，无需配置 ;push \u0026#34;redirect-gateway def1 bypass-dhcp\u0026#34; #启用此配置后客户端所有流量都将通过VPN服务器进 行转发，因此生产一般无需配置此项 ;push \u0026#34;dhcp-option DNS 208.67.222.222\u0026#34; #推送DNS服务器地址，无需配置 ;push \u0026#34;dhcp-option DNS 208.67.220.220\u0026#34; ;client-to-client #允许不同的客户端直接通信,不安全,生产环境一般无 需配置 ;duplicate-cn #多个用户共用一个证书，一般用于测试环境，生产环境建议一个用户一个证 书,无需开启 keepalive 10 120 #设置服务端活动的检测的间隔和超时时间，每隔10秒ping一次，120秒没有 回应则认为已经断线 tls-auth ta.key 0 #访止DoS等攻击的安全增强配置,服务器和每个客户端都需要拥有此密钥文 件。第二个参数在服务器端为0，客户端为1 cipher AES-256-CBC #加密算法 ;compress lz4-v2 #启用Openvpn2.4.X新版压缩算法 ;push \u0026#34;compress lz4-v2\u0026#34; #推送客户端使用新版压缩算法,和下面的comp-lzo不要同时使用 ;comp-lzo #旧户端兼容的压缩配置，需要客户端配置开启压缩,openvpn2.4.X等新版可以不 用开启 ;max-clients 100 #最多支持的客户端数量 ;user nobody #指定openvpn服务的用户 ;group nobody #指定openvpn服务的组 persist-key #重启服务时默认会重新读取key文件，开启此配置后保持使用第一次的key文件, 生产环境无需开启 persist-tun #Don’t close and reopen TUN/TAP device or run up/down scripts across SIGUSR1 or --ping-restart restarts,生产环境建议无需开启 status openvpn-status.log #服务器状态记录文件，每分钟记录一次相关信息 ;log openvpn.log #第一种日志记录方式,并指定日志路径，log会在openvpn启动的时候清 空日志文件,不建议使用 ;log-append openvpn.log #第二种日志记录方式,并指定日志路径，重启openvpn后在之前的日志后 面追加新的日志,生产环境建议使用 verb 3 #设置日志级别，0-9，级别越高记录的内容越详细,0 表示静默运行，只记 录致命错误,4 表示合理的常规用法,5 和 6 可以帮助调试连接错误。9 表示极度冗余，输出非常详细的日志 信息 ;mute 20 #对相同类别的信息只记录前20条到日志文件中 explicit-exit-notify 1 #当服务端重启后通知客户端自动重新连接服务器，此项配置仅能用于udp模 式，tcp模式无需配置即能实现重新连接功能,且开启此项后tcp配置后将导致openvpn服务无法启动,所以 tcp时必须不能开启此项 script-security 3 # 允许使用自定义脚本 auth-user-pass-verify /etc/openvpn/checkpsw.sh via-env #指定自定义脚本路径 username-as-common-name #开启用户密码验证 client-cert-not-required #只支持用户和密码方式验证,不支持证书,无此配置表示需要证书和用户密 码多种验证 修改服务器端配置文件 [root@openvpn-centos7 openvpn]# grep \u0026#39;^[a-Z].*\u0026#39; /etc/openvpn/server.conf port 1194 proto tcp dev tun ca /etc/openvpn/certs/ca.crt cert /etc/openvpn/certs/server.crt key /etc/openvpn/certs/server.key # This file should be kept secret dh /etc/openvpn/certs/dh.pem server 10.8.0.0 255.255.255.0 ifconfig-pool-persist ipp.txt push \u0026#34;route 172.30.0.0 255.255.255.0\u0026#34; keepalive 10 120 tls-auth ta.key 0 # This file is secret cipher AES-256-CBC compress lz4-v2 push \u0026#34;compress lz4-v2\u0026#34; max-clients 2048 user openvpn group openvpn persist-key persist-tun status /var/log/openvpn/openvpn-status.log log-append /var/log/openvpn/openvpn.log verb 3 mute 20 explicit-exit-notify 1 [root@openvpn-centos7 openvpn]# #准备目志相关目录 [root@openvpn-centos7 openvpn]# getent passwd openvpn openvpn❌998:996:OpenVPN:/etc/openvpn:/sbin/nologin [root@openvpn-centos7 openvpn]# mkdir /var/log/openvpn [root@openvpn-centos7 openvpn]# chown openvpn.openvpn /var/log/openvpn [root@openvpn-centos7 openvpn]# ll -d /var/log/openvpn drwxr-xr-x 2 openvpn openvpn 6 Mar 18 10:16 /var/log/openvpn [root@openvpn-centos7 openvpn]# 启动 OpenVPN 服务 [root@openvpn-centos7 server]# systemctl enable --now openvpn@server # 启动报如下错误请在终端执行该命令 openvpn --genkey --secret /etc/openvpn/ta.key Sat Mar 18 11:05:32 2023 WARNING: cannot stat file \u0026#39;ta.key\u0026#39;: No such file or directory (errno=2) Options error: --tls-auth fails with \u0026#39;ta.key\u0026#39;: No such file or directory (errno=2) Options error: Please correct these errors. Use --help for more information. # 查看状态 [root@openvpn-centos7 server]# systemctl status openvpn@server ● openvpn@server.service - OpenVPN Robust And Highly Flexible Tunneling Application On server Loaded: loaded (/usr/lib/systemd/system/openvpn@.service; enabled; vendor preset: disabled) Active: active (running) since Sat 2023-03-18 11:23:23 CST; 1min 59s ago Main PID: 2769 (openvpn) Status: \u0026#34;Initialization Sequence Completed\u0026#34; CGroup: /system.slice/system-openvpn.slice/openvpn@server.service └─2769 /usr/sbin/openvpn --cd /etc/openvpn/ --config server.conf Mar 18 11:23:23 openvpn-centos7 systemd[1]: Starting OpenVPN Robust And Highly Flexible Tunneling Application On server... Mar 18 11:23:23 openvpn-centos7 systemd[1]: Started OpenVPN Robust And Highly Flexible Tunneling Application On server 准备 OpenVPN 客户端配置文件 客户端默认范例配置文件说明 [root@openvpn-centos7 server]#grep \u0026#39;^[[:alpha:]].*\u0026#39; /usr/share/doc/openvpn/sample/sample- config-files/client.conf client #指明客户端 dev tun #指定和服务端一致的接口类型 proto udp #指定和服务端一致的协议类型 remote my-server-1 1194 #服务器端的ip或FQDN及端口 resolv-retry infinite #指定服务器端FQDN而非IP时，当客户端重新连接后会重新解FQDN对应的IP nobind #客户端不绑定监听端口，随机打开端口连接到服务端的端口 persist-key persist-tun ca ca.crt cert client.crt key client.key remote-cert-tls server #使用服务器证书校验方式 tls-auth ta.key 1 #安全加强 cipher AES-256-CBC verb 3 生成客户端用户的配置文件 #生成客户端文件,文件后缀必须为.ovpn [root@openvpn-centos7 server]#grep \u0026#39;^[[:alpha:]].*\u0026#39; /usr/share/doc/openvpn/sample/sample- config-files/client.conf \u0026gt; /etc/openvpn/client/wangxiaochun/client.ovpn #修改配置文件,内容如下 [root@openvpn-centos7 server]#vim /etc/openvpn/client/wangxiaochun/client.ovpn [root@openvpn-centos7 server]#cat /etc/openvpn/client/wangxiaochun/client.ovpn client dev tun proto tcp remote 192.1681.110 1194 #生产中为OpenVPN公网IP或者FQDN resolv-retry infinite nobind #persist-key #persist-tun ca ca.crt cert dev.crt key dev.key remote-cert-tls server #tls-auth ta.key 1 cipher AES-256-CBC verb 3 #此值不能随意指定,否则无法通信 compress lz4-v2 #此项在OpenVPN2.4.X版本使用,需要和服务器端保持一致,如不指定,默认使用 comp-lz压缩 实现 OpenVPN 客户端 Windows 客户端安装省略 Windows 客户端配置准备 保存证书到openvpn 客户端安装目录\n#在服务器打包证书并下载发送给windows客户端 [root@openvpn-centos7 dev]# pwd /etc/openvpn/client/dev [root@openvpn-centos7 dev]# ll total 20 -rw------- 1 root root 1176 Mar 18 10:01 ca.crt -rw------- 1 root root 4425 Mar 18 10:01 dev.crt -rw-r--r-- 1 root root 235 Mar 18 11:35 dev.ovpn -rw------- 1 root root 883 Mar 18 10:01 dev.req [root@openvpn-centos7 dev]# # 放置到windows客户端默认安装目录下 C:\\Program Files\\OpenVPN\\config 目录 实现访问VPN服务器的内网主机 #在服务器开启ip_forward转发功能 [root@openvpn-centos7 dev]#echo net.ipv4.ip_forward = 1 \u0026gt;\u0026gt; /etc/sysctl.conf [root@openvpn-centos7 dev]#sysctl -p net.ipv4.ip_forward = 1 配置实现内网服务器回应外网的请求的路由 #阿里云服务器不支持修改路由 [root@web1 ~]#route add -net 10.8.0.0/24 gw 172.30.0.1 在OpenVPN服务器配置 iptables 规则 #添加SNAT规则 #方法1 [root@openvpn-centos7 ~]#echo \u0026#39;iptables -t nat -A POSTROUTING -s 10.8.0.0/24 ! -d 10.8.0.0/24 -j MASQUERADE\u0026#39; \u0026gt;\u0026gt; /etc/rc.d/rc.local #方法2 [root@openvpn-centos7 ~]#echo \u0026#39;iptables -t nat -A POSTROUTING -s 10.8.0.0/24 ! -d 10.8.0.0/24 -j SNAT --to-source 172.30.0.1\u0026#39; \u0026gt;\u0026gt; /etc/rc.d/rc.local 吊销指定的用户的证书 [root@openvpn-centos7 ~]# cd /etc/openvpn/easy-rsa-server/3 [root@openvpn-centos7 3]#./easyrsa revoke dev ","permalink":"https://xyenvy.github.io/posts/openvpn%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/","summary":"准备部署OpenVPN环境 部署环境如下 共四台主机 1 openvpn server： CentOS 7.9 ens33:192.168.1.110/24 NAT模式,模拟公网IP ens36:172.30.0.1/24 仅主机模式,私网IP 2 内网主机两台 第一台主机 ens33172.30.0.100/24 仅主机模式,私网IP，无需网关 第二台主机 ens33172.30.0.200/24 仅主机模式,私网IP，无需网关 3 Windows 客户端 Windows 10/11 安装 OpenVPN 安装 OpenVPN 和证书工具 #OpenVPN服务器端 [root@openvpn-centos7 ~]#yum","title":"OpenVPN安装和使用"},{"content":"Docker 镜像加速配置 国内从DockerHub拉取镜像有时会遇到困难，此时可以配置镜像加速器。\nDocker官方和国内很多云服务商都提供了国内加速器服务，建议根据运行docker的云平台选择对应的镜像加速服务。\n下面列出国内常用的加速站点，排名不分先后,总体来说阿里云速度较稳定。\ndocker中国区官方镜像加速：\nhttps://registry.docker-cn.com 网易镜像加速：\nhttp://hub-mirror.c.163.com 中国科技大学镜像加速：\nhttps://docker.mirrors.ustc.edu.cn 腾讯云镜像加速：\nhttps://mirror.ccs.tencentyun.com 阿里云镜像加速：\nhttps://ung2thfc.mirror.aliyuncs.com 修改daemon配置文件/etc/docker/daemon.json来使用加速器\n/etc/docker/daemon.json 加入如下内容\n{ \u0026#34;registry-mirrors\u0026#34;: [ \u0026#34;https://ung2thfc.mirror.aliyuncs.com\u0026#34;, \u0026#34;https://mirror.ccs.tencentyun.com\u0026#34;, \u0026#34;https://registry.docker-cn.com\u0026#34;, \u0026#34;http://hub-mirror.c.163.com\u0026#34;, \u0026#34;https://docker.mirrors.ustc.edu.cn\u0026#34;] } 加载重启docker\n在终端输入以下命令\nsystemctl daemon-reload systemctl restart docker 打开终端执行docker info命令，可见下面信息\n.... Labels: Experimental: false Insecure Registries: 127.0.0.0/8 Registry Mirrors: https://ung2thfc.mirror.aliyuncs.com/ https://mirror.ccs.tencentyun.com/ https://registry.docker-cn.com/ http://hub-mirror.c.163.com/ https://docker.mirrors.ustc.edu.cn/ Live Restore Enabled: false 还可以使用如下脚本进行设置，执行前检查自己的环境,下列脚本可以用于新装Docker环境的机器\n#!/bin/bash tee /etc/docker/daemon.json \u0026lt;\u0026lt;-\u0026#39;EOF\u0026#39; { \u0026#34;registry-mirrors\u0026#34;: [ \u0026#34;https://ung2thfc.mirror.aliyuncs.com\u0026#34;, \u0026#34;https://mirror.ccs.tencentyun.com\u0026#34;, \u0026#34;https://registry.docker-cn.com\u0026#34;, \u0026#34;http://hub-mirror.c.163.com\u0026#34;, \u0026#34;https://docker.mirrors.ustc.edu.cn\u0026#34;] } EOF systemctl daemon-reload \u0026amp;\u0026amp; systemctl restart docker ","permalink":"https://xyenvy.github.io/posts/docker%E9%95%9C%E5%83%8F%E5%8A%A0%E9%80%9F/","summary":"Docker 镜像加速配置 国内从DockerHub拉取镜像有时会遇到困难，此时可以配置镜像加速器。 Docker官方和国内很多云服务商都提供了国内加速器服务，建议根据运行docker的云平台选择对应的镜像加速服务。 下面列出国内常用的加速站点，排名不分先后,总体来说阿里云速度较稳定。 docker","title":"Docker镜像加速"},{"content":"常见监控方案 开源监控软件：cacti、nagios、zabbix、smokeping、open-falcon等\nZabbix使用场景及系统概述 Zabbix是一个企业级解决方案，支持实时监控数千台服务器，虚拟机和网络设备，采集百万级监控指标，适用于任何IT基础架构、服务、应用程序和资源的解决方案。\nzabbix使用场景 zabbix系统概述 数据采集：\n周期性时序数据\n主机/对象：服务器、路由器、交换机、存储、防火墙、IP、PORT、URL、自定义监控对象... 采集目标：监控项，指标数据（metrics data） 数据存储：\n监控数据存储系统\nSQL: MySQL/MariaDB(Zabbix) NoSQL：Redis(Open-falcon) rrd: Round Robin Database(Cacti) 数据类型：\n历史数据: 每个监控项采集到的每个监控值 趋势数据: 趋势表里主要保留某个监控项一个小时内历史数据的最大值、最小值和平均值以及该监控项一个小时内所采 集到的数据个数。 阈值： 可按照预定义的阈值等级实现分层报警 告警机制： email,短信,微信,语音,故障自治愈\nzabbix 核心任务 数据采集：\n数据采集方式：zabbix-server，zabbix-proxy，zabbix-agent\nAgentless：SNMP,Telnet,ssh, IPMI, JMX, Agent：zabbix agent 数据存储： zabbix database 数据展示： zabbix web\ngraph -\u0026gt; screen -\u0026gt; slideshow(将多个screen以幻灯片的方式进行轮流展示) grafana:\n以zabbix为数据源展示更绚丽的界面 告警通知：\nhost (host groups) \u0026lt;- templates #从模板继承告警配置 host -\u0026gt; items -\u0026gt; triggers -\u0026gt; action (条件-conditions, 操作-operations) #自定义告警配置 规划部署 部署环境 服务器系统：centos7.9，ubuntu20.04 yum安装zabbix 安装说明\n# Install Zabbix repository wget https://repo.zabbix.com/zabbix/5.0/rhel/7/x86_64/zabbix-release-5.0-1.el7.noarch.rpm yum install zabbix-release-5.0-1.el7.noarch.rpm yum clean all # 安装Zabbix server，Web前端，agent yum install zabbix-server-mysql zabbix-agent # Install Zabbix frontend # Enable Red Hat Software Collections yum install centos-release-scl # 编辑配置文件 /etc/yum.repos.d/zabbix.repo and enable zabbix-frontend repository. [zabbix-frontend] ... enabled=1 ... # Install Zabbix frontend packages. yum install zabbix-web-mysql-scl zabbix-nginx-conf-scl # 安装数据库 # 在线一键安装脚本地址 https://itshare.work/2022/09/30/MySQLinstallScript/ # 创建初始数据库 # Make sure you have database server up and running. # 在数据库主机上运行以下代码 mysql -uroot -p mysql\u0026gt; create database zabbix character set utf8 collate utf8_bin; Query OK, 1 row affected (0.01 sec) mysql\u0026gt; create user zabbix@localhost identified by \u0026#39;123456\u0026#39;; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; grant all privileges on zabbix.* to zabbix@localhost; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; set global log_bin_trust_function_creators = 1; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; quit; # 导入初始架构和数据，系统将提示您输入新创建的密码。 [root@centos7 ~]# zcat /usr/share/doc/zabbix-server-mysql-5.0.31/create.sql.gz | mysql -uzabbix -p123456 zabbix #Disable log_bin_trust_function_creators option after importing database schema. # mysql -uroot -p password mysql\u0026gt; set global log_bin_trust_function_creators = 0; mysql\u0026gt; quit; #为Zabbix server配置数据库 #编辑配置文件 /etc/zabbix/zabbix_server.conf DBPassword=12456 # 为 Zabbix前端配置PHP # 编辑配置文件 /etc/opt/rh/rh-nginx116/nginx/conf.d/zabbix.conf uncomment and set \u0026#39;listen\u0026#39; and \u0026#39;server_name\u0026#39; directives. # listen 80; # server_name example.com; # 编辑配置文件 /etc/opt/rh/rh-php72/php-fpm.d/zabbix.conf add nginx to listen.acl_users directive. listen.acl_users = apache,nginx # Then uncomment and set the right timezone for you.(取消注释，设置时区) php_value[date.timezone] = Asia/Shanghai # 启动Zabbix server和agent进程 # 启动Zabbix server和agent进程，并为它们设置开机自启： # systemctl restart zabbix-server zabbix-agent rh-nginx116-nginx rh-php72-php-fpm # systemctl enable zabbix-server zabbix-agent rh-nginx116-nginx rh-php72-php-fpm 开始使用 http://ip:port apt安装 Zabbix 5.0 LTS for Ubuntu 20.04 (Focal), MySQL, Apache\n# Install and configure Zabbix for your platform # a. Install Zabbix repository wget https://repo.zabbix.com/zabbix/5.0/ubuntu/pool/main/z/zabbix-release/zabbix-release_5.0-1%2Bfocal_all.deb dpkg -i zabbix-release_5.0-1+focal_all.deb apt update # 安装Zabbix server，Web前端，agent apt install zabbix-server-mysql zabbix-frontend-php zabbix-apache-conf zabbix-agent # 安装数据库 apt install mysql-server -y # 创建初始数据库 # Make sure you have database server up and running. # 在数据库主机上运行以下代码。 # mysql -uroot -p password mysql\u0026gt; create database zabbix character set utf8 collate utf8_bin; mysql\u0026gt; create user zabbix@localhost identified by \u0026#39;123456\u0026#39;; mysql\u0026gt; grant all privileges on zabbix.* to zabbix@localhost; mysql\u0026gt; set global log_bin_trust_function_creators = 1; mysql\u0026gt; quit; # 导入初始架构和数据，系统将提示您输入新创建的密码。 zcat /usr/share/doc/zabbix-server-mysql*/create.sql.gz | mysql -uzabbix -p123456 zabbix # Disable log_bin_trust_function_creators option after importing database schema. # mysql -uroot -p password mysql\u0026gt; set global log_bin_trust_function_creators = 0; mysql\u0026gt; quit; # 为Zabbix server配置数据库 # 编辑配置文件 /etc/zabbix/zabbix_server.conf DBPassword=123456 # 为Zabbix前端配置PHP # 编辑配置文件 /etc/zabbix/apache.conf uncomment and set the right timezone for you. php_value date.timezone Asia/Shanghai # 动Zabbix server和agent进程 # 启动Zabbix server和agent进程，并为它们设置开机自启： systemctl restart zabbix-server zabbix-agent apache2 systemctl enable zabbix-server zabbix-agent apache2 ","permalink":"https://xyenvy.github.io/posts/zabbix/","summary":"常见监控方案 开源监控软件：cacti、nagios、zabbix、smokeping、open-falcon等 Zabbix使用场景及系统概述 Zabbix是一个企业级解决方案，支持实时监控数千台服务器，虚拟机和网络设备，采集百万级监控指标，适用于任何IT基础架构、服务、应用程序和资","title":"Zabbix"},{"content":"Playbook playbook介绍 官方链接\nhttps://docs.ansible.com/ansible/latest/user_guide/playbooks_intro.html Playbook 组成 一个 playbook(剧本)文件是一个YAML语言编写的文本文件 通常一个playbook只包括一个play 一个 play的主要包括两部分: 主机和tasks. 即实现在指定一组主机上执行一个tasks定义好的任务列表。 一个tasks中可以有一个或多个task任务 每一个Task本质上就是调用ansible的一个module 在复杂场景中,一个playbook中也可以包括多个play，实现对多组不同的主机执行不同的任务 Playbook 与 Ad-Hoc 对比 Playbook是对多个 AD-Hoc 的一种编排组合的实现方式 Playbook能控制任务执行的先后顺序 Playbook可以持久保存到文件中从而方便多次调用运行，而Ad-Hoc只能临时运行。 Playbook适合复杂的重复性的任务，而Ad-Hoc适合做快速简单的一次性任务 YAML 语言 YAML 语言介绍 YAML：YAML Ain\u0026rsquo;t Markup Language，即YAML不是标记语言。不过，在开发的这种语言时，YAML的 意思其实是：\u0026ldquo;Yet Another Markup Language\u0026rdquo;（仍是一种标记语言） YAML是一个可读性高的用来表达资料序列的格式。 YAML参考了其他多种语言，包括：XML、C语言、Python、Perl以及电子邮件格式RFC2822等。 Clark Evans在2001年在首次发表了这种语言，另外Ingy döt Net与Oren Ben-Kiki也是这语言的共同设计者 目前很多最新的软件比较流行采用此格式的文件存放配置信息，如:ubuntu，anisble，docker，kubernetes等 YAML 官方网站：\nhttp://www.yaml.org ansible 官网:\nhttps://docs.ansible.com/ansible/latest/reference_appendices/YAMLSyntax.html YAML 语言特性 YAML的可读性好 YAML和脚本语言的交互性好 YAML使用实现语言的数据类型 YAML有一个一致的信息模型 YAML易于实现 YAML可以基于流来处理 YAML表达能力强，扩展性好 YAML语法简介 在单一文件第一行，用连续三个连字号\u0026quot;-\u0026quot; 开始，还有选择性的连续三个点号( \u0026hellip; )用来表示文件结尾 次行开始正常写Playbook的内容，一般建议写明该Playbook的功能 使用#号注释代码 缩进的级别也必须是一致的，同样的缩进代表同样的级别，程序判别配置的级别是通过缩进结行来实现的 缩进不支持tab,必须使用空格进行缩进 缩进的空格数不重要，只要相同层级的元素左对齐即可 YAML文件内容是区别大小写的，key/value的值均需大小写敏感 多个key/value可同行写也可换行写，同行使用，分隔 key后面冒号要加一个空格 比如: key: value value可是个字符串，也可是另一个列表 YAML文件扩展名通常为yml或yaml 支持的数据类型 YAML 支持以下常用几种数据类型：\n标量：单个的、不可再分的值 对象：键值对的集合，又称为: 字典（dictionary）/ 哈希（hashes） / 映射（mapping） 数组：一组按次序排列的值，又称为: 列表（list）/ 序列（sequence） scalar 标量 key对应value\nname: wang age: 18 使用缩进的方式\nname: wang age: 18 标量是最基本的，不可再分的值，包括：\n字符串 布尔值 整数 浮点数 Null 时间 日期 Dictionary 字典 一个字典是由一个或多个key与value构成 key和value之间用冒号 ：分隔 冒号 : 后面有一个空格 所有 k/v 可以放在一行，,每个 k/v 之间用逗号分隔 所有每个 k/v 也可以分别放在不同行,一对k/v放在独立的一行 格式\naccount: { name: wang, age: 30 } 使用缩进方式\naccount: name: wang age: 18 范例：\n#不同行 # An employee record name: Example Developer job: Developer skill: Elite(社会精英) #同一行,也可以将key:value放置于{}中进行表示，用,分隔多个key:value # An employee record {name: \u0026#34;Example Developer\u0026#34;, job: \u0026#34;Developer\u0026#34;, skill: \u0026#34;Elite\u0026#34;} List 列表 列表由多个元素组成 每个元素放在不同行，每个元素一行,且元素前均使用中横线 - 开头，并且中横线 - 和元素之间有一个空格 也可以将所有元素用 [ ] 括起来放在同一行,每个元素之间用逗号分隔 格式\ncourse: [ linux , golang , python ] 也可以写成以 - 开头的多行\ncourse: - linux - golang - python course: - linux: manjaro - golang: gin - python: django 范例：\n#不同行,行以-开头,后面有一个空格 # A list of tasty fruits - Apple - Orange - Strawberry - Mango #同一行 [Apple,Orange,Strawberry,Mango] 范例：YAML 表示一个家庭\nname: John Smith age: 41 gender: Male spouse: { name: Jane Smith, age: 37, gender: Female } # 写在一行里 name: Jane Smith #也可以写成多行 age: 37 gender: Female children: [ {name: Jimmy Smith,age: 17, gender: Male}, {name: Jenny Smith, age:13, gender: Female}, {name: hao Smith, age: 20, gender: Male } ] #写在一行 - name: Jimmy Smith #写在多行,更为推荐的写法 age: 17 gender: Male - {name: Jenny Smith, age: 13, gender: Female} - {name: hao Smith, age: 20, gender: Male } 三种常见的数据格式 XML：Extensible Markup Language，可扩展标记语言，可用于数据交换和配置 JSON：JavaScript Object Notation, JavaScript 对象表记法，主要用来数据交换或配置，不支持注释 YAML：YAML Ain\u0026rsquo;t Markup Language YAML 不是一种标记语言， 主要用来配置，大小写敏感，不支持tab 可以用工具互相转换，参考网站：\nurl url1\nPlaybook 核心组件 官方文档\nhttps://docs.ansible.com/ansible/latest/reference_appendices/playbooks_keywords.html#playbook-keywords 一个playbook 中由多个组件组成,其中所用到的常见组件类型如下:\nHosts 执行的远程主机列表 Tasks 任务集,由多个task的元素组成的列表实现,每个task是一个字典,一个完整的代码块功能需少元素需包括 name 和 task,一个name只能包括一个task Variables 内置变量或自定义变量在playbook中调用 Templates 模板，可替换模板文件中的变量并实现一些简单逻辑的文件 Handlers 和 notify 结合使用，由特定条件触发的操作，满足条件方才执行，否则不执行 tags 标签 指定某条任务执行，用于选择运行playbook中的部分代码。ansible具有幂等性，因此 会自动跳过没有变化的部分，即便如此，有些代码为测试其确实没有发生变化的时间依然会非常地长。此时，如果确信其没有变化，就可以通过tags跳过此些代码片断 hosts 组件 Hosts：playbook中的每一个play的目的都是为了让特定主机以某个指定的用户身份执行任务。hosts用于指定要执行指定任务的主机，须事先定义在主机清单中\none.example.com one.example.com:two.example.com 192.168.1.50 192.168.1.* Websrvs:dbsrvs #或者，两个组的并集 Websrvs:\u0026amp;dbsrvs #与，两个组的交集 webservers:!dbsrvs #在websrvs组，但不在dbsrvs组 案例：\n- hosts: websrvs:appsrvs remote_user 组件 remote_user: 可用于Host和task中。也可以通过指定其通过sudo的方式在远程主机上执行任务，其可用于play全局或某任务；此外，甚至可以在sudo时使用sudo_user指定sudo时切换的用户\n- hosts: websrvs remote_user: root tasks: - name: test connection ping: remote_user: magedu sudo: yes #默认sudo为root sudo_user:wang #sudo为wang task列表和action组件 play的主体部分是task list，task list中有一个或多个task,各个task 按次序逐个在hosts中指定的所有主机上执行，即在所有主机上完成第一个task后，再开始第二个task task的目的是使用指定的参数执行模块，而在模块参数中可以使用变量。模块执行是幂等的，这意味着多次执行是安全的，因为其结果均一致 每个task都应该有其name，用于playbook的执行结果输出，建议其内容能清晰地描述任务执行步骤。 如果未提供name，则action的结果将用于输出 task两种格式：\naction: module arguments #示例: action: shell wall hello module: arguments #建议使用 #示例: shell: wall hello 注意：shell和command模块后面跟命令，而非key=value 范例:\n[root@ansible ansible]#cat hello.yml --- #first yaml文件 # - hosts: websrvs remote_user: root gather_facts: no tasks: - name: task1 debug: msg=\u0026#34;task1 running\u0026#34; - name: task2 debug: msg=\u0026#34;task2 running\u0026#34; - hosts: appsrvs remote_user: root gather_facts: no tasks: - name: task3 debug: msg=\u0026#34;task3 running\u0026#34; - name: task4 debug: msg=\u0026#34;task4 running\u0026#34; 其它组件说明 某任务的状态在运行后为changed时，可通过\u0026quot;notify\u0026quot;通知给相应的handlers任务 还可以通过\u0026quot;tags\u0026quot;给task 打标签，可在ansible-playbook命令上使用-t指定进行调用\nShellScripts VS Playbook 案例 #SHELL脚本实现 #!/bin/bash # 安装Apache yum install --quiet -y httpd # 复制配置文件 cp /tmp/httpd.conf /etc/httpd/conf/httpd.conf cp/tmp/vhosts.conf /etc/httpd/conf.d/ # 启动Apache，并设置开机启动 systemctl enable --now httpd #Playbook实现 --- - hosts: websrvs remote_user: root gather_facts: no tasks: - name: \u0026#34;安装Apache\u0026#34; yum: name=httpd - name: \u0026#34;复制配置文件\u0026#34; copy: src=/tmp/httpd.conf dest=/etc/httpd/conf/ - name: \u0026#34;复制配置文件\u0026#34; copy: src=/tmp/vhosts.conf dest=/etc/httpd/conf.d/ - name: \u0026#34;启动Apache，并设置开机启动\u0026#34; service: name=httpd state=started enabled=yes playbook 命令 格式\nansible-playbook \u0026lt;filename.yml\u0026gt; ... [options] 选项\n--syntax,--syntax-check #语法检查,功能相当于bash -n -C --check #模拟执行dry run ,只检测可能会发生的改变，但不真正执行操作 --list-hosts #列出运行任务的主机 --list-tags #列出tag --list-tasks #列出task --limit 主机列表 #只针对主机列表中的特定主机执行 -i INVENTORY, --inventory INVENTORY #指定主机清单文件,通常一个项对应一个主机清单文件 --start-at-task START_AT_TASK #从指定task开始执行,而非从头开始,START_AT_TASK为任务的name -v -vv -vvv #显示过程 范例: 一个简单的 playbook\n[root@ansible ansible]#cat hello.yml --- - hosts: websrvs tasks: - name: hello command: echo \u0026#34;hello ansible\u0026#34; [root@ansible ansible]#ansible-playbook hello.yml [root@ansible ansible]#ansible-playbook -v hello.yml 范例: 检查和限制主机\nansible-playbook file.yml --check #只检测 ansible-playbook file.yml ansible-playbook file.yml --limit websrvs 范例: 一个playbook 多个play\ncat test_plays.yaml --- - hosts: localhost remote_user: root gather_facts: no tasks: - name: play1 command: echo \u0026#34;play1\u0026#34; - hosts: centos7 remote_user: root gather_facts: no tasks: - name: play2 command: echo \u0026#34;play2\u0026#34; 忽略错误 ignore_errors 如果一个task出错,默认将不会继续执行后续的其它task 利用 ignore_errors: yes 可以忽略此task的错误,继续向下执行playbook其它task\n[root@ansible ansible]#cat test_ignore.yml --- - hosts: centos7 tasks: - name: error command: /bin/false ignore_errors: yes - name: continue command: wall continue ansible-playbook案例 安装nginx --- - hosts: centos7 # yum install nginx remote_user: root gather_facts: no tasks: - name: install nginx yum: name=nginx state=present - name: service: name=nginx state=started enabled=yes 卸载httpd #remove_httpd.yml --- - hosts: webservers remote_user: root gather_facts: no tasks: - name: remove httpd package yum: name=httpd state=absent - name: remove apache user user: name=apache state=absent - name: remove config file file: name=/etc/httpd state=absent - name: remove web html file: name=/data/html/ state=absent Playbook中使用handlers和notify handlers和notify Handlers本质是task list ，类似于MySQL中的触发器触发的行为，其中的task与前述的task并没有本质上的不同，只有在关注的资源发生变化时，才会采取一定的操作。 Notify对应的action 在所有task都执行完才会最后被触发，这样可避免多个task多次改变发生时每次都触发执行指定的操作，Handlers仅在所有的变化发生完成后一次性地执行指定操作。 在notify中列出的操作称为handler，也即notify中调用handler中定义的操作 注意:\n如果多个task通知了相同的handlers， 此handlers仅会在所有task结束后运行一 次。 只有notify对应的task发生改变了才会通知handlers， 没有改变则不会触发handlers handlers 是在所有前面的tasks都成功执行才会执行,如果前面任何一个task失败,会导致handle跳过执行 案例:\n案例：\n案例：\n范例: 部署haproxy\nforce_handlers 如果不论前面的task成功与否,都希望handlers能执行, 可以使用force_handlers: yes 强制执行handler 范例: 强制调用handlers\nPlaybook中使用tags组件 官方文档:\nhttps://docs.ansible.com/ansible/latest/user_guide/playbooks_tags.html 默认情况下， Ansible 在执行一个 playbook 时，会执行 playbook 中所有的任务，在playbook文件中，可以利用tags组件，为特定 task 指定标签，当在执行playbook时，可以只执行特定tags的task,而非整个playbook文件 可以一个task对应多个tag,也可以多个task对应同一个tag 还有另外3个特殊关键字用于标签, tagged, untagged 和 all,它们分别是仅运行已标记，只有未标记和所有任务。 tags 主要用于调试环境 范例： tag 标签\nPlaybook中使用变量 Playbook中同样也支持变量 变量名：仅能由字母、数字和下划线组成，且只能以字母开头 变量定义：\nvariable=value variable: value 范例：\nhttp_port=80 http_port: 80 通过 {{ variable_name }} 调用变量，且变量名前后建议加空格，有时用\u0026quot;{{ variable_name }}\u0026ldquo;才生效 变量来源：\nansible 的 setup facts 远程主机的所有变量都可直接调用 通过命令行指定变量，优先级最高 ansible-playbook -e varname=value test.yml 3.在playbook文件中定义\nvars: var1: value1 var2: value2 4.在独立的变量YAML文件中定义\n- hosts: all vars_files: - vars.yml 在主机清单文件中定义 主机（普通）变量：主机组中主机单独定义，优先级高于公共变量 组（公共）变量：针对主机组中所有主机定义统一变量 在项目中针对主机和主机组定义 在项目目录中创建 host_vars和group_vars目录 在role中定义\n变量的优先级从高到低如下\n-e 选项定义变量 --\u0026gt;playbook中vars_files --\u0026gt; playbook中vars变量定义 --\u0026gt;host_vars/主机名文件 --\u0026gt;主机清单中主机变量--\u0026gt; group_vars/主机组名文件--\u0026gt;group_vars/all文件--\u0026gt; 主机清单组变量 使用 setup 模块中变量 使用 facts 变量 本模块自动在playbook调用，生成的系统状态信息, 并将之存放在facts变量中 facts 包括的信息很多,如: 主机名,IP,CPU,内存,网卡等 facts 变量的实际使用场景案例\n通过facts变量获取被控端CPU的个数信息,从而生成不同的Nginx配置文件 通过facts变量获取被控端内存大小信息,从而生成不同的memcached的配置文件 通过facts变量获取被控端主机名称信息,从而生成不同的Zabbix配置文件 通过facts变量获取被控端网卡信息,从而生成不同的主机名 案例：使用setup变量\n[root@ansible ~]# ansible localhost -m setup -a \u0026#39;filter=\u0026#34;ansible_default_ipv4\u0026#34;\u0026#39; localhost | SUCCESS =\u0026gt; { \u0026#34;ansible_facts\u0026#34;: { \u0026#34;ansible_default_ipv4\u0026#34;: { \u0026#34;address\u0026#34;: \u0026#34;192.168.32.133\u0026#34;, \u0026#34;alias\u0026#34;: \u0026#34;ens160\u0026#34;, \u0026#34;broadcast\u0026#34;: \u0026#34;192.168.32.255\u0026#34;, \u0026#34;gateway\u0026#34;: \u0026#34;192.168.32.2\u0026#34;, \u0026#34;interface\u0026#34;: \u0026#34;ens160\u0026#34;, \u0026#34;macaddress\u0026#34;: \u0026#34;00:0c:29:7c:80:cd\u0026#34;, \u0026#34;mtu\u0026#34;: 1500, \u0026#34;netmask\u0026#34;: \u0026#34;255.255.255.0\u0026#34;, \u0026#34;network\u0026#34;: \u0026#34;192.168.32.0\u0026#34;, \u0026#34;prefix\u0026#34;: \u0026#34;24\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;ether\u0026#34; } }, \u0026#34;changed\u0026#34;: false } [root@ansible ~]# 范例：显示ens33的网卡的IP地址\n--- - hosts: centos7 tasks: - name: show ens33 ip debug: msg: IP address {{ ansible_ens33.ipv4.address }} #msg: IP address {{ ansible_facts[\u0026#34;ens33\u0026#34;][\u0026#34;ipv4\u0026#34;][\u0026#34;address\u0026#34;] }} #msg: IP address {{ ansible_facts.ens33.ipv4.address }} #msg: IP address {{ ansible_default_ipv4.address }} #msg: IP address {{ ansible_ens33.ipv4.address }} #msg: IP address {{ ansible_ens33.ipv4.address.split(\u0026#39;.\u0026#39;)[-1] }} #取IP中的最后一个数字 [root@ansible ansible]# ansible-playbook -v show_ip.yml Using /etc/ansible/ansible.cfg as config file PLAY [centos7] ************************************************************************************************************************* TASK [Gathering Facts] ***************************************************************************************************************** ok: [192.168.32.179] ok: [192.168.32.178] TASK [show ens33 ip] ******************************************************************************************************************* ok: [192.168.32.178] =\u0026gt; { \u0026#34;msg\u0026#34;: \u0026#34;IP address 192.168.32.178\u0026#34; } ok: [192.168.32.179] =\u0026gt; { \u0026#34;msg\u0026#34;: \u0026#34;IP address 192.168.32.179\u0026#34; } PLAY RECAP ***************************************************************************************************************************** 192.168.32.178 : ok=2 changed=0 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 192.168.32.179 : ok=2 changed=0 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 [root@ansible ansible]# 范例：修改主机名称为web-IP\n- hosts: centos7 tasks: - name: 打印facts变量 debug: msg={{ ansible_ens33.ipv4.address }} - name: 修改主机名 hostname: name=web-{{ ansible_ens33.ipv4.address }} #- name: 获取facts变量提取IP地址，以.结尾的最后一列,修改主机名为web-hostid #hostname: name=web-{{ ansible_ens33.ipv4.address.split(\u0026#39;.\u0026#39;)[-1] }} [root@ansible ansible]# ansible-playbook change_hostname.yml PLAY [centos7] ************************************************************************************************************************* TASK [Gathering Facts] ***************************************************************************************************************** ok: [192.168.32.178] ok: [192.168.32.179] TASK [打印facts变量] ******************************************************************************************************************* ok: [192.168.32.178] =\u0026gt; { \u0026#34;msg\u0026#34;: \u0026#34;192.168.32.178\u0026#34; } ok: [192.168.32.179] =\u0026gt; { \u0026#34;msg\u0026#34;: \u0026#34;192.168.32.179\u0026#34; } TASK [修改主机名] ********************************************************************************************************************** changed: [192.168.32.179] changed: [192.168.32.178] PLAY RECAP ***************************************************************************************************************************** 192.168.32.178 : ok=3 changed=1 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 192.168.32.179 : ok=3 changed=1 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 [root@ansible ansible]# 性能优化 每次执行playbook,默认会收集每个主机的所有facts变量,将会导致速度很慢,可以采用下面方法加速 方法1 关闭facts采集加速执行,此方法将导致无法使用facts变量\n- hosts: all gather_facts: no 方法2 当使用 gather_facts: no 关闭 facts，确实能加速 Ansible 执行，但是有时候又需要使用 facts 中的内容，还希望执行的速度快，这时候可以设置facts 的缓存,将facts变量信息存在redis服务器中\n[root@ansible ~]# cat /etc/ansible/ansible.cfg [defaults] # smart 表示默认收集 facts，但 facts 已有的情况下不会收集，即使用缓存 facts # implicit 表示默认收集 facts，要禁止收集，必须使用 gather_facts: False # explicit 则表示默认不收集，要显式收集，必须使用gather_facts: True gathering = smart #在使用 facts 缓存时设置为smart fact_caching_timeout = 86400 #缓存时长 fact_caching = redis #缓存存在redis中 fact_caching_connection = 10.0.0.100:6379:0 #0表示redis的0号数据库 #若redis设置了密码 fact_caching_connection = 10.0.0.100:6379:0:password register 注册变量 在playbook中可以使用register将捕获命令的输出保存在临时变量中，方便后续调用此变量,比如可以使用debug模块进行显示输出 范例: 利用debug 模块输出变量\n--- - hosts: centos7 tasks: - name: get variable shell: hostname register: name - name: print variable debug: msg: \u0026#34;{{ name }}\u0026#34; #输出register注册的name变量的全部信息,注意变量要加\u0026#34; \u0026#34;引起来 #msg: \u0026#34;{{ name.cmd }}\u0026#34; #显示命令 #msg: \u0026#34;{{ name.rc }}\u0026#34; #显示命令成功与否 #msg: \u0026#34;{{ name.stdout }}\u0026#34; #显示命令的输出结果为字符串形式,所有结果都放在一行里显示,适合于结果是单行输出 #msg: \u0026#34;{{ name.stdout_lines }}\u0026#34; #显示命令的输出结果为列表形式,逐行标准输出,适用于多行显示 #msg: \u0026#34;{{ name[\u0026#39;stdout_lines\u0026#39;] }}\u0026#34; #显示命令的执行结果为列表形式,和效果上面相同 #msg: \u0026#34;{{ name.stdout_lines[0] }}\u0026#34; #显示命令的输出结果的列表中的第一个元素 #说明 第一个 task 中，使用了 register 注册变量名为 name ；当 shell 模块执行完毕后，会将数据放到该变量中。第二给 task 中，使用了 debug 模块，并从变量name中获取数据。 [root@ansible ansible]# ansible-playbook -C register.yml PLAY [centos7] ************************************************************************************************************************* TASK [Gathering Facts] ***************************************************************************************************************** ok: [192.168.32.179] ok: [192.168.32.178] TASK [get variable] ******************************************************************************************************************** skipping: [192.168.32.179] skipping: [192.168.32.178] TASK [print variable] ****************************************************************************************************************** ok: [192.168.32.178] =\u0026gt; { \u0026#34;msg\u0026#34;: { \u0026#34;changed\u0026#34;: false, \u0026#34;cmd\u0026#34;: \u0026#34;hostname\u0026#34;, \u0026#34;delta\u0026#34;: null, \u0026#34;end\u0026#34;: null, \u0026#34;failed\u0026#34;: false, \u0026#34;msg\u0026#34;: \u0026#34;Command would have run if not in check mode\u0026#34;, \u0026#34;rc\u0026#34;: 0, \u0026#34;skipped\u0026#34;: true, \u0026#34;start\u0026#34;: null, \u0026#34;stderr\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;stderr_lines\u0026#34;: [], \u0026#34;stdout\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;stdout_lines\u0026#34;: [] } } ok: [192.168.32.179] =\u0026gt; { \u0026#34;msg\u0026#34;: { \u0026#34;changed\u0026#34;: false, \u0026#34;cmd\u0026#34;: \u0026#34;hostname\u0026#34;, \u0026#34;delta\u0026#34;: null, \u0026#34;end\u0026#34;: null, \u0026#34;failed\u0026#34;: false, \u0026#34;msg\u0026#34;: \u0026#34;Command would have run if not in check mode\u0026#34;, \u0026#34;rc\u0026#34;: 0, \u0026#34;skipped\u0026#34;: true, \u0026#34;start\u0026#34;: null, \u0026#34;stderr\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;stderr_lines\u0026#34;: [], \u0026#34;stdout\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;stdout_lines\u0026#34;: [] } } PLAY RECAP ***************************************************************************************************************************** 192.168.32.178 : ok=2 changed=0 unreachable=0 failed=0 skipped=1 rescued=0 ignored=0 192.168.32.179 : ok=2 changed=0 unreachable=0 failed=0 skipped=1 rescued=0 ignored=0 [root@ansible ansible]# 范例: 安装启动服务并检查\n--- - hosts: centos7 vars: package_name: nginx service_name: nginx tasks: - name: install {{ package_name }} yum: name={{ package_name }} - name: start {{ service_name }} service: name={{ service_name }} state=started enabled=yes - name: check shell: ps axu|grep {{ service_name }} register: check_service - name: debug debug: msg: \u0026#34;{{ check_service.stdout_lines }}\u0026#34; 范例: 修改主机名形式为 web_\u0026lt;随机字符\u0026gt;\n- hosts: centos7 tasks: - name: genarate random shell: cmd: openssl rand -base64 12 |tr -dc \u0026#39;[:alnum:]\u0026#39; register: num - name: show random debug: msg: \u0026#34;{{ num }}\u0026#34; - name: change hostname hostname: name: web-{{ num.stdout }} 范例: 修改主机名形式为 web_随机数\n- hosts: centos7 tasks: - name: 定义一个随机数，设定为变量，然后后续调用 shell: echo $((RANDOM%255)) register: web_number - name: 使用debug输出变量结果 debug: msg={{ web_number }} - name: 使用hostname模块将主机名修改为web_随机数 hostname: name=web_{{ web_number.stdout }} 范例: 批量修改主机名为随机字符\n- hosts: centos7 vars: host: web domain: wang.org tasks: - name: get variable shell: echo $RANDOM | md5sum | cut -c 1-8 register: get_random - name: print variable debug: msg: \u0026#34;{{ get_random.stdout }}\u0026#34; - name: set hostname hostname: name={{ host }}-{{ get_random.stdout }}.{{ domain }} 范例: 批量修改主机名为IP最后1位数字\n- hosts: centos7 vars: host: web domain: wang.org tasks: - name: get variable shell: hostname -I | awk \u0026#39;{print $1}\u0026#39; register: get_ip - name: print variable debug: msg: \u0026#34;{{ get_ip.stdout.split(\u0026#39;.\u0026#39;)[3] }}\u0026#34; - name: set hostname hostname: name={{ host }}-{{ get_ip.stdout.split(\u0026#39;.\u0026#39;)[3] }}.{{ domain }} 在 Playbook 命令行中定义变量 范例：\n--- - hosts: centos7 remote_user: root tasks: - name: install nginx yum: name={{ pkname }} state=present [root@ansible ~]#ansible-playbook -e pkname=nginx var2.yml 范例：\n#也可以将多个变量放在一个文件中 [root@ansible ~]#cat vars pkname1: memcached pkname2: vsftpd [root@ansible ~]#vim var2.yml --- - hosts: centos7 remote_user: root tasks: - name: install package {{ pkname1 } yum: name={{ pkname1 }} state=present - name: install package {{ pkname2 } yum: name={{ pkname2 }} state=present [root@ansible ~]#ansible-playbook -e pkname1=memcached -e pkname2=httpd var2.yml [root@ansible ~]#ansible-playbook -e \u0026#39;@vars\u0026#39; var2.yml 在playbook文件中定义变量 此方式定义的是私有变量,即只能在当前playbook中使用,不能被其它Playbook共用 范例：\n- hosts: webservers remote_user: root vars: username: user1 groupname: group1 tasks: - name: create group {{ groupname }} group: name={{ groupname }} state=present - name: create user {{ username }} user: name={{ username }} group={{ groupname }} state=present [root@ansible ~]#ansible-playbook -e \u0026#34;username=user2 groupname=group2\u0026#34; var3.yml 范例：变量的相互调用\n--- - hosts: centos7 remote_user: root vars: collect_info: \u0026#34;/data/test/{{ansible_default_ipv4[\u0026#39;address\u0026#39;]}}/\u0026#34; tasks: - name: create IP directory file: name=\u0026#34;{{collect_info}}\u0026#34; state=directory 使用专用的公共的变量文件 可以在一个独立的playbook文件中定义公共变量，在其它的playbook文件中可以引用变量文件中的变量 此方式比playbook中定义的变量优化级高\nvim vars.yml --- # variables file package_name: mariadb-server service_name: mariadb vim var5.yml --- #install package and start service - hosts: dbsrvs remote_user: root vars_files: # 指定变量文件名 - vars.yml tasks: - name: install package yum: name={{ package_name }} tags: install - name: start service service: name={{ service_name }} state=started enabled=yes 在主机清单中定义主机和主机组的变量 所有项目的主机变量 在inventory 主机清单文件中为指定的主机定义变量以便于在playbook中使用 范例：\n[webservers] www1.wang.org http_port=80 maxRequestsPerChild=808 www2.wang.org http_port=8080 maxRequestsPerChild=909 所有项目的组（公共）变量 在inventory 主机清单文件中赋予给指定组内所有主机上的在playbook中可用的变量，如果和主机变是同名，优先级低于主机变量\n案例：\n[webservers:vars] http_port=80 ntp_server=ntp.wang.org nfs_server=nfs.wang.org [all:vars] # --------- Main Variables --------------- # Cluster container-runtime supported: docker, containerd CONTAINER_RUNTIME=\u0026#34;docker\u0026#34; # Network plugins supported: calico, flannel, kube-router, cilium, kube-ovn CLUSTER_NETWORK=\u0026#34;calico\u0026#34; # Service proxy mode of kube-proxy: \u0026#39;iptables\u0026#39; or \u0026#39;ipvs\u0026#39; PROXY_MODE=\u0026#34;ipvs\u0026#34; # K8S Service CIDR, not overlap with node(host) networking SERVICE_CIDR=\u0026#34;192.168.0.0/16\u0026#34; # Cluster CIDR (Pod CIDR), not overlap with node(host) networking CLUSTER_CIDR=\u0026#34;172.16.0.0/16\u0026#34; # NodePort Range NODE_PORT_RANGE=\u0026#34;20000-60000\u0026#34; # Cluster DNS Domain CLUSTER_DNS_DOMAIN=\u0026#34;magedu.local.\u0026#34; 范例：\n[root@ansible ~]#vim /etc/ansible/hosts [webservers] 10.0.0.8 hname=www1 domain=magedu.io 10.0.0.7 hname=www2 [webservers:vars] mark=\u0026#34;-\u0026#34; [all:vars] domain=wang.org [root@ansible ~]#ansible webservers -m hostname -a \u0026#39;name={{ hname }}{{ mark }} {{ domain }}\u0026#39; #命令行指定变量： [root@ansible ~]#ansible webservers -e domain=magedu.cn -m hostname -a \u0026#39;name= {{ hname }}{{ mark }}{{ domain }}\u0026#39; 针对当前项目的主机和主机组的变量 上面的方式是针对所有项目都有效,而官方更建议的方式是使用ansible特定项目的主机变量和组变量.生产建议在每个项目对应的目录中创建额外的两个变量目录,分别是host_vars和group_vars\nhost_vars下面的文件名和主机清单主机名一致,针对单个主机进行变量定义格式:host_vars/hostname group_vars下面的文件名和主机清单中组名一致, 针对单个组进行变量定义格式: group_vars/groupname group_vars/all文件内定义的变量对所有组都有效 范例: 特定项目的主机和组变量\n[root@ansible ansible]#pwd /data/ansible [root@ansible ansible]#mkdir host_vars [root@ansible ansible]#mkdir group_vars [root@ansible ansible]#cat host_vars/10.0.0.8 id: 2 [root@ansible ansible]#cat host_vars/10.0.0.7 id: 1 [root@ansible ansible]#cat group_vars/webservers name: web [root@ansible ansible]#cat group_vars/all domain: wang.org [root@ansible ansible]#tree host_vars/ group_vars/ host_vars/ ├── 10.0.0.7 └── 10.0.0.8 group_vars/ ├── all └── webservers 0 directories, 4 files [root@ansible ansible]#cat test.yml - hosts: webservers tasks: - name: get variable command: echo \u0026#34;{{name}}{{id}}.{{domain}}\u0026#34; register: result - name: print variable debug: msg: \u0026#34;{{result.stdout}}\u0026#34; [root@ansible ansible]#ansible-playbook test.yml PLAY [webservers] ******************************************************************************** *************************************** TASK [Gathering Facts] ******************************************************************************** ******************************* ok: [10.0.0.7] ok: [10.0.0.8] TASK [get variable] ******************************************************************************** ********************************** changed: [10.0.0.7] changed: [10.0.0.8] TASK [print variable] ******************************************************************************** ******************************** ok: [10.0.0.7] =\u0026gt; { \u0026#34;msg\u0026#34;: \u0026#34;web1.wang.org\u0026#34; } ok: [10.0.0.8] =\u0026gt; { \u0026#34;msg\u0026#34;: \u0026#34;web2.wang.org\u0026#34; } PLAY RECAP ******************************************************************************** ******************************************* 10.0.0.7 : ok=3 changed=1 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 10.0.0.8 : ok=3 changed=1 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 Template 模板 模板是一个文本文件，可以用于根据每个主机的不同环境而为生成不同的文件 模板文件中支持嵌套jinja2语言的指令,来实现变量,条件判断,循环等功能 需要使用template模块实现文件的复制到远程主机,但和copy模块不同,复制过去的文件每个主机可以会有所不同\njinja2语言 Jinja2 是一个现代的，设计者友好的，仿照 Django 模板的 Python 模板语言。 它速度快，被广泛使用，并且提供了可选的沙箱模板执行环境保证安全: 特性:\n沙箱中执行 强大的 HTML 自动转义系统保护系统免受 XSS 模板继承 及时编译最优的 python 代码 可选提前编译模板的时间 易于调试。异常的行数直接指向模板中的对应行。 可配置的语法 官方网站：\nhttp://jinja.pocoo.org/ https://jinja.palletsprojects.com/en/2.11.x/ 官方中文文档\nhttp://docs.jinkan.org/docs/jinja2/ https://www.w3cschool.cn/yshfid/ jinja2 语言支持多种数据类型和操作: 字面量，如: 字符串：使用单引号或双引号,数字：整数，浮点数 列表：[item1, item2, \u0026hellip;] 元组：(item1, item2, \u0026hellip;) 字典：{key1:value1, key2:value2, \u0026hellip;} 布尔型：true/false 算术运算：+, -, *, /, //, %, ** 比较操作：==, !=, \u0026gt;, \u0026gt;=, \u0026lt;, \u0026lt;=\n逻辑运算：and，or，not 流表达式：For，If，When\n字面量： 表达式最简单的形式就是字面量。字面量表示诸如字符串和数值的 Python 对象。如\u0026quot;Hello World\u0026rdquo; 双引号或单引号中间的一切都是字符串。无论何时你需要在模板中使用一个字符串（比如函数调用、过滤器或只是包含或继承一个模板的参数），如42，42.23 数值可以为整数和浮点数。如果有小数点，则为浮点数，否则为整数。在 Python 里， 42 和 42.0 是不一样的\n算术运算： Jinja 允许用计算值。支持下面的运算符 +：把两个对象加到一起。通常对象是素质，但是如果两者是字符串或列表，你可以用这 种方式来衔接 它们。无论如何这不是首选的连接字符串的方式！连接字符串见 ~ 运算符。 {{ 1 + 1 }} 等于 2 -：用第一个数减去第二个数。 {{ 3 - 2 }} 等于 1 /：对两个数做除法。返回值会是一个浮点数。 {{ 1 / 2 }} 等于 0.5 //：对两个数做除法，返回整数商。 {{ 20 // 7 }} 等于 2 %：计算整数除法的余数。 {{ 11 % 7 }} 等于 4 ：用右边的数乘左边的操作数。 {{ 22 }} 会返回 4 。也可以用于重 复一个字符串多次。 {{ \u0026lsquo;=\u0026rsquo; * 80 }} 会打印 80 个等号的横条\n：取左操作数的右操作数次幂。 {{ 23 }} 会返回 8\n比较操作符\n== 比较两个对象是否相等 != 比较两个对象是否不等\n如果左边大于右边，返回 true = 如果左边大于等于右边，返回 true \u0026lt; 如果左边小于右边，返回 true \u0026lt;= 如果左边小于等于右边，返回 true 逻辑运算符\n对于 if 语句，在 for 过滤或 if 表达式中，它可以用于联合多个表达式 and 如果左操作数和右操作数同为真，返回 true or 如果左操作数和右操作数有一个为真，返回 true not 对一个表达式取反 (expr)表达式组 true / false true 永远是 true ，而 false 始终是 false\ntemplate template功能：可以根据和参考模块文件，动态生成相类似的配置文件 template文件存建议放于templates目录下，且命名为 .j2 结尾\nyaml/yml 文件和templates目录平级，此时playbook中指定模版文件时可不用指定路径, 目录结构如下 示例：\n./ ├── temnginx.yml └── templates └── nginx.conf.j2 范例：利用template 同步nginx配置文件\n#准备templates/nginx.conf.j2文件 [root@ansible ~]#vim temnginx.yml --- - hosts: centos7 remote_user: root tasks: - name: template config to remote hosts template: src=nginx.conf.j2 dest=/etc/nginx/nginx.conf [root@ansible ~]#ansible-playbook temnginx.yml template变更替换 范例：\n#修改文件nginx.conf.j2 [root@ansible ~]#mkdir templates [root@ansible ~]#vim templates/nginx.conf.j2 ...... worker_processes {{ ansible_processor_vcpus }}; ...... [root@ansible ~]#vim temnginx2.yml --- - hosts: centos7 remote_user: root tasks: - name: install nginx yum: name=nginx - name: template config to remote hosts template: src=nginx.conf.j2 dest=/etc/nginx/nginx.conf - name: start service service: name=nginx state=started enabled=yes [root@ansible ~]#ansible-playbook temnginx2.yml Roles 角色 角色是ansible自1.2版本引入的新特性，用于层次性、结构化地组织playbook。roles能够根据层次型结构自动装载变量文件、tasks以及handlers等。要使用roles只需要在playbook中使用include指令即可。简单来讲，roles就是通过分别将变量、文件、任务、模板及处理器放置于单独的目录中，并可以便捷地include它们的一种机制。角色一般用于基于主机构建服务的场景中，但也可以是用于构建守护进程等场景中 运维复杂的场景：建议使用 roles，代码复用度高 roles：多个角色的集合目录， 可以将多个的role，分别放至roles目录下的独立子目录中,如下示例\nroles/ mysql/ nginx/ tomcat/ redis/ 默认roles存放路径\n/root/.ansible/roles /usr/share/ansible/roles /etc/ansible/roles 官方文档:\nhttps://docs.ansible.com/ansible/latest/user_guide/playbooks_reuse_roles.html Ansible Roles目录编排 roles目录结构如下所示\n每个角色，以特定的层级目录结构进行组织 roles目录结构：\nplaybook1.yml playbook2.yml roles/ project1/ tasks/ files/ vars/ templates/ handlers/ default/ meta/ project2/ tasks/ files/ vars/ templates/ handlers/ default/ meta/ Roles各目录作用 roles/project/ :项目名称,有以下子目录\nfiles/ ：存放由copy或script模块等调用的文件 templates/：template模块查找所需要模板文件的目录 tasks/：定义task,role的基本元素，至少应该包含一个名为main.yml的文件；其它的文件需要在此文件中通过include进行包含 handlers/：至少应该包含一个名为main.yml的文件；此目录下的其它的文件需要在此文件中通过include进行包含 vars/：定义变量，至少应该包含一个名为main.yml的文件；此目录下的其它的变量文件需要在此文件中通过include进行包含,也可以通过项目目录中的group_vars/all定义变量,从而实现角色通用代码和项目数据的分离 meta/：定义当前角色的特殊设定及其依赖关系,至少应该包含一个名为main.yml的文件，其它文件需在此文件中通过include进行包含 default/：设定默认变量时使用此目录中的main.yml文件，比vars的优先级低 创建 role 创建role的步骤\n1 创建role的目录结构.在以roles命名的目录下分别创建以各角色名称命名的目录，如mysql等,在每个角色命名的目录中分别创建相关的目录和文件,比如tasks、files、handlers、templates和vars等目录；用不到的目录可以创建为空目录，也可以不创建 2 编写和准备指定role的功能文件,包括: tasks,templates,vars等相关文件 3 编写playbook文件调用上面定义的role,应用到指定的主机 针对大型项目使用Roles进行编排 范例: 利用 ansible-galaxy 创建角色目录的结构\n#创建初始化目录结构 [root@ansible roles]#ansible-galaxy role init test_role - Role test_role was created successfully [root@ansible roles]#tree test_role/ test_role/ ├── defaults │ └── main.yml ├── files ├── handlers │ └── main.yml ├── meta │ └── main.yml ├── README.md ├── tasks │ └── main.yml ├── templates ├── tests │ ├── inventory │ └── test.yml └── vars └── main.yml 8 directories, 8 files 范例：roles的目录结构\nnginx-role.yml roles/ └── nginx ├── files │ └── nginx.conf ├── tasks │ ├── groupadd.yml │ ├── install.yml │ ├── main.yml │ ├── restart.yml │ └── useradd.yml └── vars └── main.yml Playbook 调用角色 调用角色方法1：\n--- - hosts: webservers remote_user: root roles: - mysql - memcached - nginx 调用角色方法2： 键role用于指定角色名称，后续的k/v用于传递变量给角色\n--- - hosts: all remote_user: root roles: - role: mysql username: mysql - { role: nginx, username: nginx } 调用角色方法3： 还可基于条件测试实现角色调用\n--- - hosts: all remote_user: root roles: - { role: nginx, username: nginx, when: ansible_distribution_major_version == \u0026#39;7\u0026#39; } Roles 中 Tags 使用 [root@ansible ~]#vi app-role.yml --- #可以有多个play - hosts: lbserver roles: - role: haproxy - role: keepalived - hosts: appsrvs remote_user: root roles: - { role: nginx ,tags: [ \u0026#39;nginx\u0026#39;, \u0026#39;web\u0026#39; ] ,when: ansible_distribution_major_version == \u0026#34;6\u0026#34; } - { role: httpd ,tags: [ \u0026#39;httpd\u0026#39;, \u0026#39;web\u0026#39; ] } - { role: mysql ,tags: [ \u0026#39;mysql\u0026#39;, \u0026#39;db\u0026#39; ] } - role: mariadb tags: - mariadb - db tags: app #play的tag [root@ansible ~]#ansible-playbook --tags=\u0026#34;nginx,mysql\u0026#34; app-role.yml 实战案例 实现httpd角色 # 创建role目录 [root@ansible data]# ansible-galaxy role init httpd - Role htppd was created successfully [root@ansible data]# tree httpd/ httpd/ ├── defaults │ └── main.yml ├── files ├── handlers │ └── main.yml ├── meta │ └── main.yml ├── README.md ├── tasks │ └── main.yml ├── templates ├── tests │ ├── inventory │ └── test.yml └── vars └── main.yml 8 directories, 8 files [root@ansible data]# #main.yml 是task的入口文件 [root@ansible tasks]# cat main.yml --- # tasks file for httpd - include: group.yml - include: user.yml - include: install_httpd.yml - include: config.yml - inclusde: index.yml - include: service.yml [root@ansible tasks]# # 创建用户组 [root@ansible httpd]# cat tasks/group.yml - name: add group group: name={{ httpd_group}} system=yes gid={{ httpd_gid }} [root@ansible htppd]# # 创建用户 [root@ansible httpd]# cat tasks/user.yml - name: add httpd user user: name={{ httpd_user }} system=yes shel=/sbin/nologin home=/var/www uid={{ httpd_uid }} group={{ httpd_group }} [root@ansible htppd]# # yum install httpd [root@ansible httpd]# cat tasks/install_httpd.yml - name: install httpd yum: name=httpd [root@ansible httpd]# # 拷贝配置文件 #注意: 文件是放在files目录下,但src的路径无需写files目录名 [root@ansible htppd]# cat tasks/config.yml - name: httpd config copy: src=httpd.conf dest=/etc/httpd/conf backup=yes notify: restart httpd # 准备测试文件 [root@ansible htppd]# cat tasks/index.yml - name: copy index.html copy: src=index.html dest=/var/www/html [root@ansible htppd]# # start httpd [root@ansible htppd]# cat tasks/service.yml - name: start httpd service: name=httpd state=started enabled=yes [root@ansible htppd]# # 配置文件修改则重启httpd [root@ansible htppd]# cat handlers/main.yml --- # handlers file for httpd - name: restart httpd service: name=httpd state=restarted [root@ansible htppd]# #在files目录下准备两个文件 [root@ansible data]# ll httpd/files total 16 -rw-r--r-- 1 root root 11753 Mar 1 18:36 httpd.conf -rw-r--r-- 1 root root 23 Mar 1 21:10 index.html # 准备变量文件 [root@ansible data]# cat httpd/vars/main.yml --- # vars file for httpd httpd_group: apache httpd_gid: 88 httpd_user: apache httpd_uid: 88 [root@ansible data]# #在playbook中调用角色 [root@ansible data]# cat web_roles.yml --- - hosts: centos7 remote_user: root roles: - httpd #运行playbook [root@ansible data]# ansible-playbook /data/web_roles.yml 实现Nginx角色 # 创建roles目录 [root@ansible data]# ansible-galaxy init nginx - Role nginx was created successfully [root@ansible data]# ll total 12 -rw-r--r-- 1 root root 614 Mar 1 21:07 ansible.cfg -rw-r--r-- 1 root root 1382 Mar 1 21:07 hosts drwxr-xr-x 10 root root 154 Mar 1 18:07 httpd drwxr-xr-x 10 root root 154 Mar 1 21:52 nginx -rw-r--r-- 1 root root 63 Mar 1 21:14 web_roles.yml [root@ansible data]# # 创建tasks文件 [root@ansible data]# cat nginx/tasks/main.yml --- # tasks file for nginx - include: install_nginx.yml - import_playbook: config.yml - include: index.yml - import_playbook: service.yml [root@ansible data]# # 安装nginx [root@ansible data]# cat nginx/tasks/install_nginx.yml --- - name: install nginx yum: name: nginx state: present [root@ansible data]# # 配置文件 [root@ansible data]# cat nginx/tasks/config.yml --- - name: copy config template: src=nginx.conf.j2 dest=/etc/nginx/nginx.conf notify: restart nginx # 创建测试文件 [root@ansible data]# cat nginx/tasks/index.yml --- - name: copt index.html copy: src=index.html dest=/usr/share/nginx/html/ # 启动nginx [root@ansible data]# cat nginx/tasks/service.yml --- - name: start nginx service: name=nginx state=started enabled=yes #创建handler文件 [root@ansible data]# cat nginx/handlers/main.yml --- # handlers file for nginx - name: restart nginx service: naem=nginx state=restarted [root@ansible data]# ll #创建template文件 [root@ansible data]# ll nginx/templates/ total 4 -rw-r--r-- 1 root root 2336 Mar 1 22:12 nginx.conf.j2 [root@ansible data]# # 创建测试文件 [root@ansible data]# ll nginx/files/ total 4 -rw-r--r-- 1 root root 23 Mar 1 22:14 index.html [root@ansible data]# #在playbook中调用角色 [root@ansible data]# cat web_roles.yml --- - hosts: centos7 remote_user: root roles: # - httpd - nginx [root@ansible data]# #运行playbook [root@ansible data]# ansible-playbook web_roles.yml 实现MySql8角色 创建角色目录 [root@ansible data]# ansible-galaxy init mysql8 [root@ansible data]# ll total 12 -rw-r--r-- 1 root root 614 Mar 1 21:07 ansible.cfg -rw-r--r-- 1 root root 1382 Mar 1 21:07 hosts drwxr-xr-x 10 root root 154 Mar 1 18:07 httpd drwxr-xr-x 10 root root 154 Mar 1 22:55 mysql8 drwxr-xr-x 8 root root 125 Mar 1 22:44 nginx -rw-r--r-- 1 root root 75 Mar 1 22:38 web_roles.yml [root@ansible data]# 创建tasks yml文件 # 安装包 [root@ansible data]# cat mysql8/tasks/install_package.yml --- - name: install package yum: name={{ item }} state=latest loop: - libaio - numactl-libs # add group [root@ansible data]# cat mysql8/tasks/group.yml --- - name: add group group: name={{ group }} gid={{ group_gid }} [root@ansible data]# # add user [root@ansible data]# cat mysql8/tasks/user.yml --- - name: add user user: name={{ user }} uid={{ user_uid }} shell=/sbin/nologin group={{ group }} create_home=no system=yes home=/data/mysql [root@ansible data]# # 准备my.cnf文件 [root@ansible data]# cat mysql8/files/my.cnf [mysqld] server-id=1 log-bin datadir=/data/mysql socket=/data/mysql/mysql.sock log-error=/data/mysql/mysql.log pid-file=/data/mysql/mysql.pid [client] socket=/data/mysql/mysql.sock # 准备mysql二进制包 [root@ansible data]# ll mysql8/files/ total 1176056 -rw-r--r-- 1 root root 181 Mar 1 23:10 my.cnf -rw-r--r-- 1 root root 1204277208 Dec 18 2021 mysql-8.0.28-linux-glibc2.12-x86_64.tar.xz [root@ansible data]# # 将mysql二进制包解压到远程主机 [root@ansible data]# cat mysql8/tasks/unarchive.yml --- - name: copy mysql tar host # mysql_tar 为mysql二进制的压缩包名称 unarchive: src={{ mysql_tar }} dest=/usr/local/ owner=root group=root [root@ansible data]# # 将远程主机解压出的二进制包创建软连接 [root@ansible data]# cat mysql8/tasks/linkfile.yml --- - name: create link file: src=/usr/local/mysql-{{ mysql_version }}-linux-glibc2.12-x86_64 dest=/usr/local/mysql state=link [root@ansible data]# # 初始化数据库 [root@ansible data]# cat mysql8/tasks/init_mysql_data.yml --- - name: create datadir dir file: path=/data/mysql state=directory owner={{ user }} group={{ group } - name: init mysql data shell: /usr/local/mysql/bin/mysqld --initialize-insecure --user=mysql --datadir=/data/mysql [root@ansible data]# # copy config.con [root@ansible data]# cat mysql8/tasks/config.yml --- - name: copy my.cnf copy: src=my.cnf dest=/etc/my.cnf [root@ansible data]# [root@ansible data]# cat mysql8/tasks/script.yml --- - name: service script shell: /bin/cp /usr/local/mysql/support-files/mysql.server /etc/init.d/mysqld [root@ansible data]# [root@ansible data]# cat mysql8/tasks/path.yml --- - name: path copy: content=\u0026#39;PATH=/usr/local/mysql/bin:$PATH\u0026#39; dest=/etc/profile.d/mysql.sh [root@ansible data]# [root@ansible data]# cat mysql8/tasks/service.yml --- - name: service shell: chkconfig --add mysqld;/etc/init.d/mysqld start [root@ansible data]# [root@ansible data]# cat mysql8/tasks/main.yml --- # tasks file for mysql8 - include: install_package.yml - include: group.yml - include: user.yml - include: unarchive.yml - include: linkfile.yml - include: linkfile.yml - include: init_mysql_data.yml - include: config.yml - include: script.yml - include: path.yml - include: service.yml - include: secure.yml # 创建变量文件 [root@ansible data]# cat mysql8/vars/main.yml --- # vars file for mysql8 group: mysql group_gid: 306 user: mysql user_uid: 306 mysql_tar: mysql-8.0.28-linux-glibc2.12-x86_64.tar.xz mysql_version: 8.0.28 mysql_root_password: 123456 [root@ansible data]# # 调用角色 [root@ansible data]# cat web_roles.yml --- - hosts: centos7 remote_user: root roles: - mysql8 # 运行 [root@ansible data]# ansible-playbook web_roles.yml 实现Redis角色 # 创建角色目录 [root@ansible data]# ansible-galaxy init redis [root@ansible data]# tree redis/ redis/ ├── defaults │ └── main.yml ├── files ├── handlers │ └── main.yml ├── meta │ └── main.yml ├── README.md ├── tasks │ └── main.yml ├── templates ├── tests │ ├── inventory │ └── test.yml └── vars └── main.yml # 创建tasks文件 [root@ansible data]# cat redis/tasks/main.yml --- # tasks file for redis - name: Installed Redis Server yum: name: redis state: present - name: Configure Redis Server template: src: redis.conf.j2 dest: /etc/redis.conf owner: redis group: root mode: \u0026#39;0640\u0026#39; notify: Restart Redis Server - name: Start Redis Server systemd: name: redis state: started enabled: yes [root@ansible data]# # 创建handlers文件 [root@ansible data]# cat redis/handlers/main.yml --- # handlers file for redis - name: Restart Redis Server systemd: name: redis state: restarted [root@ansible data]# # 在/data/redis/templates目录下准备如下文件 [root@ansible data]# ll redis/templates/ total 48 -rw-r----- 1 root root 46729 Mar 2 02:51 redis.conf.j2 [root@ansible data]# # 调用角色 # 调用角色 [root@ansible data]# cat web_roles.yml --- - hosts: centos7 remote_user: root roles: - redis # 运行 [root@ansible data]# ansible-playbook web_roles.yml Ansible推荐学习资料 http://galaxy.ansible.com https://galaxy.ansible.com/explore#/ http://github.com/ http://ansible.com.cn/ https://github.com/ansible/ansible https://github.com/ansible/ansible-examples ","permalink":"https://xyenvy.github.io/posts/ansible2/","summary":"Playbook playbook介绍 官方链接 https://docs.ansible.com/ansible/latest/user_guide/playbooks_intro.html Playbook 组成 一个 playbook(剧本)文件是一个YAML语言编写的文本文件 通常一个playbook只包括一个play 一个 play的主要包括两部分: 主机和tasks. 即实现在指定一组主机上执行一个tasks定义好的任务列表。 一个tasks中可以有一个或多","title":"运维自动化工具Ansible(二)"},{"content":"Ansible介绍和架构 Ansible发展史 Ansible 的名称来自科幻小说《安德的游戏》中跨越时空的即时通信工具，使用它可以在相距数光年的距离，远程实时控制前线的舰队战斗 2012-03-09，发布0.0.1版，2015-10-17，Red Hat宣布1.5亿美元收购 官网： 官方文档：\nAnsible 功能 批量执行远程命令,可以对远程的多台主机同时进行命令的执行 批量安装和配置软件服务，可以对远程的多台主机进行自动化的方式配置和管理各种服务 编排高级的企业级复杂的IT架构任务, Ansible的Playbook和role可以轻松实现大型的IT复杂架构 提供自动化运维工具的开发API, 有很多运维工具,如jumpserver就是基于 ansible 实现自动化管工功能 Ansible 特点 优点\n功能丰富的模块：提供了多达数千个的各种功能的模块,完成特定任务只需调用特定模块即可，还 支持自定义模块，可使用任何编程语言写模块 使用和部署简单: 无需安装专用代理软件,基于python和SSH(默认已安装)实现 安全: 基于OpenSSH实现安全通讯无需专用协议 幂等性：一个任务执行1遍和执行n遍效果一样，不因重复执行带来意外情况,此特性和模块有关 支持playbook编排任务，YAML格式，编排任务，支持丰富的数据结构 较强大的多层解决方案 Role Python语言实现, 基于Paramiko（python对ssh的实现），PyYAML，Jinja2（模板语言）三个关键模块 属于红帽(IBM)公司产品,背景强大,未来发展前景光明 缺点\n如果管理的主机较多时,执行效率不如saltstack高 当前还不支持像MySQL数据库一样的事务回滚 Ansible 架构 Ansible 组成 组合INVENTORY、API、MODULES、PLUGINS的绿框，为ansible命令工具，其为核心执行工具\nINVENTORY：Ansible管理主机的清单文件,默认为 /etc/ansible/hosts MODULES：Ansible执行命令的功能模块，多数为内置核心模块，也可自定义 PLUGINS：模块功能的补充，如连接类型插件、循环插件、变量插件、过滤插件等，该功能不常用 API：供第三方程序调用的应用程序编程接口 Ansible 命令执行来源 USER 普通用户，即SYSTEM ADMINISTRATOR PLAYBOOKS：任务剧本（任务集），编排定义Ansible任务集的配置文件，由Ansible顺序依次执行，通常是JSON格式的YML文件 CMDB（配置管理数据库） API 调用 PUBLIC/PRIVATE CLOUD API调用 USER-\u0026gt; Ansible Playbook -\u0026gt; Ansibile 注意事项 执行ansible的主机一般称为管理端, 主控端，中控，master或堡垒机 主控端Python版本需要2.6或以上 被控端Python版本小于2.4，需要安装python-simplejson 被控端如开启SELinux需要安装libselinux-python windows 不能做为主控端,只能做为被控制端 Ansible 安装和常见模块 Ansible 安装 ansible的安装方法有多种 官方文档\nhttps://docs.ansible.com/ansible/latest/installation_guide/intro_installation.html https://docs.ansible.com/ansible/latest/installation_guide/index.html 下载\nhttps://releases.ansible.com/ansible/ pip 下载\nhttps://pypi.org/project/ansible/ 包安装方式 #CentOS 的EPEL源的rpm包安装 [root@centos ~]#yum install ansible #ubuntu 安装 [root@ubuntu ~]#apt -y install ansible pip安装 pip 是安装Python包的管理器，类似 yum 范例: 在rocky8上通过pip3安装ansible\n[root@rocky8 ~]#yum -y install python39 rust [root@rocky8 ~]#pip3 install ansible [root@rocky8 ~]#ansible --version ansible [core 2.12.6] config file = None configured module search path = [\u0026#39;/root/.ansible/plugins/modules\u0026#39;, \u0026#39;/usr/share/ansible/plugins/modules\u0026#39;] ansible python module location = /usr/lib/python3.9/site-packages/ansible ansible collection location = /root/.ansible/collections:/usr/share/ansible/collections executable location = /usr/bin/ansible python version = 3.9.6 (default, Nov 9 2021, 13:31:27) [GCC 8.5.0 20210514 (Red Hat 8.5.0-3)] jinja version = 3.1.2 libyaml = True [root@rocky8 ~]#ansible-doc -l 2\u0026gt; /dev/null|wc -l 6763 范例: 安装python3.8 支持ansible2.12以上版本\n[root@rocky8 ~]#yum -y install python38 python38-pip [root@rocky8 ~]#pip3 install --upgrade pip -i https://pypi.douban.com/simple [root@rocky8 ~]#pip3 install ansible -i https://pypi.douban.com/simple/ [root@rocky8 ~]#ansible --version ansible [core 2.12.6] config file = None configured module search path = [\u0026#39;/root/.ansible/plugins/modules\u0026#39;, \u0026#39;/usr/share/ansible/plugins/modules\u0026#39;] ansible python module location = /usr/local/lib/python3.8/site- packages/ansible ansible collection location = /root/.ansible/collections:/usr/share/ansible/collections executable location = /usr/local/bin/ansible python version = 3.8.8 (default, Nov 9 2021, 13:31:34) [GCC 8.5.0 20210514 (Red Hat 8.5.0-3)] jinja version = 3.1.2 libyaml = True 范例: 安装默认的python3.6版本会有警报提示\n[root@rocky8 ~]#yum -y install python3 [root@rocky8 ~]#pip3 install --upgrade pip -i https://pypi.douban.com/simple [root@rocky8 ~]#pip3 install ansible -i https://pypi.douban.com/simple/ [root@rocky8 ~]#ansible --version [DEPRECATION WARNING]: Ansible will require Python 3.8 or newer on the controller starting with Ansible 2.12. Current version: 3.6.8 (default, Nov 9 2021, 14:44:26) [GCC 8.5.0 20210514 (Red Hat 8.5.0-3)]. This feature will be removed from ansible-core in version 2.12. Deprecation warnings can be disabled by setting deprecation_warnings=False in ansible.cfg. /usr/local/lib/python3.6/site-packages/ansible/parsing/vault/__init__.py:44: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography and will be removed in a future release. from cryptography.exceptions import InvalidSignature ansible [core 2.11.12] config file = None configured module search path = [\u0026#39;/root/.ansible/plugins/modules\u0026#39;, \u0026#39;/usr/share/ansible/plugins/modules\u0026#39;] ansible python module location = /usr/local/lib/python3.6/site- packages/ansible ansible collection location = /root/.ansible/collections:/usr/share/ansible/collections executable location = /usr/local/bin/ansible python version = 3.6.8 (default, Nov 9 2021, 14:44:26) [GCC 8.5.0 20210514 (Red Hat 8.5.0-3)] jinja version = 3.0.3 libyaml = True [root@rocky8 ~]#ansible-doc -l 2\u0026gt; /dev/null|wc -l 6141 范例\n[root@centos7 ~]#yum -y install python-pip [root@centos7 ~]#pip install --upgrade pip [root@centos7 ~]#pip install ansible --upgrade [root@centos7 ~]#ansible --version /usr/lib64/python2.7/site-packages/cryptography/__init__.py:39: CryptographyDeprecationWarning: Python 2 is no longer supported by the Python core team. Support for it is now deprecated in cryptography, and will be removed in a future release. CryptographyDeprecationWarning, ansible 2.9.12 config file = None configured module search path = [u\u0026#39;/root/.ansible/plugins/modules\u0026#39;, u\u0026#39;/usr/share/ansible/plugins/modules\u0026#39;] ansible python module location = /usr/lib/python2.7/site-packages/ansible executable location = /usr/bin/ansible python version = 2.7.5 (default, Apr 2 2020, 13:16:51) [GCC 4.8.5 20150623 (Red Hat 4.8.5-39)] [root@centos7 ~]#ll /opt/etc/ansible/ansible.cfg -rw-r--r-- 1 wang bin 19980 Aug 11 21:34 /opt/etc/ansible/ansible.cfg 确认安装 [root@ansible ~]#ansible --version ansible 2.9.5 config file = /etc/ansible/ansible.cfg configured module search path = [\u0026#39;/root/.ansible/plugins/modules\u0026#39;, \u0026#39;/usr/share/ansible/plugins/modules\u0026#39;] ansible python module location = /usr/lib/python3.6/site-packages/ansible executable location = /usr/bin/ansible python version = 3.6.8 (default, Nov 21 2019, 19:31:34) [GCC 8.3.1 20190507 (Red Hat 8.3.1-4)] Ansible 相关文件 Ansible 配置文件列表 /etc/ansible/ansible.cfg 主配置文件，配置ansible工作特性,也可以在项目的目录中创建此文件,当前目录下如果也有ansible.cfg,则此文件优先生效,建议每个项目目录下,创建独有的ansible.cfg文 件 /etc/ansible/hosts 主机清单 /etc/ansible/roles/ 存放角色的目录 Ansible 主配置文件 Ansible 的配置文件可以放在多个不同地方,优先级从高到低顺序如下\nANSIBLE_CONFIG #环境变量,目录下的文件必须存在才能生效 ./ansible.cfg #当前目录下的ansible.cfg,一般一个项目对应一个专用配置文件,推荐使用 ~/.ansible.cfg #当前用户家目录下的.ansible.cfg /etc/ansible/ansible.cfg #系统默认配置文件 Ansible 的默认配置文件 /etc/ansible/ansible.cfg ,其中大部分的配置内容无需进行修改\n[defaults] #inventory = /etc/ansible/hosts #主机列表配置文件 #library = /usr/share/my_modules/ #库文件存放目录 #remote_tmp = $HOME/.ansible/tmp #临时py命令文件存放在远程主机目录 #local_tmp = $HOME/.ansible/tmp #本机的临时命令执行目录 #forks = 5 #默认并发数 #sudo_user = root #默认sudo 用户 #ask_sudo_pass = True #每次执行ansible命令是否询问ssh密码 #ask_pass = True #remote_port = 22 #host_key_checking = False #检查对应服务器的host_key，建议取消此行注释,实现第一次连 接自动信任目标主机 #log_path=/var/log/ansible.log #日志文件，建议启用 #module_name = command #默认模块，可以修改为shell模块 [privilege_escalation] #普通用户提权配置 #become=True #become_method=sudo #become_user=root #become_ask_pass=False 范例: 通过环境变量ANSIBLE_CONFIG指定ansible配置文件路径\n[root@rocky8 ~]#cd /data/ansible/ [root@rocky8 ansible]#cat ansbile.cfg [defaults] inventory = ./hosts [root@rocky8 ansible]#cat hosts [ubuntu] 10.0.0.100 [centos] 10.0.0.7 10.0.0.8 #定义变量 [root@rocky8 ansible]#export ANSIBLE_CONFIG=./ansbile.cfg [root@rocky8 ansible]#ansible --version ansible [core 2.12.6] config file = /data/ansible/ansbile.cfg configured module search path = [\u0026#39;/root/.ansible/plugins/modules\u0026#39;, \u0026#39;/usr/share/ansible/plugins/modules\u0026#39;] ansible python module location = /usr/lib/python3.9/site-packages/ansible ansible collection location = /root/.ansible/collections:/usr/share/ansible/collections executable location = /usr/bin/ansible python version = 3.9.6 (default, Nov 9 2021, 13:31:27) [GCC 8.5.0 20210514 (Red Hat 8.5.0-3)] jinja version = 3.1.2 libyaml = True [root@rocky8 ansible]#ansible --list-hosts all hosts (3): 10.0.0.100 10.0.0.7 10.0.0.8 范例: 创建ansible 指定项目专用的配置文件\n[root@ubuntu2004 ~]#ansible --version ansible 2.9.6 config file = /etc/ansible/ansible.cfg configured module search path = [\u0026#39;/root/.ansible/plugins/modules\u0026#39;, \u0026#39;/usr/share/ansible/plugins/modules\u0026#39;] ansible python module location = /usr/lib/python3/dist-packages/ansible executable location = /usr/bin/ansible python version = 3.8.10 (default, Mar 15 2022, 12:22:08) [GCC 9.4.0] [root@ubuntu2004 ~]#mkdir /data/ansible -p [root@ubuntu2004 ~]#cd /data/ansible/ [root@ubuntu2004 ansible]#touch ansible.cfg [root@ubuntu2004 ansible]#ansible --version ansible 2.9.6 config file = /data/ansible/ansible.cfg configured module search path = [\u0026#39;/root/.ansible/plugins/modules\u0026#39;, \u0026#39;/usr/share/ansible/plugins/modules\u0026#39;] ansible python module location = /usr/lib/python3/dist-packages/ansible executable location = /usr/bin/ansible python version = 3.8.10 (default, Mar 15 2022, 12:22:08) [GCC 9.4.0] [root@ubuntu2004 ansible]#cd [root@ubuntu2004 ~]#ansible --version ansible 2.9.6 config file = /etc/ansible/ansible.cfg configured module search path = [\u0026#39;/root/.ansible/plugins/modules\u0026#39;, \u0026#39;/usr/share/ansible/plugins/modules\u0026#39;] ansible python module location = /usr/lib/python3/dist-packages/ansible executable location = /usr/bin/ansible python version = 3.8.10 (default, Mar 15 2022, 12:22:08) [GCC 9.4.0] 范例: 当前目录下的ansible的配置文件优先生效\n[root@ansible ~]#ansible --version ansible 2.9.17 config file = /etc/ansible/ansible.cfg configured module search path = [\u0026#39;/root/.ansible/plugins/modules\u0026#39;, \u0026#39;/usr/share/ansible/plugins/modules\u0026#39;] ansible python module location = /usr/lib/python3.6/site-packages/ansible executable location = /usr/bin/ansible python version = 3.6.8 (default, Apr 16 2020, 01:36:27) [GCC 8.3.1 20191121 (Red Hat 8.3.1-5)] [root@ansible ~]#cp /etc/ansible/ansible.cfg . [root@ansible ~]#ansible --version ansible 2.9.17 config file = /root/ansible.cfg #注意配置文件路径 configured module search path = [\u0026#39;/root/.ansible/plugins/modules\u0026#39;, \u0026#39;/usr/share/ansible/plugins/modules\u0026#39;] ansible python module location = /usr/lib/python3.6/site-packages/ansible executable location = /usr/bin/ansible python version = 3.6.8 (default, Apr 16 2020, 01:36:27) [GCC 8.3.1 20191121 (Red Hat 8.3.1-5)] [root@ansible ~]# Inventory 主机清单文件 ansible的主要功用在于批量主机操作，为了便捷地使用其中的部分主机，可以在inventory 主机清单文件中将其分组组织 默认的inventory file为 /etc/ansible/hosts inventory file可以有多个，且也可以通过Dynamic Inventory来动态生成 注意:\n生产建议在每个项目目录下创建项目独立的hosts文件 通过项目目录下的ansible.cfg文件中的 inventory = ./hosts实现 官方文档:\nhttps://docs.ansible.com/ansible/latest/user_guide/intro_inventory.html 主机清单文件格式 inventory文件遵循INI文件风格，中括号中的字符为组名。可以将同一个主机同时归并到多个不同的组中,此外，当如若目标主机使用了非默认的SSH端口，还可以在主机名称之后使用冒号加端口号来标明,如果主机名称遵循相似的命名模式，还可以使用列表的方式标识各主机 Inventory 参数说明\nansible_ssh_host #将要连接的远程主机名.与你想要设定的主机的别名不同的话,可通过此变量设置. ansible_ssh_port #ssh端口号.如果不是默认的端口号,通过此变量设置.这种可以使用 ip:端口 192.168.1.100:2222 ansible_ssh_user #默认的 ssh 用户名 ansible_ssh_pass #ssh 密码(这种方式并不安全,我们强烈建议使用 --ask-pass 或 SSH 密钥) ansible_sudo_pass #sudo 密码(这种方式并不安全,我们强烈建议使用 --ask-sudo-pass) ansible_sudo_exe (new in version 1.8) #sudo 命令路径(适用于1.8及以上版本) ansible_connection #与主机的连接类型.比如:local, ssh 或者 paramiko. Ansible 1.2 以前默认使用 paramiko.1.2 以后默认使用 \u0026#39;smart\u0026#39;,\u0026#39;smart\u0026#39; 方式会根据是否支持 ControlPersist,来判断\u0026#39;ssh\u0026#39; 方式是否可行. ansible_ssh_private_key_file #ssh 使用的私钥文件.适用于有多个密钥,而你不想使用 SSH 代理的情况. ansible_shell_type #目标系统的shell类型.默认情况下,命令的执行使用 \u0026#39;sh\u0026#39; 语法,可设置为\u0026#39;csh\u0026#39; 或 \u0026#39;fish\u0026#39;. ansible_python_interpreter #目标主机的 python 路径.适用于的情况: 系统中有多个 Python,或者命令路径不是\u0026#34;/usr/bin/python\u0026#34;,比如 \\*BSD, 或者 /usr/bin/python 不是 2.X 版本的Python.之所以不使用 \u0026#34;/usr/bin/env\u0026#34; 机制,因为这要求远程用户的路径设置正确,且要求 \u0026#34;python\u0026#34;可执行程序名不可为 python以外的名字(实际有可能名为python26).与ansible_python_interpreter 的工作方式相同,可设定如 ruby 或 perl 的路径.... 范例：\nntp.wang.org [webservers] www1.wang.org:2222 www2.wang.org [dbservers] db1.wang.org db2.wang.org db3.wang.org #或者 db[1:3].wang.org 范例: 组嵌套\n[webservers] www[1:100].example.com [dbservers] db-[a:f].example.com [appservers] 10.0.0.[1:100] #定义testsrvs组中包括两个其它分组,实现组嵌套 [testsrvs:children] webservers dbservers 范例: 基于用户名和密码的ssh连接主机清单\n[test] 10.0.0.8 ansible_connection=local #指定本地连接,无需ssh配置 #每个主机分别指定用户和密码,ansible_connection=ssh 需要StrictHostKeyChecking no 或者host_key_checking = False 10.0.0.7 ansible_connection=ssh ansible_ssh_port=2222 ansible_ssh_user=wangansible_ssh_password=123456 10.0.0.6 ansible_ssh_user=root ansible_ssh_password=123456 #对每个分组的所有主机统一定义用户和密码,执行ansible命令时显示别名,如web01 [websrvs] web01 ansible_ssh_host=10.0.0.101 web02 ansible_ssh_host=10.0.0.102 [websrvs:vars] ansible_ssh_password=magedu some_host ansible_ssh_port=2222 ansible_ssh_user=manager aws_host ansible_ssh_private_key_file=/home/example/.ssh/aws.pem freebsd_host ansible_python_interpreter=/usr/local/bin/python ruby_module_host ansible_ruby_interpreter=/usr/bin/ruby.1.9.3 Ansible相关工具 /usr/bin/ansible 主程序，临时命令执行工具\n/usr/bin/ansible-doc 查看配置文档，模块功能查看工具,相当于man\n/usr/bin/ansible-playbook 定制自动化任务，编排剧本工具,相当于脚本\n/usr/bin/ansible-pull 远程执行命令的工具\n/usr/bin/ansible-vault 文件加密工具\n/usr/bin/ansible-console 基于Console界面与用户交互的执行工具\n/usr/bin/ansible-galaxy 下载/上传优秀代码或Roles模块的官网平台\n利用ansible实现管理的主要方式：\nAnsible Ad-Hoc 即利用ansible命令，主要用于临时命令使用场景\nAnsible playbook 主要用于长期规划好的，大型项目的场景，需要有前期的规划过程\nansible 使用前准备 ansible 相关工具大多数是通过ssh协议，实现对远程主机的配置管理、应用部署、任务执行等功能 建议：使用此工具前，先配置ansible主控端能基于密钥认证的方式联系各个被管理节点 范例：利用sshpass批量实现基于key验证脚本1\n[root@centos8 ~]#vim /etc/ssh/ssh_config #修改下面一行 StrictHostKeyChecking no [root@centos8 ~]#cat hosts.list 192.168.32.178 192.168.32.179 [root@centos8 ~]#vim push_ssh_key.sh #!/bin/bash rpm -ql shpass \u0026amp;\u0026gt; /dev/null || yum -y install sshpass [ -f /root/.ssh/id_rsa ] || ssh-keygen -f /root/.ssh/id_rsa -P \u0026#39;\u0026#39; export SSHPASS=123456 while read IP;do sshpass -e ssh-copy-id -o StrictHostKeyChecking=no $IP done \u0026lt; hosts.list 范例: 实现基于key验证的脚本2\n[root@centos8 ~]#cat ssh_key.sh #!/bin/bash PLIST=\u0026#34; 192.168.32.178 192.168.32.179\u0026#34; rpm -q sshpass \u0026amp;\u0026gt; /dev/null || yum -y install sshpass [ -f /root/.ssh/id_rsa ] || ssh-keygen -f /root/.ssh/id_rsa -P \u0026#39;\u0026#39; export SSHPASS=123456 for IP in $IPLIST;do { sshpass -e ssh-copy-id -o StrictHostKeyChecking=no $IP; } \u0026amp; done wait 此工具用来显示模块帮助,相当于man 格式\nansible-doc [options] [module...] -l, --list #列出可用模块 -s, --snippet #显示指定模块的playbook片段 范例: 查看帮助\n[root@rocky ~]# ansible-doc --help usage: ansible-doc [-h] [--version] [-v] [-M MODULE_PATH] [--playbook-dir BASEDIR] [-t {become,cache,callback,cliconf,connection,httpapi,inventory,lookup,netconf,shell,vars,module,strategy,role,keyword}] [-j] [-r ROLES_PATH] [-e ENTRY_POINT | -s | -F | -l | --metadata-dump] [--no-fail-on-errors] [plugin ...] plugin documentation tool positional arguments: plugin Plugin 范例：\n#列出所有模块 ansible-doc -l #查看指定模块帮助用法 ansible-doc ping #查看指定模块帮助用法 ansible-doc -s ping 范例: 查看指定的插件\n[root@rocky ~]# ansible-doc -t connection -l local execute on controller paramiko_ssh Run tasks via python ssh (paramiko) psrp Run tasks over Microsoft PowerShell Remoting Protocol ssh connect via SSH client binary winrm Run tasks over Microsoft\u0026#39;s WinRM [root@rocky ~]# [root@rocky ~]# ansible-doc -t lookup -l config Lookup current Ansible configuration values csvfile read data from a TSV or CSV file dict returns key/value pair items from dictionaries env Read the value of environment variables file read file contents fileglob list files matching a pattern first_found return first file found from list indexed_items rewrites lists to return \u0026#39;indexed items\u0026#39; ini read data from an ini file inventory_hostnames list of inventory hosts matching a host pattern items list of items lines read lines from command list simply returns what it is given nested composes a list with nested elements of other lists password retrieve or generate a random password, stored in a file pipe read output from a command random_choice return random element from list sequence generate a list based on a number sequence subelements traverse nested key from a list of dictionaries template retrieve contents of file after templating with Jinja2 together merges lists into synchronized list unvault read vaulted file(s) contents url return contents from URL varnames Lookup matching variable names vars Lookup templated value of variables [root@rocky ~]# ansible Ansible Ad-Hoc 介绍 Ansible Ad-Hoc 的执行方式的主要工具就是 ansible 特点: 一次性的执行,不会保存执行命令信息,只适合临时性或测试性的任务\nansible 命令用法 格式：\nansible \u0026lt;host-pattern\u0026gt; [-m module_name] [-a args] 选项说明：\n--version #显示版本 -m module #指定模块，默认为command -v #详细过程 -vv -vvv更详细 --list-hosts #显示主机列表，可简写 --list -C, --check #检查，并不执行 -T, --timeout=TIMEOUT #执行命令的超时时间，默认10s -k, --ask-pass #提示输入ssh连接密码，默认Key验证 -u, --user=REMOTE_USER #执行远程执行的用户,默认root -b, --become #代替旧版的sudo实现通过sudo机制实现提升权限 --become-user=USERNAME #指定sudo的runas用户，默认为root -K, --ask-become-pass #提示输入sudo时的口令 -f FORKS, --forks FORKS #指定并发同时执行ansible任务的主机数 -i INVENTORY, --inventory INVENTORY #指定主机清单文件 范例:\n#以wang用户执行ping存活检测 ansible all -m ping -u wang -k #以wang sudo至root执行ping存活检测 ansible all -m ping -u wang -k -b #以wang sudo至mage用户执行ping存活检测 ansible all -m ping -u wang -k -b --become-user=mage #以wang sudo至root用户执行ls ansible all -m command -u wang -a \u0026#39;ls /root\u0026#39; -b --become-user=root -k -K 范例: 并发执行控制\n#分别执行下面两条命令观察结果 [root@ansible ~]#ansible all -a \u0026#39;sleep 5\u0026#39; -f1 [root@ansible ~]#ansible all -a \u0026#39;sleep 5\u0026#39; -f10 范例: 使用普能用户进行远程管理\n#在所有控制端和被控制端创建用户和密码 [root@rocky8 ~]#useradd wang [root@rocky8 ~]#echo wang:123456 | chpasswd #在所有被控制端对用户sudo授权 [root@rocky8 ~]#visudo wang ALL=(ALL) NOPASSWD: ALL [root@rocky8 ~]#visudo -c /etc/sudoers: parsed OK #实现从控制端到被控制端的基于key验证 [root@ansible ~]#su - wang wang@ansible:~$ssh-keygen -f ~/.ssh/id_rsa -P \u0026#39;\u0026#39; wang@ansible:~$$ssh-copy-id wang@\u0026#39;10.0.0.8\u0026#39; #使用普通用户测试连接,默认连接权限不足失败 wang@ansible:~$ ansible 10.0.0.8 -m shell -a \u0026#39;ls /root\u0026#39; 10.0.0.8 | FAILED | rc=2 \u0026gt;\u0026gt; ls: cannot open directory \u0026#39;/root\u0026#39;: Permission deniednon-zero return code #使用普通用户通过-b选项连接实现sudo提权后连接成功 wang@ansible:~$ ansible 10.0.0.8 -m shell -a \u0026#39;ls /root\u0026#39; -b --become-user root 10.0.0.8 | CHANGED | rc=0 \u0026gt;\u0026gt; anaconda-ks.cfg #修改配置文件指定sudo机制 [root@ansible ~]#vim /etc/ansible/ansible.cfg #取消下面行前面的注释 [privilege_escalation] become=True become_method=sudo become_user=root become_ask_pass=False #再次测试 [root@ansible ~]#su - wang wang@ansible:~$ ansible 10.0.0.8 -m shell -a \u0026#39;ls /root\u0026#39; 10.0.0.8 | CHANGED | rc=0 \u0026gt;\u0026gt; anaconda-ks.cfg 范例: 使用普通用户连接远程主机执行代替另一个用户身份执行操作\n[root@centos8 ~]#useradd wang [root@centos8 ~]#echo wang:123456 | chpasswd #先在被控制端能过sudo对普通用户授权 [root@centos8 ~]#grep wang /etc/sudoers wang ALL=(ALL) NOPASSWD: ALL #以wang的用户连接用户,并利用sudo代表mage执行whoami命令 [root@ansible ~]#ansible 10.0.0.8 -m shell -a \u0026#39;whoami\u0026#39; -u wang -k -b --become- user=mage SSH password: #输入远程主机wang用户ssh连接密码 10.0.0.8 | CHANGED | rc=0 \u0026gt;\u0026gt; mage ansible的Host-pattern 用于匹配被控制的主机的列表 All ：表示所有Inventory中的所有主机 范例\nansible all -m ping *:通配符\nansible \u0026#34;*\u0026#34; -m ping ansible 192.168.1.* -m ping ansible \u0026#34;srvs\u0026#34; -m ping ansible \u0026#34;10.0.0.6 10.0.0.7\u0026#34; -m ping 或关系\nansible \u0026#34;websrvs:appsrvs\u0026#34; -m ping ansible \u0026#34;192.168.1.10:192.168.1.20\u0026#34; -m ping 逻辑与\n#在websrvs组并且在dbsrvs组中的主机 ansible \u0026#34;websrvs:\u0026amp;dbsrvs\u0026#34; -m ping 逻辑非\n#在所有主机,但不在websrvs组和dbsrvs组中的主机 #注意：此处为单引号 ansible \u0026#39;all:!dbsrvs:!websrvs\u0026#39; -m ping 综合逻辑\nansible \u0026#39;websrvs:dbsrvs:\u0026amp;appsrvs:!ftpsrvs\u0026#39; -m ping 正则表达式\nansible \u0026#34;websrvs:dbsrvs\u0026#34; -m ping ansible \u0026#34;~(web|db).*\\.magedu\\.com\u0026#34; -m ping ansible 命令的执行过程 加载自己的配置文件,默认/etc/ansible/ansible.cfg 查找主机清单中对应的主机或主机组 加载自己对应的模块文件，如：command 通过ansible将模块或命令生成对应的临时py文件，并将该文件传输至远程服务器的对应执行用户 $HOME/.ansible/tmp/ansible-tmp-数字/XXX.PY文件 给文件+x执行 执行并返回结果 删除临时py文件，退出 ansible 命令的执行状态 [root@centos8 ~]#grep -A 14 \u0026#39;\\[colors\\]\u0026#39; /etc/ansible/ansible.cfg [colors] #highlight = white #verbose = blue #warn = bright purple #error = red #debug = dark gray #deprecate = purple #skip = cyan #unreachable = red #ok = green #changed = yellow #diff_add = green #diff_remove = red #diff_lines = cyan 绿色：执行成功并且对目标主机不需要做改变的操作 黄色：执行成功并且对目标主机做变更 红色：执行失败 ansible-console 此工具可交互执行命令，支持tab，ansible 2.0+新增 提示符格式：\n执行用户@当前操作的主机组 (当前组的主机数量)[f:并发数]$ 常用子命令：\n设置并发数： forks n 例如： forks 10 切换组： cd 主机组 例如： cd web 列出当前组主机列表： list 列出所有的内置命令： ?或help 范例\n[root@ansible ~]#ansible-console Welcome to the ansible console. Type help or ? to list commands. root@all (3)[f:5]$ ping 10.0.0.7 | SUCCESS =\u0026gt; { \u0026#34;ansible_facts\u0026#34;: { \u0026#34;discovered_interpreter_python\u0026#34;: \u0026#34;/usr/bin/python\u0026#34; }, \u0026#34;changed\u0026#34;: false, \u0026#34;ping\u0026#34;: \u0026#34;pong\u0026#34; } 10.0.0.6 | SUCCESS =\u0026gt; { \u0026#34;ansible_facts\u0026#34;: { \u0026#34;discovered_interpreter_python\u0026#34;: \u0026#34;/usr/bin/python\u0026#34; }, \u0026#34;changed\u0026#34;: false, \u0026#34;ping\u0026#34;: \u0026#34;pong\u0026#34; } 10.0.0.8 | SUCCESS =\u0026gt; { \u0026#34;ansible_facts\u0026#34;: { \u0026#34;discovered_interpreter_python\u0026#34;: \u0026#34;/usr/libexec/platform-python\u0026#34; }, \u0026#34;changed\u0026#34;: false, \u0026#34;ping\u0026#34;: \u0026#34;pong\u0026#34; } root@all (3)[f:5]$ list 10.0.0.8 10.0.0.7 10.0.0.6 root@all (3)[f:5]$ cd websrvs root@websrvs (2)[f:5]$ list 10.0.0.7 10.0.0.8 root@websrvs (2)[f:5]$ forks 10 root@websrvs (2)[f:10]$ cd appsrvs root@appsrvs (2)[f:5]$ yum name=httpd state=present root@appsrvs (2)[f:5]$ service name=httpd state=started ansible-playbook 此工具用于执行编写好的 playbook 任务 范例：\nansible-playbook hello.yml cat hello.yml --- #hello world yml file - hosts: websrvs remote_user: root gather_facts: no tasks: - name: hello world command: /usr/bin/wall hello world ansible-vault 此工具可以用于加密解密yml文件 格式：\nansible-vault [create|decrypt|edit|encrypt|rekey|view] 范例\nansible-vault encrypt hello.yml #加密 ansible-vault decrypt hello.yml #解密 ansible-vault view hello.yml #查看 ansible-vault edit hello.yml #编辑加密文件 ansible-vault rekey hello.yml #修改口令 ansible-vault create new.yml #创建新文件 #执行加密的playbook,交互式输入密码 chmod 600 hello.yml ansible-playbook --ask-vault-pass hello.yml #从pass.txt文件中读取密码 ansible-playbook --vault-password-file pass.txt hello.yml #从配置文件中取得密码 #vi /etc/ansible/ansible.cfg [defaults] ault-password-file=pass.txt #可以直接执行加密文件 ansible-playbook hello.yml ansible-galaxy Galaxy 是一个免费网站, 类似于github网站, 网站上发布了很多的共享的roles角色。 Ansible 提供了ansible-galaxy命令行工具连接 url 网站下载相应的roles, 进行init(初始化、search( 查拘、install(安装、 remove(移除)等操作。\n范例：\n#搜索项目 [root@ansible ~]#ansible-galaxy search lamp #列出所有已安装的galaxy ansible-galaxy list #安装galaxy,默认下载到~/.ansible/roles下 ansible-galaxy install geerlingguy.mysql ansible-galaxy install geerlingguy.redis #删除galaxy ansible-galaxy remove geerlingguy.redis Ansible常用模块 2015年12月只270多个模块 2016年12年26日ansible 1.9.2 有540个模块 2018年01月12日ansible 2.3.8 有1378个模块 2018年05月28日ansible 2.5.3 有1562个模块 2018年07月15日ansible 2.6.3 有1852个模块 2018年11月19日ansible 2.7.2 有2080个模块 2020年03月02日ansible 2.9.5 有3387个模块 2021年12月22日ansible 2.11.8 有6141个模块 2022年06月04日ansible 2.12.6 有6763个模块 虽然模块众多，但最常用的模块也就2，30个而已，针对特定业务只需要熟悉10几个模块即可 常用模块帮助文档参考：\nhttps://docs.ansible.com/ansible/2.9/modules/modules_by_category.html https://docs.ansible.com/ansible/2.9/modules/list_of_all_modules.html https://docs.ansible.com/ansible/latest/modules/list_of_all_modules.html https://docs.ansible.com/ansible/latest/modules/modules_by_category.html Command 模块 功能：在远程主机执行命令，此为默认模块，可忽略 -m 选项 注意：此命令不支持 $VARNAME \u0026lt; \u0026gt; | ; \u0026amp; 等，可用shell模块实现 注意：此模块不具有幂等性 常见选项\nchdir=dir #执行命令前,先切换至目录dir creates=file #当file不存在时才会执行 removes=file #当file存在时才会执行 范例：\n[root@ansible ~]#ansible websrvs -m command -a \u0026#39;chdir=/etc cat centos-release\u0026#39; 10.0.0.7 | CHANGED | rc=0 \u0026gt;\u0026gt; CentOS Linux release 7.7.1908 (Core) 10.0.0.8 | CHANGED | rc=0 \u0026gt;\u0026gt; CentOS Linux release 8.1.1911 (Core) [root@ansible ~]#ansible websrvs -m command -a \u0026#39;chdir=/etc creates=/data/f1.txt cat centos-release\u0026#39; 10.0.0.7 | CHANGED | rc=0 \u0026gt;\u0026gt; CentOS Linux release 7.7.1908 (Core) 10.0.0.8 | SUCCESS | rc=0 \u0026gt;\u0026gt; skipped, since /data/f1.txt exists [root@ansible ~]#ansible websrvs -m command -a \u0026#39;chdir=/etc removes=/data/f1.txt cat centos-release\u0026#39; 10.0.0.7 | SUCCESS | rc=0 \u0026gt;\u0026gt; skipped, since /data/f1.txt does not exist 10.0.0.8 | CHANGED | rc=0 \u0026gt;\u0026gt; CentOS Linux release 8.1.1911 (Core) ansible websrvs -m command -a \u0026#39;service vsftpd start\u0026#39; ansible websrvs -m command -a \u0026#39;echo magedu |passwd --stdin wang\u0026#39; ansible websrvs -m command -a \u0026#39;rm -rf /data/\u0026#39; ansible websrvs -m command -a \u0026#39;echo hello \u0026gt; /data/hello.log\u0026#39; ansible websrvs -m command -a \u0026#34;echo $HOSTNAME\u0026#34; Shell 模块 功能：和command相似，用shell执行命令,支持各种符号,比如:*,$, \u0026gt; , 相当于增强版的command模块 注意：此模块不具有幂等性,建议能不能就用此模块,最好使用专用模块 常见选项\nchdir=dir #执行命令前,先切换至目录dir creates=file #当file不存在时才会执行 removes=file #当file存在时才会执行 范例：\n[root@ansible ~]#ansible websrvs -m shell -a \u0026#34;echo $HOSTNAME\u0026#34; 10.0.0.7 | CHANGED | rc=0 \u0026gt;\u0026gt; ansible 10.0.0.8 | CHANGED | rc=0 \u0026gt;\u0026gt; ansible [root@ansible ~]#ansible websrvs -m shell -a \u0026#39;echo $HOSTNAME\u0026#39; 10.0.0.7 | CHANGED | rc=0 \u0026gt;\u0026gt; centos7.wangxiaochun.com 10.0.0.8 | CHANGED | rc=0 \u0026gt;\u0026gt; centos8.localdomain [root@ansible ~]#ansible websrvs -m shell -a \u0026#39;echo centos | passwd --stdin wang\u0026#39; 10.0.0.7 | CHANGED | rc=0 \u0026gt;\u0026gt; Changing password for user wang. passwd: all authentication tokens updated successfully. 10.0.0.8 | CHANGED | rc=0 \u0026gt;\u0026gt; Changing password for user wang. passwd: all authentication tokens updated successfully. [root@ansible ~]#ansible websrvs -m shell -a \u0026#39;ls -l /etc/shadow\u0026#39; 10.0.0.7 | CHANGED | rc=0 \u0026gt;\u0026gt; ---------- 1 root root 889 Mar 2 14:34 /etc/shadow 10.0.0.8 | CHANGED | rc=0 \u0026gt;\u0026gt; ---------- 1 root root 944 Mar 2 14:34 /etc/shadow [root@ansible ~]#ansible websrvs -m shell -a \u0026#39;echo hello \u0026gt; /data/hello.log\u0026#39; 10.0.0.7 | CHANGED | rc=0 \u0026gt;\u0026gt; 10.0.0.8 | CHANGED | rc=0 \u0026gt;\u0026gt; [root@ansible ~]#ansible websrvs -m shell -a \u0026#39;cat /data/hello.log\u0026#39; 10.0.0.7 | CHANGED | rc=0 \u0026gt;\u0026gt; hello 10.0.0.8 | CHANGED | rc=0 \u0026gt;\u0026gt; hello 注意：调用bash执行命令 类似 cat /tmp/test.md | awk -F\u0026rsquo;|\u0026rsquo; \u0026lsquo;{print $1,$2}\u0026rsquo; \u0026amp;\u0026gt; /tmp/example.txt 这些复杂命令，即使使用shell也可能会失败，解决办法：写到脚本时，copy到远程，执行，再把需要的结果拉回执行命令的机器 范例：将shell模块代替command，设为模块\n[root@ansible ~]#vim /etc/ansible/ansible.cfg #修改下面一行 module_name = shell Script 模块 功能：在远程主机上运行ansible服务器上的脚本(无需执行权限) 注意：此模块不具有幂等性 常见选项\nchdir=dir #执行命令前,先切换至目录dir cmd #指定ansible主机的命令 creates=file #当file不存在时才会执行 removes=file #当file存在时才会执行 范例：\nansible websrvs -m script -a /data/test.sh Copy 模块 功能：复制ansible服务器主控端或远程的本机的文件到远程主机 注意: src=file 如果是没指明路径,则为当前目录或当前目录下的files目录下的file文件 常见选项\nsrc #控制端的源文件路径 dest #被控端的文件路径 owner #属主 group #属组 mode #权限 backup #是否备份 validate #验证成功才会执行copy remote_src #no是默认值,表示src文件在ansible主机,yes表示src文件在远程主机 范例:\n#如目标存在，默认覆盖，此处指定先备 ansible websrvs -m copy -a \u0026#34;src=/root/test1.sh dest=/tmp/test2.sh owner=wang mode=600 backup=yes\u0026#34; #指定内容，直接生成目标文件 ansible websrvs -m copy -a \u0026#34;content=\u0026#39;wang 123456\\nxiao 654321\\n\u0026#39; dest=/etc/rsync.pas owner=root group=root mode=0600\u0026#34; #复制/etc目录自身,注意/etc/后面没有/ ansible websrvs -m copy -a \u0026#34;src=/etc dest=/backup\u0026#34; #复制/etc/下的文件，不包括/etc/目录自身,注意/etc/后面有/ ansible websrvs -m copy -a \u0026#34;src=/etc/ dest=/backup\u0026#34; #复制/etc/suders,并校验语法 ansible websrvs -m copy -a \u0026#34;src=/etc/suders dest=/etc/sudoers.edit remote_src=yes validate=/usr/sbin/visudo -csf %s\u0026#34; Get_url 模块 功能: 用于将文件从http、https或ftp下载到被管理机节点上 常用参数如下：\nurl #下载文件的URL,支持HTTP，HTTPS或FTP协议 dest #下载到目标路径（绝对路径），如果目标是一个目录，就用原文件名，如果目标设置了名称就用目标 设置的名称 owner #指定属主 group #指定属组 mode #指定权限 force #如果yes，dest不是目录，将每次下载文件，如果内容改变替换文件。如果no，则只有在目标不存 在时才会下载 checksum #对目标文件在下载后计算摘要，以确保其完整性 #示例: checksum=\u0026#34;sha256:D98291AC[...]B6DC7B97\u0026#34;, checksum=\u0026#34;sha256:http://example.com/path/sha256sum.txt\u0026#34; url_username #用于HTTP基本认证的用户名。 对于允许空密码的站点，此参数可以不使用`url_password\u0026#39; url_password #用于HTTP基本认证的密码。 如果未指定`url_username\u0026#39;参数，则不会使用`url_password\u0026#39;参数 validate_certs #如果“no”，SSL证书将不会被验证。 适用于自签名证书在私有网站上使用 timeout #URL请求的超时时间,秒为单位 范例: 下载并MD5验证\n[root@ansible ~]#ansible websrvs -m get_url -a \u0026#39;url=http://nginx.org/download/nginx-1.18.0.tar.gz dest=/usr/local/src/nginx.tar.gz checksum=\u0026#34;md5:b2d33d24d89b8b1f87ff5d251aa27eb8\u0026#34;\u0026#39; Fetch 模块 功能：从远程主机提取文件至ansible的主控端，copy相反，目前不支持目录 常见选项\nsrc #被控制端的源文件路径,只支持文件 dest #ansible控制端的目录路径 范例：\nansible websrvs -m fetch -a \u0026#39;src=/root/test.sh dest=/data/scripts\u0026#39; 范例：\n[root@ansible ~]#ansible all -m fetch -a \u0026#39;src=/etc/redhat-release dest=/data/os\u0026#39; [root@ansible ~]#tree /data/os/ /data/os/ ├── 10.0.0.6 │ └── etc │ └── redhat-release ├── 10.0.0.7 │ └── etc │ └── redhat-release └── 10.0.0.8 └── etc └── redhat-release 6 directories, 3 files File 模块 功能：设置文件属性,创建文件,目录和软链接等 常见选项\npath #在被控端创建的路径 owner #属主 group #属组 mode #权限 state #状态 =touch #创建文件 =directory #创建目录 =link #软链接 =hard #硬链接 recurse #yes表示递归授权 范例：\n#创建空文件 ansible all -m file -a \u0026#39;path=/data/test.txt state=touch\u0026#39; ansible all -m file -a \u0026#39;path=/data/test.txt state=absent\u0026#39; ansible all -m file -a \u0026#34;path=/root/test.sh owner=wang mode=755\u0026#34; #创建目录 ansible all -m file -a \u0026#34;path=/data/mysql state=directory owner=mysql group=mysql\u0026#34; #创建软链接 ansible all -m file -a \u0026#39;src=/data/testfile path|dest|name=/data/testfile-link state=link\u0026#39; #创建目录 ansible all -m file -a \u0026#39;path=/data/testdir state=directory\u0026#39; #递归修改目录属性,但不递归至子目录 ansible all -m file -a \u0026#34;path=/data/mysql state=directory owner=mysql group=mysql\u0026#34; #递归修改目录及子目录的属性 ansible all -m file -a \u0026#34;path=/data/mysql state=directory owner=mysql group=mysql recurse=yes\u0026#34; stat 模块 功能：检查文件或文件系统的状态 注意：对于Windows目标，请改用win_stat模块\n常见选项\npath #文件/对象的完整路径（必须） 常用的返回值判断：\nexists： 判断是否存在 isuid： 调用用户的ID与所有者ID是否匹配 范例:\n[root@ansible ~]#ansible 127.0.0.1 -m stat -a \u0026#39;path=/etc/passwd\u0026#39; 127.0.0.1 | SUCCESS =\u0026gt; { \u0026#34;changed\u0026#34;: false, \u0026#34;stat\u0026#34;: { \u0026#34;atime\u0026#34;: 1614601466.7493012, \u0026#34;attr_flags\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;attributes\u0026#34;: [], \u0026#34;block_size\u0026#34;: 4096, \u0026#34;blocks\u0026#34;: 8, \u0026#34;charset\u0026#34;: \u0026#34;us-ascii\u0026#34;, \u0026#34;checksum\u0026#34;: \u0026#34;8f7a9a996d24de98bf1eab4a047f8e89e9c708cf\u0026#34;, \u0026#34;ctime\u0026#34;: 1614334259.4498665, \u0026#34;dev\u0026#34;: 2050, \u0026#34;device_type\u0026#34;: 0, \u0026#34;executable\u0026#34;: false, \u0026#34;exists\u0026#34;: true, \u0026#34;gid\u0026#34;: 0, \u0026#34;gr_name\u0026#34;: \u0026#34;root\u0026#34;, \u0026#34;inode\u0026#34;: 134691833, \u0026#34;isblk\u0026#34;: false, \u0026#34;ischr\u0026#34;: false, \u0026#34;isdir\u0026#34;: false, \u0026#34;isfifo\u0026#34;: false, \u0026#34;isgid\u0026#34;: false, \u0026#34;islnk\u0026#34;: false, \u0026#34;isreg\u0026#34;: true, \u0026#34;issock\u0026#34;: false, \u0026#34;isuid\u0026#34;: false, \u0026#34;mimetype\u0026#34;: \u0026#34;text/plain\u0026#34;, \u0026#34;mode\u0026#34;: \u0026#34;0000\u0026#34;, \u0026#34;mtime\u0026#34;: 1614334259.4498665, \u0026#34;nlink\u0026#34;: 1, \u0026#34;path\u0026#34;: \u0026#34;/etc/passwd\u0026#34;, \u0026#34;pw_name\u0026#34;: \u0026#34;root\u0026#34;, \u0026#34;readable\u0026#34;: true, \u0026#34;rgrp\u0026#34;: false, \u0026#34;roth\u0026#34;: false, \u0026#34;rusr\u0026#34;: false, \u0026#34;size\u0026#34;: 1030, \u0026#34;uid\u0026#34;: 0, \u0026#34;version\u0026#34;: \u0026#34;671641160\u0026#34;, \u0026#34;wgrp\u0026#34;: false, \u0026#34;woth\u0026#34;: false, \u0026#34;writeable\u0026#34;: true, \u0026#34;wusr\u0026#34;: false, \u0026#34;xgrp\u0026#34;: false, \u0026#34;xoth\u0026#34;: false, \u0026#34;xusr\u0026#34;: false } } 案例：\n- name: install | Check if file is already configured. stat: path={{ nginx_file_path }} connection: local register: nginx_file_result - name: install | Download nginx file get_url: url={{ nginx_file_url }} dest={{ software_files_path }} validate_certs=no connection: local when:，not. nginx_file_result.stat.exists 范例:\n[root@ansible ansible]#cat stat.yml --- - hosts: websrvs tasks: - name: check file stat: path=/data/mysql register: st - name: debug debug: msg: \u0026#34;/data/mysql is not exist\u0026#34; when: not st.stat.exists [root@ansible ansible]#ansible-playbook stat.yml PLAY [websrvs] ******************************************************************************** *************************************** TASK [Gathering Facts] ******************************************************************************** ******************************* ok: [10.0.0.7] ok: [10.0.0.8] TASK [check file] ******************************************************************************** ************************************ ok: [10.0.0.7] ok: [10.0.0.8] TASK [debug] ******************************************************************************** ***************************************** ok: [10.0.0.7] =\u0026gt; { \u0026#34;msg\u0026#34;: \u0026#34;/data/mysql is not exist\u0026#34; } ok: [10.0.0.8] =\u0026gt; { \u0026#34;msg\u0026#34;: \u0026#34;/data/mysql is not exist\u0026#34; } PLAY RECAP ******************************************************************************** ******************************************* 10.0.0.7 : ok=3 changed=0 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 10.0.0.8 : ok=3 changed=0 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 unarchive 模块 功能：解包解压缩 实现有两种用法：\n将ansible主机上的压缩包传到远程主机后解压缩至特定目录，设置remote_src=no,此为默认值,可省略 将远程本主机上或非ansible的其它主机的某个压缩包解压缩到远程主机本机的指定路径下，需要设置remote_src=yes 常见参数：\nremote_src #和copy功能一样且选项互斥，yes表示源文件在远程被控主机或其它非ansible的其它主机上，no表示文件在ansible主机上,默认值为no, 此选项代替copy选项 copy #默认为yes，当copy=yes，拷贝的文件是从ansible主机复制到远程主机上，如果设置为copy=no，会在远程主机上寻找src源文件,此选项已废弃 src #源路径，可以是ansible主机上的路径，也可以是远程主机(被管理端或者第三方主机)上的路径，如果是远程主机上的路径，则需要设置remote_src=yes dest #远程主机上的目标路径 mode #设置解压缩后的文件权限 creates=/path/file #当绝对路径/path/file不存在时才会执行 范例：\nansible all -m unarchive -a \u0026#39;src=/data/foo.tgz dest=/var/lib/foo owner=wang group=bin\u0026#39; ansible all -m unarchive -a \u0026#39;src=/tmp/foo.zip dest=/data mode=0777\u0026#39; ansible all -m unarchive -a \u0026#39;src=https://example.com/example.zip dest=/data \u0026#39; ansible websrvs -m unarchive -a \u0026#39;src=https://releases.ansible.com/ansible/ansible-2.1.6.0-0.1.rc1.tar.gz dest=/data/ owner=root remote_src=yes\u0026#39; ansible websrvs -m unarchive -a \u0026#39;src=http://nginx.org/download/nginx- 1.18.0.tar.gz dest=/usr/local/src/ remote_src=yes\u0026#39;\u0026#39; Archive 模块 功能：打包压缩保存在被管理节点\n常见选项\npath #压缩的文件或目录 dest #压缩后的文件 format #压缩格式,支持gz,bz2,xz,tar,zip 范例：\nansible websrvs -m archive -a \u0026#39;path=/var/log/ dest=/data/log.tar.bz2 format=bz2 owner=wang mode=0600\u0026#39; Hostname 模块 功能：管理主机名 常见选项\nname #修改后的主机名称 范例：\nansible node1 -m hostname -a \u0026#34;name=websrv\u0026#34; ansible 10.0.0.18 -m hostname -a \u0026#39;name=node18.wang.org\u0026#39; Cron 模块 功能：计划任务 支持时间：minute，hour，day，month，weekday 常见选项\nname #描述脚本的作用 minute #分钟 hour #小时 weekday #周 user #任务由哪个用户运行；默认root job #任务 范例：\n#备份数据库脚本 [root@centos8 ~]#cat /root/mysql_backup.sh #!/bin/bash mysqldump -A -F --single-transaction --master-data=2 -q -uroot |gzip \u0026gt; /data/mysql_`date +%F_%T`.sql.gz #创建任务 ansible 10.0.0.8 -m cron -a \u0026#39;hour=2 minute=30 weekday=1-5 name=\u0026#34;backup mysql\u0026#34; job=/root/mysql_backup.sh\u0026#39; ansible websrvs -m cron -a \u0026#34;minute=*/5 job=\u0026#39;/usr/sbin/ntpdate ntp.aliyun.com \u0026amp;\u0026gt;/dev/null\u0026#39; name=Synctime\u0026#34; #禁用计划任务 ansible websrvs -m cron -a \u0026#34;minute=*/5 job=\u0026#39;/usr/sbin/ntpdate 172.20.0.1 \u0026amp;\u0026gt;/dev/null\u0026#39; name=Synctime disabled=yes\u0026#34; #启用计划任务 ansible websrvs -m cron -a \u0026#34;minute=*/5 job=\u0026#39;/usr/sbin/ntpdate 172.20.0.1 \u0026amp;\u0026gt; /dev/null\u0026#39; name=Synctime disabled=no\u0026#34; #删除任务 ansible websrvs -m cron -a \u0026#34;name=\u0026#39;backup mysql\u0026#39; state=absent\u0026#34; ansible websrvs -m cron -a \u0026#39;state=absent name=Synctime\u0026#39; Yum 和 Apt 模块 功能：管理软件包 yum 管理软件包，只支持RHEL，CentOS，fedora，不支持Ubuntu其它版本 apt 模块管理 Debian 相关版本的软件包 yum常见选项\nname #软件包名称 state #状态 =present #安装,此为默认值 =absent #删除 =latest #最新版 list #列出指定包 enablerepo #启用哪个仓库安装 disablerepo #不使用哪些仓库的包 exclude #排除指定的包 validate #是否检验,默认为yes 范例：\n[root@ansible ~]#ansible websrvs -m yum -a \u0026#39;name=httpd state=present\u0026#39; #安装zabbix agent rpm包 [root@ansible ~]#ansible websrvs -m yum -a \u0026#39;name=https://mirrors.tuna.tsinghua.edu.cn/zabbix/zabbix/5.0/rhel/8/x86_64/zabbix-agent2-5.0.24-1.el8.x86_64.rpm state=present validate_certs=no\u0026#39; #启用epel源进行安装 [root@ansible ~]#ansible websrvs -m yum -a \u0026#39;name=nginx state=present enablerepo=epel\u0026#39; #升级除kernel和foo开头以外的所有包 [root@ansible ~]#ansible websrvs -m yum -a \u0026#39;name=* state=lastest exclude=kernel*,foo*\u0026#39; #删除 [root@ansible ~]#ansible websrvs -m yum -a \u0026#39;name=httpd state=absent\u0026#39; [root@ansible ~]#ansible websrvs -m yum -a \u0026#39;name=sl,cowsay\u0026#39; yum_repository 模块 功能: 此模块实现yum的仓库配置管理 常见选项\nname #仓库id description #仓库描述名称,对应配置文件中的name= baseurl #仓库的地址 gpgcheck #验证开启 gpgkey #仓库公钥路径 state=absen #删除 范例：\nansible websrvs -m yum_repository -a \u0026#39;name=ansible_nginx description=\u0026#34;nginx repo\u0026#34; baseurl=\u0026#34;http://nginx.org/packages/centos/$releasever/$basearch/\u0026#34; gpgcheck=yes gpgkey=\u0026#34;https://nginx.org/keys/nginx_signing.key\u0026#34;\u0026#39; [root@rocky8 ~]#cat /etc/yum.repos.d/ansible_nginx.repo [ansible_nginx] baseurl = http://nginx.org/packages/centos/$releasever/$basearch/ gpgcheck = 1 gpgkey = https://nginx.org/keys/nginx_signing.key name = nginx repo Service 模块 此模块和sytemd功能相似,选项很多相同 功能：管理服务 常见选项\nname #服务名称 state #服务状态 =started #启动 =stopped #停止 =restarted #重启 =reloaded #重载 enabled #开启自启动 daemon_reload #加载新的配置文件,适用于systemd模块 范例：\nansible all -m service -a \u0026#39;name=httpd state=started enabled=yes\u0026#39; ansible all -m service -a \u0026#39;name=httpd state=stopped\u0026#39; ansible all -m service -a \u0026#39;name=httpd state=reloaded\u0026#39; ansible all -m shell -a \u0026#34;sed -i \u0026#39;s/^Listen 80/Listen 8080/\u0026#39; /etc/httpd/conf/httpd.conf\u0026#34; ansible all -m service -a \u0026#39;name=httpd state=restarted\u0026#39; #重启动指定网卡服务 ansible all -m service -a \u0026#39;name=network state=absent args=eth0\u0026#39; User 模块 功能：管理用户 常见选项\nname #创建的名称 uid #指定uid group #指定基本组 shell #登录shell类型默认/bin/bash create_home #是否创建家目录 password #设定对应的密码，必须是加密后的字符串才行，否则不生效 system #yes表示系统用户 groups #附加组 append #追加附加组使用,yes表示增加新的附加组 state #absen删除 remove #yes表示删除用户时将家目录一起删除 generate_ssh_key #创建私钥 ssh_keyu_bits #私钥位数 ssh_key_file #私钥文件路径 范例：\n#创建用户 ansible all -m user -a \u0026#39;name=user1 comment=\u0026#34;test user\u0026#34; uid=2048 home=/app/user1group=root\u0026#39; ansible all -m user -a \u0026#39;name=nginx comment=nginx uid=88 group=nginxgroups=\u0026#34;root,daemon\u0026#34; shell=/sbin/nologin system=yes create_home=nohome=/data/nginx non_unique=yes\u0026#39; #remove=yes表示删除用户及家目录等数据,默认remove=no ansible all -m user -a \u0026#39;name=nginx state=absent remove=yes\u0026#39; #生成123456加密的密码 ansible localhost -m debug -a \u0026#34;msg={{ \u0026#39;123456\u0026#39;| password_hash(\u0026#39;sha512\u0026#39;,\u0026#39;salt\u0026#39;)}}\u0026#34; localhost | SUCCESS =\u0026gt; { \u0026#34;msg\u0026#34;: \u0026#34;$6$salt$MktMKPZJ6t59GfxcJU20DwcwQzfMvOlHFVZiOVD71w.\u0026#34; } #用上面创建的密码创建用户 ansible websrvs -m user -a \u0026#39;name=www group=www system=yes shell=/sbin/nlogin password=\u0026#34;$6$salt$MktMKPZJ6t59GfxcJU20DwcwQzfMvOlHFVZiOVD71w.\u0026#34;\u0026#39; #创建用户test,并生成4096bit的私钥 ansible websrvs -m user -a \u0026#39;name=test generate_ssh_key=yes ssh_key_bits=4096 ssh_key_file=.ssh/id_rsa\u0026#39; Group 模块 功能：管理组 常见选项\nname #指定组名称 gid #指定gid state =present #创建,默认 =absent #删除 范例：\n#创建组 ansible websrvs -m group -a \u0026#39;name=nginx gid=88 system=yes\u0026#39; #删除组 ansible websrvs -m group -a \u0026#39;name=nginx state=absent\u0026#39; Lineinfile 模块 ansible在使用sed进行替换时，经常会遇到需要转义的问题，而且ansible在遇到特殊符号进行替换时， 会存在问题，无法正常进行替换 。\nansible自身提供了两个模块：lineinfile模块和replace模块，可以方便的进行替换一般在ansible当中去修改某个文件的单行进行替换的时候需要使用lineinfile模块 功能：相当于sed，主要用于修改一行的文件内容 常见选项\npath #被控端文件的路径 regexp #正则匹配语法格式,表示被替换的内容 line #替换为的内容 state #absent表示删除 insertafter #插入到替换内容前面,如和regexp同时存在,只在没找到与regexp匹配时才使用 insertafter insertbefore #插入到替换内容后面,如和regexp同时存在,只在没找到与regexp匹配时才使用 insertafter backrefs #支持后面引用,yes和no backup #修改前先备份 create #如果文件不存在,则创建,默认不存在会出错 mode #指定权限 owner #指定用户 group #指定组 #注意 regexp参数 ：使用正则表达式匹配对应的行，当替换文本时，如果有多行文本都能被匹配，则只有最后面被 匹配到的那行文本才会被替换，当删除文本时，如果有多行文本都能被匹配，这么这些行都会被删除。 注意: 如果想进行多行匹配进行替换需要使用replace模块 范例：\n#修改监听端口 ansible websrvs -m lineinfile -a \u0026#34;path=/etc/httpd/conf/httpd.conf regexp=\u0026#39;^Listen\u0026#39; line=\u0026#39;Listen 8080\u0026#39;\u0026#34; #修改SELinux ansible all -m lineinfile -a \u0026#34;path=/etc/selinux/config regexp=\u0026#39;^SELINUX=\u0026#39;line=\u0026#39;SELINUX=disabled\u0026#39;\u0026#34; #添加网关 ansible webservers -m lineinfile -a \u0026#39;path=/etc/sysconfig/network-scripts/ifcfg-eth0 line=\u0026#34;GATEWAY=10.0.0.254\u0026#34;\u0026#39; #给主机增加一个网关，但需要增加到NAME=下面 ansible webservers -m lineinfile -a \u0026#39;path=/etc/sysconfig/network-scripts/ifcfg-eth0 insertafter=\u0026#34;^NAME=\u0026#34; line=\u0026#34;GATEWAY=10.0.0.254\u0026#34;\u0026#39; #效果如下 cat /etc/sysconfig/network-scripts/ifcfg-eth0 DEVICE=eth0 NAME=eth0 GATEWAY=10.0.0.254 #给主机增加一个网关，但需要增加到NAME=上面 ansible webservers -m lineinfile -a \u0026#39;path=/etc/sysconfig/network-scripts/ifcfg- eth0 insertbefore=\u0026#34;^NAME=\u0026#34; line=\u0026#34;GATEWAY=10.0.0.254\u0026#34;\u0026#39; #效果如下 cat /etc/sysconfig/network-scripts/ifcfg-eth0 DEVICE=eth0 GATEWAY=10.0.0.254 NAME=eth0 #删除网关 ansible webservers -m lineinfile -a \u0026#39;path=/etc/sysconfig/network-scripts/ifcfg-eth0 regexp=\u0026#34;^GATEWAY\u0026#34; state=absent\u0026#39; #删除#开头的行 ansible all -m lineinfile -a \u0026#39;dest=/etc/fstab state=absent regexp=\u0026#34;^#\u0026#34;\u0026#39; Replace 模块 该模块有点类似于sed命令，主要也是基于正则进行匹配和替换，建议使用 功能: 多行修改替换 常见选项\npath #被控端文件的路径 regexp #正则匹配语法格式,表示被替换的内容 replace #替换为的内容 after #插入到替换内容前面, before #插入到替换内容后面 backup #修改前先备份 mode #指定权限 owner #指定用户 group #指定组 范例\nansible all -m replace -a \u0026#34;path=/etc/fstab regexp=\u0026#39;^(UUID.*)\u0026#39; replace=\u0026#39;#\\1\u0026#39;\u0026#34; ansible all -m replace -a \u0026#34;path=/etc/fstab regexp=\u0026#39;^#(UUID.*)\u0026#39; replace=\u0026#39;\\1\u0026#39;\u0026#34; SELinux 模块 功能: 该模块管理 SELInux 策略 常见选项\npolicy #指定SELINUXTYPE=targeted state #指定SELINUX=disabled 范例\n[root@rocky ansible-apps]# ansible 192.168.32.132 -m selinux -a \u0026#39;state=disabled\u0026#39; 192.168.32.132 | FAILED! =\u0026gt; { \u0026#34;msg\u0026#34;: \u0026#34;The module selinux was redirected to ansible.posix.selinux, which could not be loaded.\u0026#34; } # ansible版本2.13.3出现如下错误 \u0026#34;msg\u0026#34;: \u0026#34;The module selinux was redirected to ansible.posix.selinux, which could not be loaded.\u0026#34; # 解决方法 [root@rocky ansible-apps]# ansible-galaxy collection install ansible.posix # 再次执行，显示成功 [root@rocky ansible-apps]# ansible 192.168.32.132 -m selinux -a \u0026#39;state=disabled\u0026#39; [WARNING]: SELinux state temporarily changed from \u0026#39;enforcing\u0026#39; to \u0026#39;permissive\u0026#39;. State change will take effect next reboot. 192.168.32.132 | CHANGED =\u0026gt; { \u0026#34;ansible_facts\u0026#34;: { \u0026#34;discovered_interpreter_python\u0026#34;: \u0026#34;/usr/libexec/platform-python\u0026#34; }, \u0026#34;changed\u0026#34;: true, \u0026#34;configfile\u0026#34;: \u0026#34;/etc/selinux/config\u0026#34;, \u0026#34;msg\u0026#34;: \u0026#34;Config SELinux state changed from \u0026#39;enforcing\u0026#39; to \u0026#39;disabled\u0026#39;\u0026#34;, \u0026#34;policy\u0026#34;: \u0026#34;targeted\u0026#34;, \u0026#34;reboot_required\u0026#34;: true, \u0026#34;state\u0026#34;: \u0026#34;disabled\u0026#34; } reboot 模块 功能: 重启 常见选项\nmsg #重启提示 pre_reboot_delay #重启前延迟时间的秒数 post_reboot_delay #重启后延迟时间的秒数后,再验证系统正常启动 reboot_timeout #重启后延迟时间再执行测试成功与否的命令 test_command #执行测试成功与否的命令 范例:\n[root@ansible ~]#ansible websrvs -m reboot -a \u0026#39;msg=\u0026#34;host will be reboot\u0026#34;\u0026#39; mount 模块 功能: 挂载和卸载文件系统 常见选项\nsrc #源设备路径，或网络地址 path #挂载至本地哪个路径下 fstype #设备类型； nfs opts #挂载的选项 state #挂载还是卸载 =present #永久挂载，但没有立即生效 =absent #卸载临时挂载,并删除永久挂载 =mounted #临时挂载 =unmounted #临时卸载 范例:\n#修改fstab文件永久挂载,但不立即生效 mount websrvs -m mount -a \u0026#39;src=\u0026#34;UUID=b3e48f45-f933-4c8e-a700-22a159ec9077\u0026#34; path=/home fstype=xfs opts=noatime state=present\u0026#39; #临时取消挂载 mount websrvs -m mount -a \u0026#39;path=/home fstype=xfs opts=noatime state=unmounted\u0026#39; #永久挂载,并立即生效 ansible websrvs -m mount -a \u0026#39;src=10.0.0.8:/data/wordpress path=/var/www/html/wp- content/uploads opts=\u0026#34;_netdev\u0026#34; state=mounted\u0026#39; #永久卸载,并立即生效 ansible websrvs -m mount -a \u0026#39;src=10.0.0.8:/data/wordpress path=/var/www/html/wp- content/uploads state=absent\u0026#39; Setup 模块 功能： setup 模块来收集主机的系统信息，这些 facts 信息可以直接以变量的形式使用，但是如果主机 较多，会影响执行速度 可以使用 gather_facts: no 来禁止 Ansible 收集 facts 信息 常见选项\nfilter #指定过滤条件 范例:\nansible all -m setup ansible all -m setup -a \u0026#34;filter=ansible_nodename\u0026#34; ansible all -m setup -a \u0026#34;filter=ansible_hostname\u0026#34; # 主机名称 ansible all -m setup -a \u0026#34;filter=ansible_domain\u0026#34; ansible all -m setup -a \u0026#34;filter=ansible_memtotal_mb\u0026#34; ansible all -m setup -a \u0026#34;filter=ansible_memory_mb\u0026#34; ansible all -m setup -a \u0026#34;filter=ansible_memfree_mb\u0026#34; ansible all -m setup -a \u0026#34;filter=ansible_os_family\u0026#34; ansible all -m setup -a \u0026#34;filter=ansible_distribution\u0026#34; ansible all -m setup -a \u0026#34;filter=ansible_distribution_major_version\u0026#34; ansible all -m setup -a \u0026#34;filter=ansible_distribution_version\u0026#34; ansible all -m setup -a \u0026#34;filter=ansible_processor_vcpus\u0026#34; ansible all -m setup -a \u0026#34;filter=ansible_all_ipv4_addresses\u0026#34; ansible all -m setup -a \u0026#34;filter=ansible_architecture\u0026#34; ansible all -m setup -a \u0026#34;filter=ansible_uptime_seconds\u0026#34; ansible all -m setup -a \u0026#34;filter=ansible_processor*\u0026#34; ansible all -m setup -a \u0026#39;filter=ansible_env\u0026#39; 范例：\n[root@ansible ~]#ansible all -m setup -a \u0026#39;filter=ansible_python_version\u0026#39; 10.0.0.7 | SUCCESS =\u0026gt; { \u0026#34;ansible_facts\u0026#34;: { \u0026#34;ansible_python_version\u0026#34;: \u0026#34;2.7.5\u0026#34;, \u0026#34;discovered_interpreter_python\u0026#34;: \u0026#34;/usr/bin/python\u0026#34; }, \u0026#34;changed\u0026#34;: false } 10.0.0.6 | SUCCESS =\u0026gt; { \u0026#34;ansible_facts\u0026#34;: { \u0026#34;ansible_python_version\u0026#34;: \u0026#34;2.6.6\u0026#34;, \u0026#34;discovered_interpreter_python\u0026#34;: \u0026#34;/usr/bin/python\u0026#34; }, \u0026#34;changed\u0026#34;: false } 10.0.0.8 | SUCCESS =\u0026gt; { \u0026#34;ansible_facts\u0026#34;: { \u0026#34;ansible_python_version\u0026#34;: \u0026#34;3.6.8\u0026#34;, \u0026#34;discovered_interpreter_python\u0026#34;: \u0026#34;/usr/libexec/platform-python\u0026#34; }, \u0026#34;changed\u0026#34;: false } [root@ansible ~]# 范例：取IP地址\n#取所有IP ansible 10.0.0.101 -m setup -a \u0026#39;filter=ansible_all_ipv4_addresses\u0026#39; 10.0.0.101 | SUCCESS =\u0026gt; { \u0026#34;ansible_facts\u0026#34;: { \u0026#34;ansible_all_ipv4_addresses\u0026#34;: [ \u0026#34;192.168.0.1\u0026#34;, \u0026#34;192.168.0.2\u0026#34;, \u0026#34;192.168.64.238\u0026#34;, \u0026#34;192.168.13.36\u0026#34;, \u0026#34;10.0.0.101\u0026#34;, \u0026#34;172.16.1.0\u0026#34;, \u0026#34;172.17.0.1\u0026#34; ] }, \u0026#34;changed\u0026#34;: false } #取默认IP ansible all -m setup -a \u0026#39;filter=\u0026#34;ansible_default_ipv4\u0026#34;\u0026#39; 10.0.0.101 | SUCCESS =\u0026gt; { \u0026#34;ansible_facts\u0026#34;: { \u0026#34;ansible_default_ipv4\u0026#34;: { \u0026#34;address\u0026#34;: \u0026#34;10.0.0.101\u0026#34;, \u0026#34;alias\u0026#34;: \u0026#34;eth0\u0026#34;, \u0026#34;broadcast\u0026#34;: \u0026#34;10.0.0.255\u0026#34;, \u0026#34;gateway\u0026#34;: \u0026#34;10.0.0.2\u0026#34;, \u0026#34;interface\u0026#34;: \u0026#34;eth0\u0026#34;, \u0026#34;macaddress\u0026#34;: \u0026#34;00:0c:29:e8:c7:9b\u0026#34;, \u0026#34;mtu\u0026#34;: 1500, \u0026#34;netmask\u0026#34;: \u0026#34;255.255.255.0\u0026#34;, \u0026#34;network\u0026#34;: \u0026#34;10.0.0.0\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;ether\u0026#34; } }, \u0026#34;changed\u0026#34;: false } debug 模块 功能: 此模块可以用于输出信息,并且通过 msg 定制输出的信息内容,功能类似于echo命令 注意: msg后面的变量有时需要加 \u0026quot; \u0026quot; 引起来 常见选项\nmsg #指定命令输出的信息 var #指定变量名,和msg互斥 verbosity #详细度 范例: debug 模块默认输出Hello world\n[root@ansible ~]#ansible 10.0.0.18 -m debug 10.0.0.18 | SUCCESS =\u0026gt; { \u0026#34;msg\u0026#34;: \u0026#34;Hello world!\u0026#34; } [root@ansible ansible]#cat debug.yml --- - hosts: websrvs tasks: - name: output Hello world debug: #默认没有指定msg,默认输出\u0026#34;Hello world!\u0026#34; [root@ansible ansible]#ansible-playbook debug.yml ..... TASK [output variables] ******************************************************************************** ****************************** ok: [10.0.0.7] =\u0026gt; { \u0026#34;msg\u0026#34;: \u0026#34;Hello world!\u0026#34; } ok: [10.0.0.8] =\u0026gt; { \u0026#34;msg\u0026#34;: \u0026#34;Hello world!\u0026#34; } PLAY RECAP ******************************************************************************** ******************************************* 10.0.0.7 : ok=2 changed=0 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 10.0.0.8 : ok=2 changed=0 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 范例: 利用debug 模块输出变量\n[root@centos8 ~]#cat debug.yaml --- - hosts: websrvs tasks: - name: output variables debug: msg: Host \u0026#34;{{ ansible_nodename }}\u0026#34; Ip \u0026#34;{{ ansible_default_ipv4.address }}\u0026#34; [root@centos8 ~]#ansible-playbook debug.yaml PLAY [websrvs] ******************************************************************************** *************************************** TASK [Gathering Facts] ******************************************************************************** ******************************* ok: [10.0.0.7] ok: [10.0.0.8] TASK [output variables] ******************************************************************************** ****************************** ok: [10.0.0.7] =\u0026gt; { \u0026#34;msg\u0026#34;: \u0026#34;Host \\\u0026#34;centos7.wangxiaochun.com\\\u0026#34; Ip \\\u0026#34;10.0.0.7\\\u0026#34;\u0026#34; } ok: [10.0.0.8] =\u0026gt; { \u0026#34;msg\u0026#34;: \u0026#34;Host \\\u0026#34;centos8.wangxiaochun.com\\\u0026#34; Ip \\\u0026#34;10.0.0.8\\\u0026#34;\u0026#34; } PLAY RECAP ******************************************************************************** ******************************************* 10.0.0.7 : ok=2 changed=0 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 10.0.0.8 : ok=2 changed=0 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 范例: 显示字符串特定字符\n# cat debug.yml - hosts: all gather_facts: no vars: a: \u0026#34;12345\u0026#34; tasks: - debug: msg: - \u0026#34;{{a[0]}}\u0026#34; - \u0026#34;{{a[1]}}\u0026#34; - \u0026#34;{{a[2]}}\u0026#34; #定义了一个字符串变量a，如果想要获取a字符串的第3个字符，则可以使用”a[2]”获取，索引从0开始，执行上例playbook，debug的输出信息如下： TASK [debug] ************************* ok: [test1] =\u0026gt; { \u0026#34;msg\u0026#34;: \u0026#34;1\u0026#34; \u0026#34;msg\u0026#34;: \u0026#34;2\u0026#34; \u0026#34;msg\u0026#34;: \u0026#34;3\u0026#34; } sysctl 模块 功能: 修改内核参数 常见选项\nname #内核参数 value #指定值 state #是否保存在sysctl.conf文件中,默认present sysctl_set #使用sysctl -w 验证值生效 范例:\nansible websrvs -m sysctl -a \u0026#39;name=net.ipv4.ip_forward value=1 state=present\u0026#39; 范例: 内核参数优化\n- name: Change Port Range sysctl: name: net.ipv4.ip_local_port_range value: \u0026#39;1024 65000\u0026#39; sysctl_set: yes - name: Enabled Forward sysctl: name: net.ipv4.ip_forward value: \u0026#39;1\u0026#39; sysctl_set: yes - name: Enabled tcp_reuse sysctl: name: net.ipv4.tcp_tw_reuse value: \u0026#39;1\u0026#39; sysctl_set: yes - name: Chanage tcp tw_buckets sysctl: name: net.ipv4.tcp_max_tw_buckets value: \u0026#39;5000\u0026#39; sysctl_set: yes - name: Chanage tcp_syncookies sysctl: name: net.ipv4.tcp_syncookies value: \u0026#39;1\u0026#39; sysctl_set: yes - name: Chanage tcp max_syn_backlog sysctl: name: net.ipv4.tcp_max_syn_backlog value: \u0026#39;8192\u0026#39; sysctl_set: yes - name: Chanage tcp Established Maxconn sysctl: name: net.core.somaxconn value: \u0026#39;32768\u0026#39; sysctl_set: yes state: present - name: Chanage tcp_syn_retries sysctl: name: net.ipv4.tcp_syn_retries value: \u0026#39;2\u0026#39; sysctl_set: yes state: present - name: Chanage net.ipv4.tcp_synack_retries sysctl: name: net.ipv4.tcp_synack_retries value: \u0026#39;2\u0026#39; sysctl_set: yes state: presen pam_limits 功能: 管理资源限制 范例\n- name: Change Limit /etc/security/limit.conf pam_limits: domain: \u0026#34;*\u0026#34; limit_type: \u0026#34;{{ item.limit_type }}\u0026#34; limit_item: \u0026#34;{{ item.limit_item }}\u0026#34; value: \u0026#34;{{ item.value }}\u0026#34; loop: - { limit_type: \u0026#39;soft\u0026#39;, limit_item: \u0026#39;nofile\u0026#39;,value: \u0026#39;100000\u0026#39; } - { limit_type: \u0026#39;hard\u0026#39;, limit_item: \u0026#39;nofile\u0026#39;,value: \u0026#39;10000\u0026#39; } apt_repository 模块 功能: 此模块实现apt的仓库配置管理 常见选项\nrepo #仓库信息 state #添加或删除 update_cache #是否apt update,默认yes filename #仓库文件,默认放在/etc/apt/sources.list.d/file.list 范例:\nansible ubuntu-servers -m apt_repository -a \u0026#39;repo=\u0026#34;deb http://archive.canonical.com/ubuntu focal partner\u0026#34; filename=google-chrome\u0026#39; [root@ubuntu2004 ~]#cat /etc/apt/sources.list.d/google-chrome.list deb http://archive.canonical.com/ubuntu focal partner apt_key 模块 功能: 添加和删除apt key 常见选项\nurl #key路径 state #添加或删除 范例: 生成ceph仓库配置\n#先导入key,注意先后顺序 ansible ubuntu-servers -m apt_key -a \u0026#39;url=https://download.ceph.com/keys/release.asc state=present\u0026#39; #再生成apt配置,如果不导入key此步会出错 ansible ubuntu-servers -m apt_repository -a \u0026#39;repo=\u0026#34;deb http://mirror.tuna.tsinghua.edu.cn/ceph/debian-pacific focal main\u0026#34; filename=ansible_ceph\u0026#39; #验证结果 [root@ubuntu2004 ~]#cat /etc/apt/sources.list.d/ansible_ceph.list deb http://mirror.tuna.tsinghua.edu.cn/ceph/debian-pacific focal main 其它模块 ansible 还提供了很多针对各种应用的模块,比如\nnginx_status_info nginx_status_facts mysql_db #需要安装MySQL-python包 mysql_user #需要安装MySQL-python包 redis mongodb* postgresql* haproxy git ","permalink":"https://xyenvy.github.io/posts/ansible/","summary":"Ansible介绍和架构 Ansible发展史 Ansible 的名称来自科幻小说《安德的游戏》中跨越时空的即时通信工具，使用它可以在相距数光年的距离，远程实时控制前线的舰队战斗 2012-03-09，发布0.0.1版，2015-10-17，Red Hat宣布1.5亿美元收购 官网： 官方文档： Ansible 功能 批量","title":"运维自动化工具Ansible(一)"},{"content":"Redis学习笔记 一 、Redis简介 1.1 什么是Redis Redis 是完全开源免费的，遵守BSD协议，是一个高性能(NOSQL)的key-value数据库*，Redis是一个开源的使用ANSI C语言编写、支持网络、可基于内存可持久化的日志型，Key-Value数据库，并提供多种语言的API。\nBSD是\u0026#34;Berkeley Software Distribution\u0026#34;的缩写，意思是“伯克利软件发型版本”。 BSD开源协议是一个给予使用者很大自由的协议。可以自由的使用，修改源代码，也可以将修改后的代码作为开源或者专有软件在发布。BSD代码鼓励代码共享，但需要尊重代码作者的著作权。 BSD由于允许使用者修改和重新发布代码，也允许使用或在BSD代码上开发商业软件发布和销售，一次是对商业集成很友好的协议。 1.2 NoSQL NoSQL,泛指非关系型的数据库，NoSQL即Not-only SQL,它可以作为关系型数据库的良好补充。随着互谅网web2.0网站的兴起，非关系型的数据库现在成为了一个及其热门的新领域，非关系型数据库产品的发展非常迅速。 传统数据库暴露很多难以克服的问题，如下问题：\n1、High performance - 对数据库高并发读写的需求。 2、Huge Storage - 对海量数据的高效存储和访问的需求。 3、High Scalability \u0026amp;\u0026amp; High Availability - 对数据库的高可扩展性和高课用性的需求。 1.3 NoSQL的类别 键值（Key-Value）存储数据库\n这一类数据库主要会使用到一个哈希表，这个表中有一个特定的键和一个指针指向特定的数据。 key/value模型对于IT系统涞水的优势在于简单，已部署。但是如果DBA只对部分值进行查询或者更新的时候，key/value显示的效率低下。 相关产品 ： Redis，Tokyo Cabinet 典型应用 ： 内存缓存，主要用于处理大量数据的高访问负载。 数据模型 ： 一系列键值对 优势 ： 快速查询 劣势 ： 存储的数据缺少结构化 列存储数据库\n这部分数据库通常是用来对分布式存储的海量数据。键仍然存在，但是他们的特点是指向了多个列。这些列是由列家族来安排的。 相关产品 : HBase 、Riak 典型应用 ： 分布式的文件系统 数据模型 ： 以列簇式存储，将同一列数据存在一起 优势 ： 查找速度快，可扩展性强，更容易进行分布式扩展 劣势 ： 功能相对于局限 文档型数据库\n文档型数据库：该类型的数据库模型是版本化的文档，半结构化的文档一特定的格式存储，比如JSON。文档数据库可以看做键值数据库的升级版，允许之间嵌套键值。而且文档型数据库比键值数据库的查询效率更高。 相关产品：MOngoDB 典型应用 ： web应用 数据模型 ： 一系列键值对 优势 ： 数据结构要求不严格 劣势 ： 查询性能不高，而且缺乏统一的查询语言 1.4 总结 NoSQL 数据库在一下的这几种情况下比较适用 ：\n1、数据模型比较简单；\n2、需要灵活更前的IT系统；\n3、对数据库性能要求较高；\n4、不需要高度的数据一致性；\n5、对于给定key，比较容易映射复杂的环境；\n1.5 Redis 描述 ​Redis是完全开源免费的，遵守BSD协议，是一个高性能(NoSQL)的（key-value）数据库，Redis是一个开源的使用ANSI C语言编写，支持网络，可基于内存亦可持久化的日志型，Key-Value数据库，并提供多种语言的API。\n1.6 Redis的特点 性能极高 - Redis读写的熟读110000次/s，写的速度是81000次/s。 丰富的数据类型 - Redis支持的类型String， Hash 、List 、Set 及 Ordered Set数据类型操作。 原子性 - Redis的所有操作都是原子性的，意思就是要么成功，要么失败。单个操作时原子性的。多个操作也支持事务，即原子性，通过MULTI和EXEC指令包起来。 丰富的特性 - Redis还支持publis/subscribe，通知，key过期等等特性。 高速读写 ，redis使用自己实现的分离器，代码量很短，没有使用lock(MySQL),因此效率非常高。 Redis是一个简单的，高效的，分布式的，基于内存的缓存工具。\n架设好服务器后，通过网络连接(类似数据库)，提供Key-Value缓存服务。\n简单，是Redis突出的特色。\n简单可以保证核心功能的稳定和优异。\n1.7 Redis的应用场景 可以作为数据库，缓存，热点数据(经常别查询，但是不经常被修改或者删除的数据)和消息中间件等大部分功能。\nRedis常用的场景示例如下：\n1、缓存 缓存现在几乎是所有大中型网站都在用的必杀技，合理利用缓存提升网站的访问速度，还能大大降低数据库的访问压力。Redis提供了键过期功能，也提供了灵活的键淘汰策略，所以，现在Redis用在缓存的场合非常多。 2、排行榜 Redis提供的有序集合数据类结构能够实现葛洪复杂的排行榜应用。 3、计数器 什么是计数器，，视频网站的播放量等等，每次浏览+1，并发量高时如果每次都请求数据库操作无疑是中挑战和压力。Redis提供的incr命令来实现计数器功能，内存操作，性能非常好，非常是用于这些技术场景。 4、分布式会话 集群模式下，在应用不多的情况下一般使用容日自带的session复制功能就能够满足，当应用相对复杂的系统中，一般都会搭建Redis等内存数据库为中心的session服务，session不在由容器管理，而是有session服务及内存数据管理。 5、分布式锁 在很多互联网公司中都是用来分布式技术，分布式技术带来的技术挑战是对同一个资源的并发访问，如全局ID，减库存，秒杀等场景，并发量不发的场景可以使用数据库的悲观锁，乐观锁来实现，但是在并发高的场合中，利用数据库锁来控制资源的并发访问是不太理想的，大大影响了数据库的性能。可以利用Redis的setnx功能来编写分布式的锁，如果设置返回1，说明获取所成功，否则获取锁失败，实际应用中药考虑的细节要更多。 6、社交网络 点赞、踩、关注/被关注，共同好友等是社交网站的基本功能，社交网站的访问量通常老说比较大，而且传统的关系数据库不适合这种类型的数据，Redis提供的哈希，集合等数据结构能很方便的实现这些功能。 7、最新列表 Redis列表结构，LPUSH可以在列表头部插入一个内容ID作为关键字，LTRIM可以用来限制列表的数量，这样列表永远为N个ID。无需查询最新的列表，直接根据ID 去到对应的内容也即可。 8、消息系统 消息对队列是网站比用中间件，如ActiveMQ，RabbitMQ，Kafaka等流行的消息队列中间件，主要用于业务解耦，流量削峰及异步处理试试性低的业务。Redis提供了发布/订阅及阻塞队列功能，能实现一个简单的消息队列系统。另外，这个不能喝专业的消息中间件相比。 1.8 Redis总结 优势\n性能极高 - Redis读写的熟读110000次/s，写的速度是81000次/s。 丰富的数据类型 - Redis支持的类型String， Hash 、List 、Set 及 Ordered Set数据类型操作。 原子性 - Redis的所有操作都是原子性的，意思就是要么成功，要么失败。单个操作时原子性的。多个操作也支持事务，即原子性，通过MULTI和EXEC指令包起来。 丰富的特性 - Redis还支持publis/subscribe，通知，key过期等等特性。 高速读写 ，redis使用自己实现的分离器，代码量很短，没有使用lock(MySQL),因此效率非常高。 缺点\n持久化。 Redis直接将数据存储到内存中，要将数据保存到磁盘上，Redis可以使用两种方式实现持久化过程。定时快照(snapshot)：每个一端时间将整个数据库写到磁盘上，每次均是写全部数据，代价非常高。第二种方式基于语句追加（aof）：只追踪变化的数据，但是追加的log可能过大，同时所有的操作均重新执行一遍，回复速度慢。 耗内存 、占用内存过高。 二、Redis安装 2.1 Redis官网 官方网站\n官方下载 可以根据需要下载不同版本\n2.2 Redis 安装 Redis是C语言开发，安装Redis需要先将官网下载的源码进行编译。编译依赖gcc环境，如果没有gcc环境，需要安装gcc\n2.3 安装gcc gcc的安装很简单，首先要确保root登录，其次就是Linux要能连外网\nyum -y install gcc automake autoconf libtool make 注意： 运行yum是出现/var/run/yum.pid已被锁定，PID为xxxx的另外一个程序正在运行的问题解决。\nrm -f /var/run/yum.pid 2.4 安装Redis 下载redis二进制安装包\nwget http://download.redis.io/release/redis-6.0.5.tar.gz 解压/apps目录下\ntar zxvf redis-6.0.5.tar.gz -C /apps #Linux 中剪切命令 mv redis-6.0.5.tar.gz 安装包 #Linux中复制命令: cp Files path cp redis-6.0.5.tar.gz /root/apps 进入redis中使用make命令进行编译\n[root@centos redis-5.0.8]# make MALLOC=libc LINK redis-cli CC redis-benchmark.o LINK redis-benchmark INSTALL redis-check-rdb INSTALL redis-check-aof Hint: It\u0026#39;s a good idea to run \u0026#39;make test\u0026#39; ;) make[1]: 离开目录“/root/apps/redis-5.0.8/src” [root@centos redis-5.0.8]# ll 安装成功如上\n2.5 安装到指定的位置 make PREFIX=/root/apps/redis install （安装编译后的文件）安装到指定目录；\n注意：PREFIX必须为大写，同时会自动为我们创建redis目录，并将结果安装此目录；\n三 、Redis启动 3.1 启动Redis服务端，进入到Redis的安装目录 cd /usr/local/redis 3.2 执行命令 ./bin/redis-server 3.3 Redis的客户端进行启动 ./bin/redis-cli 3.4 启动Redis客户端命令语法 redis-cli -h IP地址 -p 端口 //默认IP本机 端口号6379 3.5 检测是否服务端启动 启动redis客户端，打开终端并输入命令redis-cli。该命令连接本地的redis服务。\n127.0.0.1:6379\u0026gt; 127.0.0.1:6379\u0026gt; ping PONG 127.0.0.1:6379\u0026gt; 在以上实例中我们连接到本地的redis服务并执行PING 命令，该命令用于检测redis服务是否启动\n3.6 检查redis的进程 #执行 ps -ef | grep -i redis 来查看进程 ps -ef | grep -i redis root 10050 5728 0 23:03 pts/0 00:00:03 ./bin/redis-server *:6379 root 10077 10056 0 23:10 pts/1 00:00:00 ./bin/redis-cli root 10100 10081 0 23:22 pts/2 00:00:00 grep --color=auto -i redis [root@centos ~]# 四、Redis配置详细 Redis默认定义了很多默认配置。但在实际开发中，一般我们都会通过手动配置完成。回到安装目录下找到解压文件中的redis.conf。\nRedis的配置文件位于Redis安装目录下，文件名称为redis.conf\n4.1 配置Redis 命令：解压目录下的redis.conf配置文件复制到安装文件的目录下\n#把编译的redis.conf文件放 ，安装的redis文件目录下 [root@centos redis-5.0.8]# pwd /root/apps/redis-5.0.8 [root@centos redis-5.0.8]# cp redis.conf /root/apps/redis [root@centos redis-5.0.8]# cd .. [root@centos apps]# ll 4.2 Redis.conf 1、Redis默认不是以守护进程的方式运行，可以通过该配置项修改，使用yes启用守护进程 daemonize no 2、当Redis以守护进程方式运行时，Redis默认会把pid写入/var/run/redis.pid文件，可以通过pidfile指定 pidfile /var/run/redis.pid 3、指定Redis监听端口，默认端口为6379；’ port 6379 4、绑定的主机地址 bind 127.0.0.1 5、当客户端限制多长时间后关闭连接，如果指定为0，表示关闭该功能 timeout 300 6、指定日志记录几倍，Redis总共支持四个级别：debug，verbose，notice，warning，默认为verbose loglevel verbos 7、日志记录方式，默认为标准输出，如果配置Redis为守护进程方式运行，而这里又配置日志记录方式标准输出，则日志将会发送给/dev/null logfile stdout 8、设置数据库的数量，默认数据库为0，可以使用SELECT\u0026lt;dbid\u0026gt;命令在连接上指定数据库id databases 16 9、指定在多长时间内，有多少次更新操作，就将数据同步到数据文件，可以多个条件配合 save\u0026lt;seconds\u0026gt;\u0026lt;changes\u0026gt; Redis默认配置文件中提供了三个条件 save 900 1 save 300 10 save 60 10000 分别表示900秒(15分钟)内有1个更改，300秒(5分钟)内有10个更改以及60秒内有10000个更改。 10、指定存储至本地数据库时是否压缩数据，默认为yes，Redis采用LZF(压缩算法)压缩，如果为了节省CPU时间，可以关闭该选项，但会导致数据库文件变的巨大 rdbcompression yes 中间10个\n11、指定本地数据库文件名，默认为dump.rdb dbfilename dump.rdb 12、指定本地数据库存放目录 dir ./ 13、设置当本机为slav服务时，设置master服务的IP地址及端口，在Redis启动时，它会自动从master进行数据同步slaveof\u0026lt;masterip\u0026gt; \u0026lt;masterport\u0026gt; 14、当master服务设置了密码保护时，slav服务连接master的密码 masterauth\u0026lt;master-password\u0026gt; 15、设置Redis连接密码，如果配置了连接密码，客户端在连接Redis是需要通过AUTH \u0026lt;password\u0026gt;命令提供密码，默认关闭 requirepass foobared 16、设置同一时间最大客户端连接数，默认是无限制，Redis可以同时打开的客户端连接数为Redis进程可以打开的最大文件描述符数，如果设置maxclients 0，表示不作限制。当客户端连接数到达限制是，Redis会关闭新的连接并向客户端返回max number of clients reached错误信息 maxclients 128 17、指定Redis最大内存限制，Redis在启动时会把数据加载到内存中，达到最大内存后，Redis会先尝试清除已到期或即将到期的Key，档次方法处理后，仍然达最大内存设置，将无法再进行写入操作，但仍然可以静心读取操作。Rdis新的vm机制，会把key存放内存，Value会存放在swap区 maxmemory \u0026lt;bytes\u0026gt; 18、指定是否每次更新操作后进行日志记录，Redis在默认情况下是异步的把数据写入磁盘，如果不开启，可能会在断电时导致一端时间内的数据丢失。因为 redis 本省同步数据文件是按上面save条件来同步的，所有的数据会在一端时间内只存在于内存中。默认为no appendonly no 19、指定更新日志文件名，默认为appendonly.aof appendfulename appendonly.aof 20、指定更新日志条件，共有3个可选值： no: 表示等操作系统进行数据缓存同步到磁盘(快) always: 表示每次更新操作后活动调用fsync()将数据写到磁盘(慢，安全) everysec: 表示每秒同步一个(折中，默认值) appendfsync everysec maxmemory-policy noeviction # 内存达到上限之后的处理策略 1、volatile-lru ： 只对设置了过期时间的key进行LRU（默认值） 2、allkeys-lru ： 产出lru算法的key 3、volatile-random ： 随机删除即将过期key 4、allkey -random : 随机删除 5、volatile-ttl : 删除即将过期的 6、noeviction ： 永不过期，返回错误 结尾10个\n21、指定是否启用虚拟内存机制，默认为no，简单的介绍一下，vm机制将数据分页存放，有Redis将访问量较少的页即冷数据swap到磁盘上，访问多的页面由磁盘自动换出到内存中(在后面的文章会仔细分析Redis的vm机制) vm-enabled no 22、虚拟内存文件路径，默认值为/tmp/redis.swap，不可多个Redis实例共享 vm-swap-file /tmp/redis.swap 23、将所有大于vm-max-memory的数据存入虚拟内存，无论vm-max-memory设置多小，所有索引数据都是内存存储的(Redis的索引数据 就是keys)，也就是说，当vm-max-memory设置为0的时候，其实是所有value都存在于磁盘。默认值为0 vm-page-size 32 24、Redis swap文件分成了很多的page，一个对象可以保存咱几多个page上面，但一个page上不能被多个对象共享，vm-page-size是要根据存储的 数据大小来设定的，作者建议如果村粗很多小对象，page大小最好设置为32或者64bytes；如果存储很大大对象，则可以使用更大的page，如果不确定，就是用默认值 vm-page-size 32 25、设置swap文件中的page数量，由于页表(一种表示页面空闲或是欧诺个的bitmap)是放在内存中的，在磁盘上每8个pages将消耗1byte的内存 vm-pages 134217728 26、设置访问swap文件的线程数，最好不要超过机器的核数，如果设置为0，那么所有对swap文件的操作都是串行的，可能会造成比较长时间的延迟。默认值为 4 vm-max-threads 4 27、设置在向客户端应答时，是否把较小的包含并未一个包发送，默认为开启 glueoutputbuf yes 28、指定在超过一定的数量或者最大的元素超过某一临界值时，采用一种特殊的哈希算法 hash-max-zipmap-entries 64 hash-max-zipmap-value 512 29、指定是否激活重置哈希。默认为开启(后面在介绍Redis的哈希算法时具体介绍) activerehasing yes 30、指定包含其他的配置文件，可以在同一主机上多个redis实例之间使用同一份配置文件，而同时各个实例又拥有自己的特定配置文件 include /path/to/local.conf 4.2、内存中的维护策略 redis作为优秀的中间缓存件，时常会存储大量的数据，即使采取了集群部署来动态扩容，也应该即使的整理内存，维持系统性能。\n4.2.1 在redis中有两种解决方案 为数据设置超时时间 //设置过期时间 expire key time(以秒为单位)--这是最常用的方式 setex(String key, int seconds, String value) --字符串独有的方式 1、除了字符串自己独有设置过期时间的方法外，其他方法都需要依靠expire方法来设置时间 2、如果没有设置时间，那缓存就是永不过期 3、如果设置了过期时间，之后又想让缓存永不过期没使用persist key 采用LRU算法动态将不用的数据删除 内存管理的一种页面置换算法，对于在内存中但又不用的数据块(内存块)叫做LRU， 操作系统会根据哪些数据属于LRU而将其移除内存而腾出空间来加载另外的数据。 1.volatile-lru：设定超时时间的数据中，删除最不常使用的数据\n2.allkeys-lru：查询所有的key只能怪最近最不常使用的数据进行删除，这是应用最广泛的策略。\n3.volatile-random：在已经设定了超时的数据中随机删除。\n4.allkeys-random：查询所有的key，之后随机删除。\n5.volatile-ttl：查询全部设定超时时间的数据，之后排序，将马上要过期的数据进行删除操作。\n6.noeviction：如果设置为该属性，则不会进行删除操作，如果内存溢出则报错返回。\n7.volatile-lfu：从所有配置了过去时间的键中驱逐使用频率最少的键\n8.allkeys-lfu：从所有键中驱逐使用频率最少的键\n4.2.2 自定义配置redis 进入对应的安装目录：\n/root/apps/redis 修改redis.conf配置文件 vim redis.conf（进入命令模式 通过/内容 查找相应字符串）\ndaemonize no 修改为 daemonize yes 守护进程启动 bind 127.0.0.1 注释掉 允许除本机 外的机器访问redis服务 requirepass 设置密码 设定数据库密码 (保证服务安全/有些情况下不设定密码是无法进行远程连接访问的) Redis采用的是单进程多线程的模式。当redis.conf中选项daemonize设置成为yes时，代表开启守护进程模式。在该模式下，redis会在后台运行，并将进程pid号写入值redis.conf选项pidfile设置的文件中，此时redis将一直运行，除非手动kill该进程。但当daemonize选项设置为no时，当前界面将进入redis的命令行界面，exit强制退出或者关闭连接工具（putty,xshell等）都会呆滞redis进程退出。\n服务端开发的大部分应用都是采用后台运行的模式\nrequirepass设置密码。因为redis速度相当快，所以一台比较好的服务器下，一个外部用户在一秒内可以进行15w密码尝试，这意味你需要设定非常强大的密码来防止暴力破解。\n可以通过redis的配置文件设置密码参数，这样客户端连接大redis服务就需要密码验证，这样可以让你的redis服务更加安全。\n五 、Redis启动 5.1 Redis以守护进程服务端进行启动 // 使用该命令进行启动：【./bin/redis-server ./redis.conf 】 [root@centos redis]# ./bin/redis-server ./redis.conf 11450:C 05 Jul 2020 12:23:34.257 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo 11450:C 05 Jul 2020 12:23:34.257 # Redis version=5.0.8, bits=64, commit=00000000, modified=0, pid=11450, just started 11450:C 05 Jul 2020 12:23:34.257 # Configuration loaded [root@centos redis]# 5.2 Redis客户端进行启动 //Redis 客户端启动命令：./redis-cli [root@centos bin]# ./redis-cli 127.0.0.1:6379\u0026gt; keys * 1) \u0026#34;name\u0026#34; 127.0.0.1:6379\u0026gt; 六、Redis关闭 6.1、第一种关闭方式 (断电、非正常关闭，容易数据丢失) 查询不到redis进程id\nPID ps -ef | grep -i redis kill 查询的id进行强制关闭\nkill -9 PID 6.2、第二种关闭方式 (正常关闭，数据保存)\n关闭redis服务，通过客户端进行shutdown\n如果redis设置了密码，需要先在客户端通过密码登录，在进行shutdown即可关闭服务端\n// 在客户端使用【shutdown】命令关闭Redis服务端 127.0.0.1:6379\u0026gt; SHUTDOWN not connected\u0026gt; y Could not connect to Redis at 127.0.0.1:6379: Connection refused not connected\u0026gt; shutdown 七、远程连接 7.1 Redis远程连接比较流行的软件：RedisDesktoManager 默认不允许远程连接，需要修改一下信息才可以进行修改，\nbind 127.0.0.1 注释掉 允许除本机以外的机器访问Redis服务 requirepass 设置密码 设定数据库密码(有些情况系不设定密码是无法进行远程连接访问的) 7.2 Redis使用密码登录 // Redis客户端使用密码进行登录 【./bin/redis-cli -a redis】 [root@centos redis]# ./bin/redis-cli -a redis Warning: Using a password with \u0026#39;-a\u0026#39; or \u0026#39;-u\u0026#39; option on the command line interface may not be safe. 127.0.0.1:6379\u0026gt; keys * 1) \u0026#34;name\u0026#34; 127.0.0.1:6379\u0026gt; Centos 防火墙端口 开放8080端口（如下命令只针对Centos7以上）\n查看已经开放的端口：\nfirewall-cmd --list-ports 开启端口：\nfirewall-cmd --zone=public --add-port-6379/tcp --permanent 重启防火墙：\nfirewall-cmd --reload #重启 Firewall systemctl stop firewalld.service #停止 firewall systemctl disable firewalld.service #禁止firewall 开机启动 八 、Docker安装Redis 8.1 搜索redis docker search redis 8.2 下载镜像 docker pull redis：4.0.1 8.3 创建并运行容器 docker run -d --name redis6379 -p 6379:6379 redis:4.0.1 --requirepass \u0026#34;redis\u0026#34; 8.4 测试进入Redis进入客户端 使用redis镜像执行redis-cli命令连接到刚启动的容器\n九、Redis常用命令 Redis 命令用于在redis服务上执行操作。要在redis服务上执行命令需要一个redis客户端。\nRedis 客户端在我们之前下载的Redis的安装包中。\nRedis支持的物种数据类型 ：string(字符串)，hash(哈希)，list(列表)，set(集合)及zset（sorted set : 有序集合）等\n9.1 常用命令key管理 1、 keys * :返回满足的所有键，可以模糊匹配，比如 keys abc* ：表示以 abc 开头的 key 2、 exists key ： 是否存在指定的key ，存在返回1.不存在返回0 3、 expire key second ：设置某个key的过期时间 时间为妙 4、 del key : 删除某个key 5、 ttl key ：查看剩余时间，当key不存在是，返回-2；存在但没有设置剩余生存时间时，返回 -1，否 则，以秒为单位，返回key 的剩余生存时间。 6、 persist key ：取消过去时间 7、 PEXPIRE key millisseconds 修改key 的过期时间为毫秒 8、 select ： 选择数据库 数据库为0-15（默认一共16个数据库） 9、 设计成多个数据库实际上是为了数据库安全和备份 10、 move key dbindex ： 将当前数据中的key转移到其他数据库 11、 randomkey ： 随机返回一个key 12、 rename key key2 : 种命名key 13、 echo ： 打印命令 14、 dbsize : 查看数据库的key数量 15、 info : 查看数据库信息 16、 config get * 实时存储收到的请求，返回相关的配置 17、 flushdb ： 清除当前数据库 18、 flushall ： 清空所有数据库 9.2 DEL key 该命令用于在key存在时删除key。 9.3 EXISTS key 检查给定key是否存在。 9.4 EXPIRE key seconds 为给定key设置过期时间(以秒计) 9.5 PEXPIRE key milliseconds 设置key的过期时间以毫秒计 9.6 TTL key 以秒为单位，返回给定key的剩余生存时间(TTL, time to live) 9.7 PTTL key 以秒为单位，返回 key 的剩余生存时间 9.8 KEYS pattern 查找所有服务给定模式(pattern)的key。 keys 通配符 获取所有与pattern匹配的key，返回所有与该匹配 通配符 ： * 代表所有 ? 表示代表一个字符 9.9 RENAME key newkey 修改key的名称 9.10 MOVE key db 将当前数据库的 key 移动到给定的数据库db当中 9.11 TYPE key 返回 key 所存储的值的类型 9.12 应用场景 EXPIPER key seconds\n1、限时的优惠活动信息 2、网站数据缓存(对于一些需要定时更新的数据，例如:积分排行榜) 3、手机验证码 4、限制网站访客访问频率(例如：1分钟最多访问10次) 9.13 key的命名建议 redis单个key允许存入512M大小\n1、key 不要太长，尽量不要超过1024字节，这不仅消耗内存，而且会降低查找的效率 2、key 也不要太短，太短的话，key的可读性会降低 3、在一个项目中，key最好使用提议的命名模式，例如user:12:password 4、key名称区分大小写 十 、Redis数据类型 10.1 String 类型 String类型是Redis最基本的数据类型，一个键最大能存储512MB。\nString 数据结构最贱但的key-value类型，value其不仅是string，也可以是数字，是包含很多种类型的特殊类型，\nString类型是二进制安全的。意思是redis的string可以包含任何数据。\n比如序列化的对象进行存储，比如一张图片进行二进制存储，比如一个简单的字符串，数值等等。\nString命令 1、复制语法： SET KEY_NAME VALUE : (说明：多次设置name会覆盖)(Redis SET 命令用于设置给定 key 的值。如果 key 已经存储值，SET 就要写旧值，且无视类型)。 2、命令： SETNX key1 value：(not exist) 如果key1不存在，则设置 并返回1。如果key1存在，则不设置并返回0;(解决分布式锁 方案之一，只有在key 不存在时设置 key 的值。setnx (SET if not exits)命令在指定的key不存在时，为key设置指定的值)。 SETEX key1 10 lx :(expired)设置key1的值为lx,过期时间为10秒，10秒后key1清除（key也清除） SETEX key1 10 lx :(expired) 设置key1的值为lx，过期时间为10秒，10秒后key1清除(key 也清除) SETRANG STRING range value : 替换字符串 3、取值语法： GET KEY_NAME : Redis GET 命令用于获取指定 key 的值。如果 key 不存在，返回 nil。如果key存储的值不是字符串类型，返回一个错误。 GETRANGE key start end : 用于获取存储在指定key中字符串的子字符串。字符串的截取范围由 start 和 end 两个偏移量来决定(包括 start 和 end 在内) GETBIT key offset ：对 key 所存储的字符串值，获取指定偏移量上的为(bit)； GETTEST语法 ： GETSET KEY_NAME VALUE : GETSET 命令用于设置指定 key 的值，并返回key的旧值。当key不存在是，返回 nil STRLEN key :返回 key 所存储的字符串值的长度 4、删除语法： DEL KEY_NAME : 删除指定的key，如果存在，返回数字类型。 5、批量写：MSET K1 V1 K2 V2 ... (一次性写入多个值) 6、批量读：MGET K1 K2 K3 7、GETSET NAME VALUE : 一次性设置和读取(返回旧值，写上新值) 8、自增/自减： INCR KEY_Name : Incr 命令将key中存储的数组值增1。如果 key 不存在，那么key的值会先被初始化为0，然后在执行INCR操作 自增: INCRBY KEY_Name : 增量值Incrby 命令将key中存储的数字加上指定的增量值 自减: DECR KEY_Name 或 DECYBY KEY_NAME 减值：DECR 命令将key中存储的数字减少1 ：(注意这些key对应的必须是数字类型字符串，否则会出错。) 字符串拼接：APPEND KEY_NAME VALUE :Append 命令用于为指定的key追加至末尾，如果不存在，为其赋值 字符串长度 ：STRLEN key ########################## setex (set with expire) #设置过期时间 setnx (set if not exist) #不存在设置 在分布式锁中会常常使用！ 10.2 应用场景 1、String通常用于保存单个字符串或JSON字符串数据\n2、因String是二进制安全的，所以你完全可以把一个图片文件的内容作为字符串来存储\n3、计数器(常规key-value缓存应用。常规计数：微博数，粉丝数)\nINCR 等指令本身就具有原子操作的特定，所以我们完全可以利用redis的INCR，INCRBY,DECR,DECRBY等指令来实现原子计数的效果。假如，在某种场景下有3个客户端同时读取了mynum的值(值为2)，然后对其同时进行了加1的操作，那么，最后mynum的值一定是5。 不少网站都利用redis的这个特性来实现业务上的统计计数需求。 10.3 Hash类型 Hash类型是String类型的field和value的映射表，或者说是一个String集合。hash特别适合用于存储对象，相比较而言，将一个对象类型存储在Hash类型要存储在String类型里占用更少的内存空间，并对整个对象的存取。可以看成具有KEY和VALUE的MAP容器，该类型非常适合于存储值对象的信息。\n如：uname，upass，age等。该类型的数据仅占用很少的磁盘空间(相比于JSON).\nRedis 中每一个hash 可以存储 2的32次方 -1 键值对(40 多亿)\n10.4 Hash命令 常用命令\n一、赋值语法： 1、 HSET KEY FIELD VALUE ： 为指定的KEY,设定FILD/VALUE 2、 HMSET KEY FIELD VALUE [FIELD1，VALUE]... : 同时将多个 field-value(域-值)对设置到哈希表key中。 二、取值语法： HGET KEY FIELD :获取存储在HASH中的值，根据FIELD得到VALUE HMGET KEY FIELD [FIELD1] :获取key所有给定字段的值 HGETALL KEY :返回HASH表中所有的字段和值 HKEYS KEY : 获取所有哈希表中的字段 HLEN KEY : 获取哈希表中字段的数量 三、删除语法： HDEL KEY FIELD[FIELD2] :删除一个或多个HASH表字段 四、其它语法： HSETNX KEY FIELD VALUE : 只有在字段field 不存在时，设置哈希表字段的值 HINCRBY KEY FIELD INCREMENT :为哈希key中的指定字段的整数值加上增量 increment。 HINCRBYFLOAT KEY FIELD INCREMENT :为哈希表key 中的指定字段的浮点数值加上增量 increment HEXISTS KEY FIELD : 查看哈希表中key中，指定的字段是否存在 10.5 应用场景 Hash的应用场景 ：(存储一个用户信息对象数据)\n常用于存储一个对象\n为什么不用string存储一个对象\nhash值最接近关系数据库结构的数据类型，可以将数据库一条记录或程序中一个对象转换成hashmap存放在redis中。\n用户ID为查找的key，存储的value用户对象包含姓名，年龄，生日等信息，如果用普通的key/value结构来存储，主要有一下2中村粗方式：\n​第一种方式将用户ID作为查找key，把其他信息封装成为一个对象以序列化的方式存储，这种方式的却但是，增加了序列化/反序列化的开销，并且在需要修改其中一项信息时，需要把整个对象取回，并且修改操作需要对并发进行保护，引入CAS等复杂问题。\n​ 第二种方法是这个用户信息对象有多少成员就存成多少个key-value对儿，用用户ID+对应属性的名称作为唯一标识来取的对应属性的值，虽然省去了序列化开销和并发问题，但是用户ID重复存储，如果存在大量这样的数据，内存浪费还是非常可观的。\n10.6 总结 Redis提供的Hash很好的解决了这个问题，Redis的Hash实际内部存储的Value为一个HashMap，\n10.6 List类型 简介：\n1、 List 类型是一个链表结构的集合，其主要功能有push、pop、获取元素等。更详细的说，List类型是一个双端链表的节后，我们可以通过相关的操作进行集合的头部或者尾部添加和删除元素，List的设计是非常简单精巧，即可以最为栈，有可以最为队列，满足绝大多数的需求。 常用命令\n1、赋值语法： LPUSH KEY VALUE1 [VALUE2] :将一个或多个值插入到列表头部（从左侧添加） RPUSH KEY VALUE1 [VALUE2] ：在列表中添加一个或多个值（从有侧添加） LPUSHX KEY VAKUE :将一个值插入到已存在的列表头部。如果列表不在，操作无效 RPUSHX KEY VALUE :一个值插入已经在的列表尾部（最右边）。如果列表不在，操作无效 2、取值语法： LLEN KEY :获取列表长度 LINDEX KEY INDEX:通过索引获取列表中的元素 LRANGE KEY START STOP:获取列表指定范围内的元素 描述：返回列表中指定区间的元素，区间以偏移量START和END指定。\n其中0表示列表的第一个元素，1表示列表的第二个元素，以此类推。。。\n也可以使用负数下标，以-1表示列表的最后一个元素，-2表示列表的倒数第二个元素，一次类推。。。\nstart：页大小（页数-1）\nstop：（页大小页数）-1\n3、删除语法： LPOP KEY :移除并获取列表的第一个元素（从左侧删除） RPOP KEY :移除列表的最后一个元素，返回值为移除的元素（从右侧删除） BLPOP key1 [key2]timeout :移除并获取列表的第一个元素，如果列表没有元素会阻塞列表知道等待超时或发现可弹出元素为止。 4、修改语法： LSET KEY INDEX VALUE :通过索引设置列表元素的值 LINSERT KEY BEFORE|AFTER WORIL VALUE :在列表的元素前或者后 插入元素 描述：将值 value 插入到列表key当中，位于值world之前或之后。 高级命令\n高级语法： RPOPLPUSH source destiation : 移除列表的最后一个元素，并将该元素添加到另外一个列表并返回 示例描述： RPOPLPUSH a1 a2 : a1的最后元素移到a2的左侧 RPOPLPUSH a1 a1 : 循环列表，将最后元素移到最左侧 BRPOPLPUSH source destination timeout :从列表中弹出一个值，将弹出的元素插入到另外一个列表中并返回它；如果列表没有元素会阻塞列表知道等待超时或发现可弹出的元素为止。 List代码案例\npackage com.tyx.service.impl; import com.tyx.po.User; import lombok.extern.slf4j.Slf4j; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.data.redis.core.RedisTemplate; import org.springframework.stereotype.Service; import org.springframework.util.CollectionUtils; import java.io.Serializable; import java.util.Collections; import java.util.List; import java.util.concurrent.TimeUnit; / * @author papi * @data 2020/7/15 */ @Service @Slf4j public class UserServiceImpl { @Autowired private RedisTemplate\u0026lt;String, Object\u0026gt; redisTemplate; / * Redis有什么命令，Jedis有什么方法 * Lettuce-----》RedisTemplate进一步的封装 *RedisTemplate 方法和命令是肯定不一样的 * Redis 和 String类型 * 需求输入一个key * 先判断该key是否存在如果不存在则在mysql中进行查询，写入到redis中。并返回值。 */ public String getRedisValueByKey(String key){ if (redisTemplate.hasKey(key)) { //表示存在值，进行获取 log.info(\u0026#34;-------\u0026gt; redis中查询的数据\u0026#34;); Object o = redisTemplate.opsForValue().get(key); return (String) o; }else { //不存在去mysql中查并且赋值给reids String val = \u0026#34;redis中不存在的key\u0026#34;; log.info(\u0026#34;------\u0026gt;mysql中查询出来的：\u0026#34;+val); redisTemplate.opsForValue().set(key,val); log.info(\u0026#34;------\u0026gt;mysql中查出的数据存入redis中\u0026#34;); return val; } } / * 测试String类型 * 需求：用户输入一个redis数据。该key的有效期为28小时 */ public void expireStr(String key, String val){ redisTemplate.opsForValue().set(key,val); redisTemplate.expire(key,2,TimeUnit.HOURS); } / * 根据ID查询用户对象信息 * 先判断redis中是否存在该key * 如果不存在，查询数据库中mysql中的值，并将结果添加到redis中。 * 如果存在，直接将结果在redis查询，并返回。 */ public User getHashKey(String id){ if (redisTemplate.opsForHash().hasKey(\u0026#34;user\u0026#34;,id)){ log.info(\u0026#34;-----\u0026gt;查询redis数据库\u0026#34;); return (User) redisTemplate.opsForHash().get(\u0026#34;user\u0026#34;,id); }else { log.info(\u0026#34;-----\u0026gt;查询mysql数据库\u0026#34;); User user = new User(); user.setId(id); user.setAge(18); user.setName(\u0026#34;速速\u0026#34;); /* @param h 用户的实体 @param hk 用户主键id @param hv 整个对象 */ redisTemplate.opsForHash().put(\u0026#34;user\u0026#34;,id,user); return user; } } / * 将list放入缓存中 * @param key 值 * @param list 键 * @return true 成功 false 失败 */ public boolean lpushAll(String key, List\u0026lt;Object\u0026gt; list){ try { redisTemplate.opsForList().leftPush(key, list); return true; }catch (Exception e){ e.printStackTrace(); return false; } } / * 将list放入缓存中 * @param key 值 * @param list 键 * @param time 时间（秒） * @return true 成功 false 失败 */ public boolean lpushAll(String key, List\u0026lt;Object\u0026gt; list, long time){ try { redisTemplate.opsForList().leftPushAll(key, list); if (time \u0026gt;0){ redisTemplate.expire(key,time,TimeUnit.SECONDS); } return true; }catch (Exception e){ e.printStackTrace(); return false; } } / * 在变量左边添加元素。 * @param key * @param obj * @return */ public boolean lpush(String key, Object obj){ try { redisTemplate.opsForList().leftPush(key,obj); return true; }catch (Exception e){ e.printStackTrace(); return false; } } / * 在变量左边添加元素。 * @param key 键 * @param prvot 中间参数 * @param object 要放的值 * @return 。 */ public boolean lpush(String key, Object prvot,Object object){ try { redisTemplate.opsForList().leftPush(key,prvot,object); return true; }catch (Exception e){ e.printStackTrace(); return false; } } / * 在变量左边添加元素。 * @param key 键 * @param prvot 中间参数 * @param object 要放的值 * @return 。 */ public boolean rpush(String key, Object prvot,Object object){ try { redisTemplate.opsForList().rightPush(key,prvot,object); return true; }catch (Exception e){ e.printStackTrace(); return false; } } / * 在变量左边添加元素。 * @param key 键 * @param object 要放的值 * @return 。 */ public boolean rpush(String key, Object object){ try { redisTemplate.opsForList().rightPush(key,object); return true; }catch (Exception e){ e.printStackTrace(); return false; } } / * 在变量左边添加元素。 * @param key 键 * @param object 要放的值 * @return 。 */ public boolean lpushIfPresent(String key, Object object){ try { redisTemplate.opsForList().leftPushIfPresent(key,object); return true; }catch (Exception e){ e.printStackTrace(); return false; } } / * 移除集合中的左边第一个集合 * @param key 键 * @return 返回右边第一个值 */ public Object lpop(String key) { return redisTemplate.opsForList().leftPop(key); } / * 移除集合中的右边的元素，一般用在队列取值 * @param key 键 * @return 返回右边的元素 */ public Object rpop(String key) { return redisTemplate.opsForList().leftPop(key); } / * 获取指定区间的值 * @param key 键 * @param start 开始位置 * @param end 结束位置 * @return 返回值 */ public List\u0026lt;Object\u0026gt; lrange(String key, long start, long end) { return redisTemplate.opsForList().range(key,start,end); } / * 返回当前位置上的值。 * @param key 键 * @param index 当前位置 * @return */ public Object lindex(String key, long index) { return redisTemplate.opsForList().index(key,index); } / * * @param key 键 * @param count 统计 * @param object 移除的对象 * @return */ public long remove(String key,long count, Object object){ return redisTemplate.opsForList().remove(key,count,object); } / * 获取集合长度 * @param key 键 * @return 长度 */ public long llen(String key){ return redisTemplate.opsForList().size(key); } / * 在集合的指定位置插入元素，如果指定的位置已有元素，则覆盖，没有则新增，超过集合的下标+n则会报错； * @param key 键 * @param index 位置 * @param value 值 */ public void set(String key,Long index, Object value) { } / * 截取集合元素，保留成都内地数据 * @param key 键 * @param start 开始位置 * @param end 结束位置 */ public void trim(String key,Long start, Long end) { redisTemplate.opsForList().trim(key,start,end); } / *出去集合右边的值，同时集合的左边添加一个值 * @param key 键 * @param str 入栈的值 * @return 返回对象 */ public Object rightPopAndleftPush(String key,String str) { return redisTemplate.opsForList().rightPopAndLeftPush(key,str); } / *出去集合右边的值，同时集合的左边添加一个值,如果超过等待的时间仍然没有元素则退出 * @param key 键 * @param str 左边新增的值 * @param time 超时时间 * @return 返回移除右边的值 */ public Object rightPopAndleftPush(String key,String str,long time) { return redisTemplate.opsForList().rightPopAndLeftPush(key,str,time,TimeUnit.MINUTES); } / * 删除. * @param keys */ public void del(String ... keys){ if (keys!=null || keys.length \u0026gt; 0){ if (keys.length == 1) { redisTemplate.delete(keys[0]); }else { redisTemplate.delete(CollectionUtils.arrayToList(keys)); } } } / * 设置过期时间。 * @param key 键。 * @param seconds 过期时间。 */ public void expire(String key,long seconds){ redisTemplate.expire(key,seconds,TimeUnit.SECONDS); } } 10.7 List 的应用场景 项目应用于：1、对数据量大的集合数据删除；2、任务队列\n1、对数据量大的集合数据删减\n​列表数据显示，关注列表，粉丝列表，留言评论等\u0026hellip;..分页，热点新闻等\n利用LRANG还可以很方便的实现分页的功能，在博客系统中，每片博文的评论也可以存入一个单独的list中。\n2、任务队列\n(list 通常用来实现一个消息队列，而且可以却表先后顺序，不必像MySQL那样还需要通过ORDER BY来进行排序)\n任务队列介绍(生产者和消费者模式：) 在处理web客户端发送的命令请求是，某些操作的执行时间可能会比我们预期的更长一些，通过将待执行任务的相关信息放入队列里面，并在之后队列进行处理，用户可以推迟执行那些需要一段时间才能完成的操作，这种将工作交个任务处理器来执行的做法被称为任务队列（task queue）。 RPOPLPUSH source destination 移除列表的最后一个元素，并将该元素添加到另一个列表并返回 3、List应用场景案例1\n10.8 Set类型 简介\n​Redis的Set是String类型的无需集合。集合成员是唯一的，这就意味着集合中不能出现重复的数据。Redis中集合是通过哈希表实现的，set是通过hashtable实现的\n集合中最大的成员数为2^32 -1,类似于JAVA中的Hashtable集合。\n命令\n1、复制语法： SADD KEY member1 [member2]:向集合添加一个或多个成员 2、取值语法： SCARD KEY :获取集合的成员数 SMEMBERS KEY ：返回集合中的所有成员 SISMEMBER KEY MEMBER :判断member元素是否是集合key的成员(开发中：验证是否存在判断) SRANDMEMBER KEY [COUNT] :返回集合中一个或对个随机数 3、删除语法： SREM key member1 [member2] : 移除集合中一个或多个成员 SPOP key [count] : 移除并返回集合中的一个随机元素 SMOVE source destination member :将member 元素从Source集合移动到destination集合中 4、差集语言： SDIFF key1 [key2] :返回给定所有集合的差集 SDIFFSTORE destination key1 [key2] :返回给定所有集合的茶几并存储在destination中 5、交集语言： SUNION key1 [key2] : 返回所有给定集合的并集 SUNIONSTORE destination key1 [key2] :所有给定集合的并集存储在 destinatiion集合中 10.9 ZSet类型 有序集合(sorted set)\n简介\n1、Redis有序集合和集合一样也是string类型元素的集合，且不允许重复的成员。\n2、不同的是每个元素都会关联一个double类型的分数。redis正是通过分数来为集合中的成员进行从小到大的排序。\n3、有序集合的成员是唯一的，但分数（score）却可以重复。\n4、集合是通过哈希表实现的。集合中最大的成员数为2^32 -1。Redis的ZSet是有序，且不重复。\n（很多时候，我们都将redis中的有序结合叫做zsets，这是因为在redis中，有序集合相关的操作指令都是以z开头的）\n命令\n1、复制语法： ZADD KEY score1 member1 【score2 member2】 ：向有序集合添加一个或多个成员，或者更新已经存在成员的分数 2、取值语法： ZCARD key ：获取有序结合的成员数 ZCOUNT key min max :计算在有序结合中指定区间分数的成员数 127.0.0.1:6379\u0026gt; ZADD kim 1 tian (integer) 0 127.0.0.1:6379\u0026gt; zadd kim 2 yuan 3 xing (integer) 2 127.0.0.1:6379\u0026gt; zcount kim 1 2 (integer) 2 127.0.0.1:6379\u0026gt; ZRANK key member :返回有序集合中指定成员的所有 ZRANGE KEY START STOP [WITHSCORES]:通过索引区间返回有序集合成指定区间内的成员(低到高) ZRANGEBYSCORE KEY MIN MAX [WITHSCORES] [LIMIT] :通过分数返回有序集合指定区间内的成员 ZREVRANGE KEY START STOP [WITHSCORES] :返回有序集中是定区间内的成员，通过索引，分数从高到底 ZREVERANGEBYSCORE KEY MAX MIN [WITHSCORES] :返回有序集中指定分数区间的成员，分数从高到低排序 删除语法： DEL KEY : 移除集合 ZREM key member [member...] 移除有序集合中的一个或多个成员 ZREMRANGEBYSCORE KEY MIN MAX :移除有序集合中给定的分数区间的所有成员。 ZREMRANGEBYSCORE KEY MIN MAX :移除有序集合中给定的分数区间的所有成员。 ZINCRBY KEY INCREMENT MEMBER :增加member元素的分数increment，返回值是更改后的分数 10.10 HyperLogLog 常用命令\nPFADD key element [element ...] : 添加指定元素到HyperLoglog中 PFCOUNT KEY [key ...] :返回给定 HyperLogLog的基数估算值 PFMERGE destkey sourcekey [sourcekey ...] :将过个HyperLogLog 合并为一个HyperLoglog 应用场景\n基数不大，数据量不大就用不上，会有点大材小用浪费空间\n有局限性，就是指能统计基数数量，而没办法去知道具体的内容是什么\n统计注册 IP 数 统计每日访问 IP 数 统计页面实时 UV 数 统计在线用户数 统计用户每天搜索不同词条的个数 统计真实文章阅读数 10.11 geospatial 地理位置 GEORANDIUSBYMEMBER 找出指定元素周围的其他元素\n十一、SpringBoot整合Jedis 11.1 简介 ​我们在使用springboot搭建微服务的时候，在很多时候还是需要redis的高速缓存来缓存一些数据，存储一些高品率访问的数据，如果直接使用redis的话由比较麻烦，在这里，我们使用jedis来实现redis缓存达到高效缓存的目的。\n11.2 引入Jedis依赖 \u0026lt;!-- https://mvnrepository.com/artifact/redis.clients/jedis --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;redis.clients\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jedis\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.2.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 因为SpringBoot内默认引用了jedis版本。\n所以我们直接引入jedis依赖无需配置jedis的版本号了。\n11.3 application.yml 例如 在application.yml中配置如下信息：\n十二、SpringBoot2.x中redis使用（lettuce） java代码操作Redis，需要使用Jedis，也就是redis支持java的第三方类库 注意：Jedis2.7以上的版本才支持集群操作 12.1 maven配置 新建SpringBoot2.0.3的WEB工程，在MAVEN的pom.xml文件中加入如下依赖\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;project xmlns=\u0026#34;http://maven.apache.org/POM/4.0.0\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\u0026#34;\u0026gt; \u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt; \u0026lt;parent\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-parent\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.3.1.RELEASE\u0026lt;/version\u0026gt; \u0026lt;relativePath/\u0026gt; \u0026lt;!-- lookup parent from repository --\u0026gt; \u0026lt;/parent\u0026gt; \u0026lt;groupId\u0026gt;com.tyx\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;lettuce-demo\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.0.1-SNAPSHOT\u0026lt;/version\u0026gt; \u0026lt;name\u0026gt;lettuce-demo\u0026lt;/name\u0026gt; \u0026lt;description\u0026gt;Demo project for Spring Boot\u0026lt;/description\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;java.version\u0026gt;1.8\u0026lt;/java.version\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- 默认是lettuce客户端 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-data-redis\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- redis依赖common-pool 这个依赖一定要添加 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.commons\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;commons-pool2\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.8.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-devtools\u0026lt;/artifactId\u0026gt; \u0026lt;scope\u0026gt;runtime\u0026lt;/scope\u0026gt; \u0026lt;optional\u0026gt;true\u0026lt;/optional\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.projectlombok\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;lombok\u0026lt;/artifactId\u0026gt; \u0026lt;optional\u0026gt;true\u0026lt;/optional\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-test\u0026lt;/artifactId\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;exclusions\u0026gt; \u0026lt;exclusion\u0026gt; \u0026lt;groupId\u0026gt;org.junit.vintage\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;junit-vintage-engine\u0026lt;/artifactId\u0026gt; \u0026lt;/exclusion\u0026gt; \u0026lt;/exclusions\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;build\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/build\u0026gt; \u0026lt;/project\u0026gt; 12.2 视频中的代码 POM文件\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;project xmlns=\u0026#34;http://maven.apache.org/POM/4.0.0\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\u0026#34;\u0026gt; \u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt; \u0026lt;parent\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-parent\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.3.1.RELEASE\u0026lt;/version\u0026gt; \u0026lt;relativePath/\u0026gt; \u0026lt;!-- lookup parent from repository --\u0026gt; \u0026lt;/parent\u0026gt; \u0026lt;groupId\u0026gt;com.tyx\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;lettuce-demo\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.0.1-SNAPSHOT\u0026lt;/version\u0026gt; \u0026lt;name\u0026gt;lettuce-demo\u0026lt;/name\u0026gt; \u0026lt;description\u0026gt;Demo project for Spring Boot\u0026lt;/description\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;java.version\u0026gt;1.8\u0026lt;/java.version\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- 默认是lettuce客户端 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-data-redis\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- redis依赖common-pool 这个依赖一定要添加 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.commons\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;commons-pool2\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.8.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-devtools\u0026lt;/artifactId\u0026gt; \u0026lt;scope\u0026gt;runtime\u0026lt;/scope\u0026gt; \u0026lt;optional\u0026gt;true\u0026lt;/optional\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.projectlombok\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;lombok\u0026lt;/artifactId\u0026gt; \u0026lt;optional\u0026gt;true\u0026lt;/optional\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-test\u0026lt;/artifactId\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;exclusions\u0026gt; \u0026lt;exclusion\u0026gt; \u0026lt;groupId\u0026gt;org.junit.vintage\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;junit-vintage-engine\u0026lt;/artifactId\u0026gt; \u0026lt;/exclusion\u0026gt; \u0026lt;/exclusions\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;build\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/build\u0026gt; \u0026lt;/project\u0026gt; RedisConfig\npackage com.tyx.config; import org.springframework.cache.annotation.CachingConfigurerSupport; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory; import org.springframework.data.redis.core.RedisTemplate; import org.springframework.data.redis.serializer.GenericJackson2JsonRedisSerializer; import org.springframework.data.redis.serializer.StringRedisSerializer; import org.springframework.stereotype.Component; import java.io.Serializable; / * @author papi * @data 2020/7/15 */ @Configuration public class RedisConfig { @Bean public RedisTemplate\u0026lt;String, Object\u0026gt; redisTemplate(LettuceConnectionFactory factory){ RedisTemplate\u0026lt;String, Object\u0026gt; redisTemplate = new RedisTemplate\u0026lt;\u0026gt;(); redisTemplate.setKeySerializer(new StringRedisSerializer()); redisTemplate.setValueSerializer(new GenericJackson2JsonRedisSerializer()); redisTemplate.setConnectionFactory(factory); return redisTemplate; } } User\npackage com.tyx.po; import lombok.Data; import java.io.Serializable; / * @author papi * @data 2020/7/15 */ / * Java常用编码规范 * Java规范 */ @Data public class User implements Serializable { private String name; private int age; private String id; } UserServiceImpl\npackage com.tyx.service.impl; import com.tyx.po.User; import lombok.extern.slf4j.Slf4j; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.data.redis.core.RedisTemplate; import org.springframework.stereotype.Service; import java.io.Serializable; import java.util.concurrent.TimeUnit; / * @author papi * @data 2020/7/15 */ @Service @Slf4j public class UserServiceImpl { @Autowired private RedisTemplate\u0026lt;String, Object\u0026gt; redisTemplate; / * Redis有什么命令，Jedis有什么方法 * Lettuce-----》RedisTemplate进一步的封装 *RedisTemplate 方法和命令是肯定不一样的 * Redis 和 String类型 * 需求输入一个key * 先判断该key是否存在如果不存在则在mysql中进行查询，写入到redis中。并返回值。 */ public String getRedisValueByKey(String key){ if (redisTemplate.hasKey(key)) { //表示存在值，进行获取 log.info(\u0026#34;-------\u0026gt; redis中查询的数据\u0026#34;); Object o = redisTemplate.opsForValue().get(key); return (String) o; }else { //不存在去mysql中查并且赋值给reids String val = \u0026#34;redis中不存在的key\u0026#34;; log.info(\u0026#34;------\u0026gt;mysql中查询出来的：\u0026#34;+val); redisTemplate.opsForValue().set(key,val); log.info(\u0026#34;------\u0026gt;mysql中查出的数据存入redis中\u0026#34;); return val; } } / * 测试String类型 * 需求：用户输入一个redis数据。该key的有效期为28小时 */ public void expireStr(String key, String val){ redisTemplate.opsForValue().set(key,val); redisTemplate.expire(key,2,TimeUnit.HOURS); } / * 根据ID查询用户对象信息 * 先判断redis中是否存在该key * 如果不存在，查询数据库中mysql中的值，并将结果添加到redis中。 * 如果存在，直接将结果在redis查询，并返回。 */ public User getHashKey(String id){ if (redisTemplate.opsForHash().hasKey(\u0026#34;user\u0026#34;,id)){ log.info(\u0026#34;-----\u0026gt;查询redis数据库\u0026#34;); return (User) redisTemplate.opsForHash().get(\u0026#34;user\u0026#34;,id); }else { log.info(\u0026#34;-----\u0026gt;查询mysql数据库\u0026#34;); User user = new User(); user.setId(id); user.setAge(18); user.setName(\u0026#34;速速\u0026#34;); /* @param h 用户的实体 @param hk 用户主键id @param hv 整个对象 */ redisTemplate.opsForHash().put(\u0026#34;user\u0026#34;,id,user); return user; } } } 测试类\npackage com.tyx; import com.tyx.po.User; import com.tyx.service.impl.UserServiceImpl; import lombok.AllArgsConstructor; import org.junit.jupiter.api.Test; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.boot.test.context.SpringBootTest; @SpringBootTest class LettuceDemoApplicationTests { @Autowired private UserServiceImpl userService; @Test void contextLoads() { } @Test void T1 (){ String tyx = userService.getRedisValueByKey(\u0026#34;tyx\u0026#34;); System.out.println(\u0026#34;返回redis中的值为：\u0026#34; + tyx); } @Test void T2(){ User hashKey = userService.getHashKey(\u0026#34;1003\u0026#34;); System.out.println(hashKey); } } 12.3 查看Redis客户端信息 原因：把任何数据保存到redis中时，都需要进行序列化，默认使用JdkSerializationRedisSerializer进行数据序列化。所有的key和value还有hashkey和hashvalue的原始字符前，都加了一串字符。\n十三、Redis的发布订阅 13.1 redis发布订阅简介 Redis 发布订阅(pub/sub)是一种消息通信模式：发送者（pub）发送消息，订阅者（sub)接受消息。\nRedis客户端可以订阅任意数量的频道\nRedis 发布订阅(pub/sub)是一种消息通信模式：发送者（pub）发送消息，订阅者（sub)接受消息。 Redis 客户端可以订阅任意数量的频道。 下图展示了频道channel1，以及订阅这个频道的三个客户端---client2，client5和client1之间的关系。 //订阅端 SUBSCRIBE redischannel Reading messages ...(press ctrl-c quit) //发送端 PUBLIC redischannel \u0026#34;redis channel\u0026#34; 十四、Redis多数据库 14.1 Redis下，数据库是由一个整数索引标识，而不是一个数据库名称。默认情况下，一个客户端连接到数据库0 redis配置问阿金中下面的参数来控制数据库总数：\ndatabase 16 //（从0开始 1,2,3\u0026hellip;15）\nselect 数据库 //数据库的切换\n移动数据(将当前key移动另一库)\nmove key 名称 数据库 14.2 数据库清空 flushdb ：清除当前数据库的所有key flushall :清除整个redis的数据库所有key 十五、Redis事务 Redis事务可以一次执行多个命令，（按顺序地串行化执行，执行中不会被其他命令插入，不许加塞）\n简介\nRedis事务可以一次指定多个命令（允许在一个单独的步骤中执行一组命令），并且带有一下两个中要的保证：\n批量操作在发送EXEC命令前被放入队列缓存。 收到EXEC命令后进入事务执行，事务中任意命令执行失败，其余命令依然被执行。 在事务执行过程中，其他客户端提交的命令请求不会插入到事务执行命令列中。 Redis会将一个事务中的所有命令序列化，然后按顺序执行 执行中不会被其它命令插入，不许出现加赛行为 常用命令\nDISCARD : 取消事务，放弃执行事务块内的所有命令。 MULTI : 标记一个事务块的开始。 EXEC : 执行所有事务块内的命令。 UNWATCH: 取消watch命令对所有key的监视。 WATCH KEY [KEY ...] :监视一个(或多个)key，如果在事务执行之前这个(或这些)key被其他命令所改动，那么事务将被打断。 一个事务从开始到执行会经历以下三个阶段：\n1、开始事务。\n2、命令入队。\n3、执行事务。\n15.1示例 1 MULTI EXEC 转账功能，A向B转账50元\n一个事务的例子，它先以MULTI开始一个事务，然后将多个命令入队到事务中，最后由EXEC命令触发事务\n输入Multi命令开始，输入的命令都会一次进入命令队列中，但不会执行 知道输入Exce后，Redis会将之前的命令队列中的命令一次执行。 15.2 示例 DISCARD放弃队列运行 输入MULTI命令，输入的命令都会依次进入命令队列中，但不会执行。 直到输入Exec后，Redis会将之前的命令队列中的命令依次执行。 命令队列的过程中可以使用命令DISCARD来放弃队列运行。 15.3 示例3事务的错误处理 事务的错误处理：\n如果执行的某个命令报出了错误，则只有报错的命令不会被执行，而其他的命令都会执行，不会回滚。\n15.4 示例4 事务的错误处理 事务的错误处理：\n队列中的某个命令出现了 报告错误，执行是整个的所有队列都会被取消。\n由于之前的错误，事务执行失败\n15.5 示例5 事务的watch WATCH key [key ...] :监视一个(或多个)key，如果在事务执行前这个(或这些)key被其他命令所改动，那么事务将被打断。 需求：某一账户在一事务内进行操作，在提交事务前，另一个进程对该账户进行操作。\n15.6 应用场景 一组命令必须同时都执行，或者都不执行。\n我们想要保证一组命令在执行的过程之中不被其他命令插入。\n案例： 秒杀\n15.7 Redis事务的总结 Redis事务本质：一组命令的集合！一个事务中的所有命令都会被序列化，在事务执行过程中，会按照顺序执行！一次性，顺序性，排他性！执行一些列的命令！\nRedis事务没有隔离级别的概念！\n所有的命令在事务中，并没有直接被执行！只有发起执行命令的时候才会执行！Exec\nRedis单条命令保存原子性，但是事务不保证原子性！\nRedis 事务其实是支持原子性的！即使 Redis 不支持事务回滚机制，但是它会检查每一个事务中的命令是否错误。\n十六、Redis持久化 16.1 什么是Redis 持久化？ 持久化就是把内存的数据写到磁盘中去，防止府服务宕机内存数据丢失。\nRedis提供了两种持久化方式：RDB(默认)和AOF\n简介\n数据存放于：\n内存：高效，断电（关机）内存数据会丢失\n硬盘：读写速度慢于内存，断电数据不会丢失\nRedis持久化存储支持两种方式：RDB和AOF。RDB一定时间取存储文件，AOF默认每秒去存储历史命令，\nRedis是支持持久化的内存数据库，也就是说redis需要经常将内存中的数据同步到硬盘来保证持久化。\n16.2 RDB RDB是Redis DataBase缩写\nRedis是内存数据库，如果不将内存中的数据库状态保存到磁盘中，那么一旦服务器进程退出，服务器中的数据库的状态也会消失。造成数据的丢失，所以redis提供了持久化的功能。\n在指定的时间间隔内将内存中的数据集快照写入磁盘，也就是所说的snapshot快照，它恢复是将卡UN关照文件爱你直接读到内存里。\nRedis会单独创建（fock）一个子进程来进行持久化，会先将数据写入到一个临时文件中，待持久化过程都结束了，在用这个临时文件替换上次持久化好的文件。整个过程中，主进程是不进行任何IO操作的。这就确保了极高的性能。如果需要进行大规模的数据的恢复，且对于数据恢复的完整性不死非常敏感，那RDB方式要比AOF 方式更加的高效。RDB的缺点是最后一次持久化的数据可能丢失。\n功能核心函数rdbSave（生成RDB文件）和rdbLoad（从文件加载内存）两个函数\nrdbSave：生成RDB文件 rdbLoad：从文件夹杂内存 RDB : 是redis默认的持久化机制\n快照是默认的持久化方式。这种方式就是将内存中数据以快照的方式写入到二进制文件中，默认的文件名为dump.rdb。\n优点：\n快照保存数据极快，还原数据极快 适用于灾难备份 缺点：\n小内存机器不适合使用，RDB机制符合要求就会照快照 快照条件：\n1、服务器正常关闭：./bin/redis-cli shutdown 2、key满足一定条件，会进行快照 vim redis.config 搜索save /save save 900 1 //每秒900秒（15分钟）至少1个key发生变化，产生快照 save 300 10 //每300秒 （5分钟）至少10个key发生变化，产生快照 save 60 10000 //每60秒（1分钟）至少10000个key发生变化，产生快照 16.3 AOF 由于快照方式是在一定间隔时间做一次的，所以如果redis意外down掉的话，就会丢失最后一个快照后的所有修改。如果应用要求不能丢失任何修改的话，可以采用aof持久化方式。\nAppend-only file：aof比rdb有更好的持久化性，是由于在使用aof持久化方式是，redis会将每一个收到的命令都通过write函数追加到文件中（默认是appendonly.aof)。当redis重启是会通过重新执行文件中保存的写命令来在内存冲重建整个数据库的内容。\n每当执行服务器（定时）任务或者函数时flushAppendOnlyFile函数都会被调用，这个函数执行以下两个工作aof写入保存：\nWRITE：根据条件，将aof_buf中的缓存写入到AOF文件。\nSAVE：根据条件，调用fsync或fdatasync函数，将AOF文件保存到磁盘中。\n有三种方式如下（默认是：每秒fsync一次）\nappendonly yes //启用aof持久化方式 # appendfsync always //收到写命令就立即写入磁盘，最慢，但是保证完全的持久化 appendfysnceverysec //每秒钟写入磁盘一次，在性能和持久化方面做了很好的折中 # appendfysnc no //完全依赖os，性能孔，持久化没保证 产生的问题：\n​aof的方式也同时带来了另一个问题。持久化文件会变的越来越大。例如我们调用incr test命令 100次，问价中必须保存全部的1000条命令，其实有99条都是多余的。\n十七、Redis缓存与数据库一致性 17.1 实时同步 对强一直要求比较高的，应采用实时同步方案，即查询缓存查询不到在从DB查询，保存到缓存；更新缓存时，先更新数据库，在将缓存的设置过期（建议不要去更新缓存内容，直接设置缓存过期）。\n@Cacheable：查询时使用，注意Long类型需要转换为String类型，否则会抛异常\n@CachePut：跟新是使用，使用此注解，一定会从DB上查询数据\n@CacheEvict：删除时使用；\n@Caching ：组合用法\n17.2 异步队列 对于并发程度高的，可采用异步队列的方式同步，可采用kafka等消息中间件处理消息生产和消费。\n17.3 使用阿里的同步工具canal 17.4 采用UDF自定义函数的方式 面对mysql的API进行编程，利用触发器进行缓存同步，但UDF主要是C/C++语言实现，学习成本高。\n十八、总结 18.1 缓存穿透 缓存穿透是指查询一个一定不存在的数据，由于缓存时不命中时需要从数据库查询，查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到数据库去查询，造成缓存穿透。\n解决办法：持久层查询不到就缓存空结果，查询时先判断缓存中是否exists(key)，如果有直接返回空，没有则查询后返回，\n注意insert时需要清除查询的key，否则即便DB中有值也查询不到（当然可以设置空缓存的过去时间）\n概念\n缓存穿透的概念很简单，用户想要查询一个数据没法安redis内存数据库没有，也就是缓存没有命中，于是向持久层数据量查询。发现也没有，于是本次查询失败。当用户很多的时候，缓存都没有命中，于是都去请求持久层数据库，这会给持久层数据库造成很大的压力，这时候就相当于出现了缓存穿透。\n解决方案\n18.1.1 布隆过滤器 布隆过滤器是一种数据结构，对所有可能查询的参数以hash形式存储，在控制层先进行校验，不符合则丢弃，从而避免了对底层存储系统的查询压力；\n但是这种方法存在两个问题：\n1、如果空值能够被缓存起来，这就意味着缓存需要更过的空间村粗更过的键，因为这当中可能回有很多的空值的键；\n2、即使对空值设置了过期时间，还是会存在缓存层和存储层的数据会有一段时间窗口的不一致，这对于需要保持一致性的业务会有影响；\n18.1.2 缓存击穿 概念\n这里需要主要的是缓存击穿的区别，缓存击穿，是指一个key非常热点，在不停的扛着大并发，大并发集中对这一个点进行访问，当这个key在失效的瞬间，持续的大并发就穿破缓存，直接请求数据库，就行在一个屏幕上凿开一个洞\n当某个key在过期的瞬间，有大量的请求并发访问，这类数据一般是热点数据，由于缓存过期，会同时访问数据库来查询最新数据，并且回写缓存，会导致数据库瞬间压力过大。\n解决方案\n设置热点数据永不过期\n从缓存层面来看，没有设置过期时间，所有不会出现热点key过期后产生的问题。\n加锁互斥\n分布式锁：使用分布式锁，保证对于每个key同时只有一个线程去查询后盾服务，其他线程没有获得分布式锁的权限，因此只需要等待即可，这种方式将高并发的压力转移到了分布式锁，因此对分布式锁的考验很大。\n18.2 雪崩 雪崩：缓存大量失效的时候，引发大量查询数据库。\n解决办法：\n​用锁/分布式锁或者队列串行访问\n​ 缓存失效时间均匀分布\n如果缓存集中在一端时间内失效，发生大量的缓存穿透，所有的查询都落在数据库上，造成了缓存雪崩。 这个没有完美解决办法，但是可以分析用户的行为，尽量让失效时间点均匀分布。大所属系统设计者考虑用加锁或者队列的方式保证缓存的单线程写，从而避免失效时大量的并发请求落到底层存储系统上。 加锁排队。限流\u0026mdash;限流算法\n在缓存失效后，通过加锁或者队列来控制读数据库写缓存的线程数量。比如对某个key只允许一个线程查询数据和写缓存，其他线程等待。\n简单地来说，就是在缓存失效的时候（判断拿出来的值为空），不是立即去load db，而是先使用缓存工具的某些带成功操作返回值的操作（比如Redisde SETNX或者Memcache的ADD）去set一个mutex key，当操作返回成功是，在进行koad db 的操作应设缓存；否则，就重试整个get缓存的方法。\nSETNX ,是【SET IF NOT EXISTS]的缩写，也就是只有不存在的时候才设置，可以利用它来实现锁的效果。\n数据预热\n可以通过缓存reload机制，预选去更新缓存，再即将发生大并发访问前手动触发加载缓存不同的key，设置不同的过期时间，让缓存失效的时间点尽量均匀。\n18.3 热点key ​热点key：某个key访问非常频繁。当key失效的时候有大量线程来构建缓存，导致负载增加，系统崩溃。\n解决办法：\n使用锁，单机用synchronized ， lock等，分布式使用分布式锁 缓存过期时间不设置，而是设置在key对应的value里。如果检测到存的时间超过过期时间则 异步跟新缓存。 在value设置一个比过去时间t0小的过期时间值t1,当t1过期的时候，延长t1并做更新缓存操作。 设置标签缓存，标签缓存设置过期时间，标签缓存过期后，需异步地跟新实际缓存。 案例\n假设并发有10000个请求，想达到对个请求从数据库中获取，其他9999个请求冲redis中获取这种效果 双重检测锁测压：\n十九、可能的问题 一般来说，要将redis运用于工程项目中，只是用一台Redis是万万不能的，原因如下：\n1、从结构上，单个Redis服务器会发生单点故障，并且一台服务器需要处理所有的请求负载，压力较大；（容错性）\n2、从容量上，单个redis服务器内存容量有限，就算一台redis服务器内存容量为256G，也不能将所有内容用作Redis存储内存，一般来说，单台Redis最大使用内存不应该超过20G。\n问题：\n内存容量有限 处理能力有限 无法高可用。 二十、主从复制 简介\n电子商务网站上的商品，一般都是一次上传，无数次的浏览的，说专业点的也就是“多读少些”。\n20.1主从复制 一个Redis服务可以有多个该服务的复制品，这个Redis服务成为Master，其他的复制成为Slaves\n如图中所示：我们将一台Redis服务器作为主库（master），其他的三台作为（salve），主库负责写数据，每次有数据跟新都更新的数据同步到它的所有的从库，而从库只负责读数据。这样一来，就有了两个好处：\n1、读写分离：不仅可以提高服务器的负载能力，并且可以根据读请求的规模自由增加或者减少从库的数据。\n2、数据被复制成了好几份，就算一台机器出现故障，也可以使用其它机器的数据快速的恢复。\n需要注意的是：Redis主从复制模式中，一台主库可以用用多个从库，一个从库只能属于一个主库。\n20.2 Redis主从复制配置 在Redis中，要实现主从复制架构非常的简单，只需要在从数据库的配置文件中加上如下命令即可：\n1、主数据库不需要任务配置，创建爱哪一个从数据库：\nredis.config（配置文件信息）\n-- port 6380 : 从服务的端口号 --slaveof 127.0.0.1 6379 ：指定主服务器 2、启动从数据库：\n./bin/redis-server ./redis.conf --port 6380 --slaveof 127.0.0.1 6379 3、登录到从服务客户端\n./bin/redis-cli -p 6380 -a redis 4、哨兵模式\n简介\nRedis-Sentinel(哨兵模式)是高可用解决方案，当redis在做master-slave的高可用方案时，假如master宕机了，redis本身（以及其很多客户端）都没有实现自动进行主备切换，而redis-sentinel本身是独立运行的进程，可以部署在其他的与redis集群可通讯的机器中监控redis集群。 有了主从复制的实现之后，我们如果想从服务器进行监控，那么在redis2.6以后提供了有个“哨兵”机制，并在2.8版本以后功能稳定起来。 哨兵：故名司仪，就是监控Redis系统的运行状况。 哨兵模式的特点\n1、不时地监控redis是否按照预期良好地运行； 2、如果发现某个redis 节点运行出现状况，能够通知另外一个进程（例如它的客户端）； 3、能够进行自动切换。当一个master节点不可用时，能够选举出master的多个slave(如果有超过一个slave的话)中的一个来作为新的master，其他的slave节点会将它所追随的master地址改为被提升为master的salve的新地址。 4、哨兵为客户端提供服务发现，客户端连接哨兵，哨兵提供当前master的地址然后提供服务，如果出现切换，也就是master挂了，哨兵会提供客户端一个新地址。 20.3 基本概述 高可用\n\u0026ldquo;高可用性（High Availability）\u0026ldquo;通常用来描述一个系统经过专门的设计，从而减少停工时间，而保证器服务的高可用性。（一直都能用）\n高可用：6个99.9999% 全年停机不超过32秒。\n高并发\n高并发 （High Concurrentcy）是互联网分布式系统架构设计中必须考虑的因素之一，它通常是指，通过设计在保证系统能够同时并行处理的很多请求。\n高并发相关商用的一些指标有如下：\n响应时间（Response Time） 吞吐量（Throughput） 每秒查询率QPS（Query Pre Second），并发用户数等。 响应时间：系统对请求做出响应的时间，例如系统处理一个HTTP请求需要200ms，这个200ms就是系统的响应时间。\n吞吐量：单位时间内处理的请求数量。\nQPS ：每秒响应请求数。在互联网领域，这个指标和吞吐量区分的没有那么明显。\n并发用户：同时承载正常使用系统功能的用户数量。例如一个即使通讯系统，同时在线量一定程度上代表\n20.4 主从复制的主要作用包括 1、数据冗余：主从复制实现了数据热备份，是持久化之外的一种数据冗余的方式。\n2、故障恢复：当主节点出现 问题时，可以由从节点提供服务，实现快速的故障恢复；世界上是以一种服务的冗余。\n3、负载均衡：在主从复制的基础上，配合读写分离，可以由节点提供写的服务，由从节点提供提供读服务（即写redis数据时应用及连接主节点，读redis数据时应该用从节点），人丹服务器的负载；尤其在写少读多的场景下，通过多个从节点分担读负载，可以大大提高redis服务器的并发量。\n4、高可用的基石：除了上述作用以外，主从复制还是哨兵和集群能够实施的基础，因此说主从复制是redis高可用的基础。\n20.5 主从复制的原理 Slave 启动成功连接到master后会发送一个sync命令\nMaster接收到名，启动后台的存盘进程，同时收集所有接受到的用于修改数据集命令，在后台进程执行完毕后，master将传送的数据文件到slave，并完成一次完全同步\n全量复制：而slave服务在接受到数据库文件数据后，将其存盘并加载内存中。\n增量文件：Master继续将新的所有收集的修改命令一次传给slave，完成同步\n但是只要是重新连接master，一次完全同步（全量复制）将别自动执行。\n二十一、Redis Cluster集群 简介\n21.1 集群模式是实际使用最多的模式 Redis Cluster是社区版推出的Redis分布式集群解决方案，主要解决Redis分布式方面的需求，比如，当遇到单机内存，并发和流量等瓶颈的时候，Redis Cluster能起到很好的的负载均衡的目的。\n为什么使用redis-cluster？\n为了在大流量访问下提供稳定的业务，集群化时存储的必然形态 未来的发展趋势可定是云计算和大数据的紧密结合 只有分布式架构能满足需求 21.2 集群描述 Redis集群搭建方案：\n(1)、Twitter开发的twemproxy (2)、豌豆荚开发的codis (3)、redis观法的redis-cluster Redis集群搭建的方式有很多种，但从redis 3.0 之后变动表呢支持redis-cluster集群，志超需要3（master）+3（Slave）才能简历集群。Redis——Cluster采用无中心结构，没个节点保存数据和整个集群状态，每个节点都和其他所有 节点连接。其redis-cluster架构图如下所示：\nRedis Cluster集群几点最小配置6个节点以上（3主3从），其中主节点提供读写操作，从节点作为备用节点，不提供请求，只作为故障转移使用。\nRedis Cluster集群特点\n1、所有的redis节点彼此互联（PING-PONG)，内部使用二进制协议优化传输速度和带宽。\n2、节点的fail是通过集群中超过半数的节点检测失效时才生效。\n3、客户端与redis节点直连，不需要中间proxy层。客户端不需要连接集群所有节点，连接集群中任何一个可用节点即可。\n4、redis-cluster把所有的物理节点映射到[0-16383]slot上（不一定是平均分配），cluster负责维护\n5、redis集群预先分好16384个哈希槽，当需要在redis集群中放置一个key-value时，redis先对key使用crc16算法算出一个结果，然后把结果对16384求余数，这样对每个key都会对应一个编号在0-16383之间的哈希槽，redis会根据节点数量大致均等的将哈希槽映射到不同的节点。\n21.3 Redis Cluster集群搭建 集群搭建参考官网：\n​redis集群需要至少三个master节点，我们这里搭建三个master节点，并且给每个master在搭建一个slave节点，总共6个节点，这里用一台机器（可以多台机器部署，修改一下ip地址就可以了）部署6个redis实例，三主三从。搭建集群的步骤如下：\n创建Redis节点安装目录\nmkdir /root/apps/redis_cluster ：指定目录下 创建 redis_cluster 在redis_cluster目录，创建7000-7005 6个文件夹下\nmkdir 70000 70001 70002 70003 70004 70005 并将redis-conf分别拷贝到70000-70005文件夹下\ncp /opt/redis-5.0.8/redis.conf ./70000 修改Redis配置文件\n/root/apps/redis_cluster/70000 # 关闭保护模式 用于公网访问 protected-mode no port 70000 # 开启集群模式 cluster-enabled yes cluster-config-file nodes-70000.config cluster-node-timeout 5000 # 后台启动 daemonize yes pidfile /var/run/redis_70000.pid logfile \u0026#34;70000.log\u0026#34; # dir /redis/data # 此处绑定ip,可以是阿里内网ip和本地ip也可以直接注释掉该项 # bind 127.0.0.1 # 用于连接主节点密码 masterauth redis #设置redis密码 各个几点请保持密码一致 requirepass redis 依次复制并修改6个redis.conf\ncp ./70000/redis.conf ./70001 :依次进行复制 vim ./70001/redis.conf : 执行 %s/old/new/g 全部替换 ：wq 保存并退出 即可 6、依次启动6个节点\n将安装的redis目录下的src复制到cluster下，方便启动服务端\ncd /opt/redis-5.0.8 :进入redis安装目录 cp -r ./src/ /usr/local/redis_cluster/ :将src文件复制到redis——cluster目录中 ./src/redis-server ./7000/redis.conf ./src/redis-server ./7001/redis.conf ./src/redis-server ./7002/redis.conf ./src/redis-server ./7003/redis.conf ./src/redis-server ./7004/redis.conf ./src/redis-server ./7005/redis.conf 启动后，可以用PS查看进程：\nps -ef | grep -i redis 创建集群\nRedis 5版本后 通过redis-cli 客户端命令来创建集群。\n./src/redis-cli --cluster create -a redis 127.0.0.1:7000 127.0.0.1:7001 127.0.0.1:7002 127.0.0.1:7003 127.0.0.1:7004 127.0.0.1:7005 --cluster-replicas 1 Performing hash slots allocation on 6 nodes Trying to optimize slaves allocation for anti-affinity [OK] All 16384 slots covered. Redis Cluster集群验证\n在某台机器上（或）连接集群的7001端口的几点：\nredis-cli -h 127.0.0.1 -c -p 7000 -a redis :加参数 -c 可以连接到集群 redis cluster在设计的时候，就考虑了去中心化，去中间件，也就是说集群中的每个节点都是平等的关系，都是对等的，每个几点都保存各自的数据和整个集群的状态。每个节点都和其他所有节点连接，而且这些连接保持活跃，这样就保证了我们只需要连接集群中的任意一个节点，就可以获取到其他节点的数据。\n基本命令\ninfo replication 通过Cluster Nodes 命令和Cluster Info命令来看看集群的效果\n127.0.0.1:7000\u0026gt; info replication # Replication role:master connected_slaves:1 slave0:ip=127.0.0.1,port=7004,state=online,offset=1026,lag=1 master_replid:2c2851db4bea0ea2f9d93d60a065e868112c47d7 master_replid2:0000000000000000000000000000000000000000 master_repl_offset:1026 second_repl_offset:-1 repl_backlog_active:1 repl_backlog_size:1048576 repl_backlog_first_byte_offset:1 repl_backlog_histlen:1026 127.0.0.1:7000\u0026gt; 输入命令cluster nodes\n127.0.0.1:7000\u0026gt; cluster nodes c58e7d40e34251897af3bee6bc6edd7a500f9fa6 127.0.0.1:7005@17005 slave 3a7ac96a39a41b395d5459eeac1f17d1f6fd96d7 0 1596391181092 6 connected 71e898b018d1775214a431bd22b3408b055dbb62 127.0.0.1:7003@17003 slave 5a191a63e8c2f5dbe945451bca0552426d6e9260 0 1596391182096 4 connected 60335b82c5348215c0dbbbac5b65c769f6668e4e 127.0.0.1:7000@17000 myself,master - 0 1596391181000 1 connected 0-5460 5a191a63e8c2f5dbe945451bca0552426d6e9260 127.0.0.1:7002@17002 master - 0 1596391183102 3 connected 10923-16383 9cae9ebf31a03c09a82281dcb629aac418e22831 127.0.0.1:7004@17004 slave 60335b82c5348215c0dbbbac5b65c769f6668e4e 0 1596391182000 5 connected 3a7ac96a39a41b395d5459eeac1f17d1f6fd96d7 127.0.0.1:7001@17001 master - 0 1596391182598 2 connected 5461-10922 每个Redis的节点都有一个ID值，此ID将被此特定redis实例永久使用，以便实例在集群上下文中具有唯一的名称。每个节点都都会记住使用此ID的每个其他节点，而不是通过IP或端口号。IP地址和端口可能会发生变化，但唯一的节点标识符在节点的整个生命周期内都不会改变。我们简单称这个标识符为节点ID。\n21.4 Redis总结 简介：\n​ redis cluster 为了保证数据的高可用性，加入了主从模式，一个节点对应一个或多个从节点，主节点提供数据存取，从节点则是从主节点拉去数据备份，当这个主节点挂掉后，就会有这个从节点选取一个来充当主节点，从而保证集群不会挂掉。\n集群有ABC三个主节点，如果这3个几点都没有加入从节点，如果B挂掉了，我们就无法访问整个集群了。A和C的slot也无法访问。\n所以我们集群建立的时候，一定腰围每个主节点都添加一个从节点，比如像这样，集群包含主节点A,B,C 以及从节点A1,B1,C1，那么及时B挂掉系统也可以继续正确工作。\nB1节点代替了B节点，所有Redis集群将会选择B1节点作为新的主节点，集群将会继续正确的提供服务。当B重新开启后，它就变成B1的从节点。\n不过需要注意，如果几点B和B1同时挂掉，Redis集群就无法继续正确的提供服务了。\n21.5 关闭集群 在/root/apps/redis_cluster 目录下编写脚本文件 ： vim shutdowm.sh\n内容如下：\n/root/apps/redis_cluster/src/redis-cli -c -h 127.0.0.1 -p 7000 -a redis shutdown /root/apps/redis_cluster/src/redis-cli -c -h 127.0.0.1 -p 7001 -a redis shutdown /root/apps/redis_cluster/src/redis-cli -c -h 127.0.0.1 -p 7002 -a redis shutdown /root/apps/redis_cluster/src/redis-cli -c -h 127.0.0.1 -p 7003 -a redis shutdown /root/apps/redis_cluster/src/redis-cli -c -h 127.0.0.1 -p 7004 -a redis shutdown /root/apps/redis_cluster/src/redis-cli -c -h 127.0.0.1 -p 7005 -a redis shutdown chmod u+x shutdown.sh :然后执行将shutdown.sh变成可执行文件 ./shutdown.sh :在当前目录下启动 查看： ps aux | grep redis 官方：/usr/local/redis_cluster/redis-cli -a xxx -c -h 192.168.5.100 -p 8001 提示：-a ：访问服务端密码 ， -c 表示集群模式 ， -h指定ip地址 ，-p指定端口号 /root/apps/redis_cluster/src/redis-service ./70000/redis.conf /root/apps/redis_cluster/src/redis-service ./70001/redis.conf /root/apps/redis_cluster/src/redis-service ./70002/redis.conf /root/apps/redis_cluster/src/redis-service ./70003/redis.conf /root/apps/redis_cluster/src/redis-service ./70004/redis.conf /root/apps/redis_cluster/src/redis-service ./70005/redis.conf chmod u+x redisinstall.sh :然后执行将redisinstall.sh变成可执行文件 ./redisinstall.sh 二十二、Redis中的拓展 22.1 Redis为什么单线程还这么快 1、误区1：高性能的服务器一定是多线程的？\n2、误区2：多线程（CUP上下文会切换！）一定比单线程效率高！\n先去CPU\u0026gt;内存\u0026gt;硬盘的速度要有所了解！\n核心：redis是将所有的数据全部放在内存中的，所以说使用单线程去炒作效率就是最高的。\n多线称（CUP上下文切换：耗时！！！），对于内存来说，如果没有上下文切换效率就是最高的。对此读写就是在CUP上所以Redis 的速度是非常 快的。\n二十三、重新配置RedisTemplate package com.yux.redisdemo.redis; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.data.redis.connection.RedisConnectionFactory; import org.springframework.data.redis.core.RedisTemplate; import org.springframework.data.redis.serializer.Jackson2JsonRedisSerializer; import org.springframework.data.redis.serializer.StringRedisSerializer; import com.fasterxml.jackson.annotation.JsonAutoDetect; import com.fasterxml.jackson.annotation.PropertyAccessor; import com.fasterxml.jackson.databind.ObjectMapper; / 15 * redis配置类 16 * @author YUX 17 * @date 2018年6月6日 18 * 19 */ @Configuration public class RedisConfig { @Bean @SuppressWarnings(\u0026#34;all\u0026#34;) public RedisTemplate\u0026lt;String, Object\u0026gt; redisTemplate(RedisConnectionFactory factory) { RedisTemplate\u0026lt;String, Object\u0026gt; template = new RedisTemplate\u0026lt;String, Object\u0026gt;(); template.setConnectionFactory(factory); Jackson2JsonRedisSerializer jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer(Object.class); ObjectMapper om = new ObjectMapper(); om.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY); om.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL); jackson2JsonRedisSerializer.setObjectMapper(om); StringRedisSerializer stringRedisSerializer = new StringRedisSerializer(); // key采用String的序列化方式 template.setKeySerializer(stringRedisSerializer); // hash的key也采用String的序列化方式 template.setHashKeySerializer(stringRedisSerializer); // value序列化方式采用jackson template.setValueSerializer(jackson2JsonRedisSerializer); // hash的value序列化方式采用jackson template.setHashValueSerializer(jackson2JsonRedisSerializer); template.afterPropertiesSet(); return template; } } 二十四、重新编写RedisUtils package com.yux.redisdemo.redis; import java.util.List; import java.util.Map; import java.util.Set; import java.util.concurrent.TimeUnit; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.data.redis.core.RedisTemplate; import org.springframework.stereotype.Component; import org.springframework.util.CollectionUtils; / 14 * Redis工具类 15 * @author YUX 16 * @date 2018年6月7日 17 */ @Component public final class RedisUtil { @Autowired private RedisTemplate\u0026lt;String, Object\u0026gt; redisTemplate; // =============================common============================ / * 26 * 指定缓存失效时间 * 27 * * @param key 键 * 28 * @param time 时间(秒) * 29 * @return 30 */ public boolean expire(String key, long time) { try { if (time \u0026gt; 0) { redisTemplate.expire(key, time, TimeUnit.SECONDS); } return true; } catch (Exception e) { e.printStackTrace(); return false; } } / * 44 * 根据key 获取过期时间 * 45 * * @param key 键 不能为null * 46 * @return 时间(秒) 返回0代表为永久有效 * 47 */ public long getExpire(String key) { return redisTemplate.getExpire(key, TimeUnit.SECONDS); } / * 53 * 判断key是否存在 * 54 * * @param key 键 * 55 * @return true 存在 false不存在 * 56 */ public boolean hasKey(String key) { try { return redisTemplate.hasKey(key); } catch (Exception e) { e.printStackTrace(); return false; } } / * 67 * 删除缓存 * 68 * * @param key 可以传一个值 或多个 * 69 */ @SuppressWarnings(\u0026#34;unchecked\u0026#34;) public void del(String... key) { if (key != null \u0026amp;\u0026amp; key.length \u0026gt; 0) { if (key.length == 1) { redisTemplate.delete(key[0]); } else { redisTemplate.delete(CollectionUtils.arrayToList(key)); } } } // ============================String============================= / * 83 * 普通缓存获取 * 84 * * @param key 键 * 85 * @return 值 * 86 */ public Object get(String key) { return key == null ? null : redisTemplate.opsForValue().get(key); } / * 92 * 普通缓存放入 * 93 * * @param key 键 * 94 * @param value 值 * 95 * @return true成功 false失败 * 96 */ public boolean set(String key, Object value) { try { redisTemplate.opsForValue().set(key, value); return true; } catch (Exception e) { e.printStackTrace(); return false; } } / * 109 * 普通缓存放入并设置时间 * 110 * * @param key 键 * 111 * @param value 值 * 112 * @param time 时间(秒) time要大于0 如果time小于等于0 将设置无限期 * 113 * @return true成功 false 失败 * 114 */ public boolean set(String key, Object value, long time) { try { if (time \u0026gt; 0) { redisTemplate.opsForValue().set(key, value, time, TimeUnit.SECONDS); } else { set(key, value); } return true; } catch (Exception e) { e.printStackTrace(); return false; } } / * 130 * 递增 * 131 * * @param key 键 * 132 * @param delta 要增加几(大于0) * 133 * @return 134 */ public long incr(String key, long delta) { if (delta \u0026lt; 0) { throw new RuntimeException(\u0026#34;递增因子必须大于0\u0026#34;); } return redisTemplate.opsForValue().increment(key, delta); } / * 143 * 递减 * 144 * * @param key 键 * 145 * @param delta 要减少几(小于0) * 146 * @return 147 */ public long decr(String key, long delta) { if (delta \u0026lt; 0) { throw new RuntimeException(\u0026#34;递减因子必须大于0\u0026#34;); } return redisTemplate.opsForValue().increment(key, -delta); } // ================================Map================================= / * 157 * HashGet * 158 * * @param key 键 不能为null * 159 * @param item 项 不能为null * 160 * @return 值 * 161 */ public Object hget(String key, String item) { return redisTemplate.opsForHash().get(key, item); } / * 167 * 获取hashKey对应的所有键值 * 168 * * @param key 键 * 169 * @return 对应的多个键值 * 170 */ public Map\u0026lt;Object, Object\u0026gt; hmget(String key) { return redisTemplate.opsForHash().entries(key); } / * 176 * HashSet * 177 * * @param key 键 * 178 * @param map 对应多个键值 * 179 * @return true 成功 false 失败 * 180 */ public boolean hmset(String key, Map\u0026lt;String, Object\u0026gt; map) { try { redisTemplate.opsForHash().putAll(key, map); return true; } catch (Exception e) { e.printStackTrace(); return false; } } / * 192 * HashSet 并设置时间 * 193 * * @param key 键 * 194 * @param map 对应多个键值 * 195 * @param time 时间(秒) * 196 * @return true成功 false失败 * 197 */ public boolean hmset(String key, Map\u0026lt;String, Object\u0026gt; map, long time) { try { redisTemplate.opsForHash().putAll(key, map); if (time \u0026gt; 0) { expire(key, time); } return true; } catch (Exception e) { e.printStackTrace(); return false; } } / * 212 * 向一张hash表中放入数据,如果不存在将创建 * 213 * * @param key 键 * 214 * @param item 项 * 215 * @param value 值 * 216 * @return true 成功 false失败 * 217 */ public boolean hset(String key, String item, Object value) { try { redisTemplate.opsForHash().put(key, item, value); return true; } catch (Exception e) { e.printStackTrace(); return false; } } / * 229 * 向一张hash表中放入数据,如果不存在将创建 * 230 * * @param key 键 * 231 * @param item 项 * 232 * @param value 值 * 233 * @param time 时间(秒) 注意:如果已存在的hash表有时间,这里将会替换原有的时间 * 234 * @return true 成功 false失败 * 235 */ public boolean hset(String key, String item, Object value, long time) { try { redisTemplate.opsForHash().put(key, item, value); if (time \u0026gt; 0) { expire(key, time); } return true; } catch (Exception e) { e.printStackTrace(); return false } } / * 250 * 删除hash表中的值 * 251 * * @param key 键 不能为null * 252 * @param item 项 可以使多个 不能为null * 253 */ public void hdel(String key, Object... item) { redisTemplate.opsForHash().delete(key, item); } / * 259 * 判断hash表中是否有该项的值 * 260 * * @param key 键 不能为null * 261 * @param item 项 不能为null * 262 * @return true 存在 false不存在 * 263 */ public boolean hHasKey(String key, String item) { return redisTemplate.opsForHash().hasKey(key, item); } / * 269 * hash递增 如果不存在,就会创建一个 并把新增后的值返回 * 270 * * @param key 键 * 271 * @param item 项 * 272 * @param by 要增加几(大于0) * 273 * @return 274 */ public double hincr(String key, String item, double by) { return redisTemplate.opsForHash().increment(key, item, by); } / * 280 * hash递减 * 281 * * @param key 键 * 282 * @param item 项 * 283 * @param by 要减少记(小于0) * 284 * @return 285 */ public double hdecr(String key, String item, double by) { return redisTemplate.opsForHash().increment(key, item, -by); } // ============================set============================= / * 292 * 根据key获取Set中的所有值 * 293 * * @param key 键 * 294 * @return 295 */ public Set\u0026lt;Object\u0026gt; sGet(String key) { try { return redisTemplate.opsForSet().members(key); } catch (Exception e) { e.printStackTrace(); return null; } } / * 306 * 根据value从一个set中查询,是否存在 * 307 * * @param key 键 * 308 * @param value 值 * 309 * @return true 存在 false不存在 * 310 */ public boolean sHasKey(String key, Object value) { try { return redisTemplate.opsForSet().isMember(key, value); } catch (Exception e) { e.printStackTrace(); return false; } } / * 321 * 将数据放入set缓存 * 322 * * @param key 键 * 323 * @param values 值 可以是多个 * 324 * @return 成功个数 * 325 */ public long sSet(String key, Object... values) { try { return redisTemplate.opsForSet().add(key, values); } catch (Exception e) { e.printStackTrace(); return 0; } } / * 336 * 将set数据放入缓存 * 337 * * @param key 键 * 338 * @param time 时间(秒) * 339 * @param values 值 可以是多个 * 340 * @return 成功个数 * 341 */ public long sSetAndTime(String key, long time, Object... values) { try { Long count = redisTemplate.opsForSet().add(key, values); if (time \u0026gt; 0) expire(key, time); return count; } catch (Exception e) { e.printStackTrace(); return 0; } } / * 355 * 获取set缓存的长度 * 356 * * @param key 键 * 357 * @return 358 */ public long sGetSetSize(String key) { try { return redisTemplate.opsForSet().size(key); } catch (Exception e) { e.printStackTrace(); return 0; } } / * 369 * 移除值为value的 * 370 * * @param key 键 * 371 * @param values 值 可以是多个 * 372 * @return 移除的个数 * 373 */ public long setRemove(String key, Object... values) { try { Long count = redisTemplate.opsForSet().remove(key, values); return count; } catch (Exception e) { e.printStackTrace(); return 0; } } // ===============================list================================= / * 386 * 获取list缓存的内容 * 387 * * @param key 键 * 388 * @param start 开始 * 389 * @param end 结束 0 到 -1代表所有值 * 390 * @return 391 */ public List\u0026lt;Object\u0026gt; lGet(String key, long start, long end) try { return redisTemplate.opsForList().range(key, start, end); } catch (Exception e) { e.printStackTrace(); return null; } } / * 402 * 获取list缓存的长度 * 403 * * @param key 键 * 404 * @return 405 */ public long lGetListSize(String key) { try { return redisTemplate.opsForList().size(key); } catch (Exception e) { e.printStackTrace(); return 0; } } / * 416 * 通过索引 获取list中的值 * 417 * * @param key 键 * 418 * @param index 索引 index\u0026gt;=0时， 0 表头，1 第二个元素，依次类推；index\u0026lt;0时，-1，表尾，-2倒数第二个元素，依次类推 * 419 * @return 420 */ public Object lGetIndex(String key, long index) { try { return redisTemplate.opsForList().index(key, index); } catch (Exception e) { e.printStackTrace(); return null; } } / * 431 * 将list放入缓存 * 432 * * @param key 键 * 433 * @param value 值 * 434 * @param time 时间(秒) * 435 * @return 436 */ public boolean lSet(String key, Object value) { try { redisTemplate.opsForList().rightPush(key, value); return true; } catch (Exception e) { e.printStackTrace(); return false; } } / * 将list放入缓存 * * @param key 键 * @param value 值 * @param time 时间(秒) * @return */ public boolean lSet(String key, Object value, long time) { try { redisTemplate.opsForList().rightPush(key, value); if (time \u0026gt; 0) expire(key, time); return true; } catch (Exception e) { e.printStackTrace(); return false; } } / * 467 * 将list放入缓存 * 468 * * @param key 键 * 469 * @param value 值 * 470 * @param time 时间(秒) * 471 * @return 472 */ public boolean lSet(String key, List\u0026lt;Object\u0026gt; value) { try { redisTemplate.opsForList().rightPushAll(key, value); return true; } catch (Exception e) { e.printStackTrace(); return false; } } / * 484 * 将list放入缓存 * 485 * \u0026lt;p\u0026gt; * 486 * * @param key 键 * 487 * @param value 值 * 488 * @param time 时间(秒) * 489 * @return 490 */ public boolean lSet(String key, List\u0026lt;Object\u0026gt; value, long time) { try { redisTemplate.opsForList().rightPushAll(key, value); if (time \u0026gt; 0) expire(key, time); return true; } catch (Exception e) { e.printStackTrace(); return false; } } / * 504 * 根据索引修改list中的某条数据 * 505 * * @param key 键 * 506 * @param index 索引 * 507 * @param value 值 * 508 * @return 509 */ public boolean lUpdateIndex(String key, long index, Object value) { try { redisTemplate.opsForList().set(key, index, value); return true; } catch (Exception e) { e.printStackTrace(); return false; } } / * 521 * 移除N个值为value * 522 * * @param key 键 * 523 * @param count 移除多少个 * 524 * @param value 值 * 525 * @return 移除的个数 * 526 */ public long lRemove(String key, long count, Object value) { try { Long remove = redisTemplate.opsForList().remove(key, count, value); return remove; } catch (Exception e) { e.printStackTrace(); return 0; } } } 二十五、哨兵模式 25.1 自动选举master的模式 主从切换的技术方式是：当主机宕机之后，需要手动把一台服务器切换为主机服务器，这就需要人工干预，费时费力，还会造成一段时间内服务器不可用，这是一种不推荐的方式，更多的时候，我们在考虑使用哨兵模式。redis中2.8之后提供了哨兵模式来解决这个问题。\n哨兵模式是一种特殊的模式，首先redis提供哨兵命令，哨兵是一个独立的进程，作为进程，它会独立运行。其原理是哨兵同过发送命令，等待redis 服务器响应，从而监控运行的多个redis实例。\n这里的哨兵有两个作用：\n通过发送命令，让redis服务器返回监控其运行状态，包括主服务器和从服务器。 当哨兵检测到master宕机，会自动将slave切换成为master，然后通过发布订阅模式通知其他的服务器，修改配置文件，让她们切换主机。 然而一个哨兵进程对Redis服务器进行监控可能会出现问题，为此，我们可以使用多个哨兵进行监控。各个哨兵之间还会进行监控，这样就形成了多哨兵模式。\n假设主服务宕机，哨兵1先检测到这个结果，系统并不会马上进行failover过程，仅仅是哨兵1主管的认为服务器不可用，这个现象称为主观下线。当后面的哨兵也检测到主服务器不可用，并且数量达到一定值时，那么哨兵之间就会进行一侧投票，投票的结果由一个哨兵发起，进行failover[故障转移]操作。切换成功后，就会通过发布订阅模式，让哥哥哨兵把自己监控的服务器实现切换主机，这个过程称为可观下线。\n我们目前的装填是一主二从！\n1、配置哨兵配置文件sentinel.conf\n# sentinel monitor 被监控的名称host port 1 sentinel monitor myredis 127.0.0.1 6379 1 候命的这个数字1，代表主机挂了，slave投票看让谁阶梯称为主机，票数最多的，就会称为主机！\nredis-sentinel bin/sentinel.conf 优点：\n哨兵集群，基于主从复制模式，所有的主从配置优点，它全有 主从可以切换，故障可以转移，系统的可用性就会更好 哨兵模式就是主从模式的升级买手动到自动，更加健壮！ 缺点 ：\nredis不好在线扩容，集群容量一旦达到上限，在向扩容就十分麻烦！ 实现哨兵模式的配置其实是很麻烦的，里面有很多选择 ","permalink":"https://xyenvy.github.io/posts/redis%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","summary":"Redis学习笔记 一 、Redis简介 1.1 什么是Redis Redis 是完全开源免费的，遵守BSD协议，是一个高性能(NOSQL)的key-value数据库*，Redis是一个开源的使用ANSI C语言编写、支持网络、可基于内存可持久化的日志型，Key-Value数据库，并提供多种语言的API。","title":"Redis学习笔记"},{"content":"Nginx核心配置文件 配置文件说明 nginx官网文档说明\nhttp://nginx.org/en/docs/ tengine帮助文档\nhttp://tengine.taobao.org/nginx_docs/cn/docs Nginx的配置文件的组成部分\n主配置文件：nginx.conf\n子配置文件: include conf.d/*.conf\nfastcgi， uwsgi，scgi 等协议相关的配置文件 mime.types：支持的mime类型，MIME(Multipurpose Internet Mail Extensions)多用途互联网邮 件扩展类型，MIME消息能包含文本、图像、音频、视频以及其他应用程序专用的数据，是设定某 种扩展名的文件用一种应用程序来打开的方式类型，当该扩展名文件被访问的时候，浏览器会自动 使用指定应用程序来打开。多用于指定一些客户端自定义的文件名，以及一些媒体文件打开方式。 MIME参考文档： 参考文档\nnginx 配置文件格式说明\n配置文件由指令与指令块构成 每条指令以;分号结尾，指令与值之间以空格符号分隔 可以将多条指令放在同一行,用分号分隔即可,但可读性差,不推荐 指令块以{ }大括号将多条指令组织在一起,且可以嵌套指令块 include语句允许组合多个配置文件以提升可维护性 使用#符号添加注释，提高可读性 使用$符号使用变量 部分指令的参数支持正则表达式 Nginx主配置文件的配置指令方式\ndirective value [value2 ...]; 注意 (1) 指令必须以分号结尾 (2) 支持使用配置变量 内建变量：由Nginx模块引入，可直接引用 自定义变量：由用户使用set命令定义,格式: set variable_name value; 引用变量：$variable_name 主配置文件结构：四部分\nmain block：主配置段，即全局配置段，对http,mail都有效 #事件驱动相关的配置 event { ... } #http/https 协议相关配置段 http { ... } #默认配置文件不包括下面两个块 #mail 协议相关配置段 mail { ... } #stream 服务器相关配置段 stream { ... } 默认的nginx.conf配置文件格式说明\n#全局配置端，对全局生效，主要设置nginx的启动用户/组，启动的工作进程数量，工作模式，Nginx的PID 路径，日志路径等。 user nginx nginx; worker_processes 1; #启动工作进程数数量 events { #events设置快，主要影响nginx服务器与用户的网络连接，比如是否允许同时接受多个网络连 接，使用哪种事件驱动模型处理请求，每个工作进程可以同时支持的最大连接数，是否开启对多工作进程下的 网络连接进行序列化等。 worker_connections 1024; #设置单个nginx工作进程可以接受的最大并发，作为web服务器 的时候最大并发数为worker_connections * worker_processes，作为反向代理的时候为 (worker_connections * worker_processes)/2 } http { #http块是Nginx服务器配置中的重要部分，缓存、代理和日志格式定义等绝大多数功能和第三方模 块都可以在这设置，http块可以包含多个server块，而一个server块中又可以包含多个location块， server块可以配置文件引入、MIME-Type定义、日志自定义、是否启用sendfile、连接超时时间和单个链 接的请求上限等。 include mime.types; default_type application/octet-stream; sendfile on; #作为web服务器的时候打开sendfile加快静态文件传输，指定是否使用 sendfile系统调用来传输文件,sendfile系统调用在两个文件描述符之间直接传递数据(完全在内核中操 作)，从而避免了数据在内核缓冲区和用户缓冲区之间的拷贝，操作效率很高，被称之为零拷贝，硬盘 \u0026gt;\u0026gt; kernel buffer (快速拷贝到kernelsocket buffer) \u0026gt;\u0026gt;协议栈。 keepalive_timeout 65; #长连接超时时间，单位是秒 server { #设置一个虚拟机主机，可以包含自己的全局快，同时也可以包含多个location模块。比如 本虚拟机监听的端口、本虚拟机的名称和IP配置，多个server 可以使用一个端口，比如都使用80端口提供 web服务、 listen 80; #配置server监听的端口 server_name localhost; #本server的名称，当访问此名称的时候nginx会调用当前 serevr内部的配置进程匹配。 location / { #location其实是server的一个指令，为nginx服务器提供比较多而且灵活的指 令，都是在location中体现的，主要是基于nginx接受到的请求字符串，对用户请求的UIL进行匹配，并对特 定的指令进行处理，包括地址重定向、数据缓存和应答控制等功能都是在这部分实现，另外很多第三方模块的 配置也是在location模块中配置。 root html; #相当于默认页面的目录名称，默认是安装目录的相对路径，可以使用绝对路 径配置。 index index.html index.htm; #默认的页面文件名称 } error_page 500 502 503 504 /50x.html; #错误页面的文件名称 location = /50x.html { #location处理对应的不同错误码的页面定义到/50x.html，这个 跟对应其server中定义的目录下。 root html; #定义默认页面所在的目录 } } #和邮件相关的配置 #mail { # ... # } mail 协议相关配置段 #tcp代理配置，1.9版本以上支持 #stream { # ... # } stream 服务器相关配置段 #导入其他路径的配置文件 #include /apps/nginx/conf.d/*.conf } 全局配置 Main 全局配置段常见的配置指令分类\n正常运行必备的配置 优化性能相关的配置 用于调试及定位问题相关的配置 事件驱动相关的配置 全局配置说明:\nuser nginx nginx; #启动Nginx工作进程的用户和组 worker_processes [number | auto]; #启动Nginx工作进程的数量,一般设为和CPU核心数相同 worker_cpu_affinity 00000001 00000010 00000100 00001000 | auto ; #将Nginx工作进程绑 定到指定的CPU核心，默认Nginx是不进行进程绑定的，绑定并不是意味着当前nginx进程独占以一核心CPU， 但是可以保证此进程不会运行在其他核心上，这就极大减少了nginx的工作进程在不同的cpu核心上的来回跳 转，减少了CPU对进程的资源分配与回收以及内存管理等，因此可以有效的提升nginx服务器的性能。 CPU MASK: 00000001：0号CPU 00000010：1号CPU 10000000：7号CPU #示例: worker_cpu_affinity 0001 0010 0100 1000;第0号---第3号CPU worker_cpu_affinity 0101 1010; #示例 worker_processes 4; worker_cpu_affinity 00000010 00001000 00100000 10000000; [root@centos8 ~]# ps axo pid,cmd,psr | grep nginx 31093 nginx: master process /apps 1 34474 nginx: worker process 1 34475 nginx: worker process 3 34476 nginx: worker process 5 34477 nginx: worker process 7 35751 grep nginx #auto 绑定CPU #The special value auto (1.9.10) allows binding worker processes automatically to available CPUs: worker_processes auto; worker_cpu_affinity auto; #The optional mask parameter can be used to limit the CPUs available for automatic binding: worker_cpu_affinity auto 01010101; #错误日志记录配置，语法：error_log file [debug | info | notice | warn | error | crit | alert | emerg] #error_log logs/error.log; #error_log logs/error.log notice; error_log /usr/local/src/nginx/logs/error.log error; #pid文件保存路径 pid /usr/local/src/nginx/logs/nginx.pid; worker_priority 0; #工作进程优先级，-20~20(19) worker_rlimit_nofile 65536; #所有worker进程能打开的文件数量上限,包括:Nginx的所有连接（例 如与代理服务器的连接等），而不仅仅是与客户端的连接,另一个考虑因素是实际的并发连接数不能超过系统级 别的最大打开文件数的限制.最好与ulimit -n 或者limits.conf的值保持一致, daemon off; #前台运行Nginx服务用于测试、或者以容器运行时，需要设为off master_process off|on; #是否开启Nginx的master-worker工作模式，仅用于开发调试场景,默认为 on events { worker_connections 65536; #设置单个工作进程的最大并发连接数 use epoll; #使用epoll事件驱动，Nginx支持众多的事件驱动，比如:select、poll、epoll，只 能设置在events模块中设置。 accept_mutex on; #on为同一时刻一个请求轮流由worker进程处理,而防止被同时唤醒所有 worker,避免多个睡眠进程被唤醒的设置，默认为off，新请求会唤醒所有worker进程,此过程也称为\u0026#34;惊 群\u0026#34;，因此nginx刚安装完以后要进行适当的优化。建议设置为on multi_accept on; #on时Nginx服务器的每个工作进程可以同时接受多个新的网络连接，此指令默认 为off，即默认为一个工作进程只能一次接受一个新的网络连接，打开后几个同时接受多个。建议设置为on } 范例：实现nginx高并发配置\n[root@centos7 ~]#ulimit -n 102400 [root@centos7 ~]#while true;do ab -c 5000 -n 10000 http://10.0.0.8/;sleep 0.5;done #默认配置不支持高并发,会出现以下错误日志 [root@centos8 conf]#tail /usr/local/src/nginx/logs/error.log 2020/09/24 21:19:33 [crit] 41006#0: *1105860 open() \u0026#34;/apps/nginx/html/50x.html\u0026#34; failed (24: Too many open files), client: 10.0.0.7, server: localhost, request: \u0026#34;GET / HTTP/1.0\u0026#34;, host: \u0026#34;10.0.0.8\u0026#34; 2020/09/24 21:19:33 [crit] 41006#0: accept4() failed (24: Too many open files) 2020/09/24 21:19:33 [crit] 41006#0: *1114177 open() \u0026#34;/apps/nginx/html/index.html\u0026#34; failed (24: Too many open files), client: 10.0.0.7, server: localhost, request: \u0026#34;GET / HTTP/1.0\u0026#34;, host: \u0026#34;10.0.0.8\u0026#34; #如果systemd启动,则需要修改nginx.service文件中加LimitNOFILE=100000,才能有效 #如果非systemd启动,可以修改下面pam限制 [root@centos8 ~]#vim /etc/security/limits.conf * soft nofile 1000000 * hard nofile 1000000 [root@centos8 ~]#vim /apps/nginx/conf/nginx.conf worker_rlimit_nofile 100000; [root@centos8 ~]#systemctl restart nginx [root@centos8 ~]# watch -n1 \u0026#39;ps -axo pid,cmd,nice | grep nginx #验证进程优先级 http配置块 http { ... ... #各server的公共配置 server { #每个server用于定义一个虚拟主机,第一个server为默认虚拟服务器 ... } server { ... server_name #虚拟主机名 root #主目录 alias #路径别名 location [OPERATOR] URL { #指定URL的特性 ... if CONDITION { ... } } } } http配置协议说明\nhttp { include mime.types; #导入支持的文件类型,是相对于/usr/local/src/nginx/conf的目录 default_type application/octet-stream; #除mime.types中文件类型外,设置其它文件默认 类型，访问其它类型时会提示下载不匹配的类型文件 #日志配置部分 #log_format main \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39; # \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39; # \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;; #access_log logs/access.log main; #自定义优化参数 sendfile on; #tcp_nopush on; #在开启了sendfile的情况下，合并请求后统一发送给客户端,必须开启 sendfile #tcp_nodelay off; #在开启了keepalived模式下的连接是否启用TCP_NODELAY选项，当为 off时，延迟0.2s发送，默认On时，不延迟发送，立即发送用户响应报文。 #keepalive_timeout 0; keepalive_timeout 65 65; #设置会话保持时间,第二个值为响应首部:keepAlived:timeout=65,可以和第一个值不同 #gzip on; #开启文件压缩 server { listen 80; #设置监听地址和端口 server_name localhost; #设置server name，可以以空格隔开写多个并支持正则表达式， 如:*.magedu.com www.magedu.* ~^www\\d+\\.magedu\\.com$ default_server #charset koi8-r; #设置编码格式，默认是俄语格式，建议改为utf-8 #access_log logs/host.access.log main; location / { root html; index index.html index.htm; } #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; #定义错误页面 location = /50x.html { root html; } # proxy the PHP scripts to Apache listening on 127.0.0.1:80 # #location ~ \\.php$ { #以http的方式转发php请求到指定web服务器 # proxy_pass http://127.0.0.1; #} # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000 # #location ~ \\.php$ { #以fastcgi的方式转发php请求到php处理 # root html; # fastcgi_pass 127.0.0.1:9000; # fastcgi_index index.php; # fastcgi_param SCRIPT_FILENAME /scripts$fastcgi_script_name; # include fastcgi_params; #} # deny access to .htaccess files, if Apache\u0026#39;s document root # concurs with nginx\u0026#39;s one # #location ~ /\\.ht { #拒绝web形式访问指定文件，如很多的网站都是通过.htaccess文件来 改变自己的重定向等功能。 # deny all; #} location ~ /passwd.html { deny all; } } # another virtual host using mix of IP-, name-, and port-based configuration # #server { #自定义虚拟server # listen 8000; # listen somename:8080; # server_name somename alias another.alias; # location / { # root html; # index index.html index.htm; #指定默认网页文件，此指令由 ngx_http_index_module模块提供 # } #} # HTTPS server # #server { #https服务器配置 # listen 443 ssl; # server_name localhost; # ssl_certificate cert.pem; # ssl_certificate_key cert.key; # ssl_session_cache shared:SSL:1m; # ssl_session_timeout 5m; # ssl_ciphers HIGH:!aNULL:!MD5; # ssl_prefer_server_ciphers on; # location / { # root html; # index index.html index.htm; # } #} MIME #在响应报文中将指定的文件扩展名映射至MIME对应的类型 include /etc/nginx/mime.types; default_type application/octet-stream;#除mime.types中的类型外，指定其它文件的默认 MIME类型，浏览器一般会提示下载 types { text/html html; image/gif gif; image/jpeg jpg; } #MIME参考文档： https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Basics_of_HTTP/MIME_Types 范例：识别PHP为text\n[root@centos7 conf]# vim /usr/local/src/nginx/html/test.php \u0026lt;?php phpinfo(); ?\u0026gt; # 修改配置文件 [root@centos7 conf]# vim /usr/local/src/nginx/conf/nginx.conf http { include mime.types; default_type text/html; # 加入次行 ...... #或者修改为下面 include mime.types; default_type application/octet-stream; types{ text/plain php; #加此行 } 指定响应报文server首部 #是否在响应报文中的Content-Type显示指定的字符集，默认off不显示 charset charset | off; #示例 charset utf-8; #是否在响应报文的Server首部显示nginx版本 server_tokens on | off | build | string; 修改server字段\n如果想自定义响应报文的nginx版本信息，需要修改源码文件，重新编译 如果server_tokens on，修改 src/core/nginx.h 修改第13-14行，如下示例 #define NGINX_VERSION \u0026#34;1.68.9\u0026#34; #define NGINX_VER \u0026#34;test/\u0026#34; NGINX_VERSION 如果server_tokens off，修改 src/http/ngx_http_header_filter_module.c 第49行，如下示例： static char ngx_http_server_string[] = \u0026#34;Server: nginx\u0026#34; CRLF; 把其中的nginx改为自己想要的文字即可,如：test root 与 alias root：指定web的家目录，在定义location的时候，文件的绝对路径等于 root+location\nalias：定义路径别名，会把访问的路径重新定义到其指定的路径,文档映射的另一种机制;仅能用于 location上下文,此指令使用较少\n注意：location中使用root指令和alias指令的意义不同\nroot 给定的路径对应于location中的/uri 左侧的/ alias 给定的路径对应于location中的/uri 的完整路径 location 的详细使用 在一个server中location配置段可存在多个，用于实现从uri到文件系统的路径映射；ngnix会根据用户请 求的URI来检查定义的所有location，按一定的优先级找出一个最佳匹配，而后应用其配置\n在没有使用正则表达式的时候，nginx会先在server中的多个location选取匹配度最高的一个uri，uri是 用户请求的字符串，即域名后面的web文件路径，然后使用该location模块中的正则url和字符串，如果 匹配成功就结束搜索，并使用此location处理此请求。\nlocation 官方帮助:\nhttps://nginx.org/en/docs/http/ngx_http_core_module.html#location 语法规则\n#语法规则： location [ = | ~ | ~* | ^~ ] uri { ... } = #用于标准uri前，需要请求字串与uri精确匹配，大小敏感,如果匹配成功就停止向下匹配并立即处理请 求 ^~ #用于标准uri前，表示包含正则表达式,并且匹配以指定的正则表达式开头,对uri的最左边部分做匹配 检查，不区分字符大小写 ~ #用于标准uri前，表示包含正则表达式,并且区分大小写 ~* #用于标准uri前，表示包含正则表达式,并且不区分大写 不带符号 #匹配起始于此uri的所有的uri \\ #用于标准uri前，表示包含正则表达式并且转义字符。可以将 . * ?等转义为普通符号 #匹配优先级从高到低： =, ^~, ~/~*, 不带符号 官网案例\nlocation = / { [ configuration A ] } location / { [ configuration B ] } location /documents/ { [ configuration C ] } location ^~ /images/ { [ configuration D ] } location ~* \\.(gif|jpg|jpeg)$ { [ configuration E ] } The “/” request will match configuration A(?), the “/index.html” request will match configuration B, the “/documents/document.html” request will match configuration C, the “/images/1.gif” request will match configuration D, and the “/documents/1.jpg” request will match configuration E. 精确匹配图片 server{ listen 80; server_name localhost; root /data/web; index index.html *.html; location = /test.jpg { root /data/image; } } 匹配案例-文件名后缀 server{ listen 80; server_name localhost; root /data/web; index index.html *.html; location ~* \\.(gif|jpg|jpeg|bmp|png|tiff|tif|ico|wmf|js|css)$ { root /data/web1; } } 匹配案例-优先级 server{ listen 80; server_name localhost; root /data/web; index index.html *.html; location = /test2.jpg { root /data/web2; index index.html; } location ~* \\.(gif|jpg|jpeg|bmp|png|tiff|tif|ico|wmf|js|css)$ { root /data/web1; index index.html; } } #匹配优先级：=, ^~, ～/～*，/ location优先级：(location =) \u0026gt; (location ^~ 路径) \u0026gt; (location ~,~* 正则顺序) \u0026gt; (location 完整路径) \u0026gt; (location 部分起始路径) \u0026gt; (/) Nginx 四层访问控制 访问控制基于模块ngx_http_access_module实现，可以通过匹配客户端源IP地址进行限制 注意: 如果能在防火墙设备控制,最好就不要在nginx上配置,可以更好的节约资源\n官方帮助:\nhttp://nginx.org/en/docs/http/ngx_http_access_module.html 范例：\nlocation = /login/ { root /data/nginx/html/pc; allow 10.0.0.0/24; deny all; } location /about { alias /data/nginx/html/pc; index index.html; deny 192.168.1.1; # 禁止该IP访问 allow 192.168.1.0/24; # 允许该网段访问 allow 10.1.1.0/16; allow 2001:0db8::/32; deny all; #按先小范围到大范围排序 } Nginx 账户认证功能 由 ngx_http_auth_basic_module 模块提供此功能\n官方帮助:\nhttps://nginx.org/en/docs/http/ngx_http_auth_basic_module.html#auth_basic 范例：\n#CentOS安装包 [root@centos7 ~]#yum -y install httpd-tools #Ubuntu安装包 [root@Ubuntu ~]#apt -y install apache2-utils #创建用户 #-b 非交互式方式提交密码 [root@centos7 ~]# htpasswd -cb /usr/local/src/nginx/conf.d/passwd admin 123456 Adding password for user admin [root@centos7 conf.d]# cat passwd admin:$apr1$/MugqAsJ$MbWcOmC5U9WTZlgK5MJeU. [root@centos7 conf.d]# #安全加固 [root@centos7 ~]# chown nginx.nginx /usr/local/src/nginx/conf.d/passwd [root@centos7 ~]# chmod 600 /usr/local/src/nginx/conf.d/passwd # 修改配置文件 server{ listen 80; server_name localhost; root /data/web; index index.html *.html; location /about { alias /data/web1; index index.html *.html; auth_basic \u0026#34;login password\u0026#34;; auth_basic_user_file /usr/local/src/nginx/conf.d/passwd; } } 检测文件是否存在 try_files 会按顺序检查文件是否存在，返回第一个找到的文件或文件夹（结尾加斜线表示为文件夹）， 如果所有文件或文件夹都找不到，会进行一个内部重定向到最后一个参数。只有最后一个参数可以引起 一个内部重定向，之前的参数只设置内部URI的指向。最后一个参数是回退URI且必须存在，否则会出现 内部500错误。\n语法格式\nSyntax: try_files file ... uri; try_files file ... =code; Default: — Context: server, location 范例： 如果不存在页面, 就转到default.html页面\nserver{ listen 80; server_name localhost; root /data/web; index index.html *.html; location / { #如果不存在页面, 就转到default.html页面 # try_files $uri $uri.html $uri/index.html /about/default.html; # 返回自定义状态码 489 try_files $uri $uri/index.html $uri.html =489; index index.html *.html; } } 长连接配置 keepalive_timeout timeout [header_timeout]; #设定保持连接超时时长，0表示禁止长连接，默 认为75s，通常配置在http字段作为站点全局配置 keepalive_requests number; #在一次长连接上所允许请求的资源的最大数量，默认为1000次,建议适 当调大,比如:500 范例：\nkeepalive_requests 3; keepalive_timeout 65 60; #开启长连接后，返回客户端的会话保持时间为60s，单次长连接累计请求达到指定次数请求或65秒就会被断 开，第二个数字60为发送给客户端应答报文头部中显示的超时时间设置为60s：如不设置客户端将不显示超时 时间。 Keep-Alive:timeout=60 #浏览器收到的服务器返回的报文 #如果设置为0表示关闭会话保持功能，将如下显示： Connection:close #浏览器收到的服务器返回的报文 作为下载服务器配置 nginx_http_autoindex_module 模块处理以斜杠字符 \u0026ldquo;/\u0026rdquo; 结尾的请求，并生成目录列表,可以做为下载服务 配置使用 官方文档:\nhttps://nginx.org/en/docs/http/ngx_http_autoindex_module.html#autoindex Syntax: autoindex on | off; Default: autoindex off; Context: http, server, location 相关指令\nautoindex on | off;#自动文件索引功能，默为off autoindex_exact_size on | off; #计算文件确切大小（单位bytes），off 显示大概大小（单位 K、M)，默认on autoindex_localtime on | off ; #显示本机时间而非GMT(格林威治)时间，默认off autoindex_format html | xml | json | jsonp; #显示索引的页面文件风格，默认html limit_rate rate; #限制响应客户端传输速率(除GET和HEAD以外的所有方法)，单位B/s,即 bytes/second，默认值0,表示无限制,此指令由ngx_http_core_module提供 set $limit_rate 4k; #也可以通变量限速,单位B/s,同时设置,此项优级高.Rate limit can also be set in the $limit_rate variable, however, since version 1.17.0, this method is not recommended: 范例：\n# 配置文件 location /download { autoindex on; #自动索引功能 autoindex_exact_size on; #计算文件确切大小（单位bytes），此为默认值,off只显示大概大 小（单位kb、mb、gb） autoindex_localtime on; #on表示显示本机时间而非GMT(格林威治)时间,默为为off显示GMT 时间 limit_rate 1024k; #限速,默认不限速 root /data/web/download; } 其他配置 keepalive_disable none | browser ...; #对哪种浏览器禁用长连接 limit_except method ... { ... }，仅用于location #禁止客户端使用除了指定的请求方法之外的其它方法,如果使用会出现403错误 method:GET, HEAD, POST, PUT, DELETE，MKCOL, COPY, MOVE, OPTIONS, PROPFIND, PROPPATCH, LOCK, UNLOCK, PATCH limit_except GET { allow 192.168.0.0/24; allow 10.0.0.1; deny all; } #除了GET和HEAD 之外其它方法仅允许192.168.1.0/24网段主机使用 location /upload { root /data/nginx/html/pc; index index.html; limit_except GET { allow 10.0.0.6; deny all; } } ","permalink":"https://xyenvy.github.io/posts/nginx%E6%A0%B8%E5%BF%83%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/","summary":"Nginx核心配置文件 配置文件说明 nginx官网文档说明 http://nginx.org/en/docs/ tengine帮助文档 http://tengine.taobao.org/nginx_docs/cn/docs Nginx的配置文件的组成部分 主配置文件：nginx.conf 子配置文件: include conf.d/*.conf fastcgi， uwsgi，scgi 等协议相关的配置文件 mime.types：支持的mime类型，MIME(Multip","title":"Nginx核心配置文件"},{"content":"平滑升级流程 将旧Nginx二进制文件换成新Nginx程序文件（注意先备份) 向master进程发送USR2信号启动新nginx进程 master进程修改pid文件名加上后缀.oldbin,成为nginx.pid.oldbin master进程用新Nginx文件启动新master进程及worker子进程成为旧master的子进程,系统中将有新旧两个Nginx主进程和对应的worker子进程并存 当前新的请求仍然由旧Nginx的worker进程进行处理,将新生成的master进程的PID存放至新生成的 pid文件nginx.pid 向旧的Nginx服务进程发送WINCH信号，使旧的Nginx worker进程平滑停止 向旧master进程发送QUIT信号，关闭旧master，并删除Nginx.pid.oldbin文件 如果发现升级有问题,可以回滚∶向旧master发送HUP，向新master发送QUIT 范例：Nginx1.18.0版本升级到1.20.2 Nginx1.18.0编译安装 官方源码包下载地址：\nhttps://nginx.org/en/download.html 范例：编译安装\n系统centos8.5\nNginx版本：1.18.0\n安装扩展依赖\n[root@centos8 ~]# yum -y install gcc pcre-devel openssl-devel zlib-devel 创建用户和组 groupadd nginx useradd -s /sbin/nologin -g nginx nginx 下载安装包并解压 [root@centos8 ~]# cd /usr/local/src/ [root@centos8 ~]# wget https://nginx.org/download/nginx-1.18.0.tar.gz [root@centos8 src]# tar xf nginx-1.18.0.tar.gz [root@centos8 src]# cd nginx-1.18.0 安装 [root@centos8 nginx-1.18.0]# ./configure --prefix=/usr/local/src/nginx/ \\ # 安装位置 --user=nginx \\ # 运行的用户 --group=nginx \\ --with-http_ssl_module \\ --with-http_v2_module \\ --with-http_realip_module \\ --with-http_stub_status_module \\ --with-http_gzip_static_module \\ --with-pcre \\ --with-stream \\ --with-stream_ssl_module [root@centos8 nginx-1.18.0]#make \u0026amp;\u0026amp; make install 修改权限 [root@centos8 /]# chown -R nginx.nginx /usr/local/src/nginx/ nginx安装完成后有四个主要的目录 [root@centos8 /]# ll /usr/local/src/nginx/ total 4 drwxr-xr-x. 2 nginx nginx 4096 Jan 4 15:17 conf drwxr-xr-x. 2 nginx nginx 40 Jan 4 15:17 html drwxr-xr-x. 2 nginx nginx 6 Jan 4 15:17 logs drwxr-xr-x. 2 nginx nginx 19 Jan 4 15:17 sbin [root@centos8 /]# conf：保存nginx所有的配置文件，其中nginx.conf是nginx服务器的最核心最主要的配置文件，其他 的.conf则是用来配置nginx相关的功能的，例如fastcgi功能使用的是fastcgi.conf和 fastcgi_params两个文件，配置文件一般都有一个样板配置文件，是以.default为后缀，使用时可将其复 制并将default后缀去掉即可。 html目录中保存了nginx服务器的web文件，但是可以更改为其他目录保存web文件,另外还有一个50x的web 文件是默认的错误页面提示页面。 logs：用来保存nginx服务器的访问日志错误日志等日志，logs目录可以放在其他 验证版本及编译参数 [root@centos8 /]# ln -s /usr/local/src/nginx/sbin/nginx /usr/bin/ [root@centos8 /]# nginx -V nginx version: nginx/1.18.0 built by gcc 8.5.0 20210514 (Red Hat 8.5.0-4) (GCC) built with OpenSSL 1.1.1k FIPS 25 Mar 2021 TLS SNI support enabled configure arguments: --prefix=/usr/local/src/nginx --user=nginx --group=nginx --with-http_ssl_module --with-http_v2_module --with-http_realip_module --with-http_stub_status_module --with-http_gzip_static_module --with-pcre --with-stream --with-stream_ssl_module [root@centos8 /]# 创建Nginx启动文件 #复制同一版本的nginx的yum安装生成的service文件 [root@centos8 ~]# vim /lib/systemd/system/nginx.service [Unit] Description=nginx - high performance web server Documentation=http://nginx.org/en/docs/ After=network.target [Service] Type=forking PIDFile=/usr/local/src/nginx/logs/nginx.pid ExecStartPre=/usr/local/src//nginx/sbin/nginx -t -c /usr/local/src/nginx/conf/nginx.conf ExecStart=/usr/local/src/nginx/sbin/nginx -c /usr/local/src/nginx/conf/nginx.conf ExecReload=/bin/kill -s HUP $MAINPID ExecStop=/bin/kill -s QUIT $MAINPID PrivateTmp=true [Install] WantedBy=multi-user.target 验证启动文件 [root@centos8 ~]#systemctl daemon-reload [root@centos8 ~]#systemctl enable --now nginx Created symlink /etc/systemd/system/multi-user.target.wants/nginx.service → /usr/lib/systemd/system/nginx.service. [root@centos8 ~]# 查看Nginx运行状态 [root@centos8 ~]# systemctl status nginx ● nginx.service - nginx - high performance web server Loaded: loaded (/usr/lib/systemd/system/nginx.service; enabled; vendor preset: disabled) Active: active (running) since Wed 2023-01-04 17:53:00 CST; 2 days ago Docs: http://nginx.org/en/docs/ Main PID: 1595 (nginx) Tasks: 2 (limit: 11218) Memory: 9.1M CGroup: /system.slice/nginx.service ├─1595 nginx: master process /usr/local/src/nginx/sbin/nginx -c /usr/local/src/nginx/conf/nginx.conf └─1596 nginx: worker process Jan 04 17:53:00 centos8 systemd[1]: Starting nginx - high performance web server... Jan 04 17:53:00 centos8 nginx[1592]: nginx: the configuration file /usr/local/src/nginx/conf/nginx.conf syntax is ok Jan 04 17:53:00 centos8 nginx[1592]: nginx: configuration file /usr/local/src/nginx/conf/nginx.conf test is successful Jan 04 17:53:00 centos8 systemd[1]: nginx.service: Failed to parse PID from file /usr/local/src/nginx/logs/nginx.pid: Invalid argument Jan 04 17:53:00 centos8 systemd[1]: Started nginx - high performance web server. [root@centos8 ~]# 编译Nginx1.20.2 下载Nginx1.20.2 [root@centos8 ~]# cd /usr/local/src/ [root@centos8 src]# wget https://nginx.org/download/nginx-1.20.2.tar.gz [root@centos8 src]# tar xf nginx-1.20.2.tar.gz 查看旧版本Nginx编译选项 [root@centos8 src]# nginx -V nginx version: nginx/1.18.0 built by gcc 8.5.0 20210514 (Red Hat 8.5.0-4) (GCC) built with OpenSSL 1.1.1k FIPS 25 Mar 2021 TLS SNI support enabled configure arguments: --prefix=/usr/local/src/nginx/ --user=nginx --group=nginx --with-http_ssl_module --with-http_v2_module --with-http_realip_module --with-http_stub_status_module --with-http_gzip_static_module --with-pcre --with-stream --with-stream_ssl_module [root@centos8 src]# 编译新版本，使用旧版本相同的编译参数选项 [root@centos8 src]# cd nginx-1.20.2 [root@centos8 nginx-1.20.2]# ./configure --prefix=/usr/local/src/nginx/ --user=nginx --group=nginx --with-http_ssl_module --with-http_v2_module --with-http_realip_module --with-http_stub_status_module --with-http_gzip_static_module --with-pcre --with-stream --with-stream_ssl_module # 只需要make无需make install [root@centos8 nginx-1.20.2]# make # 编译完的软件存在objs/nginx [root@centos8 nginx-1.20.2]# ll objs/ total 7684 -rw-r--r--. 1 root root 18498 Jan 7 15:29 autoconf.err -rw-r--r--. 1 root root 53217 Jan 7 15:29 Makefile -rwxr-xr-x. 1 root root 7697296 Jan 7 15:31 nginx -rw-r--r--. 1 root root 5557 Jan 7 15:31 nginx.8 -rw-r--r--. 1 root root 7906 Jan 7 15:29 ngx_auto_config.h -rw-r--r--. 1 root root 657 Jan 7 15:29 ngx_auto_headers.h -rw-r--r--. 1 root root 8758 Jan 7 15:29 ngx_modules.c -rw-r--r--. 1 root root 60056 Jan 7 15:31 ngx_modules.o drwxr-xr-x. 9 root root 91 Jan 7 15:29 src [root@centos8 nginx-1.20.2]# # 查看两个Nginx版本 [root@centos8 nginx-1.20.2]# ./objs/nginx -v nginx version: nginx/1.20.2 [root@centos8 nginx-1.20.2]# /usr/local/src/nginx/sbin/nginx -v nginx version: nginx/1.18.0 [root@centos8 nginx-1.20.2]# # 备份旧版本Nginx [root@centos8 nginx-1.20.2]# cp /usr/local/src/nginx/sbin/nginx /usr/local/src/nginx/sbin/nginx.old [root@centos8 nginx-1.20.2]# ll /usr/local/src/nginx/sbin/ total 14776 -rwxr-xr-x. 1 root root 7562368 Jan 4 17:39 nginx -rwxr-xr-x. 1 root root 7562368 Jan 7 15:36 nginx.old [root@centos8 nginx-1.20.2]# #把新版本的nginx命令复制过去覆盖旧版本程序文件,注意:需要加 -f 选项强制覆盖,否则会提示Text file busy [root@centos8 nginx-1.20.2]# cp -f objs/nginx /usr/local/src/nginx/sbin/ cp: overwrite \u0026#39;/usr/local/src/nginx/sbin/nginx\u0026#39;? y [root@centos8 nginx-1.20.2]# # 检测是否存在问题，必须做的 [root@centos8 nginx-1.20.2]# /usr/local/src/nginx/sbin/nginx -t nginx: the configuration file /usr/local/src/nginx//conf/nginx.conf syntax is ok nginx: configuration file /usr/local/src/nginx//conf/nginx.conf test is successful [root@centos8 nginx-1.20.2]# #发送信号USR2 平滑升级可执行程序,将存储有旧版本主进程PID的文件重命名为nginx.pid.oldbin，并启动新的nginx #此时两个master的进程都在运行,只是旧的master不在监听,由新的master监听80 #此时Nginx开启一个新的master进程，这个master进程会生成新的worker进程，这就是升级后的Nginx进程，此时老的进程不会自动退出，但是当接收到新的请求不作处理而是交给新的进程处理。 [root@centos8 nginx-1.20.2]# kill -USR2 `cat /usr/local/src/nginx/logs/nginx.pid ` [root@centos8 nginx-1.20.2]# #可以看到两个master,新的master是旧版master的子进程,并生成新版的worker进程 [root@centos8 nginx-1.20.2]# ps aux | grep nginx root 1595 0.0 0.1 42452 2724 ? Ss Jan05 0:00 nginx: master process /usr/local/src/nginx/sbin/nginx -c /usr/local/src/nginx/conf/nginx.conf nginx 1596 0.0 0.2 77120 4612 ? S Jan05 0:00 nginx: worker process root 8328 0.0 0.3 42484 5860 ? S 15:44 0:00 nginx: master process /usr/local/src/nginx/sbin/nginx -c /usr/local/src/nginx/conf/nginx.conf nginx 8329 0.0 0.2 77240 4652 ? S 15:44 0:00 nginx: worker process root 8333 0.0 0.0 12136 1120 pts/0 S+ 15:45 0:00 grep --color=auto nginx [root@centos8 nginx-1.20.2]# #先关闭旧nginx的worker进程,而不关闭nginx主进程方便回滚 #向原Nginx主进程发送WINCH信号，它会逐步关闭旗下的工作进程（主进程不退出），这时所有请求都会由新版Nginx处理 [root@centos8 nginx-1.20.2]# kill -WINCH `cat /usr/local/src/nginx/logs/nginx.pid.oldbin` #如果旧版worker进程有用户的请求,会一直等待处理完后才会关闭 [root@centos8 nginx-1.20.2]# ps aux | grep nginx root 1595 0.0 0.1 42452 2724 ? Ss Jan05 0:00 nginx: master process /usr/local/src/nginx/sbin/nginx -c /usr/local/src/nginx/conf/nginx.conf root 8328 0.0 0.3 42484 5860 ? S 15:44 0:00 nginx: master process /usr/local/src/nginx/sbin/nginx -c /usr/local/src/nginx/conf/nginx.conf nginx 8329 0.0 0.2 77240 5032 ? S 15:44 0:00 nginx: worker process root 8346 0.0 0.0 12136 1144 pts/0 S+ 15:48 0:00 grep --color=auto nginx [root@centos8 nginx-1.20.2]# #经过一段时间测试，新版本服务没问题，最后发送QUIT信号,退出老的master [root@centos8 nginx-1.20.2]# kill -QUIT `cat /usr/local/src/nginx/logs/nginx.pid.oldbin` [root@centos8 nginx-1.20.2]# # 查看版本是否升级成功 [root@centos8 nginx-1.20.2]# nginx -v nginx version: nginx/1.20.2 [root@centos8 nginx-1.20.2]# #回滚 #如果升级的版本发现问题需要回滚,可以发送HUP信号,重新拉起旧版本的worker [root@centos8 nginx-1.20.2]# kill -HUB `cat /usr/local/src/nginx/logs/nginx.pid.oldbin` #最后关闭新版的master [root@centos8 nginx-1.20.2]# kill -QUIT `cat /usr/local/src/nginx/logs/nginx.pid` ","permalink":"https://xyenvy.github.io/posts/nginx%E5%B9%B3%E6%BB%91%E5%8D%87%E7%BA%A7/","summary":"平滑升级流程 将旧Nginx二进制文件换成新Nginx程序文件（注意先备份) 向master进程发送USR2信号启动新nginx进程 master进程修改pid文件名加上后缀.oldbin,成为nginx.pid.oldbin master进程用新Nginx文件启动新master进程及w","title":"Nginx平滑升级"},{"content":"CentOS Docker 安装 Docker 支持以下的 64 位 CentOS 版本：\nCentOS 7 CentOS 8 更高版本\u0026hellip; 官方安装脚本自动安装 安装命令如下：\ncurl -fsSL https://get.docker.com | bash -s docker --mirror Aliyun 也可以使用国内 daocloud 一键安装命令：\ncurl -sSL https://get.daocloud.io/docker | sh 安装docker-compose Compose 简介 Compose 是用于定义和运行多容器 Docker 应用程序的工具。通过 Compose，您可以使用 YML 文件来配置应用程序需要的所有服务。然后，使用一个命令，就可以从 YML 文件配置中创建并启动所有服务。 Compose 安装 Linux 上我们可以从 Github 上下载它的二进制包来使用，最新发行的版本地址：url\n运行以下命令以下载 Docker Compose 的当前稳定版本：\ncurl -L \u0026#34;https://github.com/docker/compose/releases/download/v2.2.2/docker-compose-$(uname -s)-$(uname -m)\u0026#34; -o /usr/local/bin/docker-compose 要安装其他版本的 Compose，请替换 v2.2.2。\nDocker Compose 存放在 GitHub，不太稳定。\n你可以也通过执行下面的命令，高速安装 Docker Compose。\ncurl -L https://get.daocloud.io/docker/compose/releases/download/v2.4.1/docker-compose-`uname -s`-`uname -m` \u0026gt; /usr/local/bin/docker-compose 将可执行权限应用于二进制文件：\nchmod +x /usr/local/bin/docker-compose 创建软链：\nln -s /usr/local/bin/docker-compose /usr/bin/docker-compose 测试是否安装成功：\n[root@centos7 ~]# docker-compose version Docker Compose version v2.4.1 docker-compose一键部署mysql 创建安装目录,根据实际情况修改 mkdr mysql cd mysql mkdir -p data/db mkdir etc 编写docker-compose.yml cd mysql vim docker-compose.yml docker-compose.yml内容如下\nversion: \u0026#39;3.1\u0026#39; services: mysql: image: mysql:5.7 #mysql版本 container_name: ${MYSQL_NAME} volumes: - ./data/db:/var/lib/mysql - ./etc/my.cnf:/etc/mysql/mysql.conf.d/mysqld.cnf restart: always ports: - ${MYSQL_PORT}:3306 environment: MYSQL_ROOT_PASSWORD: ${MYSQL_ROOT_PASSWD} #访问密码 secure_file_priv: 创建MySQL配置文件 cd mysql/etc vim my.cnf my.cnf文件内容如下\n[mysqld] character-set-server=utf8 log-bin=mysql-bin server-id=1 pid-file = /var/run/mysqld/mysqld.pid socket = /var/run/mysqld/mysqld.sock datadir = /var/lib/mysql sql_mode=STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION symbolic-links=0 secure_file_priv = wait_timeout=120 interactive_timeout=120 default-time_zone = \u0026#39;+8:00\u0026#39; skip-external-locking skip-name-resolve open_files_limit = 10240 max_connections = 1000 max_connect_errors = 6000 table_open_cache = 800 max_allowed_packet = 40m sort_buffer_size = 2M join_buffer_size = 1M thread_cache_size = 32 query_cache_size = 64M transaction_isolation = READ-COMMITTED tmp_table_size = 128M max_heap_table_size = 128M log-bin = mysql-bin sync-binlog = 1 binlog_format = ROW binlog_cache_size = 1M key_buffer_size = 128M read_buffer_size = 2M read_rnd_buffer_size = 4M bulk_insert_buffer_size = 64M lower_case_table_names = 1 explicit_defaults_for_timestamp=true skip_name_resolve = ON event_scheduler = ON log_bin_trust_function_creators = 1 innodb_buffer_pool_size = 512M innodb_flush_log_at_trx_commit = 1 innodb_file_per_table = 1 innodb_log_buffer_size = 4M innodb_log_file_size = 256M innodb_max_dirty_pages_pct = 90 innodb_read_io_threads = 4 innodb_write_io_threads = 4 编写重启脚本 cd mysql vim restart.sh restart.sh文件内容\n#!/bin/bash docker-compose stop docker-compose rm -f docker-compose up -d 编写.env文件 vim .env # 容器名称 MYSQL_NAME=docker-mysql # 启用端口 MYSQL_PORT=3306 # root密码 MYSQL_ROOT_PASSWD=123456 验证 # 执行启动脚本 bash restart.sh # 查看运行的容器 docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 36d09017f331 mysql:5.7 \u0026#34;docker-entrypoint.s…\u0026#34; 2 minutes ago Up 2 minutes 0.0.0.0:3306-\u0026gt;3306/tcp, :::3306-\u0026gt;3306/tcp, 33060/tcp docker-mysql ","permalink":"https://xyenvy.github.io/posts/docker-compose%E9%83%A8%E7%BD%B2mysql/","summary":"CentOS Docker 安装 Docker 支持以下的 64 位 CentOS 版本： CentOS 7 CentOS 8 更高版本\u0026hellip; 官方安装脚本自动安装 安装命令如下： curl -fsSL https://get.docker.com | bash -s docker --mirror Aliyun 也可以使用国内 daocloud 一键安装命令： curl -sSL https://get.daocloud.io/docker | sh 安装docker-compose Compose 简介 Compose 是用于定义和运行多容器 Docker 应用程序的工具。通过 Compose，您可以使用 YML 文件来配置应","title":"docker-compose部署MySQL"},{"content":"#!/bin/bash # #******************************************************************** #Author:yuankun #Date: 2023-01-04 #FileName：install_nginx.sh #Description：The test script #******************************************************************** # 安装资源下载路径 SRC_DIR=/usr/local/src/ # 下载地址 NGINX_URL=http://nginx.org/download/ # 安装版本 NGINX_FILE=nginx-1.20.2 TAR=.tar.gz # 安装路径 NGINX_INSTALL_DIR=/usr/local/src/nginx # 查看CPU核心数 CPUS=`lscpu |awk \u0026#39;/^CPU\\(s\\)/{print $2}\u0026#39;` . /etc/os-release # 颜色 color () { RES_COL=60 MOVE_TO_COL=\u0026#34;echo -en \\\\033[${RES_COL}G\u0026#34; SETCOLOR_SUCCESS=\u0026#34;echo -en \\\\033[1;32m\u0026#34; SETCOLOR_FAILURE=\u0026#34;echo -en \\\\033[1;31m\u0026#34; SETCOLOR_WARNING=\u0026#34;echo -en \\\\033[1;33m\u0026#34; SETCOLOR_NORMAL=\u0026#34;echo -en \\E[0m\u0026#34; echo -n \u0026#34;$1\u0026#34; \u0026amp;\u0026amp; $MOVE_TO_COL echo -n \u0026#34;[\u0026#34; if [ $2 = \u0026#34;success\u0026#34; -o $2 = \u0026#34;0\u0026#34; ] ;then ${SETCOLOR_SUCCESS} echo -n $\u0026#34; OK \u0026#34; elif [ $2 = \u0026#34;failure\u0026#34; -o $2 = \u0026#34;1\u0026#34; ] ;then ${SETCOLOR_FAILURE} echo -n $\u0026#34;FAILED\u0026#34; else ${SETCOLOR_WARNING} echo -n $\u0026#34;WARNING\u0026#34; fi ${SETCOLOR_NORMAL} echo -n \u0026#34;]\u0026#34; echo } os_type () { awk -F\u0026#39;[ \u0026#34;]\u0026#39; \u0026#39;/^NAME/{print $2}\u0026#39; /etc/os-release } os_version () { awk -F\u0026#39;\u0026#34;\u0026#39; \u0026#39;/^VERSION_ID/{print $2}\u0026#39; /etc/os-release } check () { [ -e ${NGINX_INSTALL_DIR} ] \u0026amp;\u0026amp; { color \u0026#34;nginx 已安装,请卸载后再安装\u0026#34; 1; exit; } cd ${SRC_DIR} if [ -e ${NGINX_FILE}${TAR} ];then color \u0026#34;相关文件已准备好\u0026#34; 0 else color \u0026#39;开始下载 nginx 源码包\u0026#39; 0 wget ${NGINX_URL}${NGINX_FILE}${TAR} [ $? -ne 0 ] \u0026amp;\u0026amp; { color \u0026#34;下载 ${NGINX_FILE}${TAR}文件失败\u0026#34; 1; exit; } fi } install () { color \u0026#34;开始安装 nginx\u0026#34; 0 if id nginx \u0026amp;\u0026gt; /dev/null;then color \u0026#34;nginx 用户已存在\u0026#34; 1 else useradd -s /sbin/nologin -r nginx color \u0026#34;创建 nginx 用户\u0026#34; 0 fi color \u0026#34;开始安装 nginx 依赖包\u0026#34; 0 if [ $ID == \u0026#34;centos\u0026#34; ] ;then if [[ $VERSION_ID =~ ^7 ]];then yum -y -q install make gcc pcre-devel openssl-devel zlib-devel perl-ExtUtils-Embed elif [[ $VERSION_ID =~ ^8 ]];then yum -y -q install make gcc-c++ libtool pcre pcre-devel zlib zlib-devel openssl openssl-devel perl-ExtUtils-Embed else color \u0026#39;不支持此系统!\u0026#39; 1 exit fi elif [ $ID == \u0026#34;rocky\u0026#34; ];then yum -y -q install make gcc-c++ libtool pcre pcre-devel zlib zlib-devel openssl openssl-devel perl-ExtUtils-Embed else apt update \u0026amp;\u0026gt; /dev/null apt -y install make gcc libpcre3 libpcre3-dev openssl libssl-dev zlib1g-dev \u0026amp;\u0026gt; /dev/null fi cd $SRC_DIR tar xf ${NGINX_FILE}${TAR} NGINX_DIR=`echo ${NGINX_FILE}${TAR}| sed -nr \u0026#39;s/^(.*[0-9]).*/\\1/p\u0026#39;` cd ${NGINX_DIR} \u0026amp;\u0026amp; pwd ./configure --prefix=${NGINX_INSTALL_DIR} --user=nginx --group=nginx --with-http_ssl_module --with-http_v2_module --with-http_realip_module --with-http_stub_status_module --with-http_gzip_static_module --with-pcre --with-stream --with-stream_ssl_module make -j $CPUS \u0026amp;\u0026amp; make install [ $? -eq 0 ] \u0026amp;\u0026amp; color \u0026#34;nginx 编译安装成功\u0026#34; 0 || { color \u0026#34;nginx 编译安装失败,退出!\u0026#34; 1 ;exit; } echo \u0026#34;PATH=${NGINX_INSTALL_DIR}/sbin:${PATH}\u0026#34; \u0026gt; /etc/profile.d/nginx.sh cat \u0026gt; /lib/systemd/system/nginx.service \u0026lt;\u0026lt;EOF [Unit] Description=The nginx HTTP and reverse proxy server After=network.target remote-fs.target nss-lookup.target [Service] Type=forking PIDFile=${NGINX_INSTALL_DIR}/logs/nginx.pid ExecStartPre=/bin/rm -f ${NGINX_INSTALL_DIR}/logs/nginx.pid ExecStartPre=${NGINX_INSTALL_DIR}/sbin/nginx -t ExecStart=${NGINX_INSTALL_DIR}/sbin/nginx ExecReload=/bin/kill -s HUP \\$MAINPID KillSignal=SIGQUIT TimeoutStopSec=5 KillMode=process PrivateTmp=true LimitNOFILE=100000 [Install] WantedBy=multi-user.target EOF systemctl daemon-reload systemctl enable --now nginx \u0026amp;\u0026gt; /dev/null systemctl is-active nginx \u0026amp;\u0026gt; /dev/null || { color \u0026#34;nginx 启动失败,退出!\u0026#34; 1 ; exit; } color \u0026#34;nginx 安装完成\u0026#34; 0 } check install ","permalink":"https://xyenvy.github.io/posts/%E5%9C%A8%E7%BA%BF%E4%B8%80%E9%94%AE%E5%AE%89%E8%A3%85nginx%E8%84%9A%E6%9C%AC/","summary":"#!/bin/bash # #******************************************************************** #Author:yuankun #Date: 2023-01-04 #FileName：install_nginx.sh #Description：The test script #******************************************************************** # 安装资源下载路径 SRC_DIR=/usr/local/src/ # 下载地址 NGINX_URL=http://nginx.org/download/ # 安装版本 NGINX_FILE=nginx-1.20.2 TAR=.tar.gz # 安装路径 NGINX_INSTALL_DIR=/usr/local/src/nginx # 查看CPU核心数 CPUS=`lscpu |awk \u0026#39;/^CPU\\(s\\)/{print $2}\u0026#39;` . /etc/os-release # 颜色 color () { RES_COL=60 MOVE_TO_COL=\u0026#34;echo -en \\\\033[${RES_COL}G\u0026#34; SETCOLOR_SUCCESS=\u0026#34;echo -en \\\\033[1;32m\u0026#34; SETCOLOR_FAILURE=\u0026#34;echo -en \\\\033[1;31m\u0026#34; SETCOLOR_WARNING=\u0026#34;echo -en \\\\033[1;33m\u0026#34; SETCOLOR_NORMAL=\u0026#34;echo -en \\E[0m\u0026#34; echo -n \u0026#34;$1\u0026#34; \u0026amp;\u0026amp; $MOVE_TO_COL echo -n \u0026#34;[\u0026#34; if [ $2 = \u0026#34;success\u0026#34; -o $2 = \u0026#34;0\u0026#34; ] ;then ${SETCOLOR_SUCCESS} echo -n $\u0026#34;","title":"在线一键安装Nginx脚本"},{"content":"Nginx安装 Nginx版本和安装方式 Nginx版本\nMainline version 主要开发版本,一般为奇数版本号,比如1.19 Stable version 当前最新稳定版,一般为偶数版本,如:1.20 Legacy versions 旧的稳定版,一般为偶数版本,如:1.18 Nginx安装可以使用yum或源码安装，但是推荐使用源码编译安装\nyum的版本比较旧 编译安装可以更方便自定义相关路径 使用源码编译可以自定义相关功能，更方便业务的上的使用 基于yum安装Nginx 查看系统和EPEL的nginx版本\n# centos和rocky系统 [root@centos8 ~]# yum list nginx Repository extras is listed more than once in the configuration Last metadata expiration check: 0:28:13 ago on Wed 04 Jan 2023 11:51:31 AM CST. Available Packages nginx.x86_64 1:1.14.1-9.module_el8.0.0+184+e34fea82 AppStream nginx.x86_64 1:1.14.1-9.module_el8.0.0+184+e34fea82 appstream [root@centos8 ~]# [root@centos8 ~]# dnf list nginx Repository extras is listed more than once in the configuration Last metadata expiration check: 0:28:55 ago on Wed 04 Jan 2023 11:51:31 AM CST. Available Packages nginx.x86_64 1:1.14.1-9.module_el8.0.0+184+e34fea82 AppStream nginx.x86_64 1:1.14.1-9.module_el8.0.0+184+e34fea82 appstream [root@centos8 ~]# # ubuntu系统 root@ubuntu2004:~# apt list nginx Listing... Done nginx/focal-updates,focal-security 1.18.0-0ubuntu1.4 all N: There is 1 additional version. Please use the \u0026#39;-a\u0026#39; switch to see it root@ubuntu2004:~# centos、rocky系统yum安装\nyum install nginx # centos、rocky系统安装nginx后未启动，使用如下命令启动 systemctl start nginx ubuntu系统安装\napt update;apt install nginx 官方包源安装Nginx 系统和EPEL源的中 nignx版本较旧,可以安装官方源的最新版本 官方包链接:\nhttp://nginx.org/en/linux_packages.html 官方 yum 源链接:\nhttp://nginx.org/en/linux_packages.html #RHEL-CentOS 通过官方 yum 源安装nginx\n[root@centos8 ~]# vim /etc/yum.repos.d/nginx.repo [nginx-stable] name=nginx stable repo baseurl=http://nginx.org/packages/centos/$releasever/$basearch/ gpgcheck=1 enabled=1 gpgkey=https://nginx.org/keys/nginx_signing.key module_hotfixes=true [root@centos8 ~]# yum clean all 42 files removed [root@centos8 ~]# yum makecache # 查看所有的版本 [root@centos8]# yum list nginx --showduplicates nginx stable repo 462 B/s | 47 kB 01:44 Available Packages nginx.x86_64 1.16.0-1.el8.ngx nginx-stable nginx.x86_64 1:1.14.1-9.module+el8.4.0+542+81547229 appstream nginx.x86_64 1:1.16.1-1.el8.ngx nginx-stable nginx.x86_64 1:1.18.0-1.el8.ngx nginx-stable nginx.x86_64 1:1.18.0-2.el8.ngx nginx-stable nginx.x86_64 1:1.20.0-1.el8.ngx nginx-stable nginx.x86_64 1:1.20.1-1.el8.ngx nginx-stable nginx.x86_64 1:1.20.2-1.el8.ngx nginx-stable nginx.x86_64 1:1.22.0-1.el8.ngx nginx-stable nginx.x86_64 1:1.22.1-1.el8.ngx nginx-stable #安装指定版本 [root@centos8 ~]#yum -y install nginx-1.18.0 检查安装 rpm -ql nginx 查看帮助 [root@centos8 ~]# nginx -h ···· ···· ···· Options: -?,-h : this help -v : show version and exit -V : show version and configure options then exit #显示版本和编译参数 -t : test configuration and exit #测试配置文件是否异常 -T : test configuration, dump it and exit #测试并打印 -q : suppress non-error messages during configuration testing #静默模式 -s signal : send signal to a master process: stop, quit, reopen, reload #发送信号,reload信号 会生成新的worker,但master不会重新生成 -p prefix : set prefix path (default: /etc/nginx/)#指定Nginx 目录 -c filename : set configuration file (default: /etc/nginx/nginx.conf)#配置文件路径 -g directives : set global directives out of configuration file#设置全局指令,注意和配置文件不要同时配置,否则冲突 验证配置文件 [root@centos8 ~]# nginx -t nginx: the configuration file /etc/nginx/nginx.conf syntax is ok nginx: configuration file /etc/nginx/nginx.conf test is successful [root@centos8 ~]# 启动文件 [root@centos8 ~]# cat /lib/systemd/system/nginx.service [Unit] Description=The nginx HTTP and reverse proxy server After=network.target remote-fs.target nss-lookup.target [Service] Type=forking PIDFile=/run/nginx.pid # Nginx will fail to start if /run/nginx.pid already exists but has the wrong # SELinux context. This might happen when running `nginx -t` from the cmdline. # https://bugzilla.redhat.com/show_bug.cgi?id=1268621 ExecStartPre=/usr/bin/rm -f /run/nginx.pid ExecStartPre=/usr/sbin/nginx -t ExecStart=/usr/sbin/nginx ExecReload=/bin/kill -s HUP $MAINPID KillSignal=SIGQUIT TimeoutStopSec=5 KillMode=mixed PrivateTmp=true [Install] WantedBy=multi-user.target [root@centos8 ~]# 启动Nginx systemctl enable --now nginx Nginx编译安装 官方源码包下载地址：\nhttps://nginx.org/en/download.html 范例：编译安装\n系统centos8.5\nNginx版本：1.18.0\n安装扩展依赖\n[root@centos8 ~]# yum -y install gcc pcre-devel openssl-devel zlib-devel 创建用户和组 groupadd nginx useradd -s /sbin/nologin -g nginx nginx 下载安装包并解压 [root@centos8 ~]# cd /usr/local/src/ [root@centos8 ~]# wget https://nginx.org/download/nginx-1.18.0.tar.gz [root@centos8 src]# tar xf nginx-1.18.0.tar.gz [root@centos8 src]# cd nginx-1.18.0 安装 [root@centos8 nginx-1.18.0]# ./configure --prefix=/usr/local/src/nginx/ \\ # 安装位置 --user=nginx \\ # 运行的用户 --group=nginx \\ --with-http_ssl_module \\ --with-http_v2_module \\ --with-http_realip_module \\ --with-http_stub_status_module \\ --with-http_gzip_static_module \\ --with-pcre \\ --with-stream \\ --with-stream_ssl_module [root@centos8 nginx-1.18.0]#make \u0026amp;\u0026amp; make install 修改权限 [root@centos8 /]# chown -R nginx.nginx /usr/local/src/nginx/ nginx安装完成后有四个主要的目录 [root@centos8 /]# ll /usr/local/src/nginx/ total 4 drwxr-xr-x. 2 nginx nginx 4096 Jan 4 15:17 conf drwxr-xr-x. 2 nginx nginx 40 Jan 4 15:17 html drwxr-xr-x. 2 nginx nginx 6 Jan 4 15:17 logs drwxr-xr-x. 2 nginx nginx 19 Jan 4 15:17 sbin [root@centos8 /]# conf：保存nginx所有的配置文件，其中nginx.conf是nginx服务器的最核心最主要的配置文件，其他 的.conf则是用来配置nginx相关的功能的，例如fastcgi功能使用的是fastcgi.conf和 fastcgi_params两个文件，配置文件一般都有一个样板配置文件，是以.default为后缀，使用时可将其复 制并将default后缀去掉即可。 html目录中保存了nginx服务器的web文件，但是可以更改为其他目录保存web文件,另外还有一个50x的web 文件是默认的错误页面提示页面。 logs：用来保存nginx服务器的访问日志错误日志等日志，logs目录可以放在其他 验证版本及编译参数 [root@centos8 /]# ln -s /usr/local/src/nginx/sbin/nginx /usr/bin/ [root@centos8 /]# nginx -V nginx version: nginx/1.18.0 built by gcc 8.5.0 20210514 (Red Hat 8.5.0-4) (GCC) built with OpenSSL 1.1.1k FIPS 25 Mar 2021 TLS SNI support enabled configure arguments: --prefix=/usr/local/src/nginx --user=nginx --group=nginx --with-http_ssl_module --with-http_v2_module --with-http_realip_module --with-http_stub_status_module --with-http_gzip_static_module --with-pcre --with-stream --with-stream_ssl_module [root@centos8 /]# 创建Nginx启动文件 #复制同一版本的nginx的yum安装生成的service文件 [root@centos8 ~]# vim /lib/systemd/system/nginx.service [Unit] Description=nginx - high performance web server Documentation=http://nginx.org/en/docs/ After=network.target [Service] Type=forking PIDFile=/usr/local/src/nginx/logs/nginx.pid ExecStartPre=/usr/local/src//nginx/sbin/nginx -t -c /usr/local/src/nginx/conf/nginx.conf ExecStart=/usr/local/src/nginx/sbin/nginx -c /usr/local/src/nginx/conf/nginx.conf ExecReload=/bin/kill -s HUP $MAINPID ExecStop=/bin/kill -s QUIT $MAINPID PrivateTmp=true [Install] WantedBy=multi-user.target 验证启动文件 [root@centos8 ~]#systemctl daemon-reload [root@centos8 ~]#systemctl enable --now nginx Created symlink /etc/systemd/system/multi-user.target.wants/nginx.service → /usr/lib/systemd/system/nginx.service. [root@centos8 ~]# Nginx命令和信号 nginx 命令支持向其发送信号,实现不同功能 nginx 格式\nnginx [-?hvVtTq] [-s signal] [-c filename] [-p prefix] [-g directives] 选项说明\n帮助: -? -h 使用指定的配置文件: -c 指定配置指令:-g 指定运行目录:-p 测试配置文件是否有语法错误:-t -T 打印nginx的版本信息、编译信息等:-v -V 发送信号: -s 示例: nginx -s reload 信号说明\n立刻停止服务:stop,相当于信号SIGTERM,SIGINT 优雅的停止服务:quit,相当于信号SIGQUIT 平滑重启，重新加载配置文件: reload,相当于信号SIGHUP 重新开始记录日志文件:reopen,相当于信号SIGUSR1,在切割日志时用途较大 平滑升级可执行程序:发送信号SIGUSR2,在升级版本时使用 优雅的停止工作进程:发送信号SIGWINCH,在升级版本时使用 ","permalink":"https://xyenvy.github.io/posts/nginx%E5%9F%BA%E7%A1%80/","summary":"Nginx安装 Nginx版本和安装方式 Nginx版本 Mainline version 主要开发版本,一般为奇数版本号,比如1.19 Stable version 当前最新稳定版,一般为偶数版本,如:1.20 Legacy versions 旧的稳定版,一般为偶数版本,如:1.18 Nginx安装可以使用yum或源码安装，但是推荐使用源码编译安装 yum的版本比较旧 编译安","title":"Nginx基础"},{"content":" 在线安装 系统 Centos7.9 、Rockylinux8.5、Centos8.5、ubuntu20.04实测安装成功\n#!/bin/bash # #******************************************************************** #Author: yuankun #Date: 2022-12-17 #FileName： install_redis.sh #URL: https://gzyuankun.github.io #Description: The test script #Copyright (C): 2020 All rights reserved #******************************************************************** REDIS_VERSION=redis-6.2.5 PASSWORD=123456 INSTALL_DIR=/usr/local/src/redis CPUS=`lscpu |awk \u0026#39;/^CPU\\(s\\)/{print $2}\u0026#39;` . /etc/os-release color () { RES_COL=60 MOVE_TO_COL=\u0026#34;echo -en \\\\033[${RES_COL}G\u0026#34; SETCOLOR_SUCCESS=\u0026#34;echo -en \\\\033[1;32m\u0026#34; SETCOLOR_FAILURE=\u0026#34;echo -en \\\\033[1;31m\u0026#34; SETCOLOR_WARNING=\u0026#34;echo -en \\\\033[1;33m\u0026#34; SETCOLOR_NORMAL=\u0026#34;echo -en \\E[0m\u0026#34; echo -n \u0026#34;$1\u0026#34; \u0026amp;\u0026amp; $MOVE_TO_COL echo -n \u0026#34;[\u0026#34; if [ $2 = \u0026#34;success\u0026#34; -o $2 = \u0026#34;0\u0026#34; ] ;then ${SETCOLOR_SUCCESS} echo -n $\u0026#34; OK \u0026#34; elif [ $2 = \u0026#34;failure\u0026#34; -o $2 = \u0026#34;1\u0026#34; ] ;then ${SETCOLOR_FAILURE} echo -n $\u0026#34;FAILED\u0026#34; else ${SETCOLOR_WARNING} echo -n $\u0026#34;WARNING\u0026#34; fi ${SETCOLOR_NORMAL} echo -n \u0026#34;]\u0026#34; echo } prepare(){ if [ $ID = \u0026#34;centos\u0026#34; -o $ID = \u0026#34;rocky\u0026#34; ];then yum -y install gcc make systemd-devel else apt update apt -y install gcc make libjemalloc-dev libsystemd-dev fi if [ $? -eq 0 ];then color \u0026#34;安装软件包成功\u0026#34; 0 else color \u0026#34;安装软件包失败，请检查网络配置\u0026#34; 1 exit fi } install() { if [ ! -f ${REDIS_VERSION}.tar.gz ];then wget http://download.redis.io/releases/${REDIS_VERSION}.tar.gz || { color \u0026#34;Redis 源码下载失败\u0026#34; 1 ; exit; } fi tar xf ${REDIS_VERSION}.tar.gz -C /usr/local/src cd /usr/local/src/${REDIS_VERSION} make -j $CUPS USE_SYSTEMD=yes PREFIX=${INSTALL_DIR} install \u0026amp;\u0026amp; color \u0026#34;Redis 编译安装完成\u0026#34; 0 || { color \u0026#34;Redis 编译安装失败\u0026#34; 1 ;exit ; } ln -s ${INSTALL_DIR}/bin/redis-* /usr/bin/ mkdir -p ${INSTALL_DIR}/{etc,log,data,run} cp redis.conf ${INSTALL_DIR}/etc/ sed -i -e \u0026#39;s/bind 127.0.0.1/bind 0.0.0.0/\u0026#39; -e \u0026#34;/# requirepass/a requirepass $PASSWORD\u0026#34; -e \u0026#34;/^dir .*/c dir ${INSTALL_DIR}/data/\u0026#34; -e \u0026#34;/logfile .*/c logfile ${INSTALL_DIR}/log/redis-6379.log\u0026#34; -e \u0026#34;/^pidfile .*/c pidfile ${INSTALL_DIR}/run/redis_6379.pid\u0026#34; ${INSTALL_DIR}/etc/redis.conf if id redis \u0026amp;\u0026gt; /dev/null ;then color \u0026#34;Redis 用户已存在\u0026#34; 1 else useradd -r -s /sbin/nologin redis color \u0026#34;Redis 用户创建成功\u0026#34; 0 fi chown -R redis.redis ${INSTALL_DIR} cat \u0026gt;\u0026gt; /etc/sysctl.conf \u0026lt;\u0026lt;EOF net.core.somaxconn = 1024 vm.overcommit_memory = 1 EOF sysctl -p if [ $ID = \u0026#34;centos\u0026#34; -o $ID = \u0026#34;rocky\u0026#34; ];then echo \u0026#39;echo never \u0026gt; /sys/kernel/mm/transparent_hugepage/enabled\u0026#39; \u0026gt;\u0026gt; /etc/rc.d/rc.local chmod +x /etc/rc.d/rc.local /etc/rc.d/rc.local else echo -e \u0026#39;#!/bin/bash\\necho never \u0026gt; /sys/kernel/mm/transparent_hugepage/enabled\u0026#39; \u0026gt;\u0026gt; /etc/rc.local chmod +x /etc/rc.local /etc/rc.local fi cat \u0026gt; /lib/systemd/system/redis.service \u0026lt;\u0026lt;EOF [Unit] Description=Redis persistent key-value database After=network.target [Service] ExecStart=${INSTALL_DIR}/bin/redis-server ${INSTALL_DIR}/etc/redis.conf --supervised systemd ExecStop=/bin/kill -s QUIT \\$MAINPID Type=notify User=redis Group=redis RuntimeDirectory=redis RuntimeDirectoryMode=0755 LimitNOFILE=1000000 [Install] WantedBy=multi-user.target EOF systemctl daemon-reload systemctl enable --now redis \u0026amp;\u0026gt; /dev/null if [ $? -eq 0 ];then color \u0026#34;Redis 服务启动成功,Redis信息如下:\u0026#34; 0 else color \u0026#34;Redis 启动失败\u0026#34; 1 exit fi sleep 2 redis-cli -a $PASSWORD INFO Server 2\u0026gt; /dev/null } prepare install ","permalink":"https://xyenvy.github.io/posts/redis%E4%B8%80%E9%94%AE%E5%AE%89%E8%A3%85%E8%84%9A%E6%9C%AC/","summary":"在线安装 系统 Centos7.9 、Rockylinux8.5、Centos8.5、ubuntu20.04实测安装成功 #!/bin/bash # #******************************************************************** #Author: yuankun #Date: 2022-12-17 #FileName： install_redis.sh #URL: https://gzyuankun.github.io #Description: The test script #Copyright (C): 2020 All rights reserved #******************************************************************** REDIS_VERSION=redis-6.2.5 PASSWORD=123456 INSTALL_DIR=/usr/local/src/redis CPUS=`lscpu |awk \u0026#39;/^CPU\\(s\\)/{print $2}\u0026#39;` . /etc/os-release color () { RES_COL=60 MOVE_TO_COL=\u0026#34;echo -en \\\\033[${RES_COL}G\u0026#34; SETCOLOR_SUCCESS=\u0026#34;echo -en \\\\033[1;32m\u0026#34; SETCOLOR_FAILURE=\u0026#34;echo -en \\\\033[1;31m\u0026#34; SETCOLOR_WARNING=\u0026#34;echo -en \\\\033[1;33m\u0026#34; SETCOLOR_NORMAL=\u0026#34;echo -en \\E[0m\u0026#34; echo -n \u0026#34;$1\u0026#34; \u0026amp;\u0026amp; $MOVE_TO_COL echo -n \u0026#34;[\u0026#34; if [ $2 = \u0026#34;success\u0026#34; -o $2 = \u0026#34;0\u0026#34; ] ;then ${SETCOLOR_SUCCESS} echo -n $\u0026#34; OK \u0026#34; elif [ $2 = \u0026#34;failure\u0026#34; -o $2","title":"Redis一键安装脚本"},{"content":" 系统 Centos7.9\n步骤\n1.备份\n[root@centos7-master ~]# mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.bak 2.创建/etc/yum.repos.d/CentOS-Base.repo文件并复制如下内容\n[base] name=CentOS-$releasever - Base baseurl=http://mirrors.163.com/centos/$releasever/os/$basearch/ http://mirrors.aliyun.com/centos/$releasever/os/$basearch/ http://mirrors.cloud.tencent.com/centos/$releasever/os/$basearch/ http://mirrors.tuna.tsinghua.edu.cn/centos/$releasever/os/$basearch/ http://mirrors.huaweicloud.com/centos/$releasever/os/$basearch/ http://mirror.centos.org/centos/$releasever/os/$basearch/ gpgcheck=0 #released updates [updates] name=CentOS-$releasever - Updates baseurl=http://mirrors.163.com/centos/$releasever/updates/$basearch/ http://mirrors.aliyun.com/centos/$releasever/updates/$basearch/ http://mirrors.cloud.tencent.com/centos/$releasever/updates/$basearch/ http://mirrors.tuna.tsinghua.edu.cn/centos/$releasever/updates/$basearch/ http://mirrors.huaweicloud.com/centos/$releasever/updates/$basearch/ http://mirror.centos.org/centos/$releasever/updates/$basearch/ gpgcheck=0 #additional packages that may be useful [extras] name=CentOS-$releasever - Extras baseurl=http://mirrors.163.com/centos/$releasever/extras/$basearch/ http://mirrors.aliyun.com/centos/$releasever/extras/$basearch/ http://mirrors.cloud.tencent.com/centos/$releasever/extras/$basearch/ http://mirrors.tuna.tsinghua.edu.cn/centos/$releasever/extras/$basearch/ http://mirrors.huaweicloud.com/centos/$releasever/extras/$basearch/ http://mirror.centos.org/centos/$releasever/extras/$basearch/ gpgcheck=0 #additional packages that extend functionality of existing packages [centosplus] name=CentOS-$releasever - Plus baseurl=http://mirrors.163.com/centos/$releasever/centosplus/$basearch/ http://mirrors.aliyun.com/centos/$releasever/centosplus/$basearch/ http://mirrors.cloud.tencent.com/centos/$releasever/centosplus/$basearch/ http://mirrors.tuna.tsinghua.edu.cn/centos/$releasever/centosplus/$basearch/ http://mirrors.huaweicloud.com/centos/$releasever/centosplus/$basearch/ http://mirror.centos.org/centos/$releasever/centosplus/$basearch/ gpgcheck=0 enabled=1 3.清除缓存\nyum clean all 4.重新生成缓存\nyum makecache ","permalink":"https://xyenvy.github.io/posts/centos%E7%B3%BB%E7%BB%9Fyum%E9%85%8D%E7%BD%AE/","summary":"系统 Centos7.9 步骤 1.备份 [root@centos7-master ~]# mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.bak 2.创建/etc/yum.repos.d/CentOS-Base.repo文件并复制如下内容 [base] name=CentOS-$releasever - Base baseurl=http://mirrors.163.com/centos/$releasever/os/$basearch/ http://mirrors.aliyun.com/centos/$releasever/os/$basearch/ http://mirrors.cloud.tencent.com/centos/$releasever/os/$basearch/ http://mirrors.tuna.tsinghua.edu.cn/centos/$releasever/os/$basearch/ http://mirrors.huaweicloud.com/centos/$releasever/os/$basearch/ http://mirror.centos.org/centos/$releasever/os/$basearch/ gpgcheck=0 #released updates [updates] name=CentOS-$releasever - Updates baseurl=http://mirrors.163.com/centos/$releasever/updates/$basearch/ http://mirrors.aliyun.com/centos/$releasever/updates/$basearch/ http://mirrors.cloud.tencent.com/centos/$releasever/updates/$basearch/ http://mirrors.tuna.tsinghua.edu.cn/centos/$releasever/updates/$basearch/ http://mirrors.huaweicloud.com/centos/$releasever/updates/$basearch/ http://mirror.centos.org/centos/$releasever/updates/$basearch/ gpgcheck=0 #additional packages that may be useful [extras] name=CentOS-$releasever - Extras baseurl=http://mirrors.163.com/centos/$releasever/extras/$basearch/ http://mirrors.aliyun.com/centos/$releasever/extras/$basearch/ http://mirrors.cloud.tencent.com/centos/$releasever/extras/$basearch/ http://mirrors.tuna.tsinghua.edu.cn/centos/$releasever/extras/$basearch/ http://mirrors.huaweicloud.com/centos/$releasever/extras/$basearch/ http://mirror.centos.org/centos/$releasever/extras/$basearch/ gpgcheck=0 #additional packages that extend functionality of existing packages [centosplus] name=CentOS-$releasever - Plus baseurl=http://mirrors.163.com/centos/$releasever/centosplus/$basearch/ http://mirrors.aliyun.com/centos/$releasever/centosplus/$basearch/ http://mirrors.cloud.tencent.com/centos/$releasever/centosplus/$basearch/ http://mirrors.tuna.tsinghua.edu.cn/centos/$releasever/centosplus/$basearch/ http://mirrors.huaweicloud.com/centos/$releasever/centosplus/$basearch/ http://mirror.centos.org/centos/$releasever/centosplus/$basearch/ gpgcheck=0 enabled=1 3.清除缓存 yum clean all 4.重新生成缓存 yum makecache","title":"Centos系统yum源配置"},{"content":"简介 Redis单机服务存在数据和服务的单点问题,而且单机性能也存在着上限,可以利用Redis的集群相关技术来解决这些问题.\n主从复制实现 主从命令配置 当配置Redis复制功能时，强烈建议打开主服务器的持久化功能。否则的话，由于延迟等问题，部署的主节点Redis服务应该要避免自动启动。\n参考案例: 导致主从服务器数据全部丢失\n1.假设节点A为主服务器，并且关闭了持久化。并且节点B和节点C从节点A复制数据 2.节点A崩溃，然后由自动拉起服务重启了节点A.由于节点A的持久化被关闭了，所以重启之后没有任何数据 3.节点B和节点C将从节点A复制数据，但是A的数据是空的，于是就把自身保存的数据副本删除。 在关闭主服务器上的持久化，并同时开启自动拉起进程的情况下，即便使用Sentinel来实现Redis的高可用性，也是非常危险的。因为主服务器可能拉起得非常快，以至于Sentinel在配置的心跳时间间隔内没有检测到主服务器已被重启，然后还是会执行上面的数据丢失的流程。无论何时，数据安全都是极其重要的，所以应该禁止主服务器关闭持久化的同时自动启动。\n启用主从同步 Redis Server 默认为 master节点，如果要配置为从节点,需要指定master服务器的IP,端口及连接密码在从节点执行 REPLICAOF MASTER_IP PORT 指令可以启用主从同步复制功能,早期版本使用 SLAVEOF指令\n127.0.0.1:6379\u0026gt; REPLICAOF MASTER_IP PORT #新版推荐使用 127.0.0.1:6379\u0026gt; SLAVEOF MasterIP Port #旧版使用，将被淘汰 127.0.0.1:6379\u0026gt; CONFIG SET masterauth \u0026lt;masterpass\u0026gt; 在master实现 127.0.0.1:6379\u0026gt; AUTH 123456 OK 127.0.0.1:6379\u0026gt; INFO replication #查看当前角色默认为master # Replication role:master connected_slaves:0 master_failover_state:no-failover master_replid:f945fd1714d8d3b78a149c8b2e0d57567ee6cb77 master_replid2:0000000000000000000000000000000000000000 master_repl_offset:1361 second_repl_offset:-1 repl_backlog_active:1 repl_backlog_size:1048576 repl_backlog_first_byte_offset:1 repl_backlog_histlen:1361 127.0.0.1:6379\u0026gt; 在slave实现 #在slave上设置master的IP和端口，4.0版之前的指令为slaveof 127.0.0.1:6380\u0026gt; REPLICAOF 127.0.0.1 6379 #仍可使用SLAVEOF MasterIP Port OK 127.0.0.1:6380\u0026gt; #在slave上设置master的密码 127.0.0.1:6379\u0026gt; CONFIG SET masterauth 123456 # Replication #角色变为slave 127.0.0.1:6380\u0026gt; INFO replication # Replication role:slave master_host:127.0.0.1 #指向master master_port:6379 master_link_status:up master_last_io_seconds_ago:1 master_sync_in_progress:0 slave_read_repl_offset:1515 slave_repl_offset:1515 slave_priority:100 slave_read_only:1 replica_announced:1 connected_slaves:0 master_failover_state:no-failover master_replid:f945fd1714d8d3b78a149c8b2e0d57567ee6cb77 master_replid2:0000000000000000000000000000000000000000 master_repl_offset:1515 second_repl_offset:-1 repl_backlog_active:1 repl_backlog_size:1048576 repl_backlog_first_byte_offset:1362 repl_backlog_histlen:154 127.0.0.1:6380\u0026gt; 在master实现 # 添加值 127.0.0.1:6379\u0026gt; set class m48 OK 127.0.0.1:6379\u0026gt; 在slave验证是否同步过来 # 在slave执行 127.0.0.1:6380\u0026gt; get class \u0026#34;m48\u0026#34; 127.0.0.1:6380\u0026gt; # 可以看到已经同步成功 master实现 #在master上可以看到所有slave信息 127.0.0.1:6379\u0026gt; info replication # Replication role:master connected_slaves:1 slave0:ip=127.0.0.1,port=6380,state=online,offset=1907,lag=0 master_failover_state:no-failover master_replid:f945fd1714d8d3b78a149c8b2e0d57567ee6cb77 master_replid2:0000000000000000000000000000000000000000 master_repl_offset:1907 second_repl_offset:-1 repl_backlog_active:1 repl_backlog_size:1048576 repl_backlog_first_byte_offset:1 repl_backlog_histlen:1907 127.0.0.1:6379\u0026gt; 删除主从同步 在slave实现 # 在从节点执行 REPLICAOF NO ONE 指令可以取消主从复制 #取消复制,在slave上执行REPLICAOF NO ONE,会断开和master的连接不再主从复制, 但不会清除slave 上已有的数据 127.0.0.1:6380\u0026gt; REPLICAOF no one 验证同步 查看master日志 [root@centos7-master ~]# tail -f /usr/local/src/redis/log/redis_6379.log 945:M 13 Dec 2022 22:27:17.550 * Synchronization with replica 127.0.0.1:6380 succeeded 945:M 13 Dec 2022 22:42:59.410 # Connection with replica 127.0.0.1:6380 lost. 945:M 13 Dec 2022 22:46:34.373 * Replica 127.0.0.1:6380 asks for synchronization 945:M 13 Dec 2022 22:46:34.373 * Partial resynchronization not accepted: Replication ID mismatch (Replica asked for \u0026#39;1200062e6b1065421dec8531ca2d96776029ab3d\u0026#39;, my replication IDs are \u0026#39;f945fd1714d8d3b78a149c8b2e0d57567ee6cb77\u0026#39; and \u0026#39;0000000000000000000000000000000000000000\u0026#39;) 945:M 13 Dec 2022 22:46:34.373 * Starting BGSAVE for SYNC with target: disk 945:M 13 Dec 2022 22:46:34.374 * Background saving started by pid 1690 1690:C 13 Dec 2022 22:46:34.376 * DB saved on disk 1690:C 13 Dec 2022 22:46:34.377 * RDB: 2 MB of memory used by copy-on-write 945:M 13 Dec 2022 22:46:34.435 * Background saving terminated with success 945:M 13 Dec 2022 22:46:34.435 * Synchronization with replica 127.0.0.1:6380 succeeded 查看slave日志 [root@centos7-master ~]# tail -f /usr/local/src/redis/log/redis_6380.log 946:S 13 Dec 2022 22:46:34.436 * MASTER \u0026lt;-\u0026gt; REPLICA sync: Finished with success 946:S 13 Dec 2022 22:46:34.437 * Background append only file rewriting started by pid 1691 946:S 13 Dec 2022 22:46:34.470 * AOF rewrite child asks to stop sending diffs. 1691:C 13 Dec 2022 22:46:34.470 * Parent agreed to stop sending diffs. Finalizing AOF... 1691:C 13 Dec 2022 22:46:34.470 * Concatenating 0.00 MB of AOF diff received from parent. 1691:C 13 Dec 2022 22:46:34.470 * SYNC append only file rewrite performed 1691:C 13 Dec 2022 22:46:34.471 * AOF rewrite: 2 MB of memory used by copy-on-write 946:S 13 Dec 2022 22:46:34.536 * Background AOF rewrite terminated with success 946:S 13 Dec 2022 22:46:34.536 * Residual parent diff successfully flushed to the rewritten AOF (0.00 MB) 946:S 13 Dec 2022 22:46:34.536 * Background AOF rewrite finished successfully 修改slave配置文件 [root@centos7-master ~]# vim /usr/local/src/redis/etc/redis6380.conf # replicaof \u0026lt;masterip\u0026gt; \u0026lt;masterport\u0026gt; replicaof 127.0.0.1 6379 #指定master的IP和端口号，我这里在同一台机器上安装了多实例 # masterauth \u0026lt;master-password\u0026gt; masterauth 123456 #如果密码需要设置 systemctl restart redis #在master上查看状态 127.0.0.1:6379\u0026gt; info replication # Replication role:master connected_slaves:2 slave0:ip=127.0.0.1,port=6380,state=online,offset=3307,lag=1 slave1:ip=127.0.0.1,port=6381,state=online,offset=3307,lag=1 master_failover_state:no-failover master_replid:f945fd1714d8d3b78a149c8b2e0d57567ee6cb77 master_replid2:0000000000000000000000000000000000000000 master_repl_offset:3307 second_repl_offset:-1 repl_backlog_active:1 repl_backlog_size:1048576 repl_backlog_first_byte_offset:1 repl_backlog_histlen:3307 127.0.0.1:6379\u0026gt; #停止master的redis服务：systemctl stop redis,在slave上可以观察到以下现象 127.0.0.1:6381\u0026gt; info replication # Replication role:slave master_host:192.168.1.104 master_port:6379 master_link_status:down #显示down，表示无法连接master master_last_io_seconds_ago:-1 master_sync_in_progress:0 slave_read_repl_offset:84 slave_repl_offset:84 master_link_down_since_seconds:14 slave_priority:100 slave_read_only:1 replica_announced:1 connected_slaves:0 master_failover_state:no-failover master_replid:f6eefc841166e73282b4bab58527081653ddb0d1 master_replid2:0000000000000000000000000000000000000000 master_repl_offset:84 second_repl_offset:-1 repl_backlog_active:1 repl_backlog_size:1048576 repl_backlog_first_byte_offset:15 repl_backlog_histlen:70 127.0.0.1:6381\u0026gt; slave 只读状态 验证Slave节点为只读状态, 不支持写入 127.0.0.1:6381\u0026gt; set ll aa (error) READONLY You can\u0026#39;t write against a read only replica. 127.0.0.1:6381\u0026gt; Redis实现哨兵架构 以下案例实现一主两从的基于哨兵的高可用Redis架构\n先实现主从架构 哨兵的前提是已经实现了Redis的主从复制 注意: master 的配置文件中masterauth 和slave 都必须相同 所有主从节点的 redis.conf 中关健配置 范例: 准备主从环境配置\n#在所有主从节点执行 vim redis.conf bind 0.0.0.0 masterauth \u0026#34;123456\u0026#34; requirepass \u0026#34;123456\u0026#34; #或者非交互执行 [root@centos8 ~]#sed -i -e \u0026#39;s/bind 127.0.0.1/bind 0.0.0.0/\u0026#39; -e \u0026#39;s/^# masterauth .*/masterauth 123456/\u0026#39; -e \u0026#39;s/^# requirepass .*/requirepass 123456/\u0026#39; /etc/redis.conf #在所有从节点执行 [root@centos8 ~]#echo \u0026#34;replicaof 192.168.32.133 6379\u0026#34; \u0026gt;\u0026gt; /etc/redis.conf #在所有主从节点执行 [root@centos8 ~]#systemctl enable --now redis 配置slave1 [root@redis-slave1 ~]#redis-cli -a 123456 Warning: Using a password with \u0026#39;-a\u0026#39; or \u0026#39;-u\u0026#39; option on the command line interface may not be safe. 127.0.0.1:6379\u0026gt; REPLICAOF 192.168.32.133 6379 OK 127.0.0.1:6379\u0026gt; CONFIG SET masterauth \u0026#34;123456\u0026#34; OK 配置slave2 [root@redis-slave2 ~]#redis-cli -a 123456 Warning: Using a password with \u0026#39;-a\u0026#39; or \u0026#39;-u\u0026#39; option on the command line interface may not be safe. 127.0.0.1:6379\u0026gt; REPLICAOF 192.168.32.133 6379 OK 127.0.0.1:6379\u0026gt; CONFIG SET masterauth \u0026#34;123456\u0026#34; OK 编辑哨兵配置\nsentinel配置 Sentinel实际上是一个特殊的redis服务器,有些redis指令支持,但很多指令并不支持.默认监听在 26379/tcp端口. 哨兵服务可以和Redis服务器分开部署在不同主机，但为了节约成本一般会部署在一起 所有redis节点使用相同的以下示例的配置文件 #如果是编译安装，在源码目录有sentinel.conf，复制到安装目录即可， 如:/usr/local/src/redis/etc/sentinel.conf [root@centos8 ~]#cp redis-6.2.5/sentinel.conf /usr/local/src/redis/etc/ [root@centos8 ~]#chown redis.redis /usr/local/src/redis/etc/sentinel.conf [root@centos8 ~]#vim /etc/redis-sentinel.conf bind 0.0.0.0 port 26379 daemonize yes pidfile \u0026#34;redis-sentinel.pid\u0026#34; logfile \u0026#34;sentinel_26379.log\u0026#34; dir \u0026#34;/tmp\u0026#34; #工作目录 sentinel monitor mymaster 10.0.0.8 6379 2 #mymaster是集群的名称，此行指定当前mymaster集群中master服务器的地址和端口 #2为法定人数限制(quorum)，即有几个sentinel认为master down了就进行故障转移，一般此值是所有 sentinel节点(一般总数是\u0026gt;=3的 奇数,如:3,5,7等)的一半以上的整数值，比如，总数是3，即3/2=1.5， 取整为2,是master的ODOWN客观下线的依据 sentinel auth-pass mymaster 123456 #mymaster集群中master的密码，注意此行要在上面行的下面 sentinel down-after-milliseconds mymaster 30000 #判断mymaster集群中所有节点的主观下线(SDOWN)的时间，单位：毫秒，建议3000 sentinel parallel-syncs mymaster 1 #发生故障转移后，可以同时向新master同步数据的slave的数量，数字越小总同步时间越长，但可以减轻新 master的负载压力 sentinel failover-timeout mymaster 180000 #所有slaves指向新的master所需的超时时间，单位：毫秒 sentinel deny-scripts-reconfig yes #禁止修改脚本 logfile /var/log/redis/sentinel.log 三个哨兵服务器的配置都如下 port 26379 daemonize no pidfile \u0026#34;/var/run/redis-sentinel.pid\u0026#34; logfile \u0026#34;/var/log/redis/sentinel.log\u0026#34; dir \u0026#34;/tmp\u0026#34; sentinel monitor mymaster 192.168.32.133 6379 2 #修改此行 sentinel auth-pass mymaster 123456 #增加此行 sentinel down-after-milliseconds mymaster 3000 #修改此行 sentinel parallel-syncs mymaster 1 sentinel failover-timeout mymaster 180000 sentinel deny-scripts-reconfig yes #注意此行自动生成必须唯一,一般不需要修改，如果相同则修改此值需重启redis和sentinel服务 sentinel myid 50547f34ed71fd48c197924969937e738a39975b ..... # Generated by CONFIG REWRITE protected-mode no supervised systemd sentinel leader-epoch mymaster 0 sentinel known-replica mymaster 10.0.0.28 6379 sentinel known-replica mymaster 10.0.0.18 6379 sentinel current-epoch 0 启动哨兵服务 将所有哨兵服务器都启动起来 /usr/local/src/redis/bin/redis-sentinel /usr/local/src/redis/etc/sentinel.conf 将服务写成service文件 vim /lib/systemd/system/redis-sentinel.service [Unit] Description=Redis Sentinel After=network.target [Service] ExecStart=/usr/local/src/redis/bin/redis-sentinel /usr/local/src/redis/etc/sentinel.conf --supervised systemd ExecStop=/bin/kill -s QUIT $MAINPID User=redis Group=redis RuntimeDirectory=redis RuntimeDirectoryMode=0755 [Install] WantedBy=multi-user.target #注意所有节点的目录权限,否则无法启动服务 [root@redis-master ~]#chown -R redis.redis /usr.local/src/redis/ 验证哨兵服务 查看哨兵服务端口状态,端口26379\n[root@centos8 log]# ss -ntl State Recv-Q Send-Q Local Address:Port Peer Address:Port Process LISTEN 0 511 0.0.0.0:26379 0.0.0.0:* LISTEN 0 511 0.0.0.0:6379 0.0.0.0:* LISTEN 0 128 0.0.0.0:22 0.0.0.0:* LISTEN 0 511 [::1]:6379 [::]:* LISTEN 0 128 [::]:22 [::]:* [root@centos8 log]# Sentinel 运维 手动让主节点下线\n127.0.0.1:26379\u0026gt; sentinel failover \u0026lt;masterName\u0026gt; 范例：手动故障转移\nvim redis.conf replica-priority 10 #指定优先级,值越小sentinel会优先将之选为新的master,默为值为100 systemctl restart redis #或者动态修改 [root@centos8 ~]#redis-cli -a 123456 Warning: Using a password with \u0026#39;-a\u0026#39; or \u0026#39;-u\u0026#39; option on the command line interface may not be safe. 127.0.0.1:6379\u0026gt; CONFIG GET replica-priority 1) \u0026#34;replica-priority\u0026#34; 2) \u0026#34;100\u0026#34; 127.0.0.1:6379\u0026gt; CONFIG SET replica-priority 99 OK 127.0.0.1:6379\u0026gt; CONFIG GET replica-priority 1) \u0026#34;replica-priority\u0026#34; 2) \u0026#34;99\u0026#34; [root@centos8 ~]#redis-cli -p 26379 127.0.0.1:26379\u0026gt; sentinel failover mymaster OK 应用程序连接 Sentinel Redis 官方支持多种开发语言的客户端：\nhttps://redis.io/clients 客户端连接 Sentinel 工作原理 客户端获取 Sentinel 节点集合,选举出一个 Sentinel 1.由这个sentinel 通过masterName 获取master节点信息,客户端通过sentinel get-master-addr-by-name master-name这个api来获取对应主节点信息\n2.客户端发送role指令确认master的信息,验证当前获取的“主节点”是真正的主节点，这样的目的是为了防止故障转移期间主节点的变化\n3.客户端保持和Sentinel节点集合的联系，即订阅Sentinel节点相关频道，时刻获取关于主节点的相关信息,获取新的master 信息变化,并自动连接新的master\njava 连接Sentinel哨兵 java 客户端连接Redis：\nhttps://github.com/xetorthio/jedis/blob/master/pom.xml python 连接 Sentinel 哨兵 [root@centos8 ~]#yum -y install python3 python3-redis [root@centos8 ~]#vim sentinel_test.py #!/usr/bin/python3 import redis from redis.sentinel import Sentinel #连接哨兵服务器(主机名也可以用域名) sentinel = Sentinel([(\u0026#39;192.168.32.135\u0026#39;, 26379), (\u0026#39;192.168.32.133\u0026#39;, 26379), (\u0026#39;192.168.32.132\u0026#39;, 26379)], socket_timeout=0.5) redis_auth_pass = \u0026#39;123456\u0026#39; #mymaster 是配置哨兵模式的redis集群名称，此为默认值,实际名称按照个人部署案例来填写 #获取主服务器地址 master = sentinel.discover_master(\u0026#39;mymaster\u0026#39;) print(\u0026#34;master:\u0026#34;,master) #获取从服务器地址 slave = sentinel.discover_slaves(\u0026#39;mymaster\u0026#39;) print(\u0026#34;slave:\u0026#34;,slave) #获取主服务器进行写入 master = sentinel.master_for(\u0026#39;mymaster\u0026#39;, socket_timeout=0.5, password=redis_auth_pass, db=0) w_ret = master.set(\u0026#39;name\u0026#39;, \u0026#39;xy\u0026#39;) #输出：True #获取从服务器进行读取（默认是round-roubin） slave = sentinel.slave_for(\u0026#39;mymaster\u0026#39;, socket_timeout=0.5, password=redis_auth_pass, db=0) r_ret = slave.get(\u0026#39;name\u0026#39;) print(r_ret) #输出：xy chmod +x sentinel_test.py ./sentinel_test.py master: (\u0026#39;192.168.32.135\u0026#39;, 6379) slave: [(\u0026#39;192.168.32.133\u0026#39;, 6379)] b\u0026#39;xy\u0026#39; Redis Cluster Redis Cluster 介绍 使用哨兵sentinel 只能解决Redis高可用问题，实现Redis的自动故障转移,但仍然无法解决Redis Master 单节点的性能瓶颈问题 为了解决单机性能的瓶颈，提高Redis 服务整体性能，可以使用分布式集群的解决方案 早期 Redis 分布式集群部署方案：\n客户端分区：由客户端程序自己实现写入分配、高可用管理和故障转移等,对客户端的开发实现较为复杂 代理服务：客户端不直接连接Redis,而先连接到代理服务，由代理服务实现相应读写分配，当前代理服务都是第三方实现.此方案中客户端实现无需特殊开发,实现容易,但是代理服务节点仍存有单点故障和性能瓶颈问题。比如：豌豆荚开发的 codis Redis 3.0 版本之后推出无中心架构的 Redis Cluster ，支持多个master节点并行写入和故障的自动转移动能\nRedis cluster 架构 Redis cluster 需要至少 3个master节点才能实现,slave节点数量不限,当然一般每个master都至少对应的有一个slave节点 如果有三个主节点采用哈希槽 hash slot 的方式来分配16384个槽位 slot 此三个节点分别承担的slot 区间可以是如以下方式分配\n节点M1 0－5460 节点M2 5461－10922 节点M3 10923－16383 Redis cluster的工作原理 数据分区 如果是单机存储的话，直接将数据存放在单机redis就行了。但是如果是集群存储，就需要考虑到数据分区了。\n集群通信 但是寻找槽的过程并不是一次就命中的，比如上图key将要存放在14396槽中，但是并不是一下就锁定了node3节点，可能先去询问node1，然后才访问node3。 而集群中节点之间的通信，保证了最多两次就能命中对应槽所在的节点。因为在每个节点中，都保存了其他节点的信息，知道哪个槽由哪个节点负责。这样即使第一次访问没有命中槽，但是会通知客户端，该槽在哪个节点，这样访问对应节点就能精准命中。\n集群伸缩 集群并不是建立之后，节点数就固定不变的，也会有新的节点加入集群或者集群中的节点下线，这就是集群的扩容和缩容。但是由于集群节点和槽息息相关，所以集群的伸缩也对应了槽和数据的迁移\n集群扩容 当有新的节点准备好加入集群时，这个新的节点还是孤立节点，加入有两种方式。一个是通过集群节点执行命令来和孤立节点握手，另一个则是使用脚本来添加节点。\n集群缩容 故障转移 当从节点走马上任变成主节点之后，就要开始进行替换主节点：\n让该slave节点执行slaveof no one变为master节点 将故障节点负责的槽分配给该节点 向集群中其他节点广播Pong消息，表明已完成故障转移 故障节点重启后，会成为new_master的slave节点 实战案例 基于Redis 5 以上版本的 redis cluster 部署 官方文档：\nhttps://redis.io/topics/cluster-tutorial 创建 redis cluster集群的环境准备 每个Redis 节点采用相同的相同的Redis版本、相同的密码、硬件配置 所有Redis服务器必须没有任何数据 准备六台主机，地址如下： 192.168.32.132 192.168.32.137 192.168.32.140 192.168.32.129 192.168.32.136 192.168.32.138 启用 redis cluster 配置 每个节点安装相同版每个节点修改redis配置，必须开启cluster功能的参数\nvim /etc/redis.conf bind 0.0.0.0 masterauth 123456 #建议配置，否则后期的master和slave主从复制无法成功，还需再配置 requirepass 123456 cluster-enabled yes #取消此行注释,必须开启集群，开启后 redis 进程会有cluster标识 cluster-config-file nodes-6379.conf #取消此行注释,此为集群状态数据文件,记录主从关系 及slot范围信息,由redis cluster 集群自动创建和维护 cluster-require-full-coverage no #默认值为yes,设为no可以防止一个节点不可用导致整 个cluster不可用 以下方式二选一\n执行下面命令,批量修改 sed -i.bak -e \u0026#39;s/bind 127.0.0.1/bind 0.0.0.0/\u0026#39; -e \u0026#39;/masterauth/a masterauth 123456\u0026#39; -e \u0026#39;/# requirepass/a requirepass 123456\u0026#39; -e \u0026#39;/# cluster-enabled yes/a cluster-enabled yes\u0026#39; -e \u0026#39;/# cluster-config-file nodes-6379.conf/a cluster-config-file nodes-6379.conf\u0026#39; -e \u0026#39;/cluster-require-full-coverage yes/c cluster-require-full-coverage no\u0026#39; /etc/redis.conf 如果是编译安装可以执行下面操作 sed -i.bak -e \u0026#39;/masterauth/a masterauth 123456\u0026#39; -e \u0026#39;/# cluster-enabled yes/a cluster-enabled yes\u0026#39; -e \u0026#39;/# cluster-config-file nodes-6379.conf/a cluster-config-file nodes-6379.conf\u0026#39; -e \u0026#39;/cluster-require-full-coverage yes/c cluster-require-full-coverage no\u0026#39; /usr/local/src/redis/etc/redis.conf 开机启动redis\nsystemctl enable --now redis # 修改完配置文件重启redis systemctl restart redis 验证当前Redis服务状态：\n#开启了16379的cluster的端口,实际的端口=redis port + 10000 [root@centos7 ~]# ss -ntl State Recv-Q Send-Q Local Address:Port Peer Address:Port LISTEN 0 128 *:22 *:* LISTEN 0 100 127.0.0.1:25 *:* LISTEN 0 511 *:16379 *:* LISTEN 0 511 *:6379 *:* LISTEN 0 128 [::]:22 [::]:* LISTEN 0 100 [::1]:25 [::]:* LISTEN 0 511 [::1]:16379 [::]:* LISTEN 0 511 [::1]:6379 [::]:* [root@centos7 ~]# 创建集群 #命令redis-cli的选项 --cluster-replicas 1 表示每个master对应一个slave节点 # 默认前三个为主节点 [root@centos8 etc]# redis-cli -a 123456 --cluster create 192.168.32.132:6379 192.168.32.137:6379 192.168.32.140:6379 192.168.32.129:6379 192.168.32.136:6379 192.168.32.138:6379 --cluster-replicas 1 Warning: Using a password with \u0026#39;-a\u0026#39; or \u0026#39;-u\u0026#39; option on the command line interface may not be safe. \u0026gt;\u0026gt;\u0026gt; Performing hash slots allocation on 6 nodes... Master[0] -\u0026gt; Slots 0 - 5460 Master[1] -\u0026gt; Slots 5461 - 10922 Master[2] -\u0026gt; Slots 10923 - 16383 Adding replica 192.168.32.136:6379 to 192.168.32.132:6379 Adding replica 192.168.32.138:6379 to 192.168.32.137:6379 Adding replica 192.168.32.129:6379 to 192.168.32.140:6379 M: 658dd91e4b51bf06b161e6903d4084c77abd195d 192.168.32.132:6379 slots:[0-5460] (5461 slots) master M: 46b54e8298e11e77450e232c9a0ee057b362191a 192.168.32.137:6379 slots:[5461-10922] (5462 slots) master M: f49ca2e55dae53fa0a069ea9e1d35a31ee62731e 192.168.32.140:6379 slots:[10923-16383] (5461 slots) master S: ba4bb2dc1f4550e8602f500f1e0021896e78bf54 192.168.32.129:6379 replicates f49ca2e55dae53fa0a069ea9e1d35a31ee62731e S: f720a02fee9c4826d08258b740de008040cf80c5 192.168.32.136:6379 replicates 658dd91e4b51bf06b161e6903d4084c77abd195d S: eec71072ab8ad4068b4604f7196d881f9b5363e0 192.168.32.138:6379 replicates 46b54e8298e11e77450e232c9a0ee057b362191a Can I set the above configuration? (type \u0026#39;yes\u0026#39; to accept): yes \u0026gt;\u0026gt;\u0026gt; Nodes configuration updated \u0026gt;\u0026gt;\u0026gt; Assign a different config epoch to each node \u0026gt;\u0026gt;\u0026gt; Sending CLUSTER MEET messages to join the cluster Waiting for the cluster to join . \u0026gt;\u0026gt;\u0026gt; Performing Cluster Check (using node 192.168.32.132:6379) M: 658dd91e4b51bf06b161e6903d4084c77abd195d 192.168.32.132:6379 slots:[0-5460] (5461 slots) master 1 additional replica(s) S: ba4bb2dc1f4550e8602f500f1e0021896e78bf54 192.168.32.129:6379 slots: (0 slots) slave replicates f49ca2e55dae53fa0a069ea9e1d35a31ee62731e M: f49ca2e55dae53fa0a069ea9e1d35a31ee62731e 192.168.32.140:6379 slots:[10923-16383] (5461 slots) master 1 additional replica(s) M: 46b54e8298e11e77450e232c9a0ee057b362191a 192.168.32.137:6379 slots:[5461-10922] (5462 slots) master 1 additional replica(s) S: f720a02fee9c4826d08258b740de008040cf80c5 192.168.32.136:6379 slots: (0 slots) slave replicates 658dd91e4b51bf06b161e6903d4084c77abd195d S: eec71072ab8ad4068b4604f7196d881f9b5363e0 192.168.32.138:6379 slots: (0 slots) slave replicates 46b54e8298e11e77450e232c9a0ee057b362191a [OK] All nodes agree about slots configuration. \u0026gt;\u0026gt;\u0026gt; Check for open slots... \u0026gt;\u0026gt;\u0026gt; Check slots coverage... [OK] All 16384 slots covered. [root@centos8 ~]# 验证集群 查看主从状态 127.0.0.1:6379\u0026gt; info replication # Replication role:master connected_slaves:1 slave0:ip=192.168.32.136,port=6379,state=online,offset=98,lag=1 master_failover_state:no-failover master_replid:b1bd51213722f38a83c8bb525e8a74e62392a161 master_replid2:0000000000000000000000000000000000000000 master_repl_offset:98 second_repl_offset:-1 repl_backlog_active:1 repl_backlog_size:1048576 repl_backlog_first_byte_offset:1 repl_backlog_histlen:98 127.0.0.1:6379\u0026gt; 验证集群状态\n127.0.0.1:6379\u0026gt; CLUSTER INFO cluster_state:ok cluster_slots_assigned:16384 cluster_slots_ok:16384 cluster_slots_pfail:0 cluster_slots_fail:0 cluster_known_nodes:6 # 节点数 cluster_size:3 # 三个集群 cluster_current_epoch:6 cluster_my_epoch:1 cluster_stats_messages_ping_sent:210 cluster_stats_messages_pong_sent:210 cluster_stats_messages_sent:420 cluster_stats_messages_ping_received:205 cluster_stats_messages_pong_received:210 cluster_stats_messages_meet_received:5 cluster_stats_messages_received:420 127.0.0.1:6379\u0026gt; #查看任意节点的集群状态 [root@centos8 ~]# redis-cli -a 123456 --cluster info 192.168.32.137:6379 Warning: Using a password with \u0026#39;-a\u0026#39; or \u0026#39;-u\u0026#39; option on the command line interface may not be safe. 192.168.32.137:6379 (46b54e82...) -\u0026gt; 0 keys | 5462 slots | 1 slaves. 192.168.32.140:6379 (f49ca2e5...) -\u0026gt; 0 keys | 5461 slots | 1 slaves. 192.168.32.132:6379 (658dd91e...) -\u0026gt; 0 keys | 5461 slots | 1 slaves. [OK] 0 keys in 3 masters. 0.00 keys per slot on average. [root@centos8 ~]# 查看对应关系 [root@centos8 ~]# redis-cli -a 123456 CLUSTER NODES Warning: Using a password with \u0026#39;-a\u0026#39; or \u0026#39;-u\u0026#39; option on the command line interface may not be safe. ba4bb2dc1f4550e8602f500f1e0021896e78bf54 192.168.32.129:6379@16379 slave f49ca2e55dae53fa0a069ea9e1d35a31ee62731e 0 1671364792207 3 connected 658dd91e4b51bf06b161e6903d4084c77abd195d 192.168.32.132:6379@16379 myself,master - 0 1671364792000 1 connected 0-5460 f49ca2e55dae53fa0a069ea9e1d35a31ee62731e 192.168.32.140:6379@16379 master - 0 1671364792000 3 connected 10923-16383 46b54e8298e11e77450e232c9a0ee057b362191a 192.168.32.137:6379@16379 master - 0 1671364793216 2 connected 5461-10922 f720a02fee9c4826d08258b740de008040cf80c5 192.168.32.136:6379@16379 slave 658dd91e4b51bf06b161e6903d4084c77abd195d 0 1671364793000 1 connected eec71072ab8ad4068b4604f7196d881f9b5363e0 192.168.32.138:6379@16379 slave 46b54e8298e11e77450e232c9a0ee057b362191a 0 1671364792000 2 connected [root@centos8 ~]# 测试集群写入数据 redis cluster 写入key #经过算法计算，当前key的槽位需要写入指定的node [root@centos8 ~]# redis-cli -a 123456 set k1 v1 Warning: Using a password with \u0026#39;-a\u0026#39; or \u0026#39;-u\u0026#39; option on the command line interface may not be safe. (error) MOVED 12706 192.168.32.140:6379 #槽位不在当前node所以无法写入 [root@centos8 ~]# #指定槽位对应node可写入 [root@centos8 ~]# redis-cli -h 192.168.32.140 -a 123456 set k1 v1 Warning: Using a password with \u0026#39;-a\u0026#39; or \u0026#39;-u\u0026#39; option on the command line interface may not be safe. OK [root@centos8 ~]# #对应的slave节点可以KEYS *,但GET k1失败,可以到master上执行GET k1 [root@centos8 ~]# redis-cli -h 192.168.32.129 -a 123456 get k1 Warning: Using a password with \u0026#39;-a\u0026#39; or \u0026#39;-u\u0026#39; option on the command line interface may not be safe. (error) MOVED 12706 192.168.32.140:6379 [root@centos8 ~]# redis-cli -h 192.168.32.129 -a 123456 keys \u0026#34;*\u0026#34; Warning: Using a password with \u0026#39;-a\u0026#39; or \u0026#39;-u\u0026#39; option on the command line interface may not be safe. 1) \u0026#34;k1\u0026#34; [root@centos8 ~]# Redis cluster 管理 集群扩容\n扩容适用场景： 当前客户量激增，现有的Redis cluster架构已经无法满足越来越高的并发访问请求，为解决此问题,新购置两台服务器，要求将其动态添加到现有集群，但不能影响业务的正常访问。 注意: 生产环境一般建议master节点为奇数个,比如:3,5,7,以防止脑裂现象\n添加节点准备 增加Redis 新节点，需要与之前的Redis node版本和配置一致，然后分别再启动两台Redis node，应为一主一从。\n192.168.32.133 主 192.168.32.139 从 # 修改配置文件,主从节点都修改 sed -i.bak -e \u0026#39;/masterauth/a masterauth 123456\u0026#39; -e \u0026#39;/# cluster-enabled yes/a cluster-enabled yes\u0026#39; -e \u0026#39;/# cluster-config-file nodes-6379.conf/a cluster-config-file nodes-6379.conf\u0026#39; -e \u0026#39;/cluster-require-full-coverage yes/c cluster-require-full-coverage no\u0026#39; /usr/local/src/redis/etc/redis.conf systemctl restart redis 添加新的master节点到集群\n使用以下命令添加新节点，要添加的新redis节点IP和端口添加到的已有的集群中任意节点的IP:端口 add-node new_host:new_port existing_host:existing_port [--slave --master-id \u0026lt;arg\u0026gt;] #说明： new_host:new_port #指定新添加的主机的IP和端口 existing_host:existing_port #指定已有的集群中任意节点的IP和端口 Redis 3/4 版本的添加命令： #把新的Redis 节点192.168.32.133添加到当前Redis集群当中。 [root@redis-node1 ~]#redis-trib.rb add-node 192.168.32.133:6379 192.168.32.132:6379 Redis 5 以上版本的添加命令： #将一台新的主机加入集群 [root@redis-node1 ~]#redis-cli -a 123456 --cluster add-node 192.168.32.133:6379 \u0026lt;当前 任意集群节点\u0026gt;:6379 [root@centos8 data]# redis-cli -a 123456 --cluster add-node 192.168.32.133:6379 192.168.32.132:6379 Warning: Using a password with \u0026#39;-a\u0026#39; or \u0026#39;-u\u0026#39; option on the command line interface may not be safe. \u0026gt;\u0026gt;\u0026gt; Adding node 192.168.32.133:6379 to cluster 192.168.32.132:6379 \u0026gt;\u0026gt;\u0026gt; Performing Cluster Check (using node 192.168.32.132:6379) M: 658dd91e4b51bf06b161e6903d4084c77abd195d 192.168.32.132:6379 slots:[0-5460] (5461 slots) master 1 additional replica(s) S: ba4bb2dc1f4550e8602f500f1e0021896e78bf54 192.168.32.129:6379 slots: (0 slots) slave replicates f49ca2e55dae53fa0a069ea9e1d35a31ee62731e M: f49ca2e55dae53fa0a069ea9e1d35a31ee62731e 192.168.32.140:6379 slots:[10923-16383] (5461 slots) master 1 additional replica(s) M: 46b54e8298e11e77450e232c9a0ee057b362191a 192.168.32.137:6379 slots:[5461-10922] (5462 slots) master 1 additional replica(s) S: f720a02fee9c4826d08258b740de008040cf80c5 192.168.32.136:6379 slots: (0 slots) slave replicates 658dd91e4b51bf06b161e6903d4084c77abd195d S: eec71072ab8ad4068b4604f7196d881f9b5363e0 192.168.32.138:6379 slots: (0 slots) slave replicates 46b54e8298e11e77450e232c9a0ee057b362191a [OK] All nodes agree about slots configuration. \u0026gt;\u0026gt;\u0026gt; Check for open slots... \u0026gt;\u0026gt;\u0026gt; Check slots coverage... [OK] All 16384 slots covered. \u0026gt;\u0026gt;\u0026gt; Send CLUSTER MEET to node 192.168.32.133:6379 to make it join the cluster. [OK] New node added correctly. [root@centos8 data]# 在新的master上重新分配槽位 新的node节点加到集群之后,默认是master节点，但是没有slots，需要重新分配,否则没有槽位将无法访问 注意: 重新分配槽位需要清空数据,所以需要先备份数据,扩展后再恢复数据 Redis 3/4 版本命令: [root@redis-node1 ~]# redis-trib.rb check 10.0.0.67:6379 #当前状态 [root@redis-node1 ~]# redis-trib.rb reshard \u0026lt;任意节点\u0026gt;:6379 #重新分片 [root@redis-node1 ~]# redis-trib.rb fix 10.0.0.67:6379 #如果迁移失败使用此命令修复集群 Redis 5以上版本命令： [root@redis-node1 ~]#redis-cli -a 123456 --cluster reshard \u0026lt;当前任意集群节点\u0026gt;:6379 [root@centos8 data]# redis-cli -a 123456 --cluster reshard 192.168.32.133:6379 Warning: Using a password with \u0026#39;-a\u0026#39; or \u0026#39;-u\u0026#39; option on the command line interface may not be safe. \u0026gt;\u0026gt;\u0026gt; Performing Cluster Check (using node 192.168.32.133:6379) M: 77cfc3429c8b470331520074faea7c3a21f77d1f 192.168.32.133:6379 slots: (0 slots) master S: eec71072ab8ad4068b4604f7196d881f9b5363e0 192.168.32.138:6379 slots: (0 slots) slave replicates 46b54e8298e11e77450e232c9a0ee057b362191a M: 658dd91e4b51bf06b161e6903d4084c77abd195d 192.168.32.132:6379 slots:[0-5460] (5461 slots) master 1 additional replica(s) M: 46b54e8298e11e77450e232c9a0ee057b362191a 192.168.32.137:6379 slots:[5461-10922] (5462 slots) master 1 additional replica(s) S: ba4bb2dc1f4550e8602f500f1e0021896e78bf54 192.168.32.129:6379 slots: (0 slots) slave replicates f49ca2e55dae53fa0a069ea9e1d35a31ee62731e S: f720a02fee9c4826d08258b740de008040cf80c5 192.168.32.136:6379 slots: (0 slots) slave replicates 658dd91e4b51bf06b161e6903d4084c77abd195d M: f49ca2e55dae53fa0a069ea9e1d35a31ee62731e 192.168.32.140:6379 slots:[10923-16383] (5461 slots) master 1 additional replica(s) [OK] All nodes agree about slots configuration. \u0026gt;\u0026gt;\u0026gt; Check for open slots... \u0026gt;\u0026gt;\u0026gt; Check slots coverage... [OK] All 16384 slots covered. How many slots do you want to move (from 1 to 16384)? 4096 # 复制新加入的节点的ID，即192.168.32.133的节点ID What is the receiving node ID? 77cfc3429c8b470331520074faea7c3a21f77d1f Please enter all the source node IDs. Type \u0026#39;all\u0026#39; to use all the nodes as source nodes for the hash slots. Type \u0026#39;done\u0026#39; once you entered all the source nodes IDs. Source node #1: all # 选择all Do you want to proceed with the proposed reshard plan (yes/no)? yes 为新的master指定新的slave节点 当前Redis集群中新的master节点存单点问题,还需要给其添加一个对应slave节点，实现高可用功能 有两种方式： 方法1：在新加节点到集群时，直接将之设置为slave Redis 3/4 添加命令\nredis-trib.rb add-node --slave --master-id 750cab050bc81f2655ed53900fd43d2e64423333 192.168.32.139:6379 \u0026lt;任意集群节点\u0026gt;:6379 Redis 5 以上版本添加命令：\nredis-cli -a 123456 --cluster add-node 192.168.32.139:6379 \u0026lt;任意集群节点\u0026gt;:6379 -- cluster-slave --cluster-master-id d6e2eca6b338b717923f64866bd31d42e52edc98 范例：\n# 查看当前状态 [root@centos8 ~]# redis-cli -a 123456 --cluster check 192.168.32.132:6379 Warning: Using a password with \u0026#39;-a\u0026#39; or \u0026#39;-u\u0026#39; option on the command line interface may not be safe. 192.168.32.132:6379 (658dd91e...) -\u0026gt; 0 keys | 4096 slots | 1 slaves. 192.168.32.133:6379 (77cfc342...) -\u0026gt; 0 keys | 4096 slots | 0 slaves. 192.168.32.140:6379 (f49ca2e5...) -\u0026gt; 1 keys | 4096 slots | 1 slaves. 192.168.32.137:6379 (46b54e82...) -\u0026gt; 0 keys | 4096 slots | 1 slaves. [OK] 1 keys in 4 masters. 0.00 keys per slot on average. \u0026gt;\u0026gt;\u0026gt; Performing Cluster Check (using node 192.168.32.132:6379) M: 658dd91e4b51bf06b161e6903d4084c77abd195d 192.168.32.132:6379 slots:[1365-5460] (4096 slots) master 1 additional replica(s) M: 77cfc3429c8b470331520074faea7c3a21f77d1f 192.168.32.133:6379 slots:[0-1364],[5461-6826],[10923-12287] (4096 slots) master S: ba4bb2dc1f4550e8602f500f1e0021896e78bf54 192.168.32.129:6379 slots: (0 slots) slave replicates f49ca2e55dae53fa0a069ea9e1d35a31ee62731e M: f49ca2e55dae53fa0a069ea9e1d35a31ee62731e 192.168.32.140:6379 slots:[12288-16383] (4096 slots) master 1 additional replica(s) M: 46b54e8298e11e77450e232c9a0ee057b362191a 192.168.32.137:6379 slots:[6827-10922] (4096 slots) master 1 additional replica(s) S: f720a02fee9c4826d08258b740de008040cf80c5 192.168.32.136:6379 slots: (0 slots) slave replicates 658dd91e4b51bf06b161e6903d4084c77abd195d S: eec71072ab8ad4068b4604f7196d881f9b5363e0 192.168.32.138:6379 slots: (0 slots) slave replicates 46b54e8298e11e77450e232c9a0ee057b362191a [OK] All nodes agree about slots configuration. \u0026gt;\u0026gt;\u0026gt; Check for open slots... \u0026gt;\u0026gt;\u0026gt; Check slots coverage... [OK] All 16384 slots covered. [root@centos8 ~]# #直接加为slave节点 [root@centos8 ~]# redis-cli -a 123456 --cluster add-node 192.168.32.139:6379 192.168.32.132:6379 --cluster-slave --cluster-master-id 77cfc3429c8b470331520074faea7c3a21f77d1f # 验证 [root@centos8 ~]# redis-cli -a 123456 --cluster check 192.168.32.132:6379 Warning: Using a password with \u0026#39;-a\u0026#39; or \u0026#39;-u\u0026#39; option on the command line interface may not be safe. 192.168.32.132:6379 (658dd91e...) -\u0026gt; 0 keys | 4096 slots | 1 slaves. 192.168.32.133:6379 (77cfc342...) -\u0026gt; 0 keys | 4096 slots | 1 slaves. 192.168.32.140:6379 (f49ca2e5...) -\u0026gt; 1 keys | 4096 slots | 1 slaves. 192.168.32.137:6379 (46b54e82...) -\u0026gt; 0 keys | 4096 slots | 1 slaves. [OK] 1 keys in 4 masters. 0.00 keys per slot on average. 集群缩容\n缩容适用场景： 随着业务萎缩用户量下降明显,和领导商量决定将现有Redis集群的8台主机中下线两台主机挪做它用,缩容后性能仍能满足当前业务需求 删除节点过程： 扩容时是先添加node到集群，然后再分配槽位，而缩容时的操作相反，是先将被要删除的node上的槽位迁移到集群中的其他node上，然后 才能再将其从集群中删除，如果一个node上的槽位没有被完全迁移空，删除该node时也会提示有数据出错导致无法删除。\n迁移要删除的master节点上面的槽位到其它master 注意: 被迁移Redis master源服务器必须保证没有数据，否则迁移报错并会被强制中断。 Redis 3/4 版本命令\n[root@redis-node1 ~]# redis-trib.rb reshard 10.0.0.8:6379 [root@redis-node1 ~]# redis-trib.rb fix 10.0.0.8:6379 #如果迁移失败使用此命令修复集群 Redis 5版本以上命令\n# 查看当前状态 [root@centos8 ~]# redis-cli -a 123456 --cluster check 192.168.32.132:6379 Warning: Using a password with \u0026#39;-a\u0026#39; or \u0026#39;-u\u0026#39; option on the command line interface may not be safe. 192.168.32.132:6379 (658dd91e...) -\u0026gt; 0 keys | 4096 slots | 1 slaves. 192.168.32.133:6379 (77cfc342...) -\u0026gt; 0 keys | 4096 slots | 1 slaves. 192.168.32.140:6379 (f49ca2e5...) -\u0026gt; 1 keys | 4096 slots | 1 slaves. 192.168.32.137:6379 (46b54e82...) -\u0026gt; 0 keys | 4096 slots | 1 slaves. [OK] 1 keys in 4 masters. 0.00 keys per slot on average. \u0026gt;\u0026gt;\u0026gt; Performing Cluster Check (using node 192.168.32.132:6379) M: 658dd91e4b51bf06b161e6903d4084c77abd195d 192.168.32.132:6379 slots:[1365-5460] (4096 slots) master 1 additional replica(s) M: 77cfc3429c8b470331520074faea7c3a21f77d1f 192.168.32.133:6379 slots:[0-1364],[5461-6826],[10923-12287] (4096 slots) master 1 additional replica(s) S: ba4bb2dc1f4550e8602f500f1e0021896e78bf54 192.168.32.129:6379 slots: (0 slots) slave replicates f49ca2e55dae53fa0a069ea9e1d35a31ee62731e M: f49ca2e55dae53fa0a069ea9e1d35a31ee62731e 192.168.32.140:6379 slots:[12288-16383] (4096 slots) master 1 additional replica(s) M: 46b54e8298e11e77450e232c9a0ee057b362191a 192.168.32.137:6379 slots:[6827-10922] (4096 slots) master 1 additional replica(s) S: f720a02fee9c4826d08258b740de008040cf80c5 192.168.32.136:6379 slots: (0 slots) slave replicates 658dd91e4b51bf06b161e6903d4084c77abd195d S: a44914056fd3a170850ad572c0e238b499455897 192.168.32.139:6379 slots: (0 slots) slave replicates 77cfc3429c8b470331520074faea7c3a21f77d1f S: eec71072ab8ad4068b4604f7196d881f9b5363e0 192.168.32.138:6379 slots: (0 slots) slave replicates 46b54e8298e11e77450e232c9a0ee057b362191a [OK] All nodes agree about slots configuration. \u0026gt;\u0026gt;\u0026gt; Check for open slots... \u0026gt;\u0026gt;\u0026gt; Check slots coverage... [OK] All 16384 slots covered. [root@centos8 ~]# #连接到任意集群节点，#最后1365个slot从192.168.32.133移动到第一个master节点192.168.32.132上 [root@centos8 ~]# redis-cli -a 123456 --cluster reshard 192.168.32.132:6379 Warning: Using a password with \u0026#39;-a\u0026#39; or \u0026#39;-u\u0026#39; option on the command line interface may not be safe. \u0026gt;\u0026gt;\u0026gt; Performing Cluster Check (using node 192.168.32.132:6379) M: 658dd91e4b51bf06b161e6903d4084c77abd195d 192.168.32.132:6379 slots:[1365-5460] (4096 slots) master 1 additional replica(s) M: 77cfc3429c8b470331520074faea7c3a21f77d1f 192.168.32.133:6379 slots:[0-1364],[5461-6826],[10923-12287] (4096 slots) master 1 additional replica(s) S: ba4bb2dc1f4550e8602f500f1e0021896e78bf54 192.168.32.129:6379 slots: (0 slots) slave replicates f49ca2e55dae53fa0a069ea9e1d35a31ee62731e M: f49ca2e55dae53fa0a069ea9e1d35a31ee62731e 192.168.32.140:6379 slots:[12288-16383] (4096 slots) master 1 additional replica(s) M: 46b54e8298e11e77450e232c9a0ee057b362191a 192.168.32.137:6379 slots:[6827-10922] (4096 slots) master 1 additional replica(s) S: f720a02fee9c4826d08258b740de008040cf80c5 192.168.32.136:6379 slots: (0 slots) slave replicates 658dd91e4b51bf06b161e6903d4084c77abd195d S: a44914056fd3a170850ad572c0e238b499455897 192.168.32.139:6379 slots: (0 slots) slave replicates 77cfc3429c8b470331520074faea7c3a21f77d1f S: eec71072ab8ad4068b4604f7196d881f9b5363e0 192.168.32.138:6379 slots: (0 slots) slave replicates 46b54e8298e11e77450e232c9a0ee057b362191a [OK] All nodes agree about slots configuration. \u0026gt;\u0026gt;\u0026gt; Check for open slots... \u0026gt;\u0026gt;\u0026gt; Check slots coverage... [OK] All 16384 slots covered. How many slots do you want to move (from 1 to 16384)? 1356 #共4096/3分别给其它三个master节点 What is the receiving node ID? 658dd91e4b51bf06b161e6903d4084c77abd195d # master id Please enter all the source node IDs. Type \u0026#39;all\u0026#39; to use all the nodes as source nodes for the hash slots. Type \u0026#39;done\u0026#39; once you entered all the source nodes IDs. Source node #1: 77cfc3429c8b470331520074faea7c3a21f77d1f # 删除ID，192.168.32.133的ID Source node #2: done Do you want to proceed with the proposed reshard plan (yes/no)? yes # redis-cli -a 123456 --cluster reshard 192.168.32.132:6379 该命令在执行两次 从集群中删除服务器 上面步骤完成后,槽位已经迁移走，但是节点仍然还属于集群成员，因此还需从集群删除该节点 注意: 删除服务器前,必须清除主机上面的槽位,否则会删除主机失败 Redis 3/4命令：\n[root@s~]#redis-trib.rb del-node \u0026lt;任意集群节点的IP\u0026gt;:6379 dfffc371085859f2858730e1f350e9167e287073 #dfffc371085859f2858730e1f350e9167e287073 是删除节点的ID \u0026gt;\u0026gt;\u0026gt; Removing node dfffc371085859f2858730e1f350e9167e287073 from cluster 192.168.7.102:6379 \u0026gt;\u0026gt;\u0026gt; Sending CLUSTER FORGET messages to the cluster... \u0026gt;\u0026gt;\u0026gt; SHUTDOWN the node. Redis 5以上版本命令：\n[root@redis-node1 ~]#redis-cli -a 123456 --cluster del-node \u0026lt;任意集群节点的IP\u0026gt;:6379 cb028b83f9dc463d732f6e76ca6bbcd469d948a7 #cb028b83f9dc463d732f6e76ca6bbcd469d948a7是删除节点的ID 范例\n# 查看节点信息 [root@centos8 ~]# redis-cli -a 123456 --cluster check 192.168.32.132:6379 Warning: Using a password with \u0026#39;-a\u0026#39; or \u0026#39;-u\u0026#39; option on the command line interface may not be safe. 192.168.32.132:6379 (658dd91e...) -\u0026gt; 0 keys | 8164 slots | 1 slaves. 192.168.32.133:6379 (77cfc342...) -\u0026gt; 0 keys | 28 slots | 1 slaves. 192.168.32.140:6379 (f49ca2e5...) -\u0026gt; 1 keys | 4096 slots | 1 slaves. 192.168.32.137:6379 (46b54e82...) -\u0026gt; 0 keys | 4096 slots | 1 slaves. [OK] 1 keys in 4 masters. 0.00 keys per slot on average. \u0026gt;\u0026gt;\u0026gt; Performing Cluster Check (using node 192.168.32.132:6379) M: 658dd91e4b51bf06b161e6903d4084c77abd195d 192.168.32.132:6379 slots:[0-6826],[10923-12259] (8164 slots) master 1 additional replica(s) M: 77cfc3429c8b470331520074faea7c3a21f77d1f 192.168.32.133:6379 slots:[12260-12287] (28 slots) master 1 additional replica(s) S: ba4bb2dc1f4550e8602f500f1e0021896e78bf54 192.168.32.129:6379 slots: (0 slots) slave replicates f49ca2e55dae53fa0a069ea9e1d35a31ee62731e M: f49ca2e55dae53fa0a069ea9e1d35a31ee62731e 192.168.32.140:6379 slots:[12288-16383] (4096 slots) master 1 additional replica(s) M: 46b54e8298e11e77450e232c9a0ee057b362191a 192.168.32.137:6379 slots:[6827-10922] (4096 slots) master 1 additional replica(s) S: f720a02fee9c4826d08258b740de008040cf80c5 192.168.32.136:6379 slots: (0 slots) slave replicates 658dd91e4b51bf06b161e6903d4084c77abd195d S: a44914056fd3a170850ad572c0e238b499455897 192.168.32.139:6379 slots: (0 slots) slave replicates 77cfc3429c8b470331520074faea7c3a21f77d1f S: eec71072ab8ad4068b4604f7196d881f9b5363e0 192.168.32.138:6379 slots: (0 slots) slave replicates 46b54e8298e11e77450e232c9a0ee057b362191a [OK] All nodes agree about slots configuration. \u0026gt;\u0026gt;\u0026gt; Check for open slots... \u0026gt;\u0026gt;\u0026gt; Check slots coverage... [OK] All 16384 slots covered. [root@centos8 ~]# # 删除192.168.32.133节点 [root@centos8 ~]# redis-cli -a 123456 --cluster del-node 192.168.32.132:6379 77cfc3429c8b470331520074faea7c3a21f77d1f Warning: Using a password with \u0026#39;-a\u0026#39; or \u0026#39;-u\u0026#39; option on the command line interface may not be safe. \u0026gt;\u0026gt;\u0026gt; Removing node 77cfc3429c8b470331520074faea7c3a21f77d1f from cluster 192.168.32.132:6379 \u0026gt;\u0026gt;\u0026gt; Sending CLUSTER FORGET messages to the cluster... \u0026gt;\u0026gt;\u0026gt; Sending CLUSTER RESET SOFT to the deleted node. [root@centos8 ~]# 常见面试题 Redis 做什么的,即在哪些场景下使用 如果监控 Redis 是否出现故障 Redis客户端timeout报错突然增加，排查思路是怎样的？ 请简单描述pipeline功能，为什么pipeline功能会提升redis性能? 本地redis-client访问远程Redis服务出错，说出几种常见的错误? key-value的大小超大或单key的qps超高，会对Redis本身造成什么样的影响、会对访问Redis的其他客户端造成什么样的影响？ Zabbix 监控 Redis 哪些监控项 RDB和AOF持久化区别 docker拉取一个Redis如何实现数据持久化保存 Redis 支持哪些数据类型 Redis 如何实现消息队列 描述下常见的redis集群架构有哪些，他们之间的优缺点对比 主从复制工作原理 Redis 如何实现高可用 哨兵工作原理 Redis 集群的工作原理 Redis 集群如果避免脑裂 Redis 集群最少几个节点为什么? Redis的集群槽位多少个 Redis集群中某个节点缺少一个槽位是否能使用 Redis数据写入的时候是怎么在各个节点槽位分配数据的 Redis的数据存储是以什么样的方式存储 Redis集群的各槽位和总槽位之间什么关系 ","permalink":"https://xyenvy.github.io/posts/redis%E9%9B%86%E7%BE%A4%E5%92%8C%E9%AB%98%E5%8F%AF%E7%94%A8/","summary":"简介 Redis单机服务存在数据和服务的单点问题,而且单机性能也存在着上限,可以利用Redis的集群相关技术来解决这些问题. 主从复制实现 主从命令配置 当配置Redis复制功能时，强烈建议打开主服务器的持久化功能。否则的话，由于延迟等问题，部署的主节点Redis服务应该要避免自动启动。","title":"Redis集群和高可用"},{"content":"Redis基础 简介 Redis (Remote Dictionary Server远程字典服务)是一个遵循BSD MIT开源协议的高性能的NoSQL.Redis基于ANSI C语言语言)编写的key-value数据库,是意大利的Salvatore Sanfilippo在2009年发布，从2010年3月15日起，Redis的开发工作由VMware主持。从2013年5月开始，Redis的开发由Pivotal公司赞助。目前国内外使用的公司众多,比如:阿里,腾讯,百度,京东,新浪微博,GitHub,Twitter 等Redis的出现，很大程度补偿了memcached这类key/value存储的不足，在部分场合可以对关系数据库起到很好的补充作用。它提供了Java，C/C++，Go, C#，PHP，JavaScript，Perl，Object-C，Python，Ruby，Erlang等客户端 DB-Engine月度排行榜Redis在键值型存储类的数据库长期居于首位,远远高于第二位的memcached\n特性 速度快: 10W QPS,基于内存,C语言实现 单线程 持久化 支持多种数据结构 支持多种编程语言 功能丰富: 支持Lua脚本,发布订阅,事务,pipeline等功能 简单: 代码短小精悍(单机核心代码只有23000行左右),单线程开发容易,不依赖外部库,使用简单 主从复制 支持高可用和分布式 单线程 Redis 6.0版本前一直是单线程方式处理用户的请求\n单线程为何如此快?\n纯内存 非阻塞避免线程切换和竞态消耗 注意事项\n一次只运行一条命令 避免执行长(慢)命令:keys *, flushall, flushdb, slow lua script, mutil/exec, operate bigvalue(collection) 其实不是单线程: 早期版本是单进程单线程,3.0 版本后实际还有其它的线程, 实现特定功能,如: fysnc file descriptor,close file descriptor 常见应用场景 缓存：缓存RDBMS中数据,比如网站的查询结果、商品信息、微博、新闻、消息 Session 共享：实现Web集群中的多服务器间的session共享 计数器：商品访问排行榜、浏览数、粉丝数、关注、点赞、评论等和次数相关的数值统计场景 社交：朋友圈、共同好友、可能认识他们等 地理位置: 基于地理信息系统GIS（Geographic Information System)实现摇一摇、附近的人、外卖等功能 消息队列：ELK等日志系统缓存、业务的订阅/发布系统 缓存的实现流程 数据更新操作流程：\n数据读操作流程：\nRedis安装及连接 官网下载地址\nhttp://download.redis.io/releases/ yum安装 查看yum库redis版本\nyum info redis 或者 yum info redis yum 安装 redis\nyum install -y redis # 启动 systemctl enable --now redis # 连接 [root@centos8-backup www]# redis-cli 127.0.0.1:6379\u0026gt; # 查看信息 127.0.0.1:6379\u0026gt; info # Server redis_version:5.0.3 redis_git_sha1:00000000 redis_git_dirty:0 redis_build_id:9529b692c0384fb7 redis_mode:standalone os:Linux 4.18.0-348.7.1.el8_5.x86_64 x86_64 arch_bits:64 multiplexing_api:epoll ...... ...... ...... 编译安装 Redis源码包下载地址 http://download.redis.io/releases/ 下载源码包 [root@centos7-master ~]# wget http://download.redis.io/releases/redis-6.2.6.tar.gz [root@centos7-master ~]# tar xf redis-6.2.6.tar.gz 安装依赖 # centos [root@centos7-master ~]# yum -y install gcc jemalloc-devel systemd-devel # ubuntu apt -y install make gcc libjemalloc-dev libsystemd-dev 编译安装 [root@centos7-master ~]# cd redis-6.2.6 #如果支持systemd,需要执行下面 [root@centos7-master redis-6.2.6]# make -j 2 USE_SYSTEMD=yes PREFIX=/usr/local/src/redis install # 配置环境变量 [root@centos7-master ~]# echo \u0026#39;PATH=/usr/local/src/redis/bin:$PATH\u0026#39; \u0026gt; /etc/profile.d/redis.sh [root@centos7-master ~]# [root@centos7-master ~]# . /etc/profile.d/redis.sh [root@centos7-master ~]# #准备相关目录和配置文件 #创建配置文件、日志、数据等目录 [root@centos7-master redis]# mkdir /usr/local/src/redis/{etc,log,data,run} [root@centos7-master redis-6.2.6]# cp redis.conf /usr/local/src/redis/etc/ 修改配置文件 logfile \u0026ldquo;/usr/local/src/redis/log/redis_6379.log\u0026rdquo;\n# Specify the log file name. Also the empty string can be used to force # Redis to log on the standard output. Note that if you use standard # output for logging but daemonize, logs will be sent to /dev/null logfile \u0026#34;/usr/local/src/redis/log/redis_6379.log\u0026#34; # To enable logging to the system logger, just set \u0026#39;syslog-enabled\u0026#39; to yes, # and optionally update the other syslog parameters to suit your needs. # syslog-enabled no # Specify the syslog identity. # syslog-ident redis pidfile /usr/local/src/redis/run/redis_6379.pid\n# Note that on modern Linux systems \u0026#34;/run/redis.pid\u0026#34; is more conforming # and should be used instead. #pidfile /var/run/redis_6379.pid pidfile /usr/local/src/redis/run/redis_6379.pid # Specify the server verbosity level. # This can be one of: # debug (a lot of information, useful for development/testing) # verbose (many rarely useful info, but not a mess like the debug level) # notice (moderately verbose, what you want in production probably) # warning (only very important / critical messages are logged) loglevel notice dir \u0026ldquo;/usr/local/src/redis/data/6379\u0026rdquo;\n# Note that you must specify a directory here, not a file name. dir \u0026#34;/usr/local/src/redis/data/6379\u0026#34; ################################# REPLICATION ################################# # Master-Replica replication. Use replicaof to make a Redis instance a copy of # another Redis server. A few things to understand ASAP about Redis replication. dbfilename \u0026lsquo;dump.rdb\u0026rsquo;\n# sanitize-dump-payload no # The filename where to dump the DB dbfilename \u0026#39;dump.rdb\u0026#39; 前台启动redis [root@centos7-master ~]# redis-server /usr/local/src/redis/etc/redis.conf 51487:C 07 Dec 2022 22:27:26.620 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo 51487:C 07 Dec 2022 22:27:26.620 # Redis version=6.2.6, bits=64, commit=00000000, modified=0, pid=51487, just started 51487:C 07 Dec 2022 22:27:26.620 # Configuration loaded 51487:M 07 Dec 2022 22:27:26.620 * Increased maximum number of open files to 10032 (it was originally set to 1024). 51487:M 07 Dec 2022 22:27:26.620 * monotonic clock: POSIX clock_gettime _._ _.-``__ \u0026#39;\u0026#39;-._ _.-`` `. `_. \u0026#39;\u0026#39;-._ Redis 6.2.6 (00000000/0) 64 bit .-`` .-```. ```\\/ _.,_ \u0026#39;\u0026#39;-._ ( \u0026#39; , .-` | `, ) Running in standalone mode |`-._`-...-` __...-.``-._|\u0026#39;` _.-\u0026#39;| Port: 6379 | `-._ `._ / _.-\u0026#39; | PID: 51487 `-._ `-._ `-./ _.-\u0026#39; _.-\u0026#39; |`-._`-._ `-.__.-\u0026#39; _.-\u0026#39;_.-\u0026#39;| | `-._`-._ _.-\u0026#39;_.-\u0026#39; | https://redis.io `-._ `-._`-.__.-\u0026#39;_.-\u0026#39; _.-\u0026#39; |`-._`-._ `-.__.-\u0026#39; _.-\u0026#39;_.-\u0026#39;| | `-._`-._ _.-\u0026#39;_.-\u0026#39; | `-._ `-._`-.__.-\u0026#39;_.-\u0026#39; _.-\u0026#39; `-._ `-.__.-\u0026#39; _.-\u0026#39; `-._ _.-\u0026#39; `-.__.-\u0026#39; 51487:M 07 Dec 2022 22:27:26.621 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128. 51487:M 07 Dec 2022 22:27:26.621 # Server initialized 51487:M 07 Dec 2022 22:27:26.621 # WARNING overcommit_memory is set to 0! Background save may fail under low memory condition. To fix this issue add \u0026#39;vm.overcommit_memory = 1\u0026#39; to /etc/sysctl.conf and then reboot or run the command \u0026#39;sysctl vm.overcommit_memory=1\u0026#39; for this to take effect. 51487:M 07 Dec 2022 22:27:26.621 * Ready to accept connections 帮助 [root@centos7-master ~]# redis-server -h Usage: ./redis-server [/path/to/redis.conf] [options] [-] ./redis-server - (read config from stdin) ./redis-server -v or --version ./redis-server -h or --help ./redis-server --test-memory \u0026lt;megabytes\u0026gt; Examples: ./redis-server (run the server with default conf) ./redis-server /etc/redis/6379.conf ./redis-server --port 7777 ./redis-server --port 7777 --replicaof 127.0.0.1 8888 ./redis-server /etc/myredis.conf --loglevel verbose - ./redis-server /etc/myredis.conf --loglevel verbose Sentinel mode: ./redis-server /etc/sentinel.conf --sentinel [root@centos7-master ~]# 消除启动时的三个Warning提示信息(可选) Tcp backlog\nWARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128. Tcp backlog 是指TCP的第三次握手服务器端收到客户端 ack确认号之后到服务器用Accept函数处理请求前的队列长度，即全连接队列\n#vim /etc/sysctl.conf net.core.somaxconn = 511 #sysctl -p overcommit_memory\nWARNING overcommit_memory is set to 0! Background save may fail under low memory condition. To fix this issue add \u0026#39;vm.overcommit_memory = 1\u0026#39; to /etc/sysctl.conf and then reboot or run the command \u0026#39;sysctl vm.overcommit_memory=1\u0026#39; for this to take effect. 内核参数说明\n内核参数overcommit_memory 实现内存分配策略,可选值有三个：0、1、2 0 表示内核将检查是否有足够的可用内存供应用进程使用；如果有足够的可用内存，内存申请允许；否则内存 申请失败，并把错误返回给应用进程 1 表示内核允许分配所有的物理内存，而不管当前的内存状态如何 2 表示内核允许分配超过所有物理内存和交换空间总和的内存 #vim /etc/sysctl.conf vm.overcommit_memory = 1 #sysctl -p transparent hugepage\nWARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command \u0026#39;echo never \u0026gt; /sys/kernel/mm/transparent_hugepage/enabled\u0026#39; as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled. 警告：您在内核中启用了透明大页面（THP,不同于一般4k内存页,而为2M）支持。 这将在Redis中造成延迟 和内存使用问题。 要解决此问题，请以root 用户身份运行命令“echo never\u0026gt; /sys/kernel/mm/transparent_hugepage/enabled”，并将其添加到您的/etc/rc.local中，以便在 重启后保留设置。禁用THP后，必须重新启动Redis。 注意：ubuntu20.04, Rocky8/CentOS8 默认为 never，所以此值无需优化\n验证是否消除warning\n[root@centos7-master ~]# redis-server /usr/local/src/redis/etc/redis.conf 51540:C 07 Dec 2022 22:38:45.196 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo 51540:C 07 Dec 2022 22:38:45.196 # Redis version=6.2.6, bits=64, commit=00000000, modified=0, pid=51540, just started 51540:C 07 Dec 2022 22:38:45.196 # Configuration loaded 51540:M 07 Dec 2022 22:38:45.197 * Increased maximum number of open files to 10032 (it was originally set to 1024). 51540:M 07 Dec 2022 22:38:45.197 * monotonic clock: POSIX clock_gettime _._ _.-``__ \u0026#39;\u0026#39;-._ _.-`` `. `_. \u0026#39;\u0026#39;-._ Redis 6.2.6 (00000000/0) 64 bit .-`` .-```. ```\\/ _.,_ \u0026#39;\u0026#39;-._ ( \u0026#39; , .-` | `, ) Running in standalone mode |`-._`-...-` __...-.``-._|\u0026#39;` _.-\u0026#39;| Port: 6379 | `-._ `._ / _.-\u0026#39; | PID: 51540 `-._ `-._ `-./ _.-\u0026#39; _.-\u0026#39; |`-._`-._ `-.__.-\u0026#39; _.-\u0026#39;_.-\u0026#39;| | `-._`-._ _.-\u0026#39;_.-\u0026#39; | https://redis.io `-._ `-._`-.__.-\u0026#39;_.-\u0026#39; _.-\u0026#39; |`-._`-._ `-.__.-\u0026#39; _.-\u0026#39;_.-\u0026#39;| | `-._`-._ _.-\u0026#39;_.-\u0026#39; | `-._ `-._`-.__.-\u0026#39;_.-\u0026#39; _.-\u0026#39; `-._ `-.__.-\u0026#39; _.-\u0026#39; `-._ _.-\u0026#39; `-.__.-\u0026#39; 51540:M 07 Dec 2022 22:38:45.197 # Server initialized 51540:M 07 Dec 2022 22:38:45.198 * Loading RDB produced by version 6.2.6 51540:M 07 Dec 2022 22:38:45.198 * RDB age 2 seconds 51540:M 07 Dec 2022 22:38:45.198 * RDB memory usage when created 0.77 Mb 51540:M 07 Dec 2022 22:38:45.198 # Done loading RDB, keys loaded: 0, keys expired: 0. 51540:M 07 Dec 2022 22:38:45.198 * DB loaded from disk: 0.000 seconds 51540:M 07 Dec 2022 22:38:45.198 * Ready to accept connections 创建 Redis 用户和设置数据目录权限 [root@centos7-master ~]# useradd -r -s /sbin/nologin redis [root@centos7-master ~]# chown -R redis.redis /usr/local/src/redis/ [root@centos7-master ~]# 创建 Redis 服务 Service 文件 [root@centos7-master ~]# vim /lib/systemd/system/redis.service [Unit] Description=Redis persistent key-value database After=network.target [Service] ExecStart=/usr/local/src/redis/bin/redis-server /usr/local/src/redis/etc/redis.conf --supervised systemd ExecStop=/bin/kill -s QUIT $MAINPID Type=notify User=redis Group=redis RuntimeDirectory=redis RuntimeDirectoryMode=0755 LimitNOFILE=1000000 [Install] WantedBy=multi-user.target Redis 通过Service方式启动 systemctl daemon-reload systemctl restart redis systemctl status redis Redis多实例 基于源码编译安装的前提下实现redis的多实例\n# 进入/usr/local/src/redis/etc [root@centos7-master ~]# cd /usr/local/src/redis/etc/ [root@centos7-master etc]# # 修改配置文件，使用6380,6381端口启动实例 [root@centos7-master etc]# sed \u0026#39;s/6379/6380/\u0026#39; redis.conf \u0026gt; redis6380.conf [root@centos7-master etc]# sed \u0026#39;s/6379/6380/\u0026#39; redis.conf \u0026gt; redis6381.conf # 修改所属组 [root@centos7-master etc]# chown -R redis.redis * # 修改启动文件 [root@centos7-master etc]# cp /lib/systemd/system/redis.service /lib/systemd/system/redis6380.service [root@centos7-master etc]# [root@centos7-master etc]# vim /lib/systemd/system/redis6380.service [Unit] Description=Redis persistent key-value database After=network.target [Service] ExecStart=/usr/local/src/redis/bin/redis-server /usr/local/src/redis/etc/redis6380.conf --supervised systemd ExecStop=/bin/kill -s QUIT $MAINPID Type=notify User=redis Group=redis RuntimeDirectory=redis RuntimeDirectoryMode=0755 LimitNOFILE=1000000 [Install] WantedBy=multi-user.target # 使用相同方法创建/lib/systemd/system/redis6381.service文件并修改内容 # 启动实例 [root@centos7-master etc]# systemctl status redis.service [root@centos7-master etc]# systemctl status redis6380.service [root@centos7-master etc]# systemctl status redis6381.service # 查看6379 6380 6381 端口是否启用 连接测试 [root@centos7-master etc]# redis-cli -p 6379 [root@centos7-master etc]# redis-cli -p 6380 [root@centos7-master etc]# redis-cli -p 6381 Redis 配置管理 配置文件说明 bind 0.0.0.0 #指定监听地址，支持用空格隔开的多个监听IP protected-mode yes #redis3.2之后加入的新特性，在没有设置bind IP和密码的时候,redis只允许访 问127.0.0.1:6379，可以远程连接，但当访问将提示警告信息并拒绝远程访问 port 6379 #监听端口,默认6379/tcp tcp-backlog 511 #三次握手的时候server端收到client ack确认号之后的队列值，即全连接队列长度 timeout 0 #客户端和Redis服务端的连接超时时间，默认是0，表示永不超时 tcp-keepalive 300 #tcp 会话保持时间300s daemonize no #默认no,即直接运行redis-server程序时,不作为守护进程运行，而是以前台方式运行， 如果想在后台运行需改成yes,当redis作为守护进程运行的时候，它会写一个 pid 到 /var/run/redis.pid 文件 supervised no #和OS相关参数，可设置通过upstart和systemd管理Redis守护进程，centos7后都使 用systemd pidfile /var/run/redis_6379.pid #pid文件路径,可以修改 为/apps/redis/run/redis_6379.pid loglevel notice #日志级别 logfile \u0026#34;/path/redis.log\u0026#34; #日志路径,示例:logfile \u0026#34;/apps/redis/log/redis_6379.log\u0026#34; databases 16 #设置数据库数量，默认：0-15，共16个库 always-show-logo yes #在启动redis 时是否显示或在日志中记录记录redis的logo save 900 1 #在900秒内有1个key内容发生更改,就执行快照机制 save 300 10 #在300秒内有10个key内容发生更改,就执行快照机制 save 60 10000 #60秒内如果有10000个key以上的变化，就自动快照备份 stop-writes-on-bgsave-error yes #默认为yes时,可能会因空间满等原因快照无法保存出错时，会禁 止redis写入操作，生产建议为no #此项只针对配置文件中的自动save有效 rdbcompression yes #持久化到RDB文件时，是否压缩，\u0026#34;yes\u0026#34;为压缩，\u0026#34;no\u0026#34;则反之 rdbchecksum yes #是否对备份文件开启RC64校验，默认是开启 dbfilename dump.rdb #快照文件名 dir ./ #快照文件保存路径，示例：dir \u0026#34;/apps/redis/data\u0026#34; #主从复制相关 # replicaof \u0026lt;masterip\u0026gt; \u0026lt;masterport\u0026gt; #指定复制的master主机地址和端口，5.0版之前的指令为 slaveof # masterauth \u0026lt;master-password\u0026gt; #指定复制的master主机的密码 replica-serve-stale-data yes #当从库同主库失去连接或者复制正在进行，从机库有两种运行方式： 1、设置为yes(默认设置)，从库会继续响应客户端的读请求，此为建议值 2、设置为no，除去特定命令外的任何请求都会返回一个错误\u0026#34;SYNC with master in progress\u0026#34;。 replica-read-only yes #是否设置从库只读，建议值为yes,否则主库同步从库时可能会覆盖数据，造成 数据丢失 repl-diskless-sync no #是否使用socket方式复制数据(无盘同步)，新slave第一次连接master时需 要做数据的全量同步，redis server就要从内存dump出新的RDB文件，然后从master传到slave，有两种 方式把RDB文件传输给客户端： 1、基于硬盘（disk-backed）：为no时，master创建一个新进程dump生成RDB磁盘文件，RDB完成之后由 父进程（即主进程）将RDB文件发送给slaves，此为默认值 2、基于socket（diskless）：master创建一个新进程直接dump RDB至slave的网络socket，不经过主 进程和硬盘 #推荐使用基于硬盘（为no），是因为RDB文件创建后，可以同时传输给更多的slave，但是基于socket(为 yes)， 新slave连接到master之后得逐个同步数据。只有当磁盘I/O较慢且网络较快时，可用 diskless(yes),否则一般建议使用磁盘(no) repl-diskless-sync-delay 5 #diskless时复制的服务器等待的延迟时间，设置0为关闭，在延迟时间 内到达的客户端，会一起通过diskless方式同步数据，但是一旦复制开始，master节点不会再接收新slave 的复制请求，直到下一次同步开始才再接收新请求。即无法为延迟时间后到达的新副本提供服务，新副本将排 队等待下一次RDB传输，因此服务器会等待一段时间才能让更多副本到达。推荐值：30-60 repl-ping-replica-period 10 #slave根据master指定的时间进行周期性的PING master,用于监测 master状态,默认10s repl-timeout 60 #复制连接的超时时间，需要大于repl-ping-slave-period，否则会经常报超时 repl-disable-tcp-nodelay no #是否在slave套接字发送SYNC之后禁用 TCP_NODELAY，如果选 择\u0026#34;yes\u0026#34;，Redis将合并多个报文为一个大的报文，从而使用更少数量的包向slaves发送数据，但是将使数据 传输到slave上有延迟，Linux内核的默认配置会达到40毫秒，如果 \u0026#34;no\u0026#34; ，数据传输到slave的延迟将会 减少，但要使用更多的带宽 repl-backlog-size 512mb #复制缓冲区内存大小，当slave断开连接一段时间后，该缓冲区会累积复制 副本数据，因此当slave 重新连接时，通常不需要完全重新同步，只需传递在副本中的断开连接后没有同步的 部分数据即可。只有在至少有一个slave连接之后才分配此内存空间,建议建立主从时此值要调大一些或在低峰 期配置,否则会导致同步到slave失败 repl-backlog-ttl 3600 #多长时间内master没有slave连接，就清空backlog缓冲区 replica-priority 100 #当master不可用，哨兵Sentinel会根据slave的优先级选举一个master，此 值最低的slave会优先当选master，而配置成0，永远不会被选举，一般多个slave都设为一样的值，让其自 动选择 #min-replicas-to-write 3 #至少有3个可连接的slave，mater才接受写操作 #min-replicas-max-lag 10 #和上面至少3个slave的ping延迟不能超过10秒，否则master也将停止 写操作 requirepass foobared #设置redis连接密码，之后需要AUTH pass,如果有特殊符号，用\u0026#34; \u0026#34;引起来,生 产建议设置 rename-command #重命名一些高危命令，示例：rename-command FLUSHALL \u0026#34;\u0026#34; 禁用命令 #示例: rename-command del magedu maxclients 10000 #Redis最大连接客户端 maxmemory \u0026lt;bytes\u0026gt; #redis使用的最大内存，单位为bytes字节，0为不限制，建议设为物理内存一半， 8G内存的计算方式8(G)*1024(MB)1024(KB)*1024(Kbyte)，需要注意的是缓冲区是不计算在maxmemory 内,生产中如果不设置此项,可能会导致OOM #maxmemory-policy noeviction 此为默认值 # MAXMEMORY POLICY：当达到最大内存时，Redis 将如何选择要删除的内容。您可以从以下行为中选择一 种： # # volatile-lru -\u0026gt; Evict 使用近似 LRU，只有设置了过期时间的键。 # allkeys-lru -\u0026gt; 使用近似 LRU 驱逐任何键。 # volatile-lfu -\u0026gt; 使用近似 LFU 驱逐，只有设置了过期时间的键。 # allkeys-lfu -\u0026gt; 使用近似 LFU 驱逐任何键。 # volatile-random -\u0026gt; 删除设置了过期时间的随机密钥。 # allkeys-random -\u0026gt; 删除一个随机密钥，任何密钥。 # volatile-ttl -\u0026gt; 删除过期时间最近的key（次TTL） # noeviction -\u0026gt; 不要驱逐任何东西，只是在写操作时返回一个错误。 # # LRU 表示最近最少使用 # LFU 表示最不常用 # # LRU、LFU 和 volatile-ttl 都是使用近似随机算法实现的。 # # 注意：使用上述任何一种策略，当没有合适的键用于驱逐时，Redis 将在需要更多内存的写操作时返回错 误。这些通常是创建新密钥、添加数据或修改现有密钥的命令。一些示例是：SET、INCR、HSET、LPUSH、 SUNIONSTORE、SORT（由于 STORE 参数）和 EXEC（如果事务包括任何需要内存的命令）。 #MAXMEMORY POLICY：当达到最大内存时，Redis 将如何选择要删除的内容。可以从下面行为中进行选 择： # volatile-lru -\u0026gt; 在具有过期集的键中使用近似 LRU 驱逐。 # allkeys-lru -\u0026gt; 使用近似 LRU 驱逐任何键。 # volatile-lfu -\u0026gt; 在具有过期集的键中使用近似 LFU 驱逐。 # allkeys-lfu -\u0026gt; 使用近似 LFU 驱逐任何键。 # volatile-random -\u0026gt; 从具有过期设置的密钥中删除一个随机密钥。 # allkeys-random -\u0026gt; 删除一个随机密钥，任何密钥。 # volatile-ttl -\u0026gt; 删除过期时间最近的key（次TTL） # noeviction -\u0026gt; 不要驱逐任何东西，只是在写操作时返回一个错误。 # # LRU 表示最近最少使用 # LFU 表示最不常用 # # LRU、LFU 和 volatile-ttl 均使用近似实现随机算法。 # # 注意：使用上述任何一种策略，Redis 都会在写入时返回错误操作，当没有合适的键用于驱逐时。 appendonly no #是否开启AOF日志记录，默认redis使用的是rdb方式持久化，这种方式在许多应用中已经 足够用了，但是redis如果中途宕机，会导致可能有几分钟的数据丢失(取决于dump数据的间隔时间)，根据 save来策略进行持久化，Append Only File是另一种持久化方式，可以提供更好的持久化特性，Redis会 把每次写入的数据在接收后都写入 appendonly.aof 文件，每次启动时Redis都会先把这个文件的数据读入 内存里，先忽略RDB文件。默认不启用此功能 appendfilename \u0026#34;appendonly.aof\u0026#34; #文本文件AOF的文件名，存放在dir指令指定的目录中 appendfsync everysec #aof持久化策略的配置 #no表示由操作系统保证数据同步到磁盘,Linux的默认fsync策略是30秒，最多会丢失30s的数据 #always表示每次写入都执行fsync，以保证数据同步到磁盘,安全性高,性能较差 #everysec表示每秒执行一次fsync，可能会导致丢失这1s数据,此为默认值,也生产建议值 #同时在执行bgrewriteaof操作和主进程写aof文件的操作，两者都会操作磁盘，而bgrewriteaof往往会 涉及大量磁盘操作，这样就会造成主进程在写aof文件的时候出现阻塞的情形,以下参数实现控制 no-appendfsync-on-rewrite no #在aof rewrite期间,是否对aof新记录的append暂缓使用文件同步 策略,主要考虑磁盘IO开支和请求阻塞时间。 #默认为no,表示\u0026#34;不暂缓\u0026#34;,新的aof记录仍然会被立即同步到磁盘，是最安全的方式，不会丢失数据，但是要 忍受阻塞的问题 #为yes,相当于将appendfsync设置为no，这说明并没有执行磁盘操作，只是写入了缓冲区，因此这样并不 会造成阻塞（因为没有竞争磁盘），但是如果这个时候redis挂掉，就会丢失数据。丢失多少数据呢？Linux 的默认fsync策略是30秒，最多会丢失30s的数据,但由于yes性能较好而且会避免出现阻塞因此比较推荐 #rewrite 即对aof文件进行整理,将空闲空间回收,从而可以减少恢复数据时间 auto-aof-rewrite-percentage 100 #当Aof log增长超过指定百分比例时，重写AOF文件，设置为0表 示不自动重写Aof日志，重写是为了使aof体积保持最小，但是还可以确保保存最完整的数据 auto-aof-rewrite-min-size 64mb #触发aof rewrite的最小文件大小 aof-load-truncated yes #是否加载由于某些原因导致的末尾异常的AOF文件(主进程被kill/断电等)， 建议yes aof-use-rdb-preamble no #redis4.0新增RDB-AOF混合持久化格式，在开启了这个功能之后，AOF重 写产生的文件将同时包含RDB格式的内容和AOF格式的内容，其中RDB格式的内容用于记录已有的数据，而AOF 格式的内容则用于记录最近发生了变化的数据，这样Redis就可以同时兼有RDB持久化和AOF持久化的优点（既 能够快速地生成重写文件，也能够在出现问题时，快速地载入数据）,默认为no,即不启用此功能 lua-time-limit 5000 #lua脚本的最大执行时间，单位为毫秒 cluster-enabled yes #是否开启集群模式，默认不开启,即单机模式 cluster-config-file nodes-6379.conf #由node节点自动生成的集群配置文件名称 cluster-node-timeout 15000 #集群中node节点连接超时时间，单位ms,超过此时间，会踢出集群 cluster-replica-validity-factor 10 #单位为次,在执行故障转移的时候可能有些节点和master断 开一段时间导致数据比较旧，这些节点就不适用于选举为master，超过这个时间的就不会被进行故障转移,不 能当选master，计算公式：(node-timeout * replica-validity-factor) + repl-ping- replica-period cluster-migration-barrier 1 #集群迁移屏障，一个主节点至少拥有1个正常工作的从节点，即如果主 节点的slave节点故障后会将多余的从节点分配到当前主节点成为其新的从节点。 cluster-require-full-coverage yes #集群请求槽位全部覆盖，如果一个主库宕机且没有备库就会出 现集群槽位不全，那么yes时redis集群槽位验证不全,就不再对外提供服务(对key赋值时,会出现 CLUSTERDOWN The cluster is down的提示,cluster_state:fail,但ping 仍PONG)，而no则可以 继续使用,但是会出现查询数据查不到的情况(因为有数据丢失)。生产建议为no cluster-replica-no-failover no #如果为yes,此选项阻止在主服务器发生故障时尝试对其主服务器进 行故障转移。 但是，主服务器仍然可以执行手动强制故障转移，一般为no #Slow log 是 Redis 用来记录超过指定执行时间的日志系统，执行时间不包括与客户端交谈，发送回复等 I/O操作，而是实际执行命令所需的时间（在该阶段线程被阻塞并且不能同时为其它请求提供服务）,由于 slow log 保存在内存里面，读写速度非常快，因此可放心地使用，不必担心因为开启 slow log 而影响 Redis 的速度 slowlog-log-slower-than 10000 #以微秒为单位的慢日志记录，为负数会禁用慢日志，为0会记录每个 命令操作。默认值为10ms,一般一条命令执行都在微秒级,生产建议设为1ms-10ms之间 slowlog-max-len 128 #最多记录多少条慢日志的保存队列长度，达到此长度后，记录新命令会将最旧的命 令从命令队列中删除，以此滚动删除,即,先进先出,队列固定长度,默认128,值偏小,生产建议设为1000以上 Redis的配置文件介绍\nconfig 命令实现动态修改配置 config 命令用于查看当前redis配置、以及不重启redis服务实现动态更改redis配置等 注意：不是所有配置都可以动态修改,且此方式无法持久保存\nCONFIG SET parameter value 时间复杂度：O(1) CONFIG SET 命令可以动态地调整 Redis 服务器的配置(configuration)而无须重启。 可以使用它修改配置参数，或者改变 Redis 的持久化(Persistence)方式。 CONFIG SET 可以修改的配置参数可以使用命令 CONFIG GET * 来列出，所有被 CONFIG SET 修改的配 置参数都会立即生效。 CONFIG GET parameter 时间复杂度： O(N)，其中 N 为命令返回的配置选项数量。 CONFIG GET 命令用于取得运行中的 Redis 服务器的配置参数(configuration parameters)，在 Redis 2.4 版本中， 有部分参数没有办法用 CONFIG GET 访问，但是在最新的 Redis 2.6 版本中，所 有配置参数都已经可以用 CONFIG GET 访问了。 CONFIG GET 接受单个参数 parameter 作为搜索关键字，查找所有匹配的配置参数，其中参数和值以“键- 值对”(key-value pairs)的方式排列。 比如执行 CONFIG GET s* 命令，服务器就会返回所有以 s 开头的配置参数及参数的值： 设置客户端连接密码 #设置连接密码 127.0.0.1:6379\u0026gt; CONFIG SET requirepass 123456 OK #查看连接密码 127.0.0.1:6379\u0026gt; CONFIG GET requirepass 1) \u0026#34;requirepass\u0026#34; 2) \u0026#34;123456\u0026#34; 获取当前配置 #奇数行为键，偶数行为值 127.0.0.1:6379\u0026gt; CONFIG GET * 1) \u0026#34;dbfilename\u0026#34; 2) \u0026#34;dump.rdb\u0026#34; 3) \u0026#34;requirepass\u0026#34; 4) \u0026#34;\u0026#34; 5) \u0026#34;masterauth\u0026#34; 6) \u0026#34;\u0026#34; 7) \u0026#34;cluster-announce-ip\u0026#34; 8) \u0026#34;\u0026#34; 9) \u0026#34;unixsocket\u0026#34; 10) \u0026#34;\u0026#34; 11) \u0026#34;logfile\u0026#34; 12) \u0026#34;/var/log/redis/redis.log\u0026#34; 13) \u0026#34;pidfile\u0026#34; 14) \u0026#34;/var/run/redis_6379.pid\u0026#34; 15) \u0026#34;slave-announce-ip\u0026#34; 16) \u0026#34;\u0026#34; 17) \u0026#34;replica-announce-ip\u0026#34; 18) \u0026#34;\u0026#34; 19) \u0026#34;maxmemory\u0026#34; 20) \u0026#34;0\u0026#34; ...... #查看bind 127.0.0.1:6379\u0026gt; CONFIG GET bind 1) \u0026#34;bind\u0026#34; 2) \u0026#34;0.0.0.0\u0026#34; #Redis5.0有些设置无法修改,Redis6.2.6版本支持修改bind 127.0.0.1:6379\u0026gt; CONFIG SET bind 127.0.0.1 (error) ERR Unsupported CONFIG parameter: bind 设置Redis使用的最大内存量 127.0.0.1:6379\u0026gt; CONFIG SET maxmemory 8589934592 OK 127.0.0.1:6379\u0026gt; CONFIG GET maxmemory 1) \u0026#34;maxmemory\u0026#34; 2) \u0026#34;8589934592\u0026#34; 慢查询 范例：SLOW LOG\nvim /etc/redis.conf slowlog-log-slower-than 1 #指定超过1us即为慢的指令，默认值为10000us slowlog-max-len 1024 #指定只保存最近的1024条慢记录，默认值为128 127.0.0.1:6379\u0026gt; SLOWLOG LEN #查看慢日志的记录条数 (integer) 14 127.0.0.1:6379\u0026gt; SLOWLOG GET [n] #查看慢日志的n条记录 1) 1) (integer) 14 2) (integer) 1544690617 3) (integer) 4 #第3)行表示每条指令的执行时长 4) 1) \u0026#34;slowlog\u0026#34; 127.0.0.1:6379\u0026gt; SLOWLOG GET 3 1) 1) (integer) 7 2) (integer) 1602901545 3) (integer) 26 4) 1) \u0026#34;SLOWLOG\u0026#34; 2) \u0026#34;get\u0026#34; 5) \u0026#34;127.0.0.1:38258\u0026#34; 6) \u0026#34;\u0026#34; 2) 1) (integer) 6 2) (integer) 1602901540 3) (integer) 22 4) 1) \u0026#34;SLOWLOG\u0026#34; 2) \u0026#34;get\u0026#34; 3) \u0026#34;2\u0026#34; 5) \u0026#34;127.0.0.1:38258\u0026#34; 6) \u0026#34;\u0026#34; 3) 1) (integer) 5 2) (integer) 1602901497 3) (integer) 22 4) 1) \u0026#34;SLOWLOG\u0026#34; 2) \u0026#34;GET\u0026#34; 5) \u0026#34;127.0.0.1:38258\u0026#34; 6) \u0026#34;\u0026#34; 127.0.0.1:6379\u0026gt; SLOWLOG RESET #清空慢日志 OK Redis持久化 RDB RDB 工作原理\n配置 AOF ","permalink":"https://xyenvy.github.io/posts/redis%E9%83%A8%E7%BD%B2%E5%92%8C%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/","summary":"Redis基础 简介 Redis (Remote Dictionary Server远程字典服务)是一个遵循BSD MIT开源协议的高性能的NoSQL.Redis基于ANSI C语言语言)编写的key-value数据库,是意大利的Salvatore Sanfilippo在2009年发布，从2010年3月15日起，Redis的开发工作","title":"Redis部署和基础使用"},{"content":"Nginx 简介 一、Nginx概述 1.1 概述 Nginx（“engine x”）是一个高性能的 HTTP /反向代理的服务器及电子邮件（IMAP/POP3)代理服务器。官方测试nginx能够支撑5万并发，并且cpu，内存等资源消耗却非常低，运行非常稳定。最重要的是开源，免费，可商用的。\nNginx还支持热部署，几乎可以做到7 * 24 小时不间断运行，即时运行数个月也不需要重启，还能够在不间断服务的情况下对软件进行升级维护。\n1.2 Nginx应用场景 虚拟主机：一台服务器虚拟出多个网站。\n静态资源服务：提供http资源访问服务。\n反向代理，负载均衡。当网站的访问量达到一定程度后，单台服务器不能满足用户的请求时，需要yo哪个多台服务器集群可以使用nginx做反向代理。并且多台服务器可以平均分担负载，不会因为某台服务器负载高宕机而某台服务器闲置的情况。\n1.3 正向代理 正向代理：一般的访问流程是客户端直接向目标服务器发送请求并获取内容，使用正向代理后，客户端通过配置或其他方式改为向代理服务器发送请求，并指定目标服务器（原始服务器），然后由代理服务器和原始服务器通信，转交请求并获得的内容，再返回给客户端。正向代理隐藏了真实的客户端，为客户端收发请求，使真实客户端对服务器不可见；\n1.4 反向代理 **反向代理：**正好相反。对于客户端来说，反向代理就好像目标服务器。并且客户端不需要进行任何设置。客户端向反向代理发送请求，接着反向代理判断请求走向何处，并将请求转交给客户端，使得这些内容就好像它自己的一样，一次客户端并会并会不感知到反向代理后面的服务，因此不需要客户端做任何设置，只需要把反向代理服务器当成真正的服务器就好了。\n1.5 负载均衡 负载均衡建立在现有网络结构之上，它提供一种链家有效透明的方法扩展网络设备和服务器的宽带、增加吞吐量，加强网络数据处理能力，提高网络的灵活性和可用性。\n1.6 动静分离 为了加快网站的解析速度，可以把动态页面和静态页面由不同的服务器来解析，加快解析速度，降低原来单个服务器的压力。一般来说，都需要将动态资源和静态资源分开，由于Nginx的高并发和静态资源缓存等特性，经常将静态资源部署在Nginx上。如果请求的是静态资源，直接到静态资源目录获取资源，如果是童泰资源的请求，则利用反向代理的原理，把请求转发给对应后台应用去处理，从而实现动静分离。\n二、Nginx安装 2.1 进入官网下载 2.2 安装相关依赖 2.2.1 第一步 1、 安装pcre\nwget http://downloads.sourceforge.net/project/pcre/pcre/8.37/pcre-8.37.tar.gz 2、解压文件 tar -zxvf 路径\n3、pcre主目录执行命令 :\n./configure ​ 可能遇到的情况：没有c++支持\n安装c++支持：\nyum install -y gcc gcc-c++ 4、完成后、回到pcre目录下执行\nmake \u0026amp;\u0026amp; make install 5、查看版本 :\npcre-config --version 2.2.2 第二步，安装其他依赖 zlib openssl\nyum -y install make zlib zlib-devel gcc-c++ libtool openssl openssl-devel 2.3 安装nginx 解压nginx-xx.tar.gz包\ntar -zxvf nginx-xxx.tar.gz 进入解压目录，执行./configure\n./configure make\u0026amp;\u0026amp;make install\nmake \u0026amp;\u0026amp; make install 2.3 开放端口 #查看开放的端口号 firewall-cmd --list-all #设置开放的端口号 firewall-cmd --add-service=http –permanent sudo firewall-cmd --add-port=80/tcp --permanent #重启防火墙 firewall-cmd –reload 2.4 访问 三、nginx常用命令和配置文件 3.1 常用命令 #查看版本 在/usr/local/nginx/sbin 目录下执行 ./nginx -v #启动nginx 在/usr/local/nginx/sbin 目录下执行 ./nginx #关闭nginx 在/usr/local/nginx/sbin 目录下执行 ./nginx -s stop #重加载nginx 在/usr/local/nginx/sbin 目录下执行 ./nginx -s reload 3.2 配置文件详细讲解 #配置文件位置 位置：/usr/local/nginx/conf/nginx.conf ######Nginx配置文件nginx.conf中文详解##### #定义Nginx运行的用户和用户组 user www www; #nginx进程数，建议设置为等于CPU总核心数。 worker_processes 8; #全局错误日志定义类型，[ debug | info | notice | warn | error | crit ] error_log /usr/local/nginx/logs/error.log info; #进程pid文件 pid /usr/local/nginx/logs/nginx.pid; #指定进程可以打开的最大描述符：数目 #工作模式与连接数上限 #这个指令是指当一个nginx进程打开的最多文件描述符数目，理论值应该是最多打开文件数（ulimit -n）与nginx进程数相除，但是nginx分配请求并不是那么均匀，所以最好与ulimit -n 的值保持一致。 #现在在linux 2.6内核下开启文件打开数为65535，worker_rlimit_nofile就相应应该填写65535。 #这是因为nginx调度时分配请求到进程并不是那么的均衡，所以假如填写10240，总并发量达到3-4万时就有进程可能超过10240了，这时会返回502错误。 worker_rlimit_nofile 65535; events { #参考事件模型，use [ kqueue | rtsig | epoll | /dev/poll | select | poll ]; epoll模型 #是Linux 2.6以上版本内核中的高性能网络I/O模型，linux建议epoll，如果跑在FreeBSD上面，就用kqueue模型。 #补充说明： #与apache相类，nginx针对不同的操作系统，有不同的事件模型 #A）标准事件模型 #Select、poll属于标准事件模型，如果当前系统不存在更有效的方法，nginx会选择select或poll #B）高效事件模型 #Kqueue：使用于FreeBSD 4.1+, OpenBSD 2.9+, NetBSD 2.0 和 MacOS X.使用双处理器的MacOS X系统使用kqueue可能会造成内核崩溃。 #Epoll：使用于Linux内核2.6版本及以后的系统。 #/dev/poll：使用于Solaris 7 11/99+，HP/UX 11.22+ (eventport)，IRIX 6.5.15+ 和 Tru64 UNIX 5.1A+。 #Eventport：使用于Solaris 10。 为了防止出现内核崩溃的问题， 有必要安装安全补丁。 use epoll; #单个进程最大连接数（最大连接数=连接数*进程数） #根据硬件调整，和前面工作进程配合起来用，尽量大，但是别把cpu跑到100%就行。每个进程允许的最多连接数，理论上每台nginx服务器的最大连接数为。 worker_connections 65535; #keepalive超时时间。 keepalive_timeout 60; #客户端请求头部的缓冲区大小。这个可以根据你的系统分页大小来设置，一般一个请求头的大小不会超过1k，不过由于一般系统分页都要大于1k，所以这里设置为分页大小。 #分页大小可以用命令getconf PAGESIZE 取得。 #[root@web001 ~]# getconf PAGESIZE #4096 #但也有client_header_buffer_size超过4k的情况，但是client_header_buffer_size该值必须设置为“系统分页大小”的整倍数。 client_header_buffer_size 4k; #这个将为打开文件指定缓存，默认是没有启用的，max指定缓存数量，建议和打开文件数一致，inactive是指经过多长时间文件没被请求后删除缓存。 open_file_cache max=65535 inactive=60s; #这个是指多长时间检查一次缓存的有效信息。 #语法:open_file_cache_valid time 默认值:open_file_cache_valid 60 使用字段:http, server, location 这个指令指定了何时需要检查open_file_cache中缓存项目的有效信息. open_file_cache_valid 80s; #open_file_cache指令中的inactive参数时间内文件的最少使用次数，如果超过这个数字，文件描述符一直是在缓存中打开的，如上例，如果有一个文件在inactive时间内一次没被使用，它将被移除。 #语法:open_file_cache_min_uses number 默认值:open_file_cache_min_uses 1 使用字段:http, server, location 这个指令指定了在open_file_cache指令无效的参数中一定的时间范围内可以使用的最小文件数,如果使用更大的值,文件描述符在cache中总是打开状态. open_file_cache_min_uses 1; #语法:open_file_cache_errors on | off 默认值:open_file_cache_errors off 使用字段:http, server, location 这个指令指定是否在搜索一个文件是记录cache错误. open_file_cache_errors on; } #设定http服务器，利用它的反向代理功能提供负载均衡支持 http { #文件扩展名与文件类型映射表 include mime.types; #默认文件类型 default_type application/octet-stream; #默认编码 #charset utf-8; #服务器名字的hash表大小 #保存服务器名字的hash表是由指令server_names_hash_max_size 和server_names_hash_bucket_size所控制的。参数hash bucket size总是等于hash表的大小，并且是一路处理器缓存大小的倍数。在减少了在内存中的存取次数后，使在处理器中加速查找hash表键值成为可能。如果hash bucket size等于一路处理器缓存的大小，那么在查找键的时候，最坏的情况下在内存中查找的次数为2。第一次是确定存储单元的地址，第二次是在存储单元中查找键 值。因此，如果Nginx给出需要增大hash max size 或 hash bucket size的提示，那么首要的是增大前一个参数的大小. server_names_hash_bucket_size 128; #客户端请求头部的缓冲区大小。这个可以根据你的系统分页大小来设置，一般一个请求的头部大小不会超过1k，不过由于一般系统分页都要大于1k，所以这里设置为分页大小。分页大小可以用命令getconf PAGESIZE取得。 client_header_buffer_size 32k; #客户请求头缓冲大小。nginx默认会用client_header_buffer_size这个buffer来读取header值，如果header过大，它会使用large_client_header_buffers来读取。 large_client_header_buffers 4 64k; #设定通过nginx上传文件的大小 client_max_body_size 8m; #开启高效文件传输模式，sendfile指令指定nginx是否调用sendfile函数来输出文件，对于普通应用设为 on，如果用来进行下载等应用磁盘IO重负载应用，可设置为off，以平衡磁盘与网络I/O处理速度，降低系统的负载。注意：如果图片显示不正常把这个改成off。 #sendfile指令指定 nginx 是否调用sendfile 函数（zero copy 方式）来输出文件，对于普通应用，必须设为on。如果用来进行下载等应用磁盘IO重负载应用，可设置为off，以平衡磁盘与网络IO处理速度，降低系统uptime。 sendfile on; #开启目录列表访问，合适下载服务器，默认关闭。 autoindex on; #此选项允许或禁止使用socke的TCP_CORK的选项，此选项仅在使用sendfile的时候使用 tcp_nopush on; tcp_nodelay on; #长连接超时时间，单位是秒 keepalive_timeout 120; #FastCGI相关参数是为了改善网站的性能：减少资源占用，提高访问速度。下面参数看字面意思都能理解。 fastcgi_connect_timeout 300; fastcgi_send_timeout 300; fastcgi_read_timeout 300; fastcgi_buffer_size 64k; fastcgi_buffers 4 64k; fastcgi_busy_buffers_size 128k; fastcgi_temp_file_write_size 128k; #gzip模块设置 gzip on; #开启gzip压缩输出 gzip_min_length 1k; #最小压缩文件大小 gzip_buffers 4 16k; #压缩缓冲区 gzip_http_version 1.0; #压缩版本（默认1.1，前端如果是squid2.5请使用1.0） gzip_comp_level 2; #压缩等级 gzip_types text/plain application/x-javascript text/css application/xml; #压缩类型，默认就已经包含textml，所以下面就不用再写了，写上去也不会有问题，但是会有一个warn。 gzip_vary on; #开启限制IP连接数的时候需要使用 #limit_zone crawler $binary_remote_addr 10m; #负载均衡配置 upstream jh.w3cschool.cn { #upstream的负载均衡，weight是权重，可以根据机器配置定义权重。weigth参数表示权值，权值越高被分配到的几率越大。 server 192.168.80.121:80 weight=3; server 192.168.80.122:80 weight=2; server 192.168.80.123:80 weight=3; #nginx的upstream目前支持4种方式的分配 #1、轮询（默认） #每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。 #2、weight #指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。 #例如： #upstream bakend { # server 192.168.0.14 weight=10; # server 192.168.0.15 weight=10; #} #2、ip_hash #每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。 #例如： #upstream bakend { # ip_hash; # server 192.168.0.14:88; # server 192.168.0.15:80; #} #3、fair（第三方） #按后端服务器的响应时间来分配请求，响应时间短的优先分配。 #upstream backend { # server server1; # server server2; # fair; #} #4、url_hash（第三方） #按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，后端服务器为缓存时比较有效。 #例：在upstream中加入hash语句，server语句中不能写入weight等其他的参数，hash_method是使用的hash算法 #upstream backend { # server squid1:3128; # server squid2:3128; # hash $request_uri; # hash_method crc32; #} #tips: #upstream bakend{#定义负载均衡设备的Ip及设备状态}{ # ip_hash; # server 127.0.0.1:9090 down; # server 127.0.0.1:8080 weight=2; # server 127.0.0.1:6060; # server 127.0.0.1:7070 backup; #} #在需要使用负载均衡的server中增加 proxy_pass http://bakend/; #每个设备的状态设置为: #1.down表示单前的server暂时不参与负载 #2.weight为weight越大，负载的权重就越大。 #3.max_fails：允许请求失败的次数默认为1.当超过最大次数时，返回proxy_next_upstream模块定义的错误 #4.fail_timeout:max_fails次失败后，暂停的时间。 #5.backup： 其它所有的非backup机器down或者忙的时候，请求backup机器。所以这台机器压力会最轻。 #nginx支持同时设置多组的负载均衡，用来给不用的server来使用。 #client_body_in_file_only设置为On 可以讲client post过来的数据记录到文件中用来做debug #client_body_temp_path设置记录文件的目录 可以设置最多3层目录 #location对URL进行匹配.可以进行重定向或者进行新的代理 负载均衡 } #虚拟主机的配置 server { #监听端口 listen 80; #域名可以有多个，用空格隔开 server_name www.w3cschool.cn w3cschool.cn; index index.html index.htm index.php; root /data/www/w3cschool; #对******进行负载均衡 location ~ .*.(php|php5)?$ { fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; include fastcgi.conf; } #图片缓存时间设置 location ~ .*.(gif|jpg|jpeg|png|bmp|swf)$ { expires 10d; } #JS和CSS缓存时间设置 location ~ .*.(js|css)?$ { expires 1h; } #日志格式设定 #$remote_addr与$http_x_forwarded_for用以记录客户端的ip地址； #$remote_user：用来记录客户端用户名称； #$time_local： 用来记录访问时间与时区； #$request： 用来记录请求的url与http协议； #$status： 用来记录请求状态；成功是200， #$body_bytes_sent ：记录发送给客户端文件主体内容大小； #$http_referer：用来记录从那个页面链接访问过来的； #$http_user_agent：记录客户浏览器的相关信息； #通常web服务器放在反向代理的后面，这样就不能获取到客户的IP地址了，通过$remote_add拿到的IP地址是反向代理服务器的iP地址。反向代理服务器在转发请求的http头信息中，可以增加x_forwarded_for信息，用以记录原有客户端的IP地址和原来客户端的请求的服务器地址。 log_format access \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39; \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39; \u0026#39;\u0026#34;$http_user_agent\u0026#34; $http_x_forwarded_for\u0026#39;; #定义本虚拟主机的访问日志 access_log /usr/local/nginx/logs/host.access.log main; access_log /usr/local/nginx/logs/host.access.404.log log404; #对 \u0026#34;/\u0026#34; 启用反向代理 location / { proxy_pass http://127.0.0.1:88; proxy_redirect off; proxy_set_header X-Real-IP $remote_addr; #后端的Web服务器可以通过X-Forwarded-For获取用户真实IP proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; #以下是一些反向代理的配置，可选。 proxy_set_header Host $host; #允许客户端请求的最大单文件字节数 client_max_body_size 10m; #缓冲区代理缓冲用户端请求的最大字节数， #如果把它设置为比较大的数值，例如256k，那么，无论使用firefox还是IE浏览器，来提交任意小于256k的图片，都很正常。如果注释该指令，使用默认的client_body_buffer_size设置，也就是操作系统页面大小的两倍，8k或者16k，问题就出现了。 #无论使用firefox4.0还是IE8.0，提交一个比较大，200k左右的图片，都返回500 Internal Server Error错误 client_body_buffer_size 128k; #表示使nginx阻止HTTP应答代码为400或者更高的应答。 proxy_intercept_errors on; #后端服务器连接的超时时间_发起握手等候响应超时时间 #nginx跟后端服务器连接超时时间(代理连接超时) proxy_connect_timeout 90; #后端服务器数据回传时间(代理发送超时) #后端服务器数据回传时间_就是在规定时间之内后端服务器必须传完所有的数据 proxy_send_timeout 90; #连接成功后，后端服务器响应时间(代理接收超时) #连接成功后_等候后端服务器响应时间_其实已经进入后端的排队之中等候处理（也可以说是后端服务器处理请求的时间） proxy_read_timeout 90; #设置代理服务器（nginx）保存用户头信息的缓冲区大小 #设置从被代理服务器读取的第一部分应答的缓冲区大小，通常情况下这部分应答中包含一个小的应答头，默认情况下这个值的大小为指令proxy_buffers中指定的一个缓冲区的大小，不过可以将其设置为更小 proxy_buffer_size 4k; #proxy_buffers缓冲区，网页平均在32k以下的设置 #设置用于读取应答（来自被代理服务器）的缓冲区数目和大小，默认情况也为分页大小，根据操作系统的不同可能是4k或者8k proxy_buffers 4 32k; #高负荷下缓冲大小（proxy_buffers*2） proxy_busy_buffers_size 64k; #设置在写入proxy_temp_path时数据的大小，预防一个工作进程在传递文件时阻塞太长 #设定缓存文件夹大小，大于这个值，将从upstream服务器传 proxy_temp_file_write_size 64k; } #设定查看Nginx状态的地址 location /NginxStatus { stub_status on; access_log on; auth_basic \u0026#34;NginxStatus\u0026#34;; auth_basic_user_file confpasswd; #htpasswd文件的内容可以用apache提供的htpasswd工具来产生。 } #本地动静分离反向代理配置 #所有jsp的页面均交由tomcat或resin处理 location ~ .(jsp|jspx|do)?$ { proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://127.0.0.1:8080; } #所有静态文件由nginx直接读取不经过tomcat或resin location ~ .*.(htm|html|gif|jpg|jpeg|png|bmp|swf|ioc|rar|zip|txt|flv|mid|doc|ppt| pdf|xls|mp3|wma)$ { expires 15d; } location ~ .*.(js|css)?$ { expires 1h; } } } ######Nginx配置文件nginx.conf中文详解##### 四、反向代理 4.1 单端口反向代理 实现效果：打开浏览器，在浏览器地址栏输入 ‘www.123.com’ ，跳转到 linux 系统的 tomcat 主页\n4.1.1 安装 tomcat 将Tomcat安装包复制到linux中\n进入 tomcat 的 bin 目录中，./startup.sh 启动 tomcat 服务器\n对外开放访问的端口号\nfirewall-cmd --add-port=8080/tcp --permanent firewall-cmd -reload 修改本机端口映射\n#1.修改本机 hosts 文件 增加：192.168.0.105 www.123.com 修改nginx配置文件\n访问测试 4.2 多端口反向代理 4.2.1 实现效果 访问 http://192.168.0.105:9001/edu/ 直接跳转到 127.0.0.1:8080 访问 http://192.168.0.105:9001/vod/ 直接跳转到 127.0.0.1:8081 4.2.2 安装两个 Tomcat 分别定义端口为 8001,8002 4.2.3 创建文件夹和测试页面 4.2.4 配置 nginx配置文件 4.2.5 开放端口号 firewall-cmd --add-port=8001/tcp --permanent firewall-cmd --add-port=8002/tcp --permanent firewall-cmd --add-port=9001/tcp --permanent firewall-cmd --reload 4.2.6 测试 1、访问：\n2、访问：http:// 192.168.0.105:9001/vod/a.html\n4.3 负载均衡 1、准备两台 tomcat 服务器，一台8001，一台8002\n2、 在两台 tomcat 里面 webapps 目录中，创建名称是 edu 文件夹，在 edu 文件夹中创建页面a.html，用于测试\n3、配置nginx配置文件\n# 在http模块中配置 upstream myserver{ server 192.168.0.105:8001 weight=1; server 192.168.0.105:8002 weight=2; } # 在server模块配置 listen 80; server_name 192.168.0.105; location / { proxy_pass http://myserver; root html; index index.html index.htm; } 4、nginx提供了几种分配方式(策略)\n1.轮询（默认） 每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器 down 掉，能自动剔除。 2.weight weight 代表权重，默认是1，权重越高被分配的客户端越多。 指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。例如： ```bash upstream server_pool{ server 192.168.5.21 weight=10; server 192.168.5.22 weight=10; } 3.ip_hash\n每个请求按访问 ip 的 hash 结果分配，这样每个访客固定一个后端服务器，可以解决session的问题。例如：\nupstream server_pool{ ip_hash server 192.168.5.21:80; server 192.168.5.22:80; } 4.fair(第三方，需要安装第三方模块) 按后端服务器的响应时间来分配请求，响应时间短的优先分配。\nupstream server_pool{ server 192.168.5.21:80; server 192.168.5.22:80; fair; } 5、测试\n五、动静分离 5.1 什么是动静分离 Nginx 动静分离简单来说就是把动态跟静态请求分开，不能理解成只是单纯的把动态页面和\n静态页面物理分离。\n5.2 在linux系统中准备静态资源，用于进行访问 5.3 nginx配置文件 5.4 测试 六、高可用 6.1 Keeplived+Nginx高可用集群（主从模式） 1、需要两台服务器 192.168.0.105 和 192.168.0.102\n2、在两台服务器上安装nginx和keeplived\n#1.安装keepalived yum install keepalived -y #2.keepalived.conf文件 安装之后，在etc里面生成目录 keepalived，有文件 keepalived.conf #3.修改配置文件\n105主服务器\n102副服务器\n#4. 启动keepalived\n#5.测试\n6.2 Keeplived+Nginx 高可用集群（双主模式） 修改配置\n2） 配置 LB-02 节点\n","permalink":"https://xyenvy.github.io/posts/nginx/","summary":"Nginx 简介 一、Nginx概述 1.1 概述 Nginx（“engine x”）是一个高性能的 HTTP /反向代理的服务器及电子邮件（IMAP/POP3)代理服务器。官方测试nginx能够支撑5万并发，并且cpu，内存等资源消耗却非常低，运行非常稳定。最重要的是开源，免费，可商用的。 Nginx还支持热部署","title":"Nginx"},{"content":"NFS服务 NFS工作原理 NFS：Network File System 网络文件系统，基于内核的文件系统。Sun 公司开发，通过使用 NFS，用户和程序可以像访问本地文件一样访问远端系统上的文件，基于RPC（Remote Procedure CallProtocol 远程过程调用）实现。 RPC采用C/S模式，客户机请求程序调用进程发送一个有进程参数的调用信息到服务进程，然后等待应答信息。在服务器端，进程保持睡眠状态直到调用信息到达为止。当一个调用信息到达，服务器获得进程参数，计算结果，发送答复信息，然后等待下一个调用信息，最后，客户端调用进程接收答复信息，获得进程结果，然后调用执行继续进行。\nNFS优势：节省本地存储空间，将常用的数据,如：/home目录，存放在NFS服务器上且可以通过网络访 问，本地终端将可减少自身存储空间的使用。\nNFS软件介绍 软件包：nfs-utils（包括服务器和客户端相关工具，CentOS8 最小化安装时默认没有安装），nfs-common(Ubuntu中包名)\n相关软件包：rpcbind（必须），tcp_wrappers\nKernel支持：nfs.ko\n端口：2049(nfsd), 其它端口由portmap(111)分配\nNFS服务主要进程：\nrpc.nfsd 最主要的NFS进程，管理客户端是否可登录 rpc.mountd 挂载和卸载NFS文件系统，包括权限管理 rpc.lockd 非必要，管理文件锁，避免同时写出错 rpc.statd 非必要，检查文件一致性，可修复文件 说明：CentOS 6 开始portmap进程由rpcbind代替 日志：/var/lib/nfs/ NFS配置文件\n/etc/exports /etc/exports.d/*.exports 常用选项\n默认选项：(ro,sync,root_squash,no_all_squash) ro,rw 只读和读写 async 异步，数据变化后不立即写磁盘，先写入到缓冲区中，过一段时间再写入磁盘，性能高,安全性低 sync（1.0.0后为默认）同步，数据在请求时立即写入共享存储磁盘,性能低,安全性高 root_squash （默认）远程root映射为nfsnobody,UID为65534，CentOS8 为nobody,CentOS 7以前的版本为nfsnobody no_root_squash 远程root映射成NFS服务器的root用户 all_squash 所有远程用户(包括root)都变成nfsnobody,CentOS8 为nobody no_all_squash （默认）保留共享文件的UID和GID anonuid和anongid 指明匿名用户映射为特定用户UID和组GID，而非nobody,可配合all_squash使 用 NFS工具 rpcinfo rpcinfo 工具可以查看RPC相关信息 查看注册在指定主机的RPC程序\nrpcinfo -p hostname 查看RPC注册程序\nrpcinfo -s hostname exportfs exportfs:可用于管理NFS导出的文件系统 常见选项\n-v #查看本机所有NFS共享 -r #重读配置文件，并共享目录 -a #输出本机所有共享 -au #停止本机所有共享 showmount 常见用法：\n#查看远程主机的NFS共享 showmount -e hostname mount.nfs 客户端NFS挂载 NFS相关的挂载选项：man 5 nfs\nfg #（默认）前台挂载 bg #后台挂载 hard #（默认）持续请求 soft #非持续请求 intr #和hard配合，请求可中断 rsize #和wsize 一次读和写数据最大字节数，rsize=32768 _netdev #无网络服务时不挂载NFS资源 vers #指定版本，客户端centos8默认4.2 ，centos7默认4.1 centos6默认4.0 提示：基于安全考虑，建议使用 nosuid,netdev,noexec 挂载选项\n实战案例 NFS服务器安装软件 yum install -y nfs-utils # 启动rpcbind systemctl start rpcbind # 启动nfs-server systemctl start nfs-server NFS服务器创建共享文件 # 共享根目录下的share目录 mkdir /share 添加uid和gid为300的用户nfs-upload [root@centos7-master ~]# groupadd -g 300 nfs-upload [root@centos7-master ~]# useradd -u 300 -g 300 nfs-upload [root@centos7-master ~]# #修改所属组权限 [root@centos7-master share]# chown -R 300:300 /share 修改NFS服务器配置文件 [root@centos7-master ~]# vim /etc/exports # 加入如下内容，*表示任何人，rw表示读写 /share/ 192.168.179.*(rw,anongid=300,anonuid=300) 重新加载配置 # 重新加载配置文件 [root@centos7-master ~]# exportfs -r [root@centos7-master ~]# exportfs -v /share 192.168.179.*(sync,wdelay,hide,no_subtree_check,anonuid=300,anongid=300,sec=sys,rw,secure,root_squash,no_all_squash) [root@centos7-master ~]# 客户端安装软件 yum install -y nfs-utils # 启动rpcbind systemctl start rpcbind # 启动nfs-server systemctl start nfs-server 添加用户和组 [root@centos7-slave /]# groupadd -g 300 nfs-upload [root@centos7-slave /]# useradd -u 300 -g 300 nfs-upload 在客户端挂载，挂载/nfsshare目录下 # 创建目录 mkdir /nfsshare # 查看服务器端可挂载点 [root@centos7-slave ~]# showmount -e 192.168.179.170 Export list for 192.168.179.170: /share * [root@centos7-slave nfsshare]# # 挂载方式1，关机重启会失效 [root@centos7-slave ~]# mount 192.168.179.170:/share/ /nfsshare # 方式二修改配置文件，关机重启不失效 [root@centos7-slave ~]# vim /etc/fstab # 加入如下内容 192.168.179.170:/share /nfsshare nfs defaults,_netdev 0 0 # 使配置文件生效 [root@centos7-slave nfsshare]# mount -a [root@centos7-slave nfsshare]# 测试 # 在客户端上查看/nfsshare的内容 [root@centos7-slave nfsshare]# ll total 8 -rw-r--r-- 1 nfs-upload nfs-upload 5 Dec 5 23:14 a.xtx drwxr-xr-x 2 nfs-upload nfs-upload 6 Dec 5 23:17 newfile -rw-r--r-- 1 nfs-upload nfs-upload 17 Dec 5 23:11 test.log [root@centos7-slave nfsshare]# # 在服务器端查看/share目录 [root@centos7-master share]# ll total 8 -rw-r--r-- 1 nfs-upload nfs-upload 5 Dec 5 23:14 a.xtx drwxr-xr-x 2 nfs-upload nfs-upload 6 Dec 5 23:17 newfile -rw-r--r-- 1 nfs-upload nfs-upload 17 Dec 5 23:11 test.log [root@centos7-master share]# 数据的实时同步 实时同步技术介绍 实现实时同步的方法\ninotify + rsync 方式实现数据同步 sersync ：前金山公司周洋（花椒直播）在 inotify 软件基础上进行开发的，功能更加强大 工作原理：\n要利用监控服务（inotify），监控同步数据服务器目录中信息的变化 发现目录中数据产生变化，就利用rsync服务推送到备份服务器上 inotify：\n异步的文件系统事件监控机制，利用事件驱动机制，而无须通过诸如cron等的轮询机制来获取事件，linux内核从2.6.13起支持 inotify，通过inotify可以监控文件系统中添加、删除，修改、移动等各种事件\n实现inotify软件：\ninotify-tools sersync lrsyncd inotify+rsync使用方式\ninotify 对同步数据目录信息的监控 rsync 完成对数据的同步 利用脚本进行结合 实现 inotify 内核是否支持inotify Linux支持inotify的内核最小版本为 2.6.13，参看man 7 inotify\ninotify 内核参数说明：\nmax_queued_events：inotify 事件队列最大长度，如值太小会出现 Event Queue Overflow 错 误，默认值：16384, 生产环境建议调大,比如:327679 max_user_instances：每个用户创建inotify实例最大值，默认值：128 max_user_watches：可以监视的文件的总数量（inotifywait 单进程），默认值：8192,建议调大 inotify-tools工具 inotify-tools参考文档：\nhttps://github.com/rvoicilas/inotify-tools/wiki 安装inotify-tools：基于epel源\nyum install epel-release yum -y install inotify-tools inotify-tools包主要工具：\ninotifywait： 在被监控的文件或目录上等待特定文件系统事件（open ，close，delete等）发生， 常用于实时同步的目录监控 inotifywatch：收集被监控的文件系统使用的统计数据，指文件系统事件发生的次数统计 inotifywait 命令 格式:\ninotifywait [ options ] file1 [ file2 ] [ file3 ] [ ... ] 常用选项\n-m, --monitor 始终保持事件监听 -d, --daemon 以守护进程方式执行，和-m相似，配合-o使用 -r, --recursive 递归监控目录数据信息变化 -q, --quiet 输出少量事件信息 --exclude \u0026lt;pattern\u0026gt; 指定排除文件或目录，使用扩展的正则表达式匹配的模式实现 --excludei \u0026lt;pattern\u0026gt; 和exclude相似，不区分大小写 -o, --outfile \u0026lt;file\u0026gt; 打印事件到文件中，相当于标准正确输出，注意：使用绝对路径 -s, --syslogOutput 发送错误到syslog相当于标准错误输出 --timefmt \u0026lt;fmt\u0026gt; 指定时间输出格式 --format \u0026lt;fmt\u0026gt; 指定的输出格式；即实际监控输出内容 -e inotifywait 的\u0026ndash;timefmt 时间格式 参考 man 3 strftime\n%Y #年份信息，包含世纪信息 %y #年份信息，不包括世纪信息 %m #显示月份，范围 01-12 %d #每月的第几天，范围是 01-31 %H #小时信息，使用 24小时制，范围 00-23 %M #分钟，范围 00-59 %S #秒，范例 0-60 范例：\n--timefmt \u0026#34;%Y-%m-%d %H:%M:%S\u0026#34; inotifywait 的 \u0026ndash;format 格式定义\n%T #输出时间格式中定义的时间格式信息，通过 --timefmt option 语法格式指定时间信息 %w #事件出现时，监控文件或目录的名称信息，相当于dirname %f #事件出现时，将显示监控目录下触发事件的文件或目录信息，否则为空，相当于basename %e #显示发生的事件信息，不同的事件默认用逗号分隔 %Xe #显示发生的事件信息，不同的事件指定用X进行分隔 范例\n--format \u0026#34;%T %w%f event: %;e\u0026#34; --format \u0026#39;%T %w %f\u0026#39; inotifywait -e 选项指定的事件类型\ncreate #文件或目录创建 delete #文件或目录被删除 modify #文件或目录内容被写入 attrib #文件或目录属性改变 close_write #文件或目录关闭，在写入模式打开之后关闭的 close_nowrite #文件或目录关闭，在只读模式打开之后关闭的 close #文件或目录关闭，不管读或是写模式 open #文件或目录被打开 lsdir #浏览目录内容 moved_to #文件或目录被移动到监控的目录中 moved_from #文件或目录从监控的目录中被移动 move #文件或目录不管移动到或是移出监控目录都触发事件 access #文件或目录内容被读取 delete_self #文件或目录被删除，目录本身被删除 unmount #取消挂载 范例\n-e create,delete,moved_to,close_write,attrib 范例：使用inotifywait\n# 监控一次事件 [root@centos7 /]# inotifywait /data/www/ Setting up watches. Watches established. /data/www/ CREATE,ISDIR html [root@centos7 /]# # 持续前台监控 [root@centos7 /]# inotifywait -mrq /data/www --exclude=\u0026#34;.*\\.swx|\\.swp\u0026#34; /data/www/ OPEN,ISDIR /data/www/ CLOSE_NOWRITE,CLOSE,ISDIR /data/www/ CREATE mysql.log /data/www/ OPEN mysql.log /data/www/ ATTRIB mysql.log /data/www/ CLOSE_WRITE,CLOSE mysql.log /data/www/ OPEN,ISDIR /data/www/ CLOSE_NOWRITE,CLOSE,ISDIR /data/www/ MODIFY mysql.log /data/www/ OPEN mysql.log /data/www/ MODIFY mysql.log /data/www/ CLOSE_WRITE,CLOSE mysql.log /data/www/ OPEN,ISDIR /data/www/ CLOSE_NOWRITE,CLOSE,ISDIR /data/www/ OPEN mysql.log /data/www/ ACCESS mysql.log /data/www/ CLOSE_NOWRITE,CLOSE mysql.log #持续后台监控，并记录日志 inotifywait -o /root/inotify.log -drq /data/www --timefmt \u0026#34;%Y-%m-%d %H:%M:%S\u0026#34; -- format \u0026#34;%T %w%f event: %e\u0026#34; #持续前台监控特定事件 inotifywait -mrq /data/www --timefmt \u0026#34;%F %H:%M:%S\u0026#34; --format \u0026#34;%T %w%f event: %;e\u0026#34; -e create,delete,moved_to,close_write,attrib rsync 服务 rsync 常用于做为 linux系统下的数据镜像备份工具，实现远程同步，支持本地复制，或者与其他SSH、 rsync主机同步数据，支持增量备份，配合任务计划，rsync能实现定时或间隔同步，配合inotify或 sersync，可以实现触发式的实时数据同步 官方网站:\nhttp://rsync.samba.org/ 软件包：rsync，rsync-daemon（CentOS 8） 服务文件：/usr/lib/systemd/system/rsyncd.service 配置文件：/etc/rsyncd.conf 端口：873/tcp\nrsync命令 rsync 格式\n#Local: rsync [OPTION...] SRC... [DEST] #Access via remote shell: Pull: rsync [OPTION...] [USER@]HOST:SRC... [DEST] Push: rsync [OPTION...] SRC... [USER@]HOST:DEST #Access via rsync daemon: Pull: rsync [OPTION...] [USER@]HOST::SRC... [DEST] rsync [OPTION...] rsync://[USER@]HOST[:PORT]/SRC... [DEST] Push: rsync [OPTION...] SRC... [USER@]HOST::DEST rsync [OPTION...] SRC... rsync://[USER@]HOST[:PORT]/DEST The \u0026#39;:\u0026#39; usages connect via remote shell, while \u0026#39;::\u0026#39; \u0026amp; \u0026#39;rsync://\u0026#39; usages connect to an rsync daemon, and require SRC or DEST to start with a module name. rsync有三种工作方式：\n本地文件系统上实现同步。命令行语法格式为上述\u0026quot;Local\u0026quot;段的格式。 本地主机使用远程shell和远程主机通信。命令行语法格式为上述\u0026quot;Access via remote shell\u0026quot;段的格 式。 本地主机通过网络套接字连接远程主机上的rsync daemon。命令行语法格式为上述\u0026quot;Access via rsync daemon\u0026quot;段的格式。 前两者的本质是通过本地或远程shell，而第3种方式则是让远程主机上运行rsyncd服务，使其监听在一 个端口上，等待客户端的连接。 常见选项： -v：显示rsync过程中详细信息。可以使用\u0026#34;-vvvv\u0026#34;获取更详细信息。 -P：显示文件传输的进度信息。(实际上\u0026#34;-P\u0026#34;=\u0026#34;--partial --progress\u0026#34;，其中的\u0026#34;--progress\u0026#34;才是显 示进度信息的)。 -n --dry-run ：仅测试传输，而不实际传输。常和\u0026#34;-vvvv\u0026#34;配合使用来查看rsync是如何工作的。 -a --archive ：归档模式，表示递归传输并保持文件属性。等同于\u0026#34;-rtopgDl\u0026#34;。 -r --recursive：递归到目录中去。 -t --times：保持mtime属性。强烈建议任何时候都加上\u0026#34;-t\u0026#34;，否则目标文件mtime会设置为系统时间，导 致下次更新 ：检查出mtime不同从而导致增量传输无效。 -o --owner：保持owner属性(属主)。 -g --group：保持group属性(属组)。 -p --perms：保持perms属性(权限，不包括特殊权限) -D ：是\u0026#34;--device --specials\u0026#34;选项的组合，即也拷贝设备文件和特殊文件。 -l --links：如果文件是软链接文件，则拷贝软链接本身而非软链接所指向的对象 -z ：传输时进行压缩提高效率 -R --relative：使用相对路径。意味着将命令行中指定的全路径而非路径最尾部的文件名发送给服务端， 包括它们的属性。用法见下文示例。 --size-only ：默认算法是检查文件大小和mtime不同的文件，使用此选项将只检查文件大小。 -u --update ：仅在源mtime比目标已存在文件的mtime新时才拷贝。注意，该选项是接收端判断的，不会 影响删除行为。 -d --dirs ：以不递归的方式拷贝目录本身。默认递归时，如果源为\u0026#34;dir1/file1\u0026#34;，则不会拷贝dir1 目录，使用该选项将拷贝dir1但不拷贝file1。 --max-size ：限制rsync传输的最大文件大小。可以使用单位后缀，还可以是一个小数值(例如：\u0026#34;-- max-size=1.5m\u0026#34;) --min-size ：限制rsync传输的最小文件大小。这可以用于禁止传输小文件或那些垃圾文件。 --exclude ：指定排除规则来排除不需要传输的文件。 --delete ：以SRC为主，对DEST进行同步。多则删之，少则补之。注意\u0026#34;--delete\u0026#34;是在接收端执行 的，所以它是在 ：exclude/include规则生效之后才执行的。 -b --backup ：对目标上已存在的文件做一个备份，备份的文件名后默认使用\u0026#34;~\u0026#34;做后缀。 --backup-dir：指定备份文件的保存路径。不指定时默认和待备份文件保存在同一目录下。 -e ：指定所要使用的远程shell程序，默认为ssh。 --port ：连接daemon时使用的端口号，默认为873端口。 --password-file：daemon模式时的密码文件，可以从中读取密码实现非交互式。注意，这不是远程shell 认证的密码，而是rsync模块认证的密码。 -W --whole-file：rsync将不再使用增量传输，而是全量传输。在网络带宽高于磁盘带宽时，该选项比增 量传输更高效。 --existing ：要求只更新目标端已存在的文件，目标端还不存在的文件不传输。注意，使用相对路径时如 果上层目录不存在也不会传输。 --ignore-existing：要求只更新目标端不存在的文件。和\u0026#34;--existing\u0026#34;结合使用有特殊功能，见下文示 例。 --remove-source-files：要求删除源端已经成功传输的文件 范例：两种格式访问 rsync daemon 服务\n环境 data-server:192.168.179.171(数据服务器) backup-server:192.168.179.165(备份服务器) #在备份服务器启动 rsync 进程 [root@centos8-backup ~]#rsync --daemon Failed to parse config file: /etc/rsyncd.conf [root@centos8-backup ~]#touch /etc/rsyncd.conf [root@centos8-backup ~]#rsync --daemon [root@centos8-backup /]# cat /etc/rsyncd.conf [backup] path = /web/www/ read only = no [root@centos8-backup /]# #指定目录给nobody权限，默认用户以nobody访问此目录 [root@centos8-backup ~]#setfacl -m u:nobody:rwx /data/backup/ #查看rsync服务器的模块名称 [root@centos7-slave /]# rsync rsync://192.168.179.165 backup [root@centos7-slave /]# [root@centos7-slave /]# rsync 192.168.179.165:: backup #访问rsync服务器的共享目录 #推 [root@centos7-slave /]# rsync /xy.log 192.168.179.165::backup [root@centos7-slave /]# rsync /etc/shells rsync://root@192.168.179.165/backup [root@centos7-slave /]#rsync 192.168.179.165::backup/* /opt [root@centos7-slave /]#rsync rsync://192.168.179.165/backup/* /mnt 范例：以独立服务方式运行 rsync\n# 修改配置文件 [root@centos8-backup etc]# cat rsyncd.conf #uid = root #提定以哪个用户来访问共享目录，将之指定为生成的文件所有者，默认为nobody #gid = root #默认为nobody,Ubuntu中为nogroup #port = 874 可指定非标准端口,默认873/tcp #use chroot = no #max connections = 0 #ignore errors #exclude = lost+found/ #log file = /var/log/rsyncd.log #pid file = /var/run/rsyncd.pid #lock file = /var/run/rsyncd.lock #reverse lookup = no #hosts allow = 10.0.0.0/24 #[backup] #每个模块名对应一个不同的path目录，如果同名后面模块生效 #path = /data/backup/ #comment = backup dir #read only = no #默认是yes,即只读 #auth users = rsyncuser #默认anonymous可以访问rsync服务器 #secrets file = /etc/rsync.pas # /etc/rsyncd: configuration file for rsync daemon mode # See rsyncd.conf man page for more options. # configuration example: # uid = nobody # gid = nobody # use chroot = yes # max connections = 4 # pid file = /var/run/rsyncd.pid # exclude = lost+found/ # transfer logging = yes # timeout = 900 # ignore nonreadable = yes # dont compress = *.gz *.tgz *.zip *.z *.Z *.rpm *.deb *.bz2 # [ftp] # path = /home/ftp # comment = ftp export area uid = root gid = root max connections = 0 ignore errors exclude = lost+found/ log file = /var/log/rsyncd.log pid file = /var/run/rsyncd.pid lock file = /var/run/rsyncd.lock reverse lookup = no [backup] path = /web/backup/ comment = backup dir read only = no auth users = rsyncuser secrets file = /etc/rsync.pas [root@centos8-backup etc]# #服务器端生成验证文件 [root@centos8-backup ~]#echo \u0026#34;rsyncuser:123456\u0026#34; \u0026gt; /etc/rsync.pas [root@centos8-backup ~]#chmod 600 /etc/rsync.pas #服务器端启动rsync服务 [root@centos8-backup ~]#rsync --daemon #可加入/etc/rc.d/rc.local实现开 机启动 #客户端配置密码文件 #也可将密码赋值给环境变量RSYNC_PASSWORD变量,但不安全 #export RSYNC_PASSWORD=123456 [root@centos7-slave ~]#echo \u0026#34;123456\u0026#34; \u0026gt; /etc/rsync.pas [root@centos7-slave ~]#chmod 600 /etc/rsync.pas #此为必要项,权限必须修改 #查看远程rsync服务器的模块信息 [root@centos7-slave etc]# rsync rsync://192.168.179.165 backup backup dir [root@centos7-slave etc]# #交互式验证查看具体模块内的文件 [root@centos7-slave etc]# rsync rsync://rsyncuser@192.168.179.165/backup Password: #非交互式查看共享目录 [root@centos7-slave etc]# rsync --password-file=/etc/rsync.pas rsync://rsyncuser@192.168.179.165/backup drwxrwxrwx 34 2022/12/07 16:20:07 . -rw-r--r-- 0 2022/12/07 16:20:07 xy.log -rw-r--r-- 0 2022/12/07 16:09:50 zz.log [root@centos7-slave etc]# #客户端测试同步数据 [root@data-centos8 ~]#rsync -avz --delete --password-file=/etc/rsync.pas /data/www/ rsyncuser@rsync服务器IP::backup [root@data-centos8 ~]#rsync -avz --delete --password-file=/etc/rsync.pas rsyncuser@rsync服务器IP::backup /data/www/ inotify+rsync+shell 脚本实现实时数据同步 按 5.3 搭建好 rsyncd的备份服务器，在数据服务器上创建inotify_rsync.sh脚本 注意: 此脚本执行前先确保两主机初始数据处于同步状态,此脚本实现后续的数据同步\n[root@centos7-slave ~]# vim inotify_rsync.sh #!/bin/bash SRC=\u0026#39;/data/www/\u0026#39; #注意最后的/ DEST=\u0026#39;rsyncuser@rsync服务器IP::backup\u0026#39; rpm -q inotify-tools \u0026amp;\u0026gt; /dev/null ||yum -y install inotify-tools rpm -q rsync \u0026amp;\u0026gt; /dev/null || yum -y install rsync inotifywait -mrq --exclude=\u0026#34;.*\\.swp\u0026#34; --timefmt \u0026#39;%Y-%m-%d %H:%M:%S\u0026#39; --format \u0026#39;%T %w %f\u0026#39; -e create,delete,moved_to,close_write,attrib ${SRC} |while read DATE TIME DIR FILE;do FILEPATH=${DIR}${FILE} rsync -az --delete --password-file=/etc/rsync.pas $SRC $DEST \u0026amp;\u0026amp; echo \u0026#34;At ${TIME} on ${DATE}, file $FILEPATH was backuped up via rsync\u0026#34; \u0026gt;\u0026gt; /var/log/changelist.log done #查看文件传输日志 [root@centos7-slave www]# tail -f /var/log/changelist.log sersync 实现实时数据同步 sersync介绍 sersync类似于inotify，同样用于监控，但它克服了inotify的缺点. inotify最大的不足是会产生重复事件，或者同一个目录下多个文件的操作会产生多个事件，例如，当监 控目录中有5个文件时，删除目录时会产生6个监控事件，从而导致重复调用rsync命令。另外比如：vim 文件时，inotify会监控到临时文件的事件，但这些事件相对于rsync来说是不应该被监控的\nsersync 优点：\nsersync是使用c++编写，而且对linux系统文件系统产生的临时文件和重复的文件操作进行过滤， 所以在结合rsync同步的时候，节省了运行时耗和网络资源。因此更快。 sersync配置很简单，其中提供了静态编译好的二进制文件和xml配置文件，直接使用即可 sersync使用多线程进行同步，尤其在同步较大文件时，能够保证多个服务器实时保持同步状态 sersync有出错处理机制，通过失败队列对出错的文件重新同步，如果仍旧失败，则按设定时长对 同步失败的文件重新同步 sersync不仅可以实现实时同步，另外还自带crontab功能，只需在xml配置文件中开启，即也可以 按要求隔一段时间整体同步一次，而无需再额外配置crontab功能 sersync 可以二次开发 sersync项目地址：\nhttps://code.google.com/archive/p/sersync/ sersync下载地址：\nhttps://code.google.com/archive/p/sersync/downloads 基于rsync daemon 实现 sersync # #在数据服务器上下载sersync，并拷贝至相应的目录，设置PATH变量 wget https://storage.googleapis.com/google-code-archive-downloads/v2/code.google.com/sersync/sersync2.5.4_64bit_binary_stable_final.tar.gz [root@centos7-slave ~]# tar -vxf sersync2.5.4_64bit_binary_stable_final.tar.gz [root@centos7-slave ~]# cp -r GNU-Linux-x86/ /usr/local/sersync [root@centos7-slave sersync]# echo \u0026#39;PATH=/usr/local/sersync:$PATH\u0026#39; \u0026gt; /etc/profile.d/sersync.sh [root@centos7-slave sersync]# source /etc/profile.d/sersync.sh [root@centos7-slave sersync]# #确认安装rsync客户端工具 rpm -q rsync \u0026amp;\u0026gt; /dev/null || dnf -y install rsync #备份sersync配置文件 cp /usr/local/sersync/confxml.xml{,.bak} # 修改配置文件 vim /usr/local/sersync/confxml.xml \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;ISO-8859-1\u0026#34;?\u0026gt; \u0026lt;head version=\u0026#34;2.5\u0026#34;\u0026gt; \u0026lt;host hostip=\u0026#34;localhost\u0026#34; port=\u0026#34;8008\u0026#34;\u0026gt;\u0026lt;/host\u0026gt; \u0026lt;debug start=\u0026#34;false\u0026#34;/\u0026gt; # 是否开启调试模式 \u0026lt;fileSystem xfs=\u0026#34;false\u0026#34;/\u0026gt; \u0026lt;filter start=\u0026#34;false\u0026#34;\u0026gt; #不开启文件过滤功能，当为true时,以下类型的文件将不同 步 \u0026lt;exclude expression=\u0026#34;(.*)\\.svn\u0026#34;\u0026gt;\u0026lt;/exclude\u0026gt; \u0026lt;exclude expression=\u0026#34;(.*)\\.gz\u0026#34;\u0026gt;\u0026lt;/exclude\u0026gt; \u0026lt;exclude expression=\u0026#34;^info/*\u0026#34;\u0026gt;\u0026lt;/exclude\u0026gt; \u0026lt;exclude expression=\u0026#34;^static/*\u0026#34;\u0026gt;\u0026lt;/exclude\u0026gt; \u0026lt;/filter\u0026gt; \u0026lt;inotify\u0026gt; # 监控事件，默认监控 delete/close_write/moved_from/moved_to/create folder \u0026lt;delete start=\u0026#34;true\u0026#34;/\u0026gt; \u0026lt;createFolder start=\u0026#34;true\u0026#34;/\u0026gt; \u0026lt;createFile start=\u0026#34;false\u0026#34;/\u0026gt; \u0026lt;closeWrite start=\u0026#34;true\u0026#34;/\u0026gt; \u0026lt;moveFrom start=\u0026#34;true\u0026#34;/\u0026gt; \u0026lt;moveTo start=\u0026#34;true\u0026#34;/\u0026gt; \u0026lt;attrib start=\u0026#34;true\u0026#34;/\u0026gt; #修改此行为true，文件属性变化后也会同步 \u0026lt;modify start=\u0026#34;false\u0026#34;/\u0026gt; \u0026lt;/inotify\u0026gt; \u0026lt;sersync\u0026gt; # rsync命令的配置段 \u0026lt;localpath watch=\u0026#34;/data/www\u0026#34;\u0026gt; #修改此行,需要同步的源目录或文件，建议同步目 录 \u0026lt;remote ip=\u0026#34;备份服务器IP\u0026#34; name=\u0026#34;backup\u0026#34;/\u0026gt; #修改此行,指定备份服务器地址和rsync daemon的模块名，如果下面开启了ssh start，此时name为远程shell方式运行时的目标目录 \u0026lt;!--\u0026lt;remote ip=\u0026#34;192.168.8.39\u0026#34; name=\u0026#34;tongbu\u0026#34;/\u0026gt;--\u0026gt; \u0026lt;!--\u0026lt;remote ip=\u0026#34;192.168.8.40\u0026#34; name=\u0026#34;tongbu\u0026#34;/\u0026gt;--\u0026gt; \u0026lt;/localpath\u0026gt; \u0026lt;rsync\u0026gt; \u0026lt;commonParams params=\u0026#34;-artuz\u0026#34;/\u0026gt; # 指定rsync选项 \u0026lt;auth start=\u0026#34;true\u0026#34; users=\u0026#34;rsyncuser\u0026#34; passwordfile=\u0026#34;/etc/rsync.pas\u0026#34;/\u0026gt; #修 改此行为true,指定备份服务器的rsync配置的用户和密码文件 \u0026lt;userDefinedPort start=\u0026#34;false\u0026#34; port=\u0026#34;874\u0026#34;/\u0026gt;\u0026lt;!-- port=874 --\u0026gt;#指定rsync的非 标准端口号 \u0026lt;timeout start=\u0026#34;false\u0026#34; time=\u0026#34;100\u0026#34;/\u0026gt;\u0026lt;!-- timeout=100 --\u0026gt; \u0026lt;ssh start=\u0026#34;false\u0026#34;/\u0026gt; #默认使用rsync daemon运行rsync命令,true为使用远程shell模 式 \u0026lt;/rsync\u0026gt; \u0026lt;failLog path=\u0026#34;/tmp/rsync_fail_log.sh\u0026#34; timeToExecute=\u0026#34;60\u0026#34;/\u0026gt;\u0026lt;!--default every 60mins execute once--\u0026gt; #错误重传及日志文件路径 \u0026lt;crontab start=\u0026#34;false\u0026#34; schedule=\u0026#34;600\u0026#34;\u0026gt;\u0026lt;!--600mins--\u0026gt; #不开启crontab功能 \u0026lt;crontabfilter start=\u0026#34;false\u0026#34;\u0026gt; #不开启crontab定时传输的筛选功能 \u0026lt;exclude expression=\u0026#34;*.php\u0026#34;\u0026gt;\u0026lt;/exclude\u0026gt; \u0026lt;exclude expression=\u0026#34;info/*\u0026#34;\u0026gt;\u0026lt;/exclude\u0026gt; \u0026lt;/crontabfilter\u0026gt; \u0026lt;/crontab\u0026gt; \u0026lt;plugin start=\u0026#34;false\u0026#34; name=\u0026#34;command\u0026#34;/\u0026gt; \u0026lt;/sersync\u0026gt; #####################################以下行不需要修改 #################################### \u0026lt;plugin name=\u0026#34;command\u0026#34;\u0026gt; \u0026lt;param prefix=\u0026#34;/bin/sh\u0026#34; suffix=\u0026#34;\u0026#34; ignoreError=\u0026#34;true\u0026#34;/\u0026gt; \u0026lt;!--prefix /opt/tongbu/mmm.sh suffix--\u0026gt; \u0026lt;filter start=\u0026#34;false\u0026#34;\u0026gt; \u0026lt;include expression=\u0026#34;(.*)\\.php\u0026#34;/\u0026gt; \u0026lt;include expression=\u0026#34;(.*)\\.sh\u0026#34;/\u0026gt; \u0026lt;/filter\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;plugin name=\u0026#34;socket\u0026#34;\u0026gt; \u0026lt;localpath watch=\u0026#34;/opt/tongbu\u0026#34;\u0026gt; \u0026lt;deshost ip=\u0026#34;192.168.138.20\u0026#34; port=\u0026#34;8009\u0026#34;/\u0026gt; \u0026lt;/localpath\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;plugin name=\u0026#34;refreshCDN\u0026#34;\u0026gt; \u0026lt;localpath watch=\u0026#34;/data0/htdocs/cms.xoyo.com/site/\u0026#34;\u0026gt; \u0026lt;cdninfo domainname=\u0026#34;ccms.chinacache.com\u0026#34; port=\u0026#34;80\u0026#34; username=\u0026#34;xxxx\u0026#34; passwd=\u0026#34;xxxx\u0026#34;/\u0026gt; \u0026lt;sendurl base=\u0026#34;http://pic.xoyo.com/cms\u0026#34;/\u0026gt; \u0026lt;regexurl regex=\u0026#34;false\u0026#34; match=\u0026#34;cms.xoyo.com/site([/a-zA-Z0- 9]*).xoyo.com/images\u0026#34;/\u0026gt; \u0026lt;/localpath\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/head\u0026gt; #创建连接rsynd服务器的用户密码文件,并必须修改权限 echo 123456 \u0026gt; /etc/rsync.pas chmod 600 /etc/rsync.pas #查看帮助 sersync2 -h set the system param execute：echo 50000000 \u0026gt; /proc/sys/fs/inotify/max_user_watches execute：echo 327679 \u0026gt; /proc/sys/fs/inotify/max_queued_events parse the command param _______________________________________________________ 参数-d:启用守护进程模式 参数-r:在监控前，将监控目录与远程主机用rsync命令推送一遍 c参数-n: 指定开启守护线程的数量，默认为10个 参数-o:指定配置文件，默认使用当前工作目录下的confxml.xml文件 参数-m:单独启用其他模块，使用 -m refreshCDN 开启刷新CDN模块 参数-m:单独启用其他模块，使用 -m socket 开启socket模块 参数-m:单独启用其他模块，使用 -m http 开启http模块 不加-m参数，则默认执行同步程序 #以后台方式执行同步 sersync2 -dro /usr/local/sersync/confxml.xml #如果同步失败,可以手动执行下面命令,观察过程 cd /data/www \u0026amp;\u0026amp; rsync -artuz -R --delete ./ rsyncuser@backup-server::backup --password-file=/etc/rsync.pas \u0026gt;/dev/null 2\u0026gt;\u0026amp;1 #sersync支持多实例，也即监控多个目录时，只需分别配置不同配置文件，然后使用sersync2指定对应配置文件运行 sersync2 -rd -o /etc/sersync.d/nginx.xml ","permalink":"https://xyenvy.github.io/posts/%E7%BD%91%E7%BB%9C%E6%96%87%E4%BB%B6%E5%85%B1%E4%BA%AB%E6%9C%8D%E5%8A%A1/","summary":"NFS服务 NFS工作原理 NFS：Network File System 网络文件系统，基于内核的文件系统。Sun 公司开发，通过使用 NFS，用户和程序可以像访问本地文件一样访问远端系统上的文件，基于RPC（Remote Procedure CallProtocol 远程过程调用）实现。 RPC采用C/S模式，客户机请求程序调用进程发送一个有进程参数","title":"网络文件共享服务"},{"content":"系统日志管理 系统日志介绍 在现实生活中，记录日志非常重要﹐比如:银行转账时会有转账记录﹔飞机飞行过程中的黑盒子（飞行数据记录器）记录着飞机的飞行过程. 那么将系统和应用发生的事件记录至日志中，也很意义,常可以助于排错和分析使用\n日志记录的内容包括：\n历史事件：时间，地点，人物，事件 日志级别：事件的关键性程度，Loglevel sysklogd 系统日志服务 CentOS 5 之前版本采用的日志管理系统服务 klogd: linux kernel 记录内核日志 syslogd: system application 记录应用日志 事件记录格式： 日期时间 主机 进程[pid]: 事件内容 C/S架构：通过TCP或UDP协议的服务完成日志记录传送，将分布在不同主机的日志实现集中管理\nrsyslog 系统日志服务 rsyslog是CentOS 6 以后版本的系统管理服务.它提供了高性能，出色的安全性和模块化设计。 尽管rsyslog最初是常规的syslogd，但已发展成为一种瑞士军刀式的记录工具，能够接受来自各种来源的输入，并将其转换，然后输出到不同的目的地。当应用有限的处理时，RSYSLOG每秒可以将超过一百万的消息传递到本地目的地。 即使在远程的目的地和更精细的处理中，性能通常也被认为是“惊人的”。\n官网网站\nhttps://www.rsyslog.com/ rsyslog 特性\n多线程 UDP, TCP, SSL, TLS, RELP MySQL, PGSQL, Oracle实现日志存储 强大的过滤器，可实现过滤记录日志信息中任意部分 自定义输出格式 适用于企业级中继链 rsyslog 管理 系统日志术语 facility：设施，从功能或程序上对日志进行归类\n#内置分类 auth, authpriv, cron, daemon,ftp,kern, lpr, mail, news, security(auth), user, uucp, syslog #自定义的分类 local0-local7 Priority 优先级别，从低到高排序\ndebug,info, notice, warn(warning), err(error), crit(critical), alert, emerg(panic) 参看帮助： man 3 syslog，man logger\n[root@centos8 ~]#yum -y install man-pages [root@centos8 ~]#man 3 syslog rsyslog 相关文件 程序包：rsyslog 主程序：/usr/sbin/rsyslogd CentOS 6：/etc/rc.d/init.d/rsyslog {start|stop|restart|status} CentOS 7,8：/usr/lib/systemd/system/rsyslog.service 配置文件：/etc/rsyslog.conf，/etc/rsyslog.d/.conf 库文件： /lib64/rsyslog/.so rsyslog配置文件 /etc/rsyslog.conf 配置文件格式：由三部分组成\nMODULES：相关模块配置 GLOBAL DIRECTIVES：全局配置 RULES：日志记录相关的规则配置 RULES配置格式：\nfacility.priority; facility.priority… target facility格式：\n* #所有的facility facility1,facility2,facility3,... #指定的facility列表 priority格式：\n*: 所有级别 none：没有级别，即不记录 PRIORITY：指定级别（含）以上的所有级别 =PRIORITY：仅记录指定级别的日志信息 target格式：\n文件路径：通常在/var/log/，文件路径前的-表示异步写入 用户：将日志事件通知给指定的用户，* 表示登录的所有用户 日志服务器：@host，把日志送往至指定的远程UDP日志服务器 @@host 将日志发送到远程TCP日志服务器 管道： | COMMAND，转发给其它命令处理 通常的日志文件的格式：\n日志文件有很多，如： /var/log/messages,cron,secure等，基本格式都是类似的。格式如下\n事件产生的日期时间 主机 进程(pid)：事件内容 范例：日志文件格式\n[root@centos7 ~]# tail -f /var/log/messages Dec 3 16:58:40 centos7 dbus[653]: [system] Activating via systemd: service name=\u0026#39;org.freedesktop.nm_dispatcher\u0026#39; unit=\u0026#39;dbus-org.freedesktop.nm-dispatcher.service\u0026#39; Dec 3 16:58:40 centos7 systemd: Starting Network Manager Script Dispatcher Service... Dec 3 16:58:40 centos7 dhclient[51210]: bound to 192.168.179.170 -- renewal in 745 seconds. Dec 3 16:58:40 centos7 dbus[653]: [system] Successfully activated service \u0026#39;org.freedesktop.nm_dispatcher\u0026#39; Dec 3 16:58:40 centos7 systemd: Started Network Manager Script Dispatcher Service. Dec 3 16:58:40 centos7 nm-dispatcher: req:1 \u0026#39;dhcp4-change\u0026#39; [ens33]: new request (2 scripts) Dec 3 16:58:40 centos7 nm-dispatcher: req:1 \u0026#39;dhcp4-change\u0026#39; [ens33]: start running ordered scripts... Dec 3 17:01:01 centos7 systemd: Started Session 95 of user root. Dec 3 17:11:05 centos7 dhclient[51210]: DHCPREQUEST on ens33 to 192.168.179.254 port 67 (xid=0x1f435c38) Dec 3 17:11:11 centos7 dhclient[51210]: DHCPREQUEST on ens33 to 192.168.179.254 port 67 (xid=0x1f435c38) Dec 3 17:11:26 centos7 dhclient[51210]: DHCPREQUEST on ens33 to 192.168.179.254 port 67 (xid=0x1f435c38) [root@centos7 ~]# tail -f /var/log/secure Nov 29 22:58:18 centos7 sshd[49904]: pam_unix(sshd:session): session closed for user root Nov 30 19:58:03 centos7 sshd[50030]: Accepted password for root from 192.168.179.1 port 51814 ssh2 Nov 30 19:58:03 centos7 sshd[50030]: pam_unix(sshd:session): session opened for user root by (uid=0) Nov 30 21:15:17 centos7 sshd[48764]: pam_unix(sshd:session): session closed for user root Dec 2 21:22:51 centos7 sshd[51123]: Accepted password for root from 192.168.179.1 port 53924 ssh2 Dec 2 21:22:51 centos7 sshd[51123]: pam_unix(sshd:session): session opened for user root by (uid=0) Dec 3 09:08:03 centos7 sshd[50030]: pam_unix(sshd:session): session closed for user root Dec 3 09:53:40 centos7 sshd[51295]: Accepted password for root from 192.168.179.1 port 56421 ssh2 Dec 3 09:53:40 centos7 sshd[51295]: pam_unix(sshd:session): session opened for user root by (uid=0) Dec 3 11:14:12 centos7 sshd[51123]: pam_unix(sshd:session): session closed for user root 范例：将ssh服务的日志记录至自定义的local的日志设备 修改sshd服务的配置 [root@centos7 ~]# vim /etc/ssh/sshd_config # 配置文件修改内容如下所示 SyslogFacility local2 # 重新加载sshd服务配置文件 [root@centos7 ~]# service sshd reload 修改rsyslog配置 [root@centos7 ~]# vim /etc/rsyslog.conf # 加入如下内容 local2.* /var/log/sshd.log # 重启服务 [root@centos7 ~]# systemctl restart rsyslog 测试验证 # ssh 登入该服务器 # 查看日志文件内容 tail -f /var/log/sshd.log [root@centos7 ~]# tail -f /var/log/sshd.log Dec 3 20:06:35 centos7 sshd[49356]: Server listening on 0.0.0.0 port 22. Dec 3 20:06:35 centos7 sshd[49356]: Server listening on :: port 22. Dec 3 20:07:06 centos7 sshd[52189]: Accepted publickey for root from 192.168.179.171 port 33434 ssh2: RSA SHA256:HohSbRRS/oP0nLbEZTqgSJ6WQ5Mjp3f9DxM+spRO+SI 日志中可以看到192.168.179.171的IP地址通过root用户ssh登入该设备\n启用网络日志服务 启用网络日志服务功能，可以将多个远程主机的日志，发送到集中的日志服务器，方便统一管理。\n范例：CentOS 7 和6 启用网络日志功能\n日志服务器：centos7.9，主机名称：centos7,ip:192.168.179.157 客户端1：centos7.9，主机名称：centos7-master,ip:192.168.179.170 客户端2：centos7.9，主机名称：centos7-slave,ip:192.168.179.171 修改日志服务器配置文件 # 192.168.179.157上操作 [root@centos7 ~]# vim /etc/rsyslog.conf 重启日志服务器rsyslog服务 [root@centos7 ~]# systemctl restart rsyslog 修改客户端配置文件 # 修改192.168.179.170配置文件 [root@centos7-master ~]# vim /etc/rsyslog.conf # 修改内容如下 *.info;mail.none;authpriv.none;cron.none /var/log/messages *.info;mail.none;authpriv.none;cron.none @@192.168.179.157:514 #TCP *.info;mail.none;authpriv.none;cron.none @192.168.179.157:514 #udp # 重启服务 systemctl restart rsyslog # 192.168.179.171客户端使用上面方法操作修改配置文件 测试验证 # 在日志服务器上查看日志 [root@centos7 ~]# tail -f /var/log/messages 可以看到主机名称centos7-master、centos7-slave上的日志说明实验成功\n范例：CentOS 8 启用网络日志功能\n## MODULES #### ...省略... # Provides UDP syslog reception # for parameters see http://www.rsyslog.com/doc/imudp.html module(load=\u0026#34;imudp\u0026#34;) # needs to be done just once input(type=\u0026#34;imudp\u0026#34; port=\u0026#34;514\u0026#34;) # Provides TCP syslog reception # for parameters see http://www.rsyslog.com/doc/imtcp.html module(load=\u0026#34;imtcp\u0026#34;) # needs to be done just once input(type=\u0026#34;imtcp\u0026#34; port=\u0026#34;514\u0026#34;) 常见日志文件 /var/log/secure：系统安全日志，文本格式，应周期性分析 /var/log/btmp：当前系统上，用户的失败尝试登录相关的日志信息，二进制格式，lastb命令进行查看 /var/log/wtmp：当前系统上，用户正常登录系统的相关日志信息，二进制格式，last命令可以查看 /var/log/lastlog:每一个用户最近一次的登录信息，二进制格式，lastlog命令可以查看 /var/log/dmesg：CentOS7 之前版本系统引导过程中的日志信息，文本格式，开机后的硬件变化 将不再记录，也可以通过专用命令dmesg查看，可持续记录硬件变化的情况 /var/log/boot.log 系统服务启动的相关信息，文本格式 /var/log/messages ：系统中大部分的信息 /var/log/anaconda : anaconda的日志 实战案例：利用 MySQL 存储日志信息 目标 利用rsyslog日志服务，将收集的日志记录于MySQL中\n环境准备 两台主机 一台：rsyslog日志服务器，IP：192.168.179.157 一台：mariadb数据库服务器，IP：192.168.179.178 实现步骤 # 在rsyslog服务器上安装连接mysql模块相关的程序包 [root@centos7 ~]# yum install rsyslog-mysql [root@centos7 ~]# rpm -ql rsyslog-mysql /usr/lib64/rsyslog/ommysql.so /usr/share/doc/rsyslog-8.24.0/mysql-createDB.sql [root@centos7 ~]# #将sql脚本复制到数据库服务器上 [root@centos7 ~]# scp /usr/share/doc/rsyslog-8.24.0/mysql-createDB.sql 192.168.179.148:/root/ # 在192.168.179.148上安装mysql yum install mysql-server -y # #在mysql数据库服务器上创建相关数据库和表，并授权rsyslog能连接至当前服务器 root@ubuntu1804:~# mysql mysql\u0026gt; source /root/mysql-createDB.sql; Query OK, 1 row affected (0.00 sec) mysql\u0026gt; create user \u0026#39;rsyslog\u0026#39;@\u0026#39;192.168.179.%\u0026#39; identified by \u0026#39;123456\u0026#39;; Query OK, 0 rows affected (0.04 sec) mysql\u0026gt; grant all on Syslog.* to \u0026#39;rsyslog\u0026#39;@\u0026#39;192.168.179.%\u0026#39;; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; flush privileges; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; # 配置日志服务器将日志发送至指定数据库 vim /etc/rsyslog.conf ####MODULES#### #在 MODULES 语言下面，如果是 CentOS 8 加下面行 module(load=\u0026#34;ommysql\u0026#34;) #在 MODULES 语言下面，如果是 CentOS 7，6 加下面行 $ModLoad ommysql #在RULES语句块加下面行的格式 #facility.priority :ommysql:DBHOST,DBNAME,DBUSER, PASSWORD *.info :ommysql:192.168.179.148,Syslog,rsyslog,123456 # 重启服务 测试 # 在日志服务器上生成日志 logger \u0026#39;this is test log\u0026#39; #在数据库上查询到上面的测试日志 mysql\u0026gt; select count(*) from SystemEvents; +----------+ | count(*) | +----------+ | 66 | +----------+ 1 row in set (0.00 sec) mysql\u0026gt; logrotate 日志转储 logrotate 介绍 logrotate 程序是一个日志文件管理工具。用来把旧的日志文件删除，并创建新的日志文件，称为日志转 储或滚动。可以根据日志文件的大小，也可以根据其天数来转储，这个过程一般通过 cron 程序来执行\nlogrotate 配置 软件包：logrotate 相关文件\n计划任务：/etc/cron.daily/logrotate\n程序文件：/usr/sbin/logrotate\n配置文件： /etc/logrotate.conf\n日志文件：/var/lib/logrotate/logrotate.status\n配置文件主要参数如下：\n范例：对指定日志手动执行日志转储\n# 生成测试日志 [root@centos7-master ~]# dd if=/dev/zero of=/var/log/test1.log bs=2M count=1 1+0 records in 1+0 records out 2097152 bytes (2.1 MB) copied, 0.0017554 s, 1.2 GB/s [root@centos7-master ~]# [root@centos7-master ~]# dd if=/dev/zero of=/var/log/test2.log bs=2M count=1 1+0 records in 1+0 records out 2097152 bytes (2.1 MB) copied, 0.00240458 s, 872 MB/s [root@centos7-master ~]# #针对不同的日志创建转储配置文件 [root@centos7-master ~]# vim /etc/logrotate.d/test1 /var/log/test1.log { daily rotate 5 compress delaycompress missingok size 1M notifempty create 640 bin nobody postrotate echo `date +%F_%T` \u0026gt;\u0026gt; /data/test1.log endscript } [root@centos7-master ~]# vim /etc/logrotate.d/test2 /var/log/test2.log { daily rotate 5 compress delaycompress missingok size 1M notifempty create 644 root root postrotate echo `date +%F_%T` \u0026gt;\u0026gt; /data/test2.log endscript } #针对一个测试日志，手动执行日志转储 [root@centos7-master ~]# logrotate /etc/logrotate.d/test1 [root@centos7-master ~]# ll /var/log/test* -rw-r----- 1 bin nobody 0 Dec 4 11:12 /var/log/test1.log -rw-r--r-- 1 root root 2097152 Dec 4 11:07 /var/log/test1.log.1 -rw-r--r-- 1 root root 2097152 Dec 4 11:07 /var/log/test2.log [root@centos7-master ~]# [root@centos7-master ~]# ll /data/ total 1800 -rw-r--r-- 1 root root 915255 Nov 27 17:22 1127.sql -rw-r--r-- 1 root root 914921 Nov 25 10:23 all.sql drwxr-xr-x 3 root root 18 Nov 29 22:45 mastermha drwxr-x--- 11 mysql mysql 4096 Dec 3 20:30 mysql -rw-r--r-- 1 root root 20 Dec 4 11:12 test1.log [root@centos7-master ~]# #对所有日志进行手动转储 [root@centos7-master ~]# logrotate /etc/logrotate.conf ","permalink":"https://xyenvy.github.io/posts/%E6%97%A5%E5%BF%97%E6%9C%8D%E5%8A%A1%E7%AE%A1%E7%90%86/","summary":"系统日志管理 系统日志介绍 在现实生活中，记录日志非常重要﹐比如:银行转账时会有转账记录﹔飞机飞行过程中的黑盒子（飞行数据记录器）记录着飞机的飞行过程. 那么将系统和应用发生的事件记录至日志中，也很意义,常可以助于排错和分析使用 日志记录的内容包括： 历史事件：时间，地点，人物，事件 日志级","title":"日志服务管理"},{"content":"MySQL集群 主从复制架构和原理 MySQL主从复制 读写分离 复制：每个节点都有相同的数据集，向外扩展，基于二进制日志的单向复制 复制的功用 负载均衡读操作 备份 高可用和故障切换 数据分布 MySQL升级 复制架构 一主一从复制架构\n一主多从复制架构\n主从复制原理 主从复制相关线程 主节点： dump Thread：为每个Slave的I/O Thread启动一个dump线程，用于向其发送binary log events 从节点： I/O Thread：向Master请求二进制日志事件，并保存于中继日志中 SQL Thread：从中继日志中读取日志事件，在本地完成重放 跟复制功能相关的文件 master.info：用于保存slave连接至master时的相关信息，例如账号、密码、服务器地址等 relay-log.info：保存在当前slave节点上已经复制的当前二进制日志和本地relay log日志的对应关 系 mysql-relay-bin.00000#: 中继日志,保存从主节点复制过来的二进制日志,本质就是二进制日志 说明:\n范例: 中继日志 MySQL8.0 取消 master.info 和 relay-log.info文件 实现主从复制配置 官网参考\nhttps://dev.mysql.com/doc/refman/8.0/en/replication-configuration.html https://dev.mysql.com/doc/refman/5.7/en/replication-configuration.html https://dev.mysql.com/doc/refman/5.5/en/replication-configuration.html https://mariadb.com/kb/en/library/setting-up-replication/ MySQL版本：5.7.38 centos7.9 主节点配置\n（1）启用二进制日志\nvim /etc/my.cnf [mysqld] log_bin (2)为当前节点设置一个全局唯一的ID号\n[mysqld] server-id=# log-basename=master #可选项，设置datadir中日志名称，确保不依赖主机名 说明\nserver-id的取值范围 1 to 4294967295 (\u0026gt;= MariaDB 10.2.2)，默认值为1，MySQL8.0默认值为1 0 to 4294967295 (\u0026lt;= MariaDB 10.2.1)，默认值为0，如果从节点为0，所有master都将拒绝此 slave的连接 注意：修改配置文件后重启mysql服务\n（3）创建有复制权限的用户账号\n#MySQL8.0 分成两步实现 # 创建用户 mysql\u0026gt; create user test@\u0026#39;192.168.179.165\u0026#39; identified by\u0026#39;123456\u0026#39;; Query OK, 0 rows affected (0.02 sec) mysql\u0026gt; # 赋予权限 mysql\u0026gt; grant replication slave on *.* to test@\u0026#39;192.168.179.165\u0026#39;; Query OK, 0 rows affected (0.01 sec) mysql\u0026gt; #其他 mysql\u0026gt; GRANT REPLICATION SLAVE ON *.* TO \u0026#39;test\u0026#39;@\u0026#39;HOST\u0026#39; IDENTIFIED BY \u0026#39;123456\u0026#39;; (4)完全备份数据库\n[root@centos7 ~]# mysqldum -A -F --master-data=1 --single-transaction \u0026gt; /backup/all_`date +%F`.sql [root@centos7 backup]# ll /backup/ total 1216 -rw-r--r-- 1 root root 1244691 Nov 23 23:07 all_2022-11-23.sql [root@centos7 backup]# 从节点配置\n(1)修改从节点server-id,不能和主节点server-id一致\n[mysqld] server-id=2 #或者使用如下配置 [mysqld] server_id=# #为当前节点设置一个全局惟的ID号 log-bin read_only=ON #设置数据库只读，针对supper user无效 relay_log=relay-log #relay log的文件路径，默认值hostname-relay-bin relay_log_index=relay-log.index #默认值hostname-relay-bin.index （2）使用有复制权限的用户账号连接至主服务器，并启动复制线程\n从节点导入主节点完全备份的数据\n# 关闭二进制日志 mysql\u0026gt; set sql_log_bin=0; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; # 还原备份 mysql\u0026gt; source all_2022-11-23.sql; # 开启二进制日志 mysql\u0026gt; set sql_log_bin=1; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; # 开启线程 mysql\u0026gt; start slave; Query OK, 0 rows affected, 1 warning (0.03 sec) mysql\u0026gt; mysql客户端命令行执行如下内容\nCHANGE MASTER TO MASTER_HOST=\u0026#39;192.168.179.170\u0026#39;, MASTER_USER=\u0026#39;test\u0026#39;,MASTER_PASSWORD=\u0026#39;123456\u0026#39;,MASTER_LOG_FILE=\u0026#39;mysql-bin.000007\u0026#39;, MASTER_LOG_POS=154; MASTER_LOG_FILE=\u0026lsquo;mysql-bin.000007\u0026rsquo;, MASTER_LOG_POS=154;的值可以从备份sql文件中找到，如图所示：\n最后启动复制线程\nstart slave 扩展：\nshow slave status\\G # 查看相关状态信息 从节点更换主节点\n\u0026gt;mysql stop slave; #停止复制线程 \u0026gt;mysql reset slave all; # 清除信息 再次使用有复制权限的用户账号连接至主服务器，并启动复制线程 级联复制 案例：三台主机实现级联复制\n步骤\n# 192.168.179.170充当master # 192.168.179.171充当slave1 # 192.168.179.157充当slave2 # 操作系统：centos7.9 #MySQL版本：5.7.38 在master上实现，即192.168.179.170\n# 在master上实现，即192.168.179.170 vim /etc/my.cnf [mysqld] server-id=170 log-bin=/data/mysql/mysql-bin 重启服务\n[root@centos7 ~]# systemctl restart mysql [root@centos7 ~]# 创建具有复制权限的账号\nmysql\u0026gt; grant replication slave on *.* to \u0026#39;test\u0026#39;@\u0026#39;192.168.179.%\u0026#39; identified by \u0026#39;123456\u0026#39;; Query OK, 0 rows affected, 1 warning (0.00 sec) mysql\u0026gt; 完全备份\n[root@centos7 ~]# mysqldump -uroot -p123456 -A -F --single-transaction --master-data=1 \u0026gt; /data/all.sql; [root@centos7 ~]# scp /data/all.sql root@192.168.179.171:/data [root@centos7 ~]# scp /data/all.sql root@192.168.179.157:/data 在中间级联实现\n#在中间级联实现,即192.168.179.171 #修改配置文件 vim /etc/my.cnf [mysqld] server-id=171 log-bin=/data/mysql/slave1-bin read-only log_slave_updates #级联复制中间节点的必选项,MySQL8.0此为默认值,可以不要人为添加 #重启mysql service mysqld restart或者systemctl restart mysql # 还原数据库 vim /data/all.sql mysql\u0026gt; set sql_log_bin=0; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; mysql\u0026gt; source /data/all.sql; mysql\u0026gt; show master logs; +-------------------+-----------+ | Log_name | File_size | +-------------------+-----------+ | slave1-bin.000001 | 801 | | slave1-bin.000002 | 458 | +-------------------+-----------+ 2 rows in set (0.01 sec) mysql\u0026gt; mysql\u0026gt; set sql_log_bin=1; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; mysql\u0026gt; start slave; Query OK, 0 rows affected (0.01 sec) mysql\u0026gt; 在第三个节点slave上实现\nvim /etc/my.cnf [mysqld] server-id=157 log-bin=/data/mysql/slave2-bin # 还原数据库 vim /data/all.sql mysql\u0026gt; set sql_log_bin=0; mysql\u0026gt; source /data/all.sql mysql\u0026gt; set sql_log_bin=1; mysql\u0026gt; start slave; 半同步复制 范例：centos7.9在MySQL5.7.38实现半同步复制\n# 主服务器配置，安装semisync_slave.so插件 mysql\u0026gt; INSTALL PLUGIN rpl_semi_sync_master SONAME \u0026#39;semisync_master.so\u0026#39;; Query OK, 0 rows affected (0.05 sec) mysql\u0026gt; # 修改配置文件 vim /etc/my.cnf rpl_semi_sync_master_enabled=ON #修改此行,需要先安装semisync_master.so插件后,再重启,否则无法启动 rpl_semi_sync_master_timeout=3000 #设置3s内无法同步，也将返回成功信息给客户端 # 重启服务 systemctl restart mysql #slave服务器配置 #安装semisync_slave.so插件 mysql\u0026gt; INSTALL PLUGIN rpl_semi_sync_master SONAME \u0026#39;semisync_master.so\u0026#39;; Query OK, 0 rows affected (0.05 sec) #注意:如果已经实现主从复制,需要stop slave;start slave; mysql\u0026gt; stop slave; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; start slave -\u0026gt; ; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; # 重启mysql服务 systemctl restart mysql # 修改配置文件 vim /etc/my.cnf rpl_semi_sync_slave_enabled=ON # 重启mysql服务 systemctl restart mysql 测试半同步\n# 停止从库slave1 [root@centos7 ~]# systemctl stop mysql # 主库创建表 mysql\u0026gt; create database hellodb; Query OK, 1 row affected (3.00 sec) mysql\u0026gt; # 设置的是三秒内无法同步返回成功，所以看到是3S后返回成功 实战案例：利用Mycat实现MySQL的读写分离 所有主机系统环境\ncentos7.9 服务器三台\nmycat-server 192.168.179.157 #内存建议2G以上 mysql-master 192.168.179.170 MySQL 5.7 mysql-slave 192.168.179.171 MySQL 5.7 关闭SELinux和防火墙\nsystemctl stop firewalld setenforce 0 时间同步 注意：主从复制的过程省略，参考实现主从复制过程\n代理服务器上安装Mycat\n下载地址:\n# 安装jdk [root@centos7 ~]# yum install -y java # 验证 [root@centos7 ~]# java -version openjdk version \u0026#34;1.8.0_352\u0026#34; OpenJDK Runtime Environment (build 1.8.0_352-b08) OpenJDK 64-Bit Server VM (build 25.352-b08, mixed mode) [root@centos7 ~]# [root@centos7 ~]# mkdir /apps [root@centos7 ~]# tar xf Mycat-server-1.6.7.4-release-20200105164103-linux.tar.gz -C /apps/ [root@centos7 ~]# #配置环境变量 [root@centos7 ~]# echo \u0026#39;PATH=/apps/mycat/bin:$PATH\u0026#39; \u0026gt; /etc/profile.d/mycat.sh [root@centos7 ~]# source /etc/profile.d/mycat.sh #注意: 此步启动较慢,需要等一会儿,另外如果内存太小,会导致无法启动 [root@centos7 ~]# mycat start Starting Mycat-server... [root@centos7 ~]# # 查看日志是否启动成功 [root@centos7 ~]# tail -f /apps/mycat/logs/wrapper.log STATUS | wrapper | 2022/11/26 23:27:52 | --\u0026gt; Wrapper Started as Daemon STATUS | wrapper | 2022/11/26 23:27:52 | Launching a JVM... INFO | jvm 1 | 2022/11/26 23:28:08 | Wrapper (Version 3.2.3) http://wrapper.tanukisoftware.org INFO | jvm 1 | 2022/11/26 23:28:08 | Copyright 1999-2006 Tanuki Software, Inc. All Rights Reserved. INFO | jvm 1 | 2022/11/26 23:28:08 | INFO | jvm 1 | 2022/11/26 23:28:10 | MyCAT Server startup successfully. see logs in logs/mycat.log #用默认密码123456来连接mycat [root@centos7 ~]# mysql -uroot -p123456 -h 192.168.179.157 -P8066 mysql: [Warning] Using a password on the command line interface can be insecure. Welcome to the MySQL monitor. Commands end with ; or \\g. Your MySQL connection id is 1 Server version: 5.6.29-mycat-1.6.7.4-release-20200105164103 MyCat Server (OpenCloudDB) Copyright (c) 2000, 2022, Oracle and/or its affiliates. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type \u0026#39;help;\u0026#39; or \u0026#39;\\h\u0026#39; for help. Type \u0026#39;\\c\u0026#39; to clear the current input statement. mysql\u0026gt; show databases; +----------+ | DATABASE | +----------+ | TESTDB | +----------+ 1 row in set (0.00 sec) mysql\u0026gt; # 在主节点上创建账号用于mycat数据读写分离 mysql\u0026gt;create user admin@\u0026#39;192.168.179.%\u0026#39; identified by\u0026#39;123456\u0026#39;; # 赋予权限 mysql\u0026gt; grant all on *.* to \u0026#39;admin\u0026#39;@\u0026#39;192.168.179.%\u0026#39; IDENTIFIED BY \u0026#39;123456\u0026#39;; Query OK, 0 rows affected, 1 warning (0.01 sec) # 刷新 # mysql\u0026gt; flush privileges; Query OK, 0 rows affected (0.01 sec) mysql\u0026gt; 修改schema.xml实现读写分离策略\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34;?\u0026gt; \u0026lt;!DOCTYPE mycat:schema SYSTEM \u0026#34;schema.dtd\u0026#34;\u0026gt; \u0026lt;mycat:schema xmlns:mycat=\u0026#34;http://io.mycat/\u0026#34;\u0026gt; \u0026lt;schema name=\u0026#34;TESTDB\u0026#34; checkSQLschema=\u0026#34;false\u0026#34; sqlMaxLimit=\u0026#34;100\u0026#34; dataNode=\u0026#34;dn1\u0026#34;\u0026gt; \u0026lt;/schema\u0026gt; \u0026lt;dataNode name=\u0026#34;dn1\u0026#34; dataHost=\u0026#34;localhost1\u0026#34; database=\u0026#34;reggie\u0026#34; /\u0026gt; \u0026lt;dataHost name=\u0026#34;localhost1\u0026#34; maxCon=\u0026#34;1000\u0026#34; minCon=\u0026#34;10\u0026#34; balance=\u0026#34;1\u0026#34; writeType=\u0026#34;0\u0026#34; dbType=\u0026#34;mysql\u0026#34; dbDriver=\u0026#34;native\u0026#34; switchType=\u0026#34;1\u0026#34; slaveThreshold=\u0026#34;100\u0026#34;\u0026gt; \u0026lt;heartbeat\u0026gt;select user()\u0026lt;/heartbeat\u0026gt; \u0026lt;writeHost host=\u0026#34;host1\u0026#34; url=\u0026#34;192.168.179.170:3306\u0026#34; user=\u0026#34;admin\u0026#34; password=\u0026#34;123456\u0026#34;\u0026gt; \u0026lt;readHost host=\u0026#34;host2\u0026#34; url=\u0026#34;192.168.179.171:3306\u0026#34; user=\u0026#34;admin\u0026#34; password=\u0026#34;123456\u0026#34; /\u0026gt; \u0026lt;/writeHost\u0026gt; \u0026lt;/dataHost\u0026gt; \u0026lt;/mycat:schema\u0026gt; 重启mycat\n[root@centos7 ~]# mycat restart Stopping Mycat-server... Stopped Mycat-server. Starting Mycat-server... 在Mycat服务器上连接并测试\n[root@centos8 ~]# mysql -uroot -p123456 -h 192.168.179.157 -P8066 mysql\u0026gt; show databases; +----------+ | DATABASE | +----------+ | TESTDB | //只能看一个虚拟数据库,数据库内容映射的是reggie内容 +----------+ 1 row in set (0.00 sec) mysql\u0026gt; mysql\u0026gt; use TESTDB; Reading table information for completion of table and column names You can turn off this feature to get a quicker startup with -A Database changed mysql\u0026gt; show tables; +------------------+ | Tables_in_reggie | +------------------+ | address_book | | category | | dish | | dish_flavor | | employee | | order_detail | | orders | | setmeal | | setmeal_dish | | shopping_cart | | user | +------------------+ 11 rows in set (0.01 sec) mysql\u0026gt; MHA实战案例 主从复制搭建过程省略\n在所有MySQL服务器上安装mha4mysql-node包\n下载地址 mha4mysql-manager mha4mysql-node #下载 https://github.com/yoshinorim/mha4mysql-manager/wiki/Downloads https://github.com/yoshinorim/mha4mysql-node/releases/tag/v0.58 https://github.com/yoshinorim/mha4mysql-node/releases/tag/v0.58 yum -y install mha4mysql-node-0.58-0.el7.centos.noarch.rpm 在管理节点上安装两个包mha4mysql-manager和mha4mysql-node\n[root@mha-manager ~]#yum -y install mha4mysql-manager-0.58- 0.el7.centos.noarch.rpm [root@mha-manager ~]#yum -y install mha4mysql-node-0.58-0.el7.centos.noarch.rpm 在所有节点实现相互之间ssh key验证\n[root@centos7 ~]# ssh-keygen [root@centos7 ~]# ssh-copy-id 127.0.0.1 [root@centos7 ~]# scp -r .ssh 192.168.179.170:/root/ [root@centos7 ~]# scp -r .ssh 192.168.179.171:/root/ [root@centos7 ~]# scp -r .ssh 192.168.179.157:/root/ 在管理节点创建配置文件\n[root@centos7 ~]# mkdir /etc//mastermha/ [root@centos7 ~]# vim app1.cnf # 文件内容 [server default] user=mhauser #用于远程连接MySQL所有节点的用户,需要有管理员的权限 password=123456 manager_workdir=/data/mastermha/app1/ #目录会自动生成,无需手动创建 manager_log=/data/mastermha/app1/manager.log remote_workdir=/data/mastermha/app1/ ssh_user=root #用于实现远程ssh基于KEY的连接,访问二进制日志 repl_user=test #主从复制的用户信息 repl_password=123456 ping_interval=1 #健康性检查的时间间隔 master_ip_failover_script=/usr/local/bin/master_ip_failover #切换VIP的perl脚本,不 支持跨网络,也可用Keepalived实现 report_script=/usr/local/bin/sendmail.sh #当执行报警脚本 check_repl_delay=0 #默认值为1,表示如果slave中从库落后主库relay log超过100M，主库不会选 择这个从库为新的master，因为这个从库进行恢复需要很长的时间.通过设置参数check_repl_delay=0， mha触发主从切换时会忽略复制的延时，对于设置candidate_master=1的从库非常有用，这样确保这个从库 一定能成为最新的master master_binlog_dir=/data/mysql/ #指定二进制日志存放的目录,mha4mysql-manager-0.58必须指 定,之前版本不需要指定 [server1] hostname=192.168.179.170 port=3306 candidate_master=1 [server2] hostname=192.168.179.171 port=3306 candidate_master=1 #设置为优先候选master，即使不是集群中事件最新的slave,也会优先当 master [server3] hostname=192.168.179.157 port=3306 最终文件内容\n[server default] user=mhauser password=123456 manager_workdir=/data/mastermha/app1/ manager_log=/data/mastermha/app1/manager.log remote_workdir=/data/mastermha/app1/ ssh_user=root repl_user=test repl_password=123456 ping_interval=1 master_ip_failover_script=/usr/local/bin/master_ip_failover report_script=/usr/local/bin/sendmail.sh # 发送邮件脚本 check_repl_delay=0 master_binlog_dir=/data/mysql/ [server1] hostname=192.168.179.170 candidate_master=1 [server2] hostname=192.168.179.171 [server3] hostname=192.168.179.157 主节点创建账号user=mhauser #用于远程连接MySQL所有节点的用户,需要有管理员的权限 password=123456\nmysql\u0026gt; create user mhauser@\u0026#39;192.168.179.%\u0026#39; identified by \u0026#39;123456\u0026#39;; Query OK, 0 rows affected (0.05 sec) mysql\u0026gt; mysql\u0026gt; grant all on *.* to mhauser@\u0026#39;192.168.179.%\u0026#39;; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; master_ip_failover_script=/usr/local/bin/master_ip_failover文件内容\n#!/usr/bin/env perl # Copyright (C) 2011 DeNA Co.,Ltd. # # This program is free software; you can redistribute it and/or modify # it under the terms of the GNU General Public License as published by # the Free Software Foundation; either version 2 of the License, or # (at your option) any later version. # # This program is distributed in the hope that it will be useful, # but WITHOUT ANY WARRANTY; without even the implied warranty of # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the # GNU General Public License for more details. # # You should have received a copy of the GNU General Public License # along with this program; if not, write to the Free Software # Foundation, Inc., # 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA ## Note: This is a sample script and is not complete. Modify the script based on your environment. use strict; use warnings FATAL =\u0026gt; \u0026#39;all\u0026#39;; use Getopt::Long; use MHA::DBHelper; my ( $command, $ssh_user, $orig_master_host, $orig_master_ip, $orig_master_port, $new_master_host, $new_master_ip, $new_master_port, $new_master_user, $new_master_password ); my $vip = \u0026#39;192.168.179.157/24\u0026#39;; my $key = \u0026#34;1\u0026#34;; my $ssh_start_vip = \u0026#34;/sbin/ifconfig eth0:$key $vip\u0026#34;; my $ssh_stop_vip = \u0026#34;/sbin/ifconfig eth0:$key down\u0026#34;; GetOptions( \u0026#39;command=s\u0026#39; =\u0026gt; \\$command, \u0026#39;ssh_user=s\u0026#39; =\u0026gt; \\$ssh_user, \u0026#39;orig_master_host=s\u0026#39; =\u0026gt; \\$orig_master_host, \u0026#39;orig_master_ip=s\u0026#39; =\u0026gt; \\$orig_master_ip, \u0026#39;orig_master_port=i\u0026#39; =\u0026gt; \\$orig_master_port, \u0026#39;new_master_host=s\u0026#39; =\u0026gt; \\$new_master_host, \u0026#39;new_master_ip=s\u0026#39; =\u0026gt; \\$new_master_ip, \u0026#39;new_master_port=i\u0026#39; =\u0026gt; \\$new_master_port, \u0026#39;new_master_user=s\u0026#39; =\u0026gt; \\$new_master_user, \u0026#39;new_master_password=s\u0026#39; =\u0026gt; \\$new_master_password, ); exit \u0026amp;main(); sub main { if ( $command eq \u0026#34;stop\u0026#34; || $command eq \u0026#34;stopssh\u0026#34; ) { # $orig_master_host, $orig_master_ip, $orig_master_port are passed. # If you manage master ip address at global catalog database, # invalidate orig_master_ip here. my $exit_code = 1; eval { # updating global catalog, etc $exit_code = 0; }; if ($@) { warn \u0026#34;Got Error: $@\\n\u0026#34;; exit $exit_code; } exit $exit_code; } elsif ( $command eq \u0026#34;start\u0026#34; ) { # all arguments are passed. # If you manage master ip address at global catalog database, # activate new_master_ip here. # You can also grant write access (create user, set read_only=0, etc) here. my $exit_code = 10; eval { print \u0026#34;Enabling the VIP - $vip on the new master - $new_master_host \\n\u0026#34;; \u0026amp;start_vip(); \u0026amp;stop_vip(); $exit_code = 0; }; if ($@) { warn $@; exit $exit_code; } exit $exit_code; } elsif ( $command eq \u0026#34;status\u0026#34; ) { print \u0026#34;Checking the Status of the script.. OK \\n\u0026#34;; `ssh $ssh_user\\@$orig_master_host \\\u0026#34; $ssh_start_vip \\\u0026#34;`; exit 0; } else { \u0026amp;usage(); exit 1; } } sub start_vip() { `ssh $ssh_user\\@$new_master_host \\\u0026#34; $ssh_start_vip \\\u0026#34;`; } # A simple system call that disable the VIP on the old_master sub stop_vip() { `ssh $ssh_user\\@$orig_master_host \\\u0026#34; $ssh_stop_vip \\\u0026#34;`; } sub usage { print \u0026#34;Usage: master_ip_failover --command=start|stop|stopssh|status --orig_master_host=host --orig_master_ip=ip --orig_master_port=port --new_master_host=host --new_master_ip=ip --new_master_port=port\\n\u0026#34;; } master修改mysql配置文件\n[mysqld] server_id=170 log-bin=/data/mysql/mysql-bin skip_name_resolve=1 slave节点上修改\n[mysqld] server_id=171 #不同节点此值各不相同 log-bin=/data/mysql/mysql-bin read_only relay_log_purge=0 skip_name_resolve=1 检查环境\nmasterha_check_ssh --conf=/etc/mastermha/app1.cnf # 范例 [root@centos7 ~]# masterha_check_ssh --conf=/etc/mastermha/app1.cnf Tue Nov 29 22:21:44 2022 - [warning] Global configuration file /etc/masterha_default.cnf not found. Skipping. Tue Nov 29 22:21:44 2022 - [info] Reading application default configuration from /etc/mastermha/app1.cnf.. Tue Nov 29 22:21:44 2022 - [info] Reading server configuration from /etc/mastermha/app1.cnf.. Tue Nov 29 22:21:44 2022 - [info] Starting SSH connection tests.. Tue Nov 29 22:21:45 2022 - [debug] Tue Nov 29 22:21:44 2022 - [debug] Connecting via SSH from root@192.168.179.170(192.168.179.170:22) to root@192.168.179.171(192.168.179.171:22).. Tue Nov 29 22:21:44 2022 - [debug] ok. Tue Nov 29 22:21:44 2022 - [debug] Connecting via SSH from root@192.168.179.170(192.168.179.170:22) to root@192.168.179.157(192.168.179.157:22).. Tue Nov 29 22:21:45 2022 - [debug] ok. Tue Nov 29 22:21:46 2022 - [debug] Tue Nov 29 22:21:45 2022 - [debug] Connecting via SSH from root@192.168.179.171(192.168.179.171:22) to root@192.168.179.170(192.168.179.170:22).. Tue Nov 29 22:21:45 2022 - [debug] ok. Tue Nov 29 22:21:45 2022 - [debug] Connecting via SSH from root@192.168.179.171(192.168.179.171:22) to root@192.168.179.157(192.168.179.157:22).. Tue Nov 29 22:21:45 2022 - [debug] ok. Tue Nov 29 22:21:47 2022 - [debug] Tue Nov 29 22:21:45 2022 - [debug] Connecting via SSH from root@192.168.179.157(192.168.179.157:22) to root@192.168.179.170(192.168.179.170:22).. Tue Nov 29 22:21:45 2022 - [debug] ok. Tue Nov 29 22:21:45 2022 - [debug] Connecting via SSH from root@192.168.179.157(192.168.179.157:22) to root@192.168.179.171(192.168.179.171:22).. Tue Nov 29 22:21:46 2022 - [debug] ok. Tue Nov 29 22:21:47 2022 - [info] All SSH connection tests passed successfully. [root@centos7 ~]# masterha_check_repl --conf=/etc/mastermha/app1.cnf # 范例 [root@centos7 ~]# masterha_check_repl --conf=/etc/mastermha/app1.cnf ...... ...... ter_host=192.168.179.170 --orig_master_ip=192.168.179.170 --orig_master_port=3306 Checking the Status of the script.. OK bash: /sbin/ifconfig: No such file or directory Tue Nov 29 22:45:13 2022 - [info] OK. Tue Nov 29 22:45:13 2022 - [warning] shutdown_script is not defined. Tue Nov 29 22:45:13 2022 - [info] Got exit code 0 (Not master dead). MySQL Replication Health is OK. 查看状态\nmasterha_check_status --conf=/etc/mastermha/app1.cnf app1 is stopped(2:NOT_RUNNING). 启动和停止mha\n# 后台运行 nohup masterha_manager --conf=/etc/mastermha/app1.cnf --remove_dead_master_conf --ignore_last_failover \u0026amp;\u0026gt; /dev/null # 前台运行 masterha_manager --conf=/etc/mastermha/app1.cnf -- remove_dead_master_conf --ignore_last_failover #如果想停止后台执行的MHA,可以执行下面命令 [root@mha-master ~]#masterha_stop --conf=/etc/mastermha/app1.cnf Stopped app1 successfully. 查看状态\n[root@centos7 app1]# masterha_check_status --conf=/etc/mastermha/app1.cnf app1 (pid:48280) is running(0:PING_OK), master:192.168.179.170 ","permalink":"https://xyenvy.github.io/posts/mysql%E9%9B%86%E7%BE%A4/","summary":"MySQL集群 主从复制架构和原理 MySQL主从复制 读写分离 复制：每个节点都有相同的数据集，向外扩展，基于二进制日志的单向复制 复制的功用 负载均衡读操作 备份 高可用和故障切换 数据分布 MySQL升级 复制架构 一主一从复制架构 一主多从复制架构 主从复制原理 主从复制相关线程 主节点： dump Thread","title":"MySQL集群"},{"content":"实战案例：特定数据库的备份脚本 系统：centos8.5 MySQL版本：8.0 #!/bin/bash TIME=`date +%F_%H-%M-%S` # 备份目录 DIR=/mysql_backup # 备份数据库 DB=hellodb # 数据库密码 PASSWD=123456 # 判断备份数据库目录是否存在 [ -d $DIR ] || mkdir $DIR # 备份 mysqldump -uroot -p\u0026#34;$PASSWD\u0026#34; -F -E -R --triggers --single-transaction --master-data=2 --default-character-set=utf8mb4 -q -B $DB | gzip \u0026gt; ${DIR}/${DB}_${TIME}.sql.gz 实战案例：分库备份的实战脚本 系统：centos8.5 MySQL版本：8.0 #!/bin/bash TIME=`date +%F_%H-%M-%S` DIR=/backup PASS=123456 [ -d \u0026#34;$DIR\u0026#34; ] || mkdir $DIR for DB in `mysql -uroot -p\u0026#34;$PASS\u0026#34; -e \u0026#39;show databases\u0026#39; | grep -Ev \u0026#34;^Database|.*schema$\u0026#34;`;do mysqldump -uroot -p\u0026#34;$PASS\u0026#34; -F --single-transaction --master-data=2 --default-character-set=utf8mb4 -q -B $DB | gzip \u0026gt; ${DIR}/${DB}_${TIME}.sql.gz done ","permalink":"https://xyenvy.github.io/posts/mysql%E5%A4%87%E4%BB%BD%E8%84%9A%E6%9C%AC/","summary":"实战案例：特定数据库的备份脚本 系统：centos8.5 MySQL版本：8.0 #!/bin/bash TIME=`date +%F_%H-%M-%S` # 备份目录 DIR=/mysql_backup # 备份数据库 DB=hellodb # 数据库密码 PASSWD=123456 # 判断备份数据库目录是否存在 [ -d $DIR ] || mkdir $DIR # 备份 mysqldump -uroot -p\u0026#34;$PASSWD\u0026#34; -F -E -R --triggers --single-transaction --master-data=2 --default-character-set=utf8mb4 -q -B $DB | gzip \u0026gt; ${DIR}/${DB}_${TIME}.sql.gz 实战案例：分库备份的实战脚本 系统：centos8.5 MySQL版本：8.0 #!/bin/bash","title":"MySQL备份脚本"},{"content":"OSI模型 名称 协议 7 应用层 DNS、http、ssh、FTP等 6 表示层 DNS、http、ssh、FTP等 5 会话层 DNS、http、ssh、FTP等 4 传输层 tcp、udp 3 网络层 IPV4、IPV6、ARP 2 数据链路层 以太网、无线LAN 1 物理层 光纤 http协议 http协议：超文本传输协议，基于TCP协议的应用层传输协议，一种 无状态的、以请求/应答方式的运行的协议（无状态：对于事物处理没有记忆功能）\n主要组成 http协议主要有三大部分组成\n起始行：描述请求或相应的文本 头部字段：使用key-value形式更加详细说明报文 消息正文：实际传输的数据，可以是文本、图片、视频等 http请求报文 请求行 请求头 请求体 http响应报文 响应行 响应头 响应体 TCP协议 tcp/ip协议：面向连接的、可靠的基于字节流的传输层协议。\n特点\n基于连接的：数据传输前需要建立连接\n全双工：双向传输\n字节流：不限制传输大小\n流量缓冲：解决双方处理能力的不匹配\n可靠的传输服务：保证可达、信息丢包时通过重发机制实施可靠性\n拥塞控制：防止网络出现恶性拥塞\n三次握手\n刚开始客户端处于 closed 的状态，服务端处于 listen 状态。然后 1、第一次握手：客户端给服务端发一个 SYN 报文，并指明客户端的初始化序列号 ISN（c）。此时客户端处于 SYN_Send 状态。\n2、第二次握手：服务器收到客户端的 SYN 报文之后，会以自己的 SYN 报文作为应答，并且也是指定了自己的初始化序列号 ISN(s)，同时会把客户端的 ISN + 1 作为 ACK 的值，表示自己已经收到了客户端的 SYN，此时服务器处于 SYN_REVD 的状态。\n3、第三次握手：客户端收到 ACK+SYN 报文之后，会发送一个 ACK 报文，当然，也是一样把服务器的 ISN + 1 作为 ACK 的值，表示已经收到了服务端的 SYN 报文，此时客户端处于 establised 状态。\n4、服务器收到 ACK 报文之后，也处于 establised 状态，此时，双方以建立起了链接。\nSYN是同步的缩写，SYN段是发送到另外一台计算机的TCP数据包，请求在她们之间建立连接 ACK是“确认”的缩写。ACK数据包是任何确认收到一条消息或一系列数据包的TCP数据包 四次挥手\n刚开始双方都处于 establised 状态，假如是客户端先发起关闭请求，则：\n1、第一次挥手：客户端发送一个 FIN 报文，报文中会指定一个序列号。此时客户端处于FIN_WAIT1状态。\n2、第二次握手：服务端收到 FIN 之后，会发送 ACK 报文，且把客户端的序列号值 + 1 作为 ACK 报文的序列号值，表明已经收到客户端的报文了，此时服务端处于 CLOSE_WAIT状态。\n3、第三次挥手：如果服务端也想断开连接了，和客户端的第一次挥手一样，发给 FIN 报文，且指定一个序列号。此时服务端处于 LAST_ACK 的状态。\n4、第四次挥手：客户端收到 FIN 之后，一样发送一个 ACK 报文作为应答，且把服务端的序列号值 + 1 作为自己 ACK 报文的序列号值，此时客户端处于 TIME_WAIT 状态。需要过一阵子以确保服务端收到自己的 ACK 报文之后才会进入 CLOSED 状态\n5、服务端收到 ACK 报文之后，就处于关闭连接了，处于 CLOSED 状态。\n为什么TIME-WAIT状态必须等待2MSL的时间？\n保证客户端最后一个ACK能够到达服务器端 防止失效的请求报文段出现在本次连接中 ","permalink":"https://xyenvy.github.io/posts/http/","summary":"OSI模型 名称 协议 7 应用层 DNS、http、ssh、FTP等 6 表示层 DNS、http、ssh、FTP等 5 会话层 DNS、http、ssh、FTP等 4 传输层 tcp、udp 3 网络层 IPV4、IPV6、ARP 2 数据链路层 以太网、无线LAN 1 物理层 光纤 http协议 http协议：超文本传输协","title":"http"},{"content":"环境：\n系统：rocky8.5 MySQL版本:8.0.28 在线安装 #!/bin/bash # #Author:yuankun #Date:2022-09-29 #Filename:install_mysql-8.0.28-linux-glibc2.12-x86_64.sh . /etc/init.d/functions color=\u0026#39;echo -e \\E[01;31m\u0026#39; end=\u0026#39;\\E[0m\u0026#39; # 设置mysql root用户密码 MYSQL_ROOT_PASSWD=123456 MYSQL_VERSION=mysql-8.0.28-linux-glibc2.12-x86_64.tar.xz check(){ ${color}安装前环境检查......${end} # 判断当前用户是否是root用户，不是则退出安装 if [ ${UID} -ne 0 ];then action \u0026#34;当前用户不是root,安装失败!\u0026#34; false exit fi # 判断是否安装wget，没有安装则使用yum安装wget rpm -q wget || yum install -y wget # 判断/usr/local/mysql目录是否存在，存在则exit if [ -e /usr/local/mysql ];then ${color}\u0026#34;mysql已经安装,安装失败!\u0026#34;${end} exit fi # 下载二进制程序包 wget https://cdn.mysql.com/archives/mysql-8.0/mysql-8.0.28-linux-glibc2.12-x86_64.tar.xz # 判断二进制程序包是否存在 if [ ! -e ${MYSQL_VERSION} ];then ${color}\u0026#34;文件不存在,安装失败!\u0026#34;${end} ${color}\u0026#34;请检查脚本以及主机环境，然后再次尝试安装。即将退出安装流程!\u0026#34;${end} exit else ${color}\u0026#34;安装前环境检查完毕,环境要求满足!\u0026#34;${end} fi } # 安装mysql install_mysql(){ ${color}\u0026#34;开始安装mysql......\u0026#34;${end} # 安装依赖 yum install -y -q libaio numactl-libs # 解压缩 tar xf ${MYSQL_VERSION} -C /usr/local/ cd /usr/local/ MYSQL_FILE=`echo ${MYSQL_VERSION} | sed -nr \u0026#39;s/^(.*[0-9]).*/\\1/p\u0026#39;` ln -s /usr/local/${MYSQL_FILE} /usr/local/mysql chown -R root.root /usr/local/mysql/ id mysql \u0026amp;\u0026gt; /dev/null || { useradd -s /sbin/nologin -r mysql ; action \u0026#34;创建mysql用户\u0026#34;; } # 环境变量 echo \u0026#39;PATH=/usr/local/mysql/bin/:$PATH\u0026#39; \u0026gt; /etc/profile.d/mysql.sh . /etc/profile.d/mysql.sh ln -s /usr/local/mysql/bin/* /usr/bin/ # 配置文件 cat \u0026gt; /etc/my.cnf \u0026lt;\u0026lt;-EOF [mysqld] server-id=1 log-bin datadir=/data/mysql socket=/data/mysql/mysql.sock log-error=/data/mysql/mysql.log pid-file=/data/mysql/mysql.pid [client] socket=/data/mysql/mysql.sock EOF [ -d /data ] || mkdir /data mysqld --initialize --user=mysql --datadir=/data/mysql cp /usr/local/mysql/support-files/mysql.server /etc/init.d/mysqld chkconfig --add mysqld chkconfig mysqld on service mysqld start [ $? -ne 0 ] \u0026amp;\u0026amp; { $color\u0026#34;数据库启动失败，退出!\u0026#34;$end;exit; } sleep 3 MYSQL_OLDPASSWORD=`awk \u0026#39;/A temporary password/{print $NF}\u0026#39; /data/mysql/mysql.log` mysqladmin -uroot -p${MYSQL_OLDPASSWORD} password ${MYSQL_ROOT_PASSWD} \u0026amp;\u0026gt;/dev/null action \u0026#34;数据库安装完成\u0026#34; } # 调用函数 check install_mysql 扩展：在线一键安装MySQL5.7.39脚本\n系统：rocky8.5 MySQL版本:5.7.39 在线安装 #!/bin/bash # #Author yuankun #Date 2022-11-19 #Filename install_mysql-5.7.39-linux-glibc2.12-x86_64.sh . /etc/init.d/functions color=\u0026#39;echo -e \\E[01;31m\u0026#39; end=\u0026#39;\\E[0m\u0026#39; # 设置mysql root用户密码 MYSQL_ROOT_PASSWD=123456 MYSQL_VERSION=mysql-5.7.39-linux-glibc2.12-x86_64.tar.gz check(){ ${color}安装前环境检查......${end} # 判断当前用户是否是root用户，不是则退出安装 if [ ${UID} -ne 0 ];then action \u0026#34;当前用户不是root,安装失败!\u0026#34; false exit fi # 判断是否安装wget，没有安装则使用yum安装wget rpm -q wget || yum install -y wget # 判断/usr/local/mysql目录是否存在，存在则exit if [ -e /usr/local/mysql ];then ${color}\u0026#34;mysql已经安装,安装失败!\u0026#34;${end} exit fi # 下载二进制程序包 wget https://cdn.mysql.com/archives/mysql-5.7/mysql-5.7.39-linux-glibc2.12-x86_64.tar.gz # 判断二进制程序包是否存在 if [ ! -e ${MYSQL_VERSION} ];then ${color}\u0026#34;文件不存在,安装失败!\u0026#34;${end} ${color}\u0026#34;请检查脚本以及主机环境，然后再次尝试安装。即将退出安装流程!\u0026#34;${end} exit else ${color}\u0026#34;安装前环境检查完毕,环境要求满足!\u0026#34;${end} fi } # 安装mysql install_mysql(){ ${color}\u0026#34;开始安装mysql......\u0026#34;${end} # 安装依赖 yum install -y -q libaio numactl-libs # 解压缩 tar xf ${MYSQL_VERSION} -C /usr/local/ cd /usr/local/ MYSQL_FILE=`echo ${MYSQL_VERSION} | sed -nr \u0026#39;s/^(.*[0-9]).*/\\1/p\u0026#39;` ln -s /usr/local/${MYSQL_FILE} /usr/local/mysql chown -R root.root /usr/local/mysql/ id mysql \u0026amp;\u0026gt; /dev/null || { useradd -s /sbin/nologin -r mysql ; action \u0026#34;创建mysql用户\u0026#34;; } # 环境变量 echo \u0026#39;PATH=/usr/local/mysql/bin/:$PATH\u0026#39; \u0026gt; /etc/profile.d/mysql.sh . /etc/profile.d/mysql.sh ln -s /usr/local/mysql/bin/* /usr/bin/ # 配置文件 cat \u0026gt; /etc/my.cnf \u0026lt;\u0026lt;-EOF [mysqld] server-id=1 log-bin datadir=/data/mysql socket=/data/mysql/mysql.sock log-error=/data/mysql/mysql.log pid-file=/data/mysql/mysql.pid [client] socket=/data/mysql/mysql.sock EOF [ -d /data ] || mkdir /data mysqld --initialize --user=mysql --datadir=/data/mysql cp /usr/local/mysql/support-files/mysql.server /etc/init.d/mysqld chkconfig --add mysqld chkconfig mysqld on service mysqld start [ $? -ne 0 ] \u0026amp;\u0026amp; { $color\u0026#34;数据库启动失败，退出!\u0026#34;$end;exit; } sleep 3 MYSQL_OLDPASSWORD=`awk \u0026#39;/A temporary password/{print $NF}\u0026#39; /data/mysql/mysql.log` mysqladmin -uroot -p${MYSQL_OLDPASSWORD} password ${MYSQL_ROOT_PASSWD} \u0026amp;\u0026gt;/dev/null action \u0026#34;数据库安装完成\u0026#34; } # 调用函数 check install_mysql 离线安装\n注意：需要提前将二进制包下载到本地\n系统：rocky8.5\nMySQL版本:8.0.28\n#!/bin/bash # #Author yuankun #Date 2022-11-19 #Filename install_offline_mysql-8.0.28-linux-glibc2.12-x86_64.sh . /etc/init.d/functions color=\u0026#39;echo -e \\E[01;31m\u0026#39; end=\u0026#39;\\E[0m\u0026#39; # 设置mysql root用户密码 MYSQL_ROOT_PASSWD=123456 # mysql 版本 MYSQL_VERSION=mysql-8.0.28-linux-glibc2.12-x86_64.tar.xz check(){ ${color}安装前环境检查......${end} # 判断当前用户是否是root用户，不是则退出安装 if [ ${UID} -ne 0 ];then action \u0026#34;当前用户不是root,安装失败!\u0026#34; false exit fi # 判断/usr/local/mysql目录是否存在，存在则exit if [ -e /usr/local/mysql ];then ${color}\u0026#34;mysql已经安装，安装失败!\u0026#34;${end} exit fi # 判断二进制程序包是否存在 if [ ! -e ${MYSQL_VERSION} ];then ${color}\u0026#34;文件不存在,安装失败!\u0026#34;${end} ${color}\u0026#34;请检查脚本以及主机环境，然后再次尝试安装。即将退出安装流程!\u0026#34;${end} exit else ${color}\u0026#34;安装前环境检查完毕,环境要求满足!\u0026#34;${end} fi } install_mysql(){ ${color}\u0026#34;开始安装mysql......\u0026#34;${end} # 安装依赖 yum install -y -q libaio numactl-libs # 解压缩 tar xf ${MYSQL_VERSION} -C /usr/local/ cd /usr/local/ MYSQL_FILE=`echo ${MYSQL_VERSION} | sed -nr \u0026#39;s/^(.*[0-9]).*/\\1/p\u0026#39;` ln -s /usr/local/${MYSQL_FILE} /usr/local/mysql chown -R root.root /usr/local/mysql/ id mysql \u0026amp;\u0026gt; /dev/null || { useradd -s /sbin/nologin -r mysql ; action \u0026#34;创建mysql用户\u0026#34;; } # 环境变量 echo \u0026#39;PATH=/usr/local/mysql/bin/:$PATH\u0026#39; \u0026gt; /etc/profile.d/mysql.sh . /etc/profile.d/mysql.sh ln -s /usr/local/mysql/bin/* /usr/bin/ # 配置文件 cat \u0026gt; /etc/my.cnf \u0026lt;\u0026lt;-EOF [mysqld] server-id=1 log-bin datadir=/data/mysql socket=/data/mysql/mysql.sock log-error=/data/mysql/mysql.log pid-file=/data/mysql/mysql.pid [client] socket=/data/mysql/mysql.sock EOF [ -d /data ] || mkdir /data mysqld --initialize --user=mysql --datadir=/data/mysql cp /usr/local/mysql/support-files/mysql.server /etc/init.d/mysqld chkconfig --add mysqld chkconfig mysqld on service mysqld start [ $? -ne 0 ] \u0026amp;\u0026amp; { $color\u0026#34;数据库启动失败，退出!\u0026#34;$end;exit; } sleep 3 MYSQL_OLDPASSWORD=`awk \u0026#39;/A temporary password/{print $NF}\u0026#39; /data/mysql/mysql.log` mysqladmin -uroot -p${MYSQL_OLDPASSWORD} password ${MYSQL_ROOT_PASSWD} \u0026amp;\u0026gt;/dev/null action \u0026#34;数据库安装完成\u0026#34; } # 调用函数 check install_mysql 离线安装Mysql5.7.38\n操作系统：centos7.9 mysql版本：5.7.38 mysql-5.7.38-linux-glibc2.12-x86_64.tar.gz下载链接 wget https://mirrors.cloud.tencent.com/mysql/downloads/MySQL-5.7/mysql-5.7.38-linux-glibc2.12-x86_64.tar.gz #!/bin/bash # #Author yuankun #Date 2022-11-24 #Filename install_offline_mysql-5.7.38-linux-glibc2.12-x86_64.sh . /etc/init.d/functions color=\u0026#39;echo -e \\E[01;31m\u0026#39; end=\u0026#39;\\E[0m\u0026#39; # 设置mysql root用户密码 MYSQL_ROOT_PASSWD=123456 # mysql 版本 MYSQL_VERSION=mysql-5.7.38-linux-glibc2.12-x86_64.tar.gz check(){ ${color}安装前环境检查......${end} # 判断当前用户是否是root用户，不是则退出安装 if [ ${UID} -ne 0 ];then action \u0026#34;当前用户不是root,安装失败!\u0026#34; false exit fi # 判断/usr/local/mysql目录是否存在，存在则exit if [ -e /usr/local/mysql ];then ${color}\u0026#34;mysql已经安装，安装失败!\u0026#34;${end} exit fi # 判断二进制程序包是否存在 if [ ! -e ${MYSQL_VERSION} ];then ${color}\u0026#34;文件不存在,安装失败!\u0026#34;${end} ${color}\u0026#34;请检查脚本以及主机环境，然后再次尝试安装。即将退出安装流程!\u0026#34;${end} exit else ${color}\u0026#34;安装前环境检查完毕,环境要求满足!\u0026#34;${end} fi } install_mysql(){ ${color}\u0026#34;开始安装mysql......\u0026#34;${end} # 安装依赖 yum install -y -q libaio numactl-libs # 解压缩 tar xf ${MYSQL_VERSION} -C /usr/local/ cd /usr/local/ MYSQL_FILE=`echo ${MYSQL_VERSION} | sed -nr \u0026#39;s/^(.*[0-9]).*/\\1/p\u0026#39;` ln -s /usr/local/${MYSQL_FILE} /usr/local/mysql chown -R root.root /usr/local/mysql/ id mysql \u0026amp;\u0026gt; /dev/null || { useradd -s /sbin/nologin -r mysql ; action \u0026#34;创建mysql用户\u0026#34;; } # 环境变量 echo \u0026#39;PATH=/usr/local/mysql/bin/:$PATH\u0026#39; \u0026gt; /etc/profile.d/mysql.sh . /etc/profile.d/mysql.sh ln -s /usr/local/mysql/bin/* /usr/bin/ # 配置文件 cat \u0026gt; /etc/my.cnf \u0026lt;\u0026lt;-EOF [mysqld] server-id=1 log-bin datadir=/data/mysql socket=/data/mysql/mysql.sock log-error=/data/mysql/mysql.log pid-file=/data/mysql/mysql.pid [client] socket=/data/mysql/mysql.sock EOF [ -d /data ] || mkdir /data mysqld --initialize --user=mysql --datadir=/data/mysql cp /usr/local/mysql/support-files/mysql.server /etc/init.d/mysqld chkconfig --add mysqld chkconfig mysqld on service mysqld start [ $? -ne 0 ] \u0026amp;\u0026amp; { $color\u0026#34;数据库启动失败，退出!\u0026#34;$end;exit; } sleep 3 MYSQL_OLDPASSWORD=`awk \u0026#39;/A temporary password/{print $NF}\u0026#39; /data/mysql/mysql.log` mysqladmin -uroot -p${MYSQL_OLDPASSWORD} password ${MYSQL_ROOT_PASSWD} \u0026amp;\u0026gt;/dev/null action \u0026#34;数据库安装完成\u0026#34; } # 调用函数 check install_mysql ","permalink":"https://xyenvy.github.io/posts/mysqlinstallscript/","summary":"环境： 系统：rocky8.5 MySQL版本:8.0.28 在线安装 #!/bin/bash # #Author:yuankun #Date:2022-09-29 #Filename:install_mysql-8.0.28-linux-glibc2.12-x86_64.sh . /etc/init.d/functions color=\u0026#39;echo -e \\E[01;31m\u0026#39; end=\u0026#39;\\E[0m\u0026#39; # 设置mysql root用户密码 MYSQL_ROOT_PASSWD=123456 MYSQL_VERSION=mysql-8.0.28-linux-glibc2.12-x86_64.tar.xz check(){ ${color}安装前环境检查......${end} # 判断当前用户是否是root用户，不是则退出安装 if [ ${UID} -ne 0 ];then action \u0026#34;当前用户不是root,安装失败","title":"MySQL一键安装脚本"},{"content":"MySQL的特性 MySQL安装 安装方式介绍 程序包管理器管理的程序包 源代码编译安装 二进制格式的程序包：展开至特定路径，并经过简单配置后即可使用\nrpm安装 CentOS 安装光盘 项目官方 国内镜像 url\n范例1：CentOS 7 利用yum源安装MySQL8.0\nMySQL官网\n官网下载rpm包 利用rz命令将rpm包上传到主机 扩展：\nrz命令yum安装:yum install lrzsz 安装rpm包 root@centos7[~]-\u0026gt;yum install mysql80-community-release-el7-7.noarch.rpm 安装MySQL root@centos7[~]-\u0026gt;yum install -y mysql-community-server 范例2：CentOS 7 利用yum源安装MySQL5.7\n[root@centos7 ~]#tee /etc/yum.repos.d/mysql.repo \u0026lt;\u0026lt;EOF [mysql] name=mysql5.7 baseurl=https://mirrors.tuna.tsinghua.edu.cn/mysql/yum/mysql-5.7-community-el7- x86_64/ gpgcheck=0 EOF [root@centos7 ~]#yum -y install mysql-community-server [root@centos7 ~]#systemctl enable --now mysqld 二进制安装 环境\n系统：rocky8.5\nMySQL版本：mysql-8.0.28-linux-glibc2.12-x86_64.tar.xz\n步骤\n安装相关包 yum -y install libaio numactl-libs 准备用户 groupadd mysql useradd -r -g mysql -s /bin/false mysql 下载二进制程序包 # -P下载到指定目录 wget https://cdn.mysql.com/archives/mysql-8.0/mysql-8.0.28-linux-glibc2.12-x86_64.tar.xz -P /usr/local/ ln -s mysql-8.0.28-linux-glibc2.12-x86_64 mysql chown -R root.root /usr/local/mysql/ 准备环境变量 echo \u0026#39;PATH=/usr/local/mysql/bin:$PATH\u0026#39; \u0026gt; /etc/profile.d/mysql.sh . /etc/profile.d/mysql.sh 准备配置文件 vim /etc/my.cnf [mysqld] datadir=/data/mysql skip_name_resolve=1 socket=/data/mysql/mysql.sock log-error=/data/mysql/mysql.log pid-file=/data/mysql/mysql.pid [client] socket=/data/mysql/mysql.sock 初始化数据库文件并提取root密码 mkdir -pv /data/mysql grep password /data/mysql/mysql.log 生成随机密码\nmysqld --initialize --user=mysql --datadir=/data/mysql 生成空密码\nmysqld --initialize-insecure --user=mysql --datadir=/data/mysql 准备服务脚本和启动 [root@rocky local]# cp /usr/local/mysql/support-files/mysql.server /etc/init.d/mysqld chkconfig --add mysqld # 启动服务 service mysqld start 修改口令 # 修改随机密码为指定密码 mysqladmin -uroot -p\u0026#39;9ATjCOB(jIef\u0026#39; password 123456 #修改前面生成的空密码为指定密码 mysqladmin -uroot password 123456 测试登录 mysql -uroot -p\u0026#39;123456\u0026#39; 注意：登录mysql报如下信息\nmysql: error while loading shared libraries: libtinfo.so.5: cannot open shared object file: No such file or directory 解决方法：\nln -s /usr/lib64/libtinfo.so.6.1 /usr/lib64/libtinfo.so.5 登录成功：\n源码编译安装 MySQL多实例 SQL语言 SQL语言的兴起与语法标准 SQL语句分类 DDL: Data Defination Language 数据定义语言 CREATE，DROP，ALTER DML: Data Manipulation Language 数据操纵语言 INSERT，DELETE，UPDATE 软件开发：CRUD DQL：Data Query Language 数据查询语言 SELECT DCL：Data Control Language 数据控制语言 GRANT，REVOKE TCL：Transaction Control Language 事务控制语言 COMMIT，ROLLBACK，SAVEPOINT 字符集和排序 查看所有支持的字符集 show character set; show charset; 查看支持的所有排序 show collation; #注意 utf8_general_ci不区分大小写 utf8_bin 区分大小写 查看当前使用的排序规则 mysql\u0026gt; show variables like \u0026#39;collation%\u0026#39;; +----------------------+-------------------+ | Variable_name | Value | +----------------------+-------------------+ | collation_connection | utf8_general_ci | | collation_database | latin1_swedish_ci | | collation_server | latin1_swedish_ci | +----------------------+-------------------+ 3 rows in set (0.01 sec) 设置服务器端默认字符集 vim /etc/my.cnf #针对mysql客户端 [mysql] default-character-set=utf8mb4 #针对所有MySQL客户端 [client] default-character-set=utf8mb4 查看当前字符集的使用情况 mysql\u0026gt; show variables like \u0026#39;character%\u0026#39;; +--------------------------+----------------------------------------------------------------+ | Variable_name | Value | +--------------------------+----------------------------------------------------------------+ | character_set_client | utf8mb4 | | character_set_connection | utf8mb4 | | character_set_database | latin1 | | character_set_filesystem | binary | | character_set_results | utf8mb4 | | character_set_server | latin1 | | character_set_system | utf8 | | character_sets_dir | /usr/local/mysql-5.7.39-linux-glibc2.12-x86_64/share/charsets/ | +--------------------------+----------------------------------------------------------------+ 8 rows in set (0.00 sec) mysql\u0026gt; 面试题: VARCHAR(50) 能存放几个 UTF8 编码的汉字？\n存放的汉字个数与版本相关。 mysql 4.0以下版本，varchar(50) 指的是 50 字节，如果存放 UTF8 格式编码的汉字时（每个汉字3字 节），只能存放16 个。 mysql 5.0以上版本，varchar(50) 指的是 50 字符，无论存放的是数字、字母还是 UTF8 编码的汉字， 都可以存放 50 个。 ＭySQL用户管理 相关数据库和表 元数据数据库：mysql 系统授权表：db, host, user,columns_priv, tables_priv, procs_priv, proxies_priv 用户账号 \u0026#39;USERNAME\u0026#39;@\u0026#39;HOST\u0026#39; @\u0026#39;HOST\u0026#39;: 主机名： user1@\u0026#39;web1.magedu.org\u0026#39; IP地址或Network 通配符： % _ 示例：wang@\u0026#39;172.16.%.%\u0026#39; user2@\u0026#39;192.168.1.%\u0026#39; mage@\u0026#39;10.0.0.0/255.255.0.0\u0026#39; 创建用户：create user CREATE USER \u0026#39;USERNAME\u0026#39;@\u0026#39;HOST\u0026#39; [IDENTIFIED BY \u0026#39;password\u0026#39;]； #示例: create user test@\u0026#39;10.0.0.0/255.255.255.0\u0026#39; identified by \u0026#39;123456\u0026#39;; create user test2@\u0026#39;10.0.0.%\u0026#39; identified by 123456 新建用户的默认权限：USAGE\n用户重命名：RENAME USER RENAME USER old_user_name TO new_user_name; 删除用户 DROP USER \u0026#39;USERNAME\u0026#39;@\u0026#39;HOST\u0026#39; 删除空用户\nDROP USER \u0026#39;\u0026#39;@\u0026#39;localhost\u0026#39;; 修改密码\n注意 新版mysql中用户密码可以保存在mysql.user表的authentication_string字段中 如果mysql.user表的authentication_string和password字段都保存密码，authentication_string 优先生效\n#方法1,用户可以也可通过此方式修改自已的密码 SET PASSWORD FOR \u0026#39;user\u0026#39;@\u0026#39;host\u0026#39; = PASSWORD(\u0026#39;password\u0026#39;); #MySQL8.0 版本不支持此方法, 因为password函数被取消 set password for root@\u0026#39;localhost\u0026#39;=\u0026#39;123456\u0026#39; ; #MySQL8.0版本支持此方法,此方式直接将密码 123456加密后存放在mysql.user表的authentication_string字段 #方法2 ALTER USER test@\u0026#39;%\u0026#39; IDENTIFIED BY \u0026#39;centos\u0026#39;; #通用改密码方法, 用户可以也可通过此方式修 改自已的密码,MySQL8 版本修改密码 #方法3 此方式MySQL8.0不支持,因为password函数被取消 UPDATE mysql.user SET password=PASSWORD(\u0026#39;password\u0026#39;) WHERE clause; #mariadb 10.3 update mysql.user set authentication_string=password(\u0026#39;ubuntu\u0026#39;) where user=\u0026#39;mage\u0026#39;; #此方法需要执行下面指令才能生效： FLUSH PRIVILEGES; 忘记管理员密码解决方法\n启动mysqld进程时，为其使用如下选项： --skip-grant-tables --skip-networking 使用UPDATE命令修改管理员密码 关闭mysqld进程，移除上述两个选项，重启mysqld\n范例:Mariadb 和MySQL5.6版之前破解root密码\n[root@centos8 ~]#vim /etc/my.cnf [mysqld] skip-grant-tables skip-networking [root@centos8 ~]#systemctl restart mysqld|mariadb [root@centos8 ~]#mysql #方法1 #mariadb 旧版和MySQL5.6版之前 MariaDB [(none)]\u0026gt; update mysql.user set password=password(\u0026#39;ubuntu\u0026#39;) where user=\u0026#39;root\u0026#39;; #mariadb 新版 MariaDB [(none)]\u0026gt; update mysql.user set authentication_string=password(\u0026#39;ubuntu\u0026#39;) where user=\u0026#39;root\u0026#39;; #方法2 MariaDB [(none)]\u0026gt; flush privileges; MariaDB [(none)]\u0026gt; alter user root@\u0026#39;localhost\u0026#39; identified by \u0026#39;ubuntu\u0026#39;; [root@centos8 ~]#vim /etc/my.cnf [mysqld] #skip-grant-tables #skip-networking [root@centos8 ~]#systemctl restart mysqld|mariadb [root@centos8 ~]#mysql -uroot -pubuntu 范例: MySQL5.7和8.0 破解root密码\n[root@centos8 ~]#vim /etc/my.cnf [mysqld] skip-grant-tables skip-networking #MySQL8.0不需要 [root@centos8 ~]#systemctl restart mysqld #方法1 mysql\u0026gt; update mysql.user set authentication_string=\u0026#39;\u0026#39; where user=\u0026#39;root\u0026#39; and host=\u0026#39;localhost\u0026#39;; #方法2 mysql\u0026gt; flush privileges; #再执行下面任意一个命令 mysql\u0026gt; alter user root@\u0026#39;localhost\u0026#39; identified by \u0026#39;ubuntu\u0026#39;; mysql\u0026gt; set password for root@\u0026#39;localhost\u0026#39;=\u0026#39;ubuntu\u0026#39;; [root@centos8 ~]#vim /etc/my.cnf [mysqld] #skip-grant-tables #skip-networking [root@centos8 ~]#systemctl restart mysqld [root@centos8 ~]#mysql -uroot -pubuntu 范例: 删库跑路之清空root密码方法\n#此方法适用于包安装方式的MySQL或Mariadb [root@centos8 ~]#systemctl stop mysqld [root@centos8 ~]#rm -rf /var/lib/mysql/* [root@centos8 ~]#systemctl start mysqld 权限管理 权限类别：\n管理类\n程序类\n数据库级别\n表级别\n字段级别\n管理类：\nCREATE USER FILE SUPER SHOW DATABASES RELOAD SHUTDOWN REPLICATION SLAVE REPLICATION CLIENT LOCK TABLES PROCESS CREATE TEMPORARY TABLES 程序类：针对 FUNCTION、PROCEDURE、TRIGGER\nCREATE ALTER DROP EXCUTE\n库和表级别：针对 DATABASE、TABLE ALTER CREATE CREATE VIEW DROP INDEX SHOW VIEW WITH GRANT OPTION：能将自己获得的权限转赠给其他用户 数据操作 SELECT -INSERT DELETE UPDATE 字段级别 SELECT(col1,col2,\u0026hellip;) UPDATE(col1,col2,\u0026hellip;) INSERT(col1,col2,\u0026hellip;) 所有权限 ALL PRIVILEGES 或 ALL 授权\n授权：GRANT GRANT SELECT (col1), INSERT (col1,col2) ON mydb.mytbl TO \u0026#39;someuser\u0026#39;@\u0026#39;somehost\u0026#39;; GRANT ALL ON wordpress.* TO wordpress@\u0026#39;10.0.0.%\u0026#39; ; GRANT ALL PRIVILEGES ON *.* TO \u0026#39;root\u0026#39;@\u0026#39;10.0.0.%\u0026#39; WITH GRANT OPTION; #创建用户和授权同时执行的方式在MySQL8.0取消了 GRANT ALL ON wordpress.* TO wordpress@\u0026#39;192.168.8.%\u0026#39; IDENTIFIED BY \u0026#39;magedu\u0026#39;; GRANT ALL PRIVILEGES ON *.* TO \u0026#39;root\u0026#39;@\u0026#39;192.168.8.%\u0026#39; IDENTIFIED BY \u0026#39;magedu\u0026#39; WITH GRANT OPTION; 取消授权\n取消授权：REVOKE REVOKE DELETE ON *.* FROM \u0026#39;testuser\u0026#39;@\u0026#39;172.16.0.%\u0026#39;; 查看指定用户获得的授权\nHelp SHOW GRANTS SHOW GRANTS FOR \u0026#39;user\u0026#39;@\u0026#39;host\u0026#39;; SHOW GRANTS FOR CURRENT_USER[()]; 注意： MariaDB服务进程启动时会读取mysql库中所有授权表至内存 (1) GRANT或REVOKE等执行权限操作会保存于系统表中，MariaDB的服务进程通常会自动重读授权表， 使之生效 (2) 对于不能够或不能及时重读授权表的命令，可手动让MariaDB的服务进程重读授权表： mysql\u0026gt; FLUSH PRIVILEGES;\nMyISAM 存储引擎 MyISAM 引擎特点 不支持事务 表级锁定 读写相互阻塞，写入不能读，读时不能写 只缓存索引 不支持外键约束 不支持聚簇索引 读取数据较快，占用资源较少 不支持MVCC（多版本并发控制机制）高并发 崩溃恢复性较差 MySQL5.5.5 前默认的数据库引擎 MyISAM 存储引擎适用场景 只读（或者写较少） 表较小（可以接受长时间进行修复操作） MyISAM 引擎文件 tbl_name.frm 表格式定义 tbl_name.MYD 数据文件 tbl_name.MYI 索引文件 InnoDB 引擎 InnoDB引擎特点 行级锁 支持事务，适合处理大量短期事务 读写阻塞与事务隔离级别相关 可缓存数据和索引 支持聚簇索引 崩溃恢复性更好 支持MVCC高并发 从MySQL5.5后支持全文索引 从MySQL5.5.5开始为默认的数据库引擎 管理存储引擎 查看mysql支持的存储引擎\nshow engines; 查看当前默认的存储引擎\nshow variables like \u0026#39;%storage_engine%\u0026#39;; 设置默认的存储引擎\nvim /etc/my.cnf [mysqld] default_storage_engine= InnoDB 查看库中所有表使用的存储引擎\nshow table status from db_name; 查看库中指定表的存储引擎\nshow table status like \u0026#39;tb_name\u0026#39;; show create table tb_name; 设置表的存储引擎：\nCREATE TABLE tb_name(... ) ENGINE=InnoDB; ALTER TABLE tb_name ENGINE=InnoDB; 实战案例：数据库冷备份和热备份 MySQL8.0\n冷备份：\n备份过程 # 停止数据库 systemctl stop mysql # rsync可以保留文件属性 [root@centos8 ~]#rsync -a /var/lib/mysql 10.0.0.28:/data/ #如果配置及二进制文件相关有特殊设置也需要备份 #还原 [root@centos8 ~]#yum -y install mysql-server [root@centos8 ~]#cp -a /data/mysql/* /var/lib/mysql/ [root@centos8 ~]#systemctl start mysqld mysqldump备份工具 mysqldump 说明 逻辑备份工具： mysqldump, mydumper, phpMyAdmin Schema和数据存储在一起、巨大的SQL语句、单个巨大的备份文件 mysqldump是MySQL的客户端命令，通过mysql协议连接至mysql服务器进行备份 命令格式:\nmysqldump [OPTIONS] database [tables] #支持指定数据库和指定多表的备份，但数据库本身定义 不备份 mysqldump [OPTIONS] -B DB1 [DB2 DB3...] #支持指定数据库备份，包含数据库本身定义也会备份 mysqldump [OPTIONS] -A [OPTIONS] #备份所有数据库，包含数据库本身定义也会备份 mysqldump参考：\nhttps://dev.mysql.com/doc/refman/5.7/en/mysqldump.html mysqldump 常见通用选项：\n-u, --user=name User for login if not current user -p, --password[=name] Password to use when connecting to server -A, --all-databases #备份所有数据库，含create database -B, --databases db_name… #指定备份的数据库，包括create database语句 -E, --events：#备份相关的所有event scheduler -R, --routines：#备份所有存储过程和自定义函数 --triggers：#备份表相关触发器，默认启用,用--skip-triggers，不备份触发器 --default-character-set=utf8 #指定字符集 --master-data[=#]：#注意：MySQL8.0.26版以后，此选项变为--source-data #此选项须启用二进制日志 #1：所备份的数据之前加一条记录为CHANGE MASTER TO语句，非注释，不指定#，默认为1，适合于主从复 制多机使用 #2：记录为被注释的#CHANGE MASTER TO语句，适合于单机使用,适用于备份还原 #此选项会自动关闭--lock-tables功能，自动打开-x | --lock-all-tables功能（除非开启-- single-transaction） -F, --flush-logs #备份前滚动日志，锁定表完成后，执行flush logs命令,生成新的二进制日志文件， 配合-A 或 -B 选项时，会导致刷新多次数据库。建议在同一时刻执行转储和日志刷新，可通过和--single- transaction或-x，--master-data 一起使用实现，此时只刷新一次二进制日志 --compact #去掉注释，适合调试，节约备份占用的空间,生产不使用 -d, --no-data #只备份表结构,不备份数据,即只备份create table -t, --no-create-info #只备份数据,不备份表结构,即不备份create table -n,--no-create-db #不备份create database，可被-A或-B覆盖 --flush-privileges #备份mysql或相关时需要使用 -f, --force #忽略SQL错误，继续执行 --hex-blob #使用十六进制符号转储二进制列，当有包括BINARY,VARBINARY,BLOB， BIT的数据类型的列时使用，避免乱码 -q, --quick #不缓存查询，直接输出，加快备份速度 mysqldump的MyISAM存储引擎相关的备份选项： MyISAM不支持事务，只能支持温备；不支持热备，所以必须先锁定要备份的库，而后启动备份操作\n-x,--lock-all-tables #加全局读锁，锁定所有库的所有表，同时加--single-transaction或-- lock-tables选项会关闭此选项功能，注意：数据量大时，可能会导致长时间无法并发访问数据库 -l,--lock-tables #对于需要备份的每个数据库，在启动备份之前分别锁定其所有表，默认为on,-- skip-lock-tables选项可禁用,对备份MyISAM的多个库,可能会造成数据不一致 #注：以上选项对InnoDB表一样生效，实现温备，但不推荐使用 mysqldump的InnoDB存储引擎相关的备份选项： InnoDB 存储引擎支持事务,可以利用事务的相应的隔离级别,实现热备，也可以实现温备但不建议用\n--single-transaction #此选项Innodb中推荐使用，不适用MyISAM，此选项会开始备份前，先执行START TRANSACTION指令开启 事务 #此选项通过在单个事务中转储所有表来创建一致的快照。 仅适用于存储在支持多版本控制的存储引擎中的表 （目前只有InnoDB可以）; 转储不保证与其他存储引擎保持一致。 在进行单事务转储时，要确保有效的转储 文件（正确的表内容和二进制日志位置），没有其他连接应该使用以下语句：ALTER TABLE，DROP TABLE， RENAME TABLE，TRUNCATE TABLE,此选项和--lock-tables（此选项隐含提交挂起的事务）选项是相互 排斥,备份大型表时，建议将--single-transaction选项和--quick结合一起使用 生产环境实战备份策略 InnoDB建议备份策略\nmysqldump -uroot -p -A -F -E -R --triggers --single-transaction --master-data=1 --flush-privileges --default-character-set=utf8 --hex-blob \u0026gt;${BACKUP}/fullbak_${BACKUP_TIME}.sql MyISAM建议备份策略\nmysqldump -uroot -p -A -F -E -R -x --master-data=1 --flush-privileges -- triggers --default-character-set=utf8 --hex-blob \u0026gt;${BACKUP}/fullbak_${BACKUP_TIME}.sql mysqldump 备份还原实战案例 实战案例：特定数据库的备份脚本 系统：centos8.5\nmysql:8.0\n#!/bin/bash TIME=`date +%F_%H-%M-%S` # 备份目录 DIR=/mysql_backup # 备份数据库 DB=hellodb # 数据库密码 PASSWD=123456 # 判断备份数据库目录是否存在 [ -d $DIR ] || mkdir $DIR # 备份 mysqldump -uroot -p\u0026#34;$PASSWD\u0026#34; -F -E -R --triggers --single-transaction --master-data=2 --default-character-set=utf8mb4 -q -B $DB | gzip \u0026gt; ${DIR}/${DB}_${TIME}.sql.gz 实战案例：分库备份的实战脚本 系统：centos8.5 MySQL版本：8.0 #!/bin/bash TIME=`date +%F_%H-%M-%S` DIR=/backup PASS=123456 [ -d \u0026#34;$DIR\u0026#34; ] || mkdir $DIR for DB in `mysql -uroot -p\u0026#34;$PASS\u0026#34; -e \u0026#39;show databases\u0026#39; | grep -Ev \u0026#34;^Database|.*schema$\u0026#34;`;do mysqldump -uroot -p\u0026#34;$PASS\u0026#34; -F --single-transaction --master-data=2 --default-character-set=utf8mb4 -q -B $DB | gzip \u0026gt; ${DIR}/${DB}_${TIME}.sql.gz done 实战案例：完全备份和还原 #开启二进制日志 [root@centos8 ~]#vim /etc/my.cnf.d/mariadb-server.cnf [mysqld] log-bin #备份 [root@centos8 ~]#mysqldump -uroot -pmagedu -A -F --single-transaction --master- data=2 |gzip \u0026gt; /backup/all-`date +%F`.sql.gz #还原 [root@centos8 backup]#dnf install mariadb-server [root@centos8 backup]#gzip -d all-2019-11-27.sql.gz [root@centos8 ~]#mysql MariaDB [(none)]\u0026gt; set sql_log_bin=off; MariaDB [(none)]\u0026gt; source /backup/all-2019-11-27.sql MariaDB [(none)]\u0026gt; set sql_log_bin=on; 实战案例：恢复误删除的表 案例说明：每天2：30做完全备份，早上10：00误删除了表students，10：10才发现故障，现需要将数 据库还原到10：10的状态，且恢复被删除的students表\n#查看数据库是否开启二进制 mysql\u0026gt; select @@log_bin; +-----------+ | @@log_bin | +-----------+ | 1 | +-----------+ 1 row in set (0.01 sec) mysql\u0026gt; select @@sql_log_bin; +---------------+ | @@sql_log_bin | +---------------+ | 1 | +---------------+ 1 row in set (0.01 sec) mysql\u0026gt; # log_bin、sql_log_bin的值为1说明已经开启二进制日志 # 查看当前二进制文件在什么位置 mysql\u0026gt; show master logs; +------------------+-----------+-----------+ | Log_name | File_size | Encrypted | +------------------+-----------+-----------+ | mysql-bin.000001 | 204 | No | | mysql-bin.000002 | 157 | No | +------------------+-----------+-----------+ 2 rows in set (0.01 sec) mysql\u0026gt; # 备份的时候开启刷新二进制日志，会生成新的二进制的日志 #完全备份 [root@centos7 ~]# mysqldump -uroot -p123456 -A -F --single-transaction --master-data=2 | gzip \u0026gt; /backup/all_`date +%F`.sql.gz # 完全备份后进行数据更新 mysql\u0026gt; insert students (name,age,gender) values(\u0026#39;jack\u0026#39;,22,\u0026#39;M\u0026#39;); Query OK, 1 row affected (0.01 sec) mysql\u0026gt; insert students (name,age,gender) values(\u0026#39;rose\u0026#39;,20,\u0026#39;f\u0026#39;); Query OK, 1 row affected (0.01 sec) # 误删除学生表 mysql\u0026gt; drop table students; Query OK, 0 rows affected (0.07 sec) mysql\u0026gt; # 后续其他表继续更新 mysql\u0026gt; insert teachers (name,age,gender)values(\u0026#39;wang\u0026#39;,30,\u0026#39;M\u0026#39;); Query OK, 1 row affected (0.01 sec) mysql\u0026gt; mysql\u0026gt; insert teachers (name,age,gender)values(\u0026#39;mage\u0026#39;,28,\u0026#39;M\u0026#39;); Query OK, 1 row affected (0.05 sec) mysql\u0026gt; # 停止数据库访问 # 备份从完全备份后的二进制日志 [root@centos7 ~]# mysqlbinlog --start-position=157 /data/mysql/mysql-bin.000003 \u0026gt; /backup/inc.sql # 找到误删除的语句，从备份中删除此语句 #DROP TABLE `students` /* generated by server */ #利用完全备份和修改过的二进制日志进行还原 [root@centos8 ~]#mysql -uroot -p mysql\u0026gt; set sql_log_bin=0; mysql\u0026gt; source /backup/allbackup_2019-11-27_10:20:08.sql; mysql\u0026gt; source /backup/inc.sql mysql\u0026gt; set sql_log_bin=1; ","permalink":"https://xyenvy.github.io/posts/mysql/","summary":"MySQL的特性 MySQL安装 安装方式介绍 程序包管理器管理的程序包 源代码编译安装 二进制格式的程序包：展开至特定路径，并经过简单配置后即可使用 rpm安装 CentOS 安装光盘 项目官方 国内镜像 url 范例1：CentOS 7 利用yum源安装MySQL8.0 MySQL官网 官网下载rpm包 利用rz命令将rp","title":"MySQL"},{"content":"防火墙基本认识 Netfilter Linux防火墙是由Netfilter组件提供的，Netfilter工作在内核空间，集成在linux内核中。 Netfilter 是Linux 2.4.x之后新一代的Linux防火墙机制，是linux内核的一个子系统。Netfilter采用模块 化设计，具有良好的可扩充性，提供扩展各种网络服务的结构化底层框架。Netfilter与IP协议栈是无缝 契合，并允许对数据报进行过滤、地址转换、处理等操作。\nNetfilter官网文档\n[root@centos7 ~]# grep -m 10 NETFILTER /boot/config-3.10.0-1160.el7.x86_64 CONFIG_NETFILTER=y # CONFIG_NETFILTER_DEBUG is not set CONFIG_NETFILTER_ADVANCED=y CONFIG_BRIDGE_NETFILTER=m CONFIG_NETFILTER_NETLINK=m CONFIG_NETFILTER_NETLINK_ACCT=m CONFIG_NETFILTER_NETLINK_QUEUE=m CONFIG_NETFILTER_NETLINK_LOG=m CONFIG_NETFILTER_NETLINK_QUEUE_CT=y CONFIG_NETFILTER_SYNPROXY=m [root@centos7 ~]# 防火墙工具介绍 iptables 由软件包iptables提供的命令行工具，工作在用户空间，用来编写规则，写好的规则被送往netfilter，告 诉内核如何去处理信息包。\n查看iptables信息 [root@centos7 ~]# rpm -qi iptables Name : iptables Version : 1.4.21 Release : 35.el7 Architecture: x86_64 Install Date: Sat 17 Sep 2022 10:31:09 AM CST Group : System Environment/Base Size : 1556976 License : GPLv2 Signature : RSA/SHA256, Thu 15 Oct 2020 02:51:02 AM CST, Key ID 24c6a8a7f4a80eb5 Source RPM : iptables-1.4.21-35.el7.src.rpm Build Date : Fri 02 Oct 2020 12:52:54 AM CST Build Host : x86-01.bsys.centos.org Relocations : (not relocatable) Packager : CentOS BuildSystem \u0026lt;http://bugs.centos.org\u0026gt; Vendor : CentOS URL : http://www.netfilter.org/ Summary : Tools for managing Linux kernel packet filtering capabilities Description : The iptables utility controls the network packet filtering code in the Linux kernel. If you need to set up firewalls and/or IP masquerading, you should install this package. [root@centos7 ~]# 范例：安装iptables的server包\n# 安装dnf [root@centos7 ~]# yum install dnf # 安装iptables-services [root@centos7 ~]# dnf -y install iptables-services # 查看iptables-services文件列表 [root@centos7 ~]# rpm -ql iptables-services /etc/sysconfig/ip6tables /etc/sysconfig/iptables /usr/lib/systemd/system/ip6tables.service /usr/lib/systemd/system/iptables.service /usr/libexec/initscripts/legacy-actions/ip6tables /usr/libexec/initscripts/legacy-actions/ip6tables/panic /usr/libexec/initscripts/legacy-actions/ip6tables/save /usr/libexec/initscripts/legacy-actions/iptables /usr/libexec/initscripts/legacy-actions/iptables/panic /usr/libexec/initscripts/legacy-actions/iptables/save /usr/libexec/iptables /usr/libexec/iptables/ip6tables.init /usr/libexec/iptables/iptables.init [root@centos7 ~]# firewalld 从CentOS 7 版开始引入了新的前端管理工具 软件包：\nfirewalld firewalld-config 管理工具：\nfirewall-cmd 命令行工具 firewall-config 图形工作 nftables 它重用了netfilter框架的许多部分，例如连接跟踪和NAT功能。它还保留了命名法和基本iptables设计的几个部分，例如表，链和规则。就像iptables一样，表充当链的容器，并且链包含单独的规则，这些规则可以执行操作，例如丢弃数据包，移至下一个规则或跳至新链。 从用户的角度来看，nftables添加了一个名为nft的新工具，该工具替代了iptables，arptables和 ebtables中的所有其他工具。从体系结构的角度来看，它还替换了内核中处理数据包过滤规则集运行时评估的那些部分。\n查看软件信息 [root@centos7 ~]# rpm -qi nftables Name : nftables Epoch : 1 Version : 0.8 Release : 14.el7 Architecture: x86_64 Install Date: Wed 28 Sep 2022 11:36:55 AM CST Group : Unspecified Size : 500068 License : GPLv2 Signature : RSA/SHA256, Fri 23 Aug 2019 05:36:19 AM CST, Key ID 24c6a8a7f4a80eb5 Source RPM : nftables-0.8-14.el7.src.rpm Build Date : Fri 09 Aug 2019 09:13:15 AM CST Build Host : x86-01.bsys.centos.org Relocations : (not relocatable) Packager : CentOS BuildSystem \u0026lt;http://bugs.centos.org\u0026gt; Vendor : CentOS URL : http://netfilter.org/projects/nftables/ Summary : Netfilter Tables userspace utillites Description : Netfilter Tables userspace utilities. [root@centos7 ~]# 范例：centos8支持三种防火墙服务\n[root@rocky ~]# systemctl status iptables.service ● iptables.service - IPv4 firewall with iptables Loaded: loaded (/usr/lib/systemd/system/iptables.service; disabled; vendor preset: disabled) Active: inactive (dead) [root@rocky ~]# systemctl status firewalld.service ● firewalld.service - firewalld - dynamic firewall daemon Loaded: loaded (/usr/lib/systemd/system/firewalld.service; disabled; vendor preset: enabled) Active: inactive (dead) Docs: man:firewalld(1) [root@rocky ~]# systemctl status nftables.service ● nftables.service - Netfilter Tables Loaded: loaded (/usr/lib/systemd/system/nftables.service; disabled; vendor preset: disabled) Active: inactive (dead) Docs: man:nft(8) [root@rocky ~]# netfilter中五个勾子函数和报文流向 Netfilter在内核中选取五个位置放了五个hook(勾子) function(INPUT、OUTPUT、FORWARD、 PREROUTING、POSTROUTING)，而这五个hook function向用户开放，用户可以通过一个命令工具 （iptables）向其写入规则。\n由信息过滤表（table）组成，包含控制IP包处理的规则集（rules），规则被分组放在链（chain）上。\n提示：从 Linux kernel 4.2 版以后，Netfilter 在prerouting 前加了一个 ingress 勾子函数。可以使用这 个新的入口挂钩来过滤来自第2层的流量，这个新挂钩比预路由要早，基本上是 tc 命令（流量控制工 具）的替代品。 三种报文流向\n流入本机：PREROUTING \u0026ndash;\u0026gt; INPUT\u0026ndash;\u0026gt;用户空间进程 流出本机：用户空间进程 \u0026ndash;\u0026gt;OUTPUT\u0026ndash;\u0026gt; POSTROUTING 转发：PREROUTING \u0026ndash;\u0026gt; FORWARD \u0026ndash;\u0026gt; POSTROUTING iptables组成 iptables由五个表table和五个链chain以及一些规则组成\n链 chain：\n内置链：每个内置链对应于一个钩子函数 自定义链：用于对内置链进行扩展或补充，可实现更灵活的规则组织管理机制；只有Hook钩子调 用自定义链时，才生效 五个内置链chain:\nINPUT,OUTPUT,FORWARD,PREROUTING,POSTROUTING 五个表：filter、nat、mangle、raw、security\nfilter：过滤规则表，根据预定义的规则过滤符合条件的数据包,默认表 nat：network address translation 地址转换规则表 mangle：修改数据标记位规则表 raw：关闭启用的连接跟踪机制，加快封包穿越防火墙速度 security：用于强制访问控制（MAC）网络规则，由Linux安全模块（如SELinux）实现 优先级由高到低的顺序为： 优先级由高到低的顺序为\nsecurity --\u0026gt;raw--\u0026gt;mangle--\u0026gt;nat--\u0026gt;filter 表和链对应关系\n数据包过滤匹配流程\n内核中数据包的传输过程\n当一个数据包进入网卡时，数据包首先进入PREROUTING链，内核根据数据包目的IP判断是否需要 转送出去 如果数据包是进入本机的，数据包就会沿着图向下移动，到达INPUT链。数据包到达INPUT链后， 任何进程都会收到它。本机上运行的程序可以发送数据包，这些数据包经过OUTPUT链，然后到达 POSTROUTING链输出 如果数据包是要转发出去的，且内核允许转发，数据包就会向右移动，经过FORWARD链，然后到 达POSTROUTING链输出 范例\n[root@rocky ~]# iptables -vnL -t filter Chain INPUT (policy ACCEPT 0 packets, 0 bytes) pkts bytes target prot opt in out source destination 168 10248 ACCEPT all -- * * 0.0.0.0/0 0.0.0.0/0 state RELATED,ESTABLISHED 0 0 ACCEPT icmp -- * * 0.0.0.0/0 0.0.0.0/0 0 0 ACCEPT all -- lo * 0.0.0.0/0 0.0.0.0/0 0 0 ACCEPT tcp -- * * 0.0.0.0/0 0.0.0.0/0 state NEW tcp dpt:22 0 0 REJECT all -- * * 0.0.0.0/0 0.0.0.0/0 reject-with icmp-host-prohibited Chain FORWARD (policy ACCEPT 0 packets, 0 bytes) pkts bytes target prot opt in out source destination 0 0 REJECT all -- * * 0.0.0.0/0 0.0.0.0/0 reject-with icmp-host-prohibited Chain OUTPUT (policy ACCEPT 101 packets, 11034 bytes) pkts bytes target prot opt in out source destination [root@rocky ~]# CentOS 6 nat表不支持INPUT链\niptables规则说明 iptables规则组成 规则rule：根据规则的匹配条件尝试匹配报文，对匹配成功的报文根据规则定义的处理动作作出处理， 规则在链接上的次序即为其检查时的生效次序 匹配条件：默认为与条件，同时满足 基本匹配：IP，端口，TCP的Flags（SYN,ACK等） 扩展匹配：通过复杂高级功能匹配 处理动作：称为target，跳转目标\n内建处理动作：ACCEPT,DROP,REJECT,SNAT,DNAT,MASQUERADE,MARK,LOG\u0026hellip; 自定义处理动作：自定义chain，利用分类管理复杂情形 规则要添加在链上，才生效；添加在自定义链上不会自动生效 白名单:只有指定的特定主机可以访问,其它全拒绝 黑名单:只有指定的特定主机拒绝访问,其它全允许,默认方式\niptables规则添加时考量点 要实现哪种功能：判断添加在哪张表上 报文流经的路径：判断添加在哪个链上 报文的流向：判断源和目的 匹配规则：业务需要 iptables用法说明 帮助：man 8 iptables 格式：\niptables [-t table] {-A|-C|-D} chain rule-specification 范例：filter表中INPUT规则\niptables命令格式详解\niptables [-t table] SUBCOMMAND chain [-m matchname [per-match-options]] -j targetname [per-target-options] 1、-t table：指定表 raw, mangle, nat, [filter]默认 2、SUBCOMMAND：子命令 链管理类：\n-N：new, 自定义一条新的规则链 -E：重命名自定义链；引用计数不为0的自定义链不能够被重命名，也不能被删除 -X：delete，删除自定义的空的规则链 -P：Policy，设置默认策略；对filter表中的链而言，其默认策略有：ACCEPT：接受, DROP：丢弃 范例\n# 定义新的规则链 [root@rocky ~]# iptables -N web_chain ","permalink":"https://xyenvy.github.io/posts/firewall/","summary":"防火墙基本认识 Netfilter Linux防火墙是由Netfilter组件提供的，Netfilter工作在内核空间，集成在linux内核中。 Netfilter 是Linux 2.4.x之后新一代的Linux防火墙机制，是linux内核的一个子系统。Netfilter采用模块 化设计，具有良好的可扩充性，提供扩展各种网","title":"防火墙"},{"content":"名字解析介绍和DNS DNS服务工作原理 DNS查询类型 递归查询： 是指DNS服务器在收到用户发起的请求时，必须向用户返回一个准确的查询结果。如果DNS服务器 本地没有存储与之对应的信息，则该服务器需要询问其他服务器，并将返回的查询结构提交给用 户。 一般客户机和本地DNS服务器之间属于递归查询，即当客户机向DNS服务器发出请求后,若DNS服 务器本身不能解析，则会向另外的DNS服务器发出查询请求，得到最终的肯定或否定的结果后转交 给客户机。此查询的源和目标保持不变,为了查询结果只需要发起一次查询 递归算法:客户端向LocalDNS发起域名查询\u0026ndash;\u0026gt;localDNS不知道域名对应的IP\u0026ndash;\u0026gt;但它知道谁知道-\u0026gt;他 代为帮客户端去查找\u0026ndash;\u0026gt;最后再返回最终结果 迭代查询： 是指DNS服务器在收到用户发起的请求时，并不直接回复查询结果，而是告诉另一台DNS服务器的 地址，用户再向这台DNS服务器提交请求，这样依次反复，直到返回查询结果。 一般情况下(有例外)本地的DNS服务器向其它DNS服务器的查询属于迭代查询,如：若对方不能返回 权威的结果，则它会向下一个DNS服务器(参考前一个DNS服务器返回的结果)再次发起进行查询， 直到返回查询的结果为止。此查询的源不变,但查询的目标不断变化,为查询结果一般需要发起多次 查询 迭代算法︰\n客户端向LocalDNS发起域名查询\u0026ndash;\u0026gt;localDNS不知道域名对应的IP\u0026ndash;\u0026gt;但它知道谁知道并 推荐客户端应该找谁\u0026ndash;\u0026gt;客户端自己去找它 DNS缓存: DNS缓存是将解析数据存储在靠近发起请求的客户端的位置，也可以说DNS数据是可以缓存在任意 位置，最终目的是以此减少递归查询过程，可以更快的让用户获得请求结果。 解析类型 FQDN \u0026ndash;\u0026gt; IP 正向解析 IP \u0026ndash;\u0026gt; FQDN 反向解析\n注意：正反向解析是两个不同的名称空间，是两棵不同的解析树 完整查询流程 Client --\u0026gt;hosts文件 --\u0026gt; Client DNS Service Local Cache --\u0026gt; DNS Server (recursion递 归) --\u0026gt; DNS Server Cache --\u0026gt;DNS iteration(迭代) --\u0026gt; 根--\u0026gt; 顶级域名DNS--\u0026gt;二级域名DNS… DNS服务相关概念和技术 各种资源记录 区域解析库：由众多资源记录RR(Resource Record)组成 记录类型：A, AAAA, PTR, SOA, NS, CNAME, MX\nSOA：Start Of Authority，起始授权记录；一个区域解析库有且仅能有一个SOA记录，必须位于解析库的第一条记录 A：internet Address，作用，FQDN \u0026ndash;\u0026gt; IP AAAA：FQDN \u0026ndash;\u0026gt; IPv6 PTR：PoinTeR，IP \u0026ndash;\u0026gt; FQDN NS：Name Server，专用于标明当前区域的DNS服务器 CNAME ： Canonical Name，别名记录 MX：Mail eXchanger，邮件交换器 TXT：对域名进行标识和说明的一种方式，一般做验证记录时会使用此项，如：SPF（反垃圾邮件）记录，https验证等，如下示例 _dnsauth TXT 2012011200000051qgs69bwoh4h6nht4n1h0lr038x SOA记录 name: 当前区域的名字，例如\u0026quot;magedu.org.\u0026quot; value: 有多部分组成 注意：\n当前区域的主DNS服务器的FQDN，也可以使用当前区域的名字，只是注释功能，可以不需要配置 对应的NS记录和A记录 当前区域管理员的邮箱地址；但地址中不能使用@符号，一般用.替换，例如：admin.magedu.org 主从服务区域传输相关定义以及否定的答案的统一的TTL 范例\nmagedu.org. 86400 IN SOA ns.magedu.org. nsadmin.magedu.org. ( 2015042201 ;序列号 2H ;刷新时间 10M ;重试时间 1W ;过期时间 1D ;否定答案的TTL值 ) NS记录 name: 当前区域的名字 value: 当前区域的某DNS服务器的名字，例如: ns.magedu.org. 注意：\n相邻的两个资源记录的name相同时，后续的可省略\n对NS记录而言，任何一个ns记录后面的服务器名字，都应该在后续有一个A记录\n一个区域可以有多个NS记录\n范例：\nmagedu.org. IN NS ns1.magedu.org. magedu.org. IN NS ns2.magedu.org. MX记录 name: 当前区域的名字\nvalue: 当前区域的某邮件服务器(smtp服务器)的主机名\n注意：\n一个区域内，MX记录可有多个；但每个记录的value之前应该有一个数字(0-99)，表示此服务器的优先级；数字越小优先级越高\n对MX记录而言，任何一个MX记录后面的服务器名字，都应该在后续有一个A记录\n范例：\nmagedu.org. IN MX 10 mx1.magedu.org. IN MX 20 mx2.magedu.org. mx1 A 10.0.0.100 mx2 A 10.0.0.200 A记录 name: 某主机的FQDN，例如：www.magedu.org.\nvalue: 主机名对应主机的IP地址\n避免用户写错名称时给错误答案，可通过泛域名解析进行解析至某特定地址\n范例：\nwww.magedu.org. IN A 1.1.1.1 www.magedu.org. IN A 2.2.2.2 mx1.magedu.org. IN A 3.3.3.3 mx2.magedu.org. IN A 4.4.4.4 $GENERATE 1-254 HOST$ IN A 1.2.3.$ *.magedu.org. IN A 5.5.5.5 magedu.org. IN A 6.6.6.6 #注意：如果有和DNS的IP相同的多个同名的A记录，优先返回DNS的本机IP AAAA记录 name: FQDN value: IPv6 PTR记录 name: IP，有特定格式，把IP地址反过来写，1.2.3.4，要写作4.3.2.1；而有特定后缀：in- addr.arpa.，所以完整写法为：4.3.2.1.in-addr.arpa. value: FQDN 注意：网络地址及后缀可省略；主机地址依然需要反着写 例如：\n4.3.2.1.in-addr.arpa. IN PTR www.magedu.org. #如1.2.3为网络地址，可简写成： 4 IN PTR www.magedu.org. CNAME别名记录 name: 别名的FQDN value: 真正名字的FQDN 例如\nwww.magedu.org. IN CNAME websrv.magedu.org. DNS软件bind DNS服务器软件：bind，powerdns，dnsmasq，unbound，coredns\nbind相关程序包 yum list all bind*\nbind：服务器 bind-utils: 客户端 bind-libs：相关库,依赖关系自动安装 bind-chroot: 安全包，将dns相关文件放至 /var/named/chroot/\n范例：安装bind软件\n[root@centos8 ~]#dnf -y install bind bind-utils [root@ubuntu2004 ~]#apt -y install bind9 bind9-utils bind包相关文件 BIND主程序：/usr/sbin/named 服务脚本和Unit名称：/etc/rc.d/init.d/named，/usr/lib/systemd/system/named.service 主配置文件：/etc/named.conf, /etc/named.rfc1912.zones, /etc/rndc.key 管理工具：/usr/sbin/rndc：remote name domain controller，默认与bind安装在同一主机，且 只能通过127.0.0.1连接named进程，提供辅助性的管理功能；953/tcp 解析库文件：/var/named/ZONE_NAME.ZONE 注意： (1) 一台物理服务器可同时为多个区域提供解析 (2) 必须要有根区域文件；named.ca (3) 应该有两个（如果包括ipv6的，应该更多）实现localhost和本地回环地址的解析库\n主配置文件 全局配置：options {}; 日志子系统配置：logging {}; 区域定义：本机能够为哪些zone进行解析，就要定义哪些zone zone \u0026ldquo;ZONE_NAME\u0026rdquo; IN {}; 注意： 任何服务程序如果期望其能够通过网络被其它主机访问，至少应该监听在一个能与外部主机通信的 IP地址上 缓存名称服务器的配置：监听外部地址即可 dnssec: 建议关闭dnssec，设为no ","permalink":"https://xyenvy.github.io/posts/dns/","summary":"名字解析介绍和DNS DNS服务工作原理 DNS查询类型 递归查询： 是指DNS服务器在收到用户发起的请求时，必须向用户返回一个准确的查询结果。如果DNS服务器 本地没有存储与之对应的信息，则该服务器需要询问其他服务器，并将返回的查询结构提交给用 户。 一般客户机和本地DNS服务器之间属于递归","title":"DNS服务"},{"content":"多主机协作工作时，各个主机的时间同步很重要，时间不一致会造成很多重要应用的故障，如：加密协议，日志，集群等， 利用NTP（Network Time Protocol） 协议使网络中的各个计算机时间达到同步。目前NTP协议属于运维基础架构中必备的基本服务之一\n时间同步服务 时间同步软件\nntpdate chrony ntp:\n将系统时钟和世界协调时钟UTC同步，精度在局域网内可达0.1ms，在互联网上绝大多数的地方精度可以 达到1-50ms 项目官网：\nhttp://www.ntp.org 范例：ubuntu同步时间\n安装ntpdate apt install ntpdate 同步时间 # ntp.aliyun.com阿里云时间同步服务器地址 ntpdate ntp.aliyun.com 扩展：\n阿里云公共NTP服务器 Unix/linux类：ntp.aliyun.com，ntp1-7.aliyun.com windows类： time.pool.aliyun.com 腾讯公共NTP time1-5.cloud.tencent.com 大学ntp服务 s1a.time.edu.cn 北京邮电大学 s1b.time.edu.cn 清华大学 s1c.time.edu.cn 北京大学 国家授时中心服务器：210.72.145.44 美国标准技术院: time.nist.gov 注意：CentOS 8上已经没有ntpdate命令，因此该种时间同步方式不建议使用\nchrony： 实现NTP协议的的自由软件。可使系统时钟与NTP服务器，参考时钟（例如GPS接收器）以及使用手表 和键盘的手动输入进行同步。还可以作为NTPv4（RFC 5905）服务器和对等体运行，为网络中的计算机 提供时间服务。设计用于在各种条件下良好运行，包括间歇性和高度拥挤的网络连接，温度变化（计算 机时钟对温度敏感），以及不能连续运行或在虚拟机上运行的系统。 通过Internet同步的两台机器之间的典型精度在几毫秒之内，在LAN上，精度通常为几十微秒。利用硬 件时间戳或硬件参考时钟，可实现亚微秒的精度\nchrony chrony介绍 chrony 的优势：\n更快的同步只需要数分钟而非数小时时间，从而最大程度减少了时间和频率误差，对于并非全天24 小时运行的虚拟计算机而言非常有用\n能够更好地响应时钟频率的快速变化，对于具备不稳定时钟的虚拟机或导致时钟频率发生变化的节 能技术而言非常有用\n在初始同步后，它不会停止时钟，以防对需要系统时间保持单调的应用程序造成影响\n在应对临时非对称延迟时（例如，在大规模下载造成链接饱和时）提供了更好的稳定性\n无需对服务器进行定期轮询，因此具备间歇性网络连接的系统仍然可以快速同步时钟\nchrony官网:\nhttps://chrony.tuxfamily.org chrony官方文档：https://chrony.tuxfamily.org/documentation.html chrony 文件组成 包：chrony\n两个主要程序：chronyd和chronyc\nchronyd：后台运行的守护进程，用于调整内核中运行的系统时钟和时钟服务器同步。它确定计算 机增减时间的比率，并对此进行补偿 chronyc：命令行用户工具，用于监控性能并进行多样化的配置。它可以在chronyd实例控制的计 算机上工作，也可在一台不同的远程计算机上工作\n服务unit 文件： /usr/lib/systemd/system/chronyd.service 监听端口： 服务端: 123/udp,客户端: 323/udp 配置文件： /etc/chrony.conf 配置文件chrony.conf 官网文档:\nhttps://chrony.tuxfamily.org/doc/3.5/chrony.conf.html server #可用于时钟服务器，iburst 选项当服务器可达时，发送一个八个数据包而不是通常的一个数据 包。 包间隔通常为2秒,可加快初始同步速度 pool #该指令的语法与server 指令的语法相似，不同之处在于它用于指定NTP服务器池而不是单个 NTP服务器。池名称应解析为随时间可能会变化的多个地址 driftfile #根据实际时间计算出计算机增减时间的比率，将它记录到一个文件中，会在重启后为系统时钟作 出补偿 rtcsync #启用内核模式，系统时间每11分钟会拷贝到实时时钟（RTC） allow / deny #指定一台主机、子网，或者网络以允许或拒绝访问本服务器 cmdallow / cmddeny #可以指定哪台主机可以通过chronyd使用控制命令 bindcmdaddress #允许chronyd监听哪个接口来接收由chronyc执行的命令 makestep # 通常chronyd将根据需求通过减慢或加速时钟，使得系统逐步纠正所有时间偏差。在某些特定 情况下，系统时钟可能会漂移过快，导致该调整过程消耗很长的时间来纠正系统时钟。该指令强制chronyd在 调整期大于某个阀值时调整系统时钟 local stratum 10 #即使server指令中时间服务器不可用，也允许将本地时间作为标准时间授时给其它 客户端 NTP 客户端工具 chronyc 可以运行在交互式和非交互式两种方式，支持以下子命令\nhelp 命令可以查看更多chronyc的交互命令 accheck 检查是否对特定主机可访问当前服务器 activity 显示有多少NTP源在线/离线 sources [-v] 显示当前时间源的同步信息 sourcestats [-v]显示当前时间源的同步统计信息 add server 手动添加一台新的NTP服务器 clients 报告已访问本服务器的客户端列表 delete 手动移除NTP服务器或对等服务器 settime 手动设置守护进程时间 tracking 显示系统时间信息 时间工具 timedatectl 时间和时区管理 查看日期时间和时区以及NTP状态\nroot@ubuntu2004:~# timedatectl Local time: Sat 2022-09-17 11:49:00 UTC Universal time: Sat 2022-09-17 11:49:00 UTC RTC time: Sat 2022-09-17 11:49:00 Time zone: Etc/UTC (UTC, +0000) System clock synchronized: yes NTP service: active RTC in local TZ: no root@ubuntu2004:~# 查看时区列表\nroot@ubuntu2004:~# root@ubuntu2004:~# timedatectl list-timezones Africa/Abidjan Africa/Accra Africa/Addis_Ababa Africa/Algiers Africa/Asmara Africa/Asmera Africa/Bamako Africa/Bangui Africa/Banjul Africa/Bissau Africa/Blantyre Africa/Brazzaville Africa/Bujumbura Africa/Cairo Africa/Casablanca Africa/Ceuta ......... ......... 修改时区\n# 修改时区亚洲上海 root@ubuntu2004:~# timedatectl set-timezone Asia/Shanghai root@ubuntu2004:~# 修改时区方式2\n#修改时区 root@ubuntu2004:~# rm -f /etc/localtime root@ubuntu2004:~# ln -s /usr/share/zoneinfo/Asia/Shanghai /etc/localtime #修改日期时间： timedatectl set-time \u0026#34;2017-01-23 10:30:00\u0026#34; #开启NTP： timedatectl set-ntp true/false 修改时间\n#修改日期时间： timedatectl set-time \u0026#34;2017-01-23 10:30:00\u0026#34; #需要修改时间为24小时，可以修改/etc/default/locale，默认没有LC_TIME这个变量，在文件中增加一行： LC_TIME=en_DK.UTF-8 #开启NTP： timedatectl set-ntp true/false 实战：实现私有的时间服务器 安装chrony # centos系统检查是否安装 rpm -q chrony # 安装 yum install chrony # 启动服务 systemctl start chronyd # ubuntu系统上安装,ubuntu系统上安装完成后已经启动 apt install chrony 服务器端配置 # IP:192.168.179.146作为时间同步服务器端，192.168.179.146的时间与阿里云时间同步器服务器同步 [root@centos7 ~]# hostname -I 192.168.179.146 [root@centos7 ~]# # 修改192.168.179.146配置文件 /etc/chrony.conf server ntp.aliyun.com iburst server ntp1.aliyun.com iburst server ntp2.aliyun.com iburst allow 0.0.0.0/0 #加此行,指定允许同步的网段\n删除此行注释,当互联网无法连接,仍然可以为客户端提供时间同步服务\n重启chrony服务\nsystemctl restart chronyd 服务启动后会打开端口123/udp\n显示当前的时间源同步信息\n[root@centos7 ~]# chronyc sources -V 210 Number of sources = 2 MS Name/IP address Stratum Poll Reach LastRx Last sample =============================================================================== ^* 203.107.6.88 2 6 37 58 -365us[-3079us] +/- 40ms ^? 120.25.115.20 2 7 110 123 -773us[-3488us] +/- 26ms [root@centos7 ~]# # *号表示当前同步的时间源地址 客户端配置\n# 客户端 root@ubuntu2004:~# hostname -I 192.168.179.147 root@ubuntu2004:~# #ubuntu系统配置文件与centos目录不一样 root@ubuntu2004:~# vim /etc/chrony/chrony.conf 重启chrony服务\nroot@ubuntu2004:~# systemctl restart chronyd 确认同步成功\nroot@ubuntu2004:~# chronyc sources -V 210 Number of sources = 1 MS Name/IP address Stratum Poll Reach LastRx Last sample =============================================================================== ^* 192.168.179.146 3 6 17 44 +64us[ +218us] +/- 38ms root@ubuntu2004:~# # ^* 192.168.179.146表示已经成功与192.168.179.146时间同步 ","permalink":"https://xyenvy.github.io/posts/%E6%97%B6%E9%97%B4%E5%90%8C%E6%AD%A5%E6%9C%8D%E5%8A%A1/","summary":"多主机协作工作时，各个主机的时间同步很重要，时间不一致会造成很多重要应用的故障，如：加密协议，日志，集群等， 利用NTP（Network Time Protocol） 协议使网络中的各个计算机时间达到同步。目前NTP协议属于运维基础架构中必备的基本服务之一 时间同步服务 时间同步软件 ntpdate chrony ntp: 将系统时","title":"时间同步服务"},{"content":"#!/bin/bash # 检查sshpass是否安装，没有安装则安装sshpass rpm -q sshpass \u0026amp;\u0026gt; /dev/null || yum install sshpass # 主机root用户密码 export SSHPASS=123456 # 主机地址 NET=192.168.179 # 主机地址 for i in {20..140};do { # 生成随机密码 PASS=`openssl rand -base64 9` # 链接远程主机并修改root用户密码 StrictHostKeyChecking=no 跳过检查 sshpass -e ssh -o StrictHostKeyChecking=no ${NET}.${i} \u0026#34;echo root:${PASS} | chpasswd \u0026amp;\u0026gt; /dev/null\u0026#34; # IP和密码重定向到文件中 echo $NET.$i:$PASS \u0026gt;\u0026gt; host.txt }\u0026amp; # 后台运行 done wait sshpass使用帮助\n[root@centos7 data]# sshpass --help sshpass: invalid option -- \u0026#39;-\u0026#39; Usage: sshpass [-f|-d|-p|-e] [-hV] command parameters -f filename Take password to use from file -d number Use number as file descriptor for getting password -p password Provide password as argument (security unwise) -e Password is passed as env-var \u0026#34;SSHPASS\u0026#34; With no parameters - password will be taken from stdin -P prompt Which string should sshpass search for to detect a password prompt -v Be verbose about what you\u0026#39;re doing -h Show help (this screen) -V Print version information At most one of -f, -d, -p or -e should be used [root@centos7 data]# ","permalink":"https://xyenvy.github.io/posts/%E6%89%B9%E9%87%8F%E4%BF%AE%E6%94%B9%E4%B8%BB%E6%9C%BA%E5%AF%86%E7%A0%81%E4%B8%BA%E9%9A%8F%E6%9C%BA%E5%AD%97%E7%AC%A6/","summary":"#!/bin/bash # 检查sshpass是否安装，没有安装则安装sshpass rpm -q sshpass \u0026amp;\u0026gt; /dev/null || yum install sshpass # 主机root用户密码 export SSHPASS=123456 # 主机地址 NET=192.168.179 # 主机地址 for i in {20..140};do { # 生成随机密码 PASS=`openssl rand -base64 9` # 链接远程主机并修改root用户密码 StrictHostKeyChecking=no 跳过检查 sshpass -e ssh -o StrictHostKeyChecking=no ${NET}.${i} \u0026#34;echo root:${PASS} | chpasswd \u0026amp;\u0026gt; /dev/null\u0026#34; # IP和密码重定向到文件中 echo $NET.$i:$PASS \u0026gt;\u0026gt; host.txt }\u0026amp; # 后台运行 done wait s","title":"批量修改主机密码为随机字符"},{"content":"ssh: secure shell protocol, 22/tcp, 安全的远程登录，实现加密通信，代替传统的 telnet 协议\nssh服务介绍 ssh: secure shell protocol, 22/tcp, 安全的远程登录，实现加密通信，代替传统的 telnet 协议 具体的软件实现：\nOpenSSH：ssh协议的开源实现，CentOS 默认安装 dropbear：另一个ssh协议的开源项目的实现 SSH 协议版本\nv1：基于CRC-32做MAC，不安全；man-in-middle v2：双方主机协议选择安全的MAC方式，基于DH算法做密钥交换，基于RSA或DSA实现身份认证 openssh 服务 OpenSSH是SSH （Secure SHell） 协议的免费开源实现，一般在各种Linux版本中会默认安装，基于C/S结构 Openssh软件相关包：\nopenssh openssh-clients openssh-server 客户端 ssh命令 ssh命令是ssh客户端，允许实现对远程系统经验证地加密安全访问\n当用户远程连接ssh服务器时，会复制ssh服务器/etc/ssh/ssh_host*key.pub文件中的公钥到客户机的~/.ssh/know_hosts中。下次连接时，会自动匹配相对应的私钥，不能匹配，将拒绝连接 ssh客户端配置文件： /etc/ssh/ssh_config 主要配置:\n#StrictHostKeyChecking ask #首次登录不显示检查提示 StrictHostKeyChecking no # IdentityFile ~/.ssh/id_rsa # IdentityFile ~/.ssh/id_dsa # IdentityFile ~/.ssh/id_ecdsa # IdentityFile ~/.ssh/id_ed25519 # Port 22 范例：禁止首次连接的询问过程\n[root@centos7 ~]#sed -i.bak \u0026#39;/StrictHostKeyChecking/s/.*/StrictHostKeyChecking no/\u0026#39; /etc/ssh/ssh_config 格式\nssh [user@]host [COMMAND] ssh [-l user] host [COMMAND] 常用选项\n-p port #远程服务器监听的端口 -b #指定连接的源IP -v #调试模式 -C #压缩方式 -X #支持x11转发 -t #强制伪tty分配，如：ssh -t remoteserver1 ssh -t remoteserver2 ssh remoteserver3 -o option 如：-o StrictHostKeyChecking=no -i \u0026lt;file\u0026gt; #指定私钥文件路径，实现基于key验证，默认使用文件： ~/.ssh/id_dsa, ~/.ssh/id_ecdsa, ~/.ssh/id_ed25519，~/.ssh/id_rsa等 在远程主机执行本地脚本\n[root@rocky ~]# cat test.sh #!/bin/bash hostname -I [root@rocky ~]# ssh root@192.168.179.145 /bin/bash \u0026lt;test.sh root@192.168.179.145\u0026#39;s password: 192.168.179.145 [root@rocky ~]# 其他ssh客户端工具 scp命令 scp [options] SRC... DEST/ 方式：\nscp [options] [user@]host:/sourcefile /destpath scp [options] /sourcefile [user@]host:/destpath scp [options] [user@]host1:/sourcetpath [user@]host2:/destpath 常用选项\n-C 压缩数据流 -r 递归复制 -p 保持原文件的属性信息 -q 静默模式 -P PORT 指明remote host的监听的端口 ```bash **范例:从远程机器复制文件到本地目录** ```TEXT scp root@10.10.10.10:/opt/soft/nginx-0.5.38.tar.gz /opt/soft/ 范例： 上传本地文件到远程机器指定目录*\nscp /opt/soft/nginx-0.5.38.tar.gz root@10.10.10.10:/opt/soft/scptest 注:复制目录加上选项-r\nrsync命令 rsync工具可以基于ssh和rsync协议实现高效率的远程系统之间复制文件，使用安全的shell连接做为传输方式，比scp更快，基于增量数据同步，即只复制两方不同的文件，此工具来自于rsync包 注意：通信两端主机都需要安装 rsync 软件\nrsync -av /etc server1:/tmp/ #复制目录和目录下文件 rsync -av /etc/ server1:/tmp/ #只复制目录下文件 常用选型\n-n 模拟复制过程 -v 显示详细过程 -r 递归复制目录树 -p 保留权限 -t 保留修改时间戳 -g 保留组信息 -o 保留所有者信息 -l 将软链接文件本身进行复制（默认） -L 将软链接文件指向的文件复制 -u 如果接收者的文件比发送者的文件较新，将忽略同步 -z 压缩，节约网络带宽 -a 存档，相当于-rlptgoD，但不保留ACL（-A）和SELinux属性（-X） --delete 源数据删除，目标数据也自动同步删除 --progress 显示进度 --bwlimit=5120 #限速以KB为单位,5120表示5MB 范例:复制文件到远程主机目录下\nrsync ./test.sh root@192.168.179.145:/root 自动登录 ssh工具 sshpass 由EPEL源提供，ssh登陆不能在命令行中指定密码。sshpass的出现，解决了这一问题。sshpass用于非 交互SSH的密码验证，一般用在sh脚本中，无须再次输入密码（本机known_hosts文件中有的主机才能 生效）。它允许你用 -p 参数指定明文密码，然后直接登录远程服务器，它支持密码从命令行、文件、环 境变量中读取。 格式：\nsshpass [option] command parameters 常用选项\n-p password #后跟密码它允许你用 -p 参数指定明文密码，然后直接登录远程服务器 -f filename #后跟保存密码的文件名，密码是文件内容的第一行 -e #将环境变量SSHPASS作为密码 范例:登录远程主机执行指定命令\n# 检测sshpass是否安装 [root@rocky ~]# rpm -q sshpass package sshpass is not installed # 安装sshpass [root@rocky ~]# yum install sshpass # 登录远程主机，首次登录不显示检查提示，执行hostname -I命令 [root@rocky ~]# sshpass -p 123456 ssh -o StrictHostKeyChecking=no root@192.168.179.145 hostname -I 192.168.179.145 [root@rocky ~]# 实现基于密钥登录方式验证 在客户端生成密钥对\nssh-keygen -t rsa [-P \u0026#39;password\u0026#39;] [-f “~/.ssh/id_rsa\u0026#34;] 把公钥文件传输至远程服务器对应用户的家目录\nssh-copy-id [-i [identity_file]] [user@]host 重设私钥口令：\nssh-keygen -p 在SecureCRT或Xshell实现基于key验证 在SecureCRT工具—\u0026gt;创建公钥—\u0026gt;生成Identity.pub文件 转化为openssh兼容格式（适合SecureCRT，Xshell不需要转化格式），并复制到需登录主机上相应文 件authorized_keys中,注意权限必须为600，在需登录的ssh主机上执行：\nssh-keygen -i -f Identity.pub \u0026gt;\u0026gt; .ssh/authorized_keys 范例：实现基于 key 验证\n[root@centos8 ~]#ssh-keygen Generating public/private rsa key pair. Enter file in which to save the key (/root/.ssh/id_rsa): #回车，接受默认值 Enter passphrase (empty for no passphrase): #回车，接受默认值，空密码 Enter same passphrase again: #回车，接受默认值 Your identification has been saved in /root/.ssh/id_rsa. Your public key has been saved in /root/.ssh/id_rsa.pub. The key fingerprint is: SHA256:vpPtmqRv1llmoSvqT2Lx5C0LPGTE0pvdAqhDqlR5jLY root@centos8.wangxiaochun.com The key\u0026#39;s randomart image is: +---[RSA 3072]----+ | | | ++ | | .=oo= | | oo.oo = . . | |..oE * S .. . | |o . + * o. + | |. * B+.* | | . B*== | | .+*B=. | +----[SHA256]-----+ [root@centos8 ~]#ll .ssh/ total 8 -rw------- 1 root root 2622 May 22 09:51 id_rsa -rw-r--r-- 1 root root 583 May 22 09:51 id_rsa.pub [root@centos8 ~]# # 将本主机的公钥复制到远程主机的authorized_keys中 [root@centos8 ~]#ssh-copy-id root@10.0.0.7 /usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: \u0026#34;/root/.ssh/id_rsa.pub\u0026#34; The authenticity of host \u0026#39;10.0.0.7 (10.0.0.7)\u0026#39; can\u0026#39;t be established. ECDSA key fingerprint is SHA256:s//WMgPVXmOjqfOg3f3X0nmaPZF+Fj5vPdWCnAzDcpU. Are you sure you want to continue connecting (yes/no/[fingerprint])? yes /usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed /usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys root@10.0.0.7\u0026#39;s password: #输入远程用户的密码 Number of key(s) added: 1 Now try logging into the machine, with: \u0026#34;ssh \u0026#39;10.0.0.7\u0026#39;\u0026#34; and check to make sure that only the key(s) you wanted were added. #对私钥加密 [root@centos8 ~]#ssh-keygen -p ssh服务配置 服务器端：sshd 服务器端的配置文件: /etc/ssh/sshd_config 服务器端的配置文件帮助：man 5 sshd_config 常用参数：\nPort 22 #生产建议修改 ListenAddress ip LoginGraceTime 2m PermitRootLogin yes #默认ubuntu不允许root远程ssh登录 StrictModes yes #检查.ssh/文件的所有者，权限等 MaxAuthTries 6 #pecifies the maximum number of authentication attempts permitted per connection. Once the number of failures reaches half this value, additional failures are logged. The default is 6. MaxSessions 10 #同一个连接最大会话 PubkeyAuthentication yes #基于key验证 PermitEmptyPasswords no #空密码连接 PasswordAuthentication yes #基于用户名和密码连接 GatewayPorts no ClientAliveInterval 10 #单位:秒 ClientAliveCountMax 3 #默认3 UseDNS yes #提高速度可改为no GSSAPIAuthentication yes #提高速度可改为no MaxStartups #未认证连接最大值，默认值10 Banner /path/file #以下可以限制可登录用户的办法： AllowUsers user1 user2 user3 DenyUsers user1 user2 user3 AllowGroups g1 g2 DenyGroups g1 g2 范例：设置 ssh 空闲60s 自动注销\nVim /etc/ssh/sshd_config ClientAliveInterval 60 ClientAliveCountMax 0 Service sshd restart #注意：新开一个连接才有效 范例：解决ssh登录缓慢的问题\nvim /etc/ssh/sshd_config UseDNS no GSSAPIAuthentication no systemctl restart sshd ","permalink":"https://xyenvy.github.io/posts/ssh%E6%9C%8D%E5%8A%A1/","summary":"ssh: secure shell protocol, 22/tcp, 安全的远程登录，实现加密通信，代替传统的 telnet 协议 ssh服务介绍 ssh: secure shell protocol, 22/tcp, 安全的远程登录，实现加密通信，代替传统的 telnet 协议 具体的软件实现： OpenSSH：ssh协议的开源实现，CentOS 默认安装 dropbear：另一个ssh协议的开源项目的实现 SSH 协议版本 v1：基于CRC-3","title":"ssh服务"},{"content":"OpenSSL计划在1998年开始，其目标是发明一套自由的加密工具，在互联网上使用。OpenSSL以Eric Young以及Tim Hudson两人开发的SSLeay为基础，随着两人前往RSA公司任职，SSLeay在1998年12月停止开发。因此在1998年12月，社群另外分支出OpenSSL，继续开发下去\n在rocky上实现私有CA和证书申请 创建CA相关目录和文件/etc/pki/CA [root@rocky pki]# mkdir -pv /etc/pki/CA/{certs,crl,newcerts,private} mkdir: created directory \u0026#39;/etc/pki/CA\u0026#39; mkdir: created directory \u0026#39;/etc/pki/CA/certs\u0026#39; mkdir: created directory \u0026#39;/etc/pki/CA/crl\u0026#39; mkdir: created directory \u0026#39;/etc/pki/CA/newcerts\u0026#39; mkdir: created directory \u0026#39;/etc/pki/CA/private\u0026#39; [root@rocky pki]# 创建index.txt文件(/etc/pki/CA目录下) [root@rocky CA]# touch index.txt #指定第一个颁发证书的序列号，为16进制数 [root@rocky CA]# echo 01 \u0026gt; /etc/pki/CA/serial 0F /etc/pki/CA/certs [root@rocky CA]# [root@rocky CA]# tree . ├── certs ├── crl ├── index.txt ├── newcerts └── private 4 directories, 1 file [root@rocky CA]# 创建CA的私钥 [root@rocky CA]# pwd /etc/pki/CA #因为加了小括号，因此是在子进程中运行的，umask的值不会影响当前进程 [root@rocky CA]# (umask 066;openssl genrsa -out private/cakey.pem 2048) Generating RSA private key, 2048 bit long modulus (2 primes) .................................................................................................................................+++++ .............+++++ e is 65537 (0x010001) [root@rocky CA]# 给CA颁发自签名证书 [root@rocky pki]# openssl req -new -x509 -key /etc/pki/CA/private/cakey.pem -days 3650 -out /etc/pki/CA/cacert.pem You are about to be asked to enter information that will be incorporated into your certificate request. What you are about to enter is what is called a Distinguished Name or a DN. There are quite a few fields but you can leave some blank For some fields there will be a default value, If you enter \u0026#39;.\u0026#39;, the field will be left blank. ----- Country Name (2 letter code) [XX]:CN # 指定国家 State or Province Name (full name) []:guizhou # 指定省 Locality Name (eg, city) [Default City]:duyun # 指定城市 Organization Name (eg, company) [Default Company Ltd]:magedu # 公司 Organizational Unit Name (eg, section) []:it # 部门 Common Name (eg, your name or your server\u0026#39;s hostname) []:m48 # 指定给颁发者 Email Address []: # 邮箱地址 参数说明\n-new：生成新证书签署请求； -x509：专用用于CA生成字签证书 -key：生成请求时用到的私钥文件 -day：证书的有效期限 -out：证书的保存路径（在配置文件当中有固定路径，该文件可以自动生成） 用户生成私钥和证书申请 [root@rocky CA]# mkdir -pv /data/app1 mkdir: created directory \u0026#39;/data\u0026#39; mkdir: created directory \u0026#39;/data/app1\u0026#39; [root@rocky CA]# # 生成私钥文件 [root@rocky app1]# (umask 066;openssl genrsa -out /data/app1/app1.key 2048) Generating RSA private key, 2048 bit long modulus (2 primes) .......................+++++ .............+++++ e is 65537 (0x010001) [root@rocky app1]# #生成证书申请文件 [root@rocky app1]# openssl req -new -key /data/app1/app1.key -out /data/app1/app1.csr You are about to be asked to enter information that will be incorporated into your certificate request. What you are about to enter is what is called a Distinguished Name or a DN. There are quite a few fields but you can leave some blank For some fields there will be a default value, If you enter \u0026#39;.\u0026#39;, the field will be left blank. ----- Country Name (2 letter code) [XX]:guizhou string is too long, it needs to be no more than 2 bytes long Country Name (2 letter code) [XX]:duyun^C [root@rocky app1]# openssl req -new -key /data/app1/app1.key -out /data/app1/app1.csr You are about to be asked to enter information that will be incorporated into your certificate request. What you are about to enter is what is called a Distinguished Name or a DN. There are quite a few fields but you can leave some blank For some fields there will be a default value, If you enter \u0026#39;.\u0026#39;, the field will be left blank. ----- Country Name (2 letter code) [XX]:CN State or Province Name (full name) []:guizhou Locality Name (eg, city) [Default City]:duyun Organization Name (eg, company) [Default Company Ltd]:magedu Organizational Unit Name (eg, section) []:it Common Name (eg, your name or your server\u0026#39;s hostname) []:m48 Email Address []: 注意：默认要求 国家，省，公司名称三项必须和CA一致\nCA颁发证书 [root@rocky CA]# openssl ca -in /data/app1/app1.csr -out /etc/pki/CA/certs/app1.crt -days 1000 Using configuration from /etc/pki/tls/openssl.cnf Check that the request matches the signature Signature ok Certificate Details: Serial Number: 1 (0x1) Validity Not Before: Sep 12 04:28:42 2022 GMT Not After : Jun 8 04:28:42 2025 GMT Subject: countryName = CN stateOrProvinceName = guizhou organizationName = magedu organizationalUnitName = it commonName = m48 X509v3 extensions: X509v3 Basic Constraints: CA:FALSE Netscape Comment: OpenSSL Generated Certificate X509v3 Subject Key Identifier: F9:E4:5D:C9:C7:70:0C:E9:17:CC:90:88:7E:78:20:57:38:04:EC:69 X509v3 Authority Key Identifier: keyid:EA:34:E4:C1:8C:1B:F2:F9:22:D5:A2:AE:BD:2F:EA:13:28:24:43:60 Certificate is to be certified until Jun 8 04:28:42 2025 GMT (1000 days) Sign the certificate? [y/n]:y 1 out of 1 certificate requests certified, commit? [y/n]y Write out database with 1 new entries Data Base Updated [root@rocky CA]# 查看证书 [root@rocky CA]# cat /etc/pki/CA/certs/app1.crt Certificate: Data: Version: 3 (0x2) Serial Number: 1 (0x1) Signature Algorithm: sha256WithRSAEncryption Issuer: C=CN, ST=guizhou, L=duyun, O=magedu, OU=it, CN=m48 Validity Not Before: Sep 12 04:28:42 2022 GMT Not After : Jun 8 04:28:42 2025 GMT Subject: C=CN, ST=guizhou, O=magedu, OU=it, CN=m48 Subject Public Key Info: Public Key Algorithm: rsaEncryption RSA Public-Key: (2048 bit) Modulus: 00:b1:d4:eb:6e:8d:32:db:5e:ce:5d:6c:43:73:ef: 28:d3:08:8b:ae:8b:42:bf:6a:57:27:76:03:fe:ac: 55:62:2f:7a:9c:97:37:aa:53:40:df:35:6c:be:28: c1:c2:b5:e0:af:f0:d3:be:40:3c:15:1e:59:47:40: f0:85:20:c2:da:ca:83:a2:6f:7a:89:3d:35:ba:cf: 03:cb:cd:e0:15:96:76:56:23:30:ce:be:c6:1e:d0: a1:fb:27:0c:0f:cf:19:1b:03:9a:08:c8:a2:f1:46: 18:b6:f0:08:ef:10:26:12:2b🇩🇪ba:a3:9b:8e:f5: 13🆎6a:4d:08:8c:59:30:ef:78:d1:29:6d:3a:4e: df:c0:cc:d8:04:84:e8:3d:5f:90:67:45:b5:a8:22: 8f:6f:ad:83:c9:04:ba:5e:98:3f:f8:2b:49:45:31: 01:0e:7d:60:b3:ad:44:5f:9d:90:6c:34:9d:5c:31: 26:01:d3:75:fe:58:66:81:b5:d9:b3:83:99:e0:10: 62:26:37:62:0e:6c:ea:06:ff:3e:b6:a1:c0:e2:27: 0e:85:4c:44:eb:84:16:b6:36:b9:4f:74:fa:c7:89: 32:a2:c4:e3:d4:11:a2:7c:61:2d:82:a8:3d:2c:e3: 17:c4:ec🇩🇪ae:28:07:07:94:3c:62:1d:49:c0:c0: 12:41 Exponent: 65537 (0x10001) X509v3 extensions: X509v3 Basic Constraints: CA:FALSEs Netscape Comment: OpenSSL Generated Certificate X509v3 Subject Key Identifier: F9:E4:5D:C9:C7:70:0C:E9:17:CC:90:88:7E:78:20:57:38:04:EC:69 X509v3 Authority Key Identifier: keyid:EA:34:E4:C1:8C:1B:F2:F9:22:D5:A2:AE:BD:2F:EA:13:28:24:43:60 Signature Algorithm: sha256WithRSAEncryption 0c:90:51:c2:89:75:d7:e1:92:e7:a3:90:cb:f0:c0:96:a7:0f: 9f:e6:b5:2b:45:ed:be:ee:86:cf:0c:f9:06:9c:21:27:25:f8: 6c:d9:1c:84:87:8f:df:c2:c9:8f:65:7a:e9:84:2c:13:a8:1d: d9🆎65:02:c4:d5:8f:b3:17:a1:7c:d3:e3:06:83:06:43:5c: f6:a1:1a:b8:f4:98:7c:28:a9:4e:44:f5:82:ac:9f:77:b7:2f: cd:a6:c7:df:8c:24:84:0c:36:ad:2e:69:24:b7:0f:17:80:7d: f5:57:4c:df:8d:fb:7d:9e:27:22:bb:7e:b9:e4:aa:45:63:63: 41:00:64:c6:ff:69:47:1c:b2:ca:49:2a:56:3a:9c:c0:3b:19: 58:64:22:c2:e2:6c:27:bb:c1:d6:8f:55:a0:77:a0:a8:10:6d: 5c:cb:01:50:91🆎86:ac:88:ee:dc:0e:9d:6c:35:c4:7b:fe: 33:52:a3:f8:a8:25:1d:51:51:ed:2c:25:cf:c7:d3:18:73:81: 42:0f:6f:b7:e6:3f:87:2a:12:4b:71:9c:a1:c2:07:91:a6:10: 5f:5f:c2:28:59:f6:2b:ba:ff:d6:56:69:03:c2:49:36:f0:35: b4:38:70:7c:29:b8:f6:7d:72:c7:6f:cf:23:ef:e2:5f:d3:73: fc:26:9a:ec -----BEGIN CERTIFICATE----- MIIDnDCCAoSgAwIBAgIBATANBgkqhkiG9w0BAQsFADBbMQswCQYDVQQGEwJDTjEQ MA4GA1UECAwHZ3VpemhvdTEOMAwGA1UEBwwFZHV5dW4xDzANBgNVBAoMBm1hZ2Vk dTELMAkGA1UECwwCaXQxDDAKBgNVBAMMA200ODAeFw0yMjA5MTIwNDI4NDJaFw0y NTA2MDgwNDI4NDJaMEsxCzAJBgNVBAYTAkNOMRAwDgYDVQQIDAdndWl6aG91MQ8w DQYDVQQKDAZtYWdlZHUxCzAJBgNVBAsMAml0MQwwCgYDVQQDDANtNDgwggEiMA0G CSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCx1OtujTLbXs5dbENz7yjTCIuui0K/ alcndgP+rFViL3qclzeqU0DfNWy+KMHCteCv8NO+QDwVHllHQPCFIMLayoOib3qJ PTW6zwPLzeAVlnZWIzDOvsYe0KH7JwwPzxkbA5oIyKLxRhi28AjvECYSK966o5uO 9ROrak0IjFkw73jRKW06Tt/AzNgEhOg9X5BnRbWoIo9vrYPJBLpemD/4K0lFMQEO fWCzrURfnZBsNJ1cMSYB03X+WGaBtdmzg5ngEGImN2IObOoG/z62ocDiJw6FTETr hBa2NrlPdPrHiTKixOPUEaJ8YS2CqD0s4xfE7N6uKAcHlDxiHUnAwBJBAgMBAAGj ezB5MAkGA1UdEwQCMAAwLAYJYIZIAYb4QgENBB8WHU9wZW5TU0wgR2VuZXJhdGVk IENlcnRpZmljYXRlMB0GA1UdDgQWBBT55F3Jx3AM6RfMkIh+eCBXOATsaTAfBgNV HSMEGDAWgBTqNOTBjBvy+SLVoq69L+oTKCRDYDANBgkqhkiG9w0BAQsFAAOCAQEA DJBRwol11+GS56OQy/DAlqcPn+a1K0Xtvu6Gzwz5BpwhJyX4bNkchIeP38LJj2V6 6YQsE6gd2atlAsTVj7MXoXzT4waDBkNc9qEauPSYfCipTkT1gqyfd7cvzabH34wk hAw2rS5pJLcPF4B99VdM3437fZ4nIrt+ueSqRWNjQQBkxv9pRxyyykkqVjqcwDsZ WGQiwuJsJ7vB1o9VoHegqBBtXMsBUJGrhqyI7twOnWw1xHv+M1Kj+KglHVFR7Swl z8fTGHOBQg9vt+Y/hyoSS3GcocIHkaYQX1/CKFn2K7r/1lZpA8JJNvA1tDhwfCm4 9n1yx2/PI+/iX9Nz/Caa7A== -----END CERTIFICATE----- [root@rocky CA]# [root@rocky CA]# openssl x509 -in /etc/pki/CA/certs/app1.crt -noout -issuer issuer=C = CN, ST = guizhou, L = duyun, O = magedu, OU = it, CN = m48 [root@rocky CA]# # 验证指定编号对应证书的有效性 [root@rocky CA]# openssl ca -status 01 Using configuration from /etc/pki/tls/openssl.cnf 01=Valid (V) [root@rocky CA]# 证书的吊销 [root@rocky newcerts]# openssl ca -revoke /etc/pki/CA/newcerts/01.pem Using configuration from /etc/pki/tls/openssl.cnf Revoking Certificate 01. Data Base Updated [root@rocky newcerts]# openssl ca -status 01 Using configuration from /etc/pki/tls/openssl.cnf 01=Revoked (R) [root@rocky newcerts]# 生成证书吊销列表文件 [root@rocky newcerts]#echo 01 \u0026gt; /etc/pki/CA/crlnumber [root@rocky newcerts]#openssl ca -gencrl -out /etc/pki/CA/crl.pem ","permalink":"https://xyenvy.github.io/posts/rocky%E4%B8%8A%E5%AE%9E%E7%8E%B0%E7%A7%81%E6%9C%89ca%E5%92%8C%E8%AF%81%E4%B9%A6%E7%94%B3%E8%AF%B7/","summary":"\u003cp\u003eOpenSSL计划在1998年开始，其目标是发明一套自由的加密工具，在互联网上使用。OpenSSL以Eric Young以及Tim Hudson两人开发的SSLeay为基础，随着两人前往RSA公司任职，SSLeay在1998年12月停止开发。因此在1998年12月，社群另外分支出OpenSSL，继续开发下去\u003c/p\u003e\u003c/p\u003e","title":"Rocky上实现私有CA和证书申请"},{"content":"一、at命令 1、at命令的准备工作 1）安装 at 软件包\n[root@centos7 ~]# yum install -y at 2）需要 atd 服务的支持。atd 服务是独立的服务\n查看atd服务状态：# systemctl status atd 开启atd服务：# systemctl start atd 关闭atd服务：# systemctl stop atd 3）查看是否开始开机启动服务：如果弹出enabled，说明开机启动此服务\n[root@rocky ~]# systemctl is-enabled atd enabled [root@rocky ~]# 4）安装好 at 软件包并开启 atd 服务之后，at 命令才可以正常使用。\n[root@rocky ~]# systemctl start atd [root@rocky ~]# systemctl status atd 2、at 命令的访问控制 访问控制：是指允许哪些用户使用 at 命令设定定时任务，或者不允许哪些用户使用 at 命令。可以将其想象成设定黑名单或白名单。at 命令的访问控制是依靠 /etc/at.allow（白名单）和 /etc/at.deny（黑名单）这两个文件来实现的，具体规则如下：\n1)如果系统中有 /etc/at.allow 文件，那么只有写入 /etc/at.allow 文件（白名单）中的用户可以使用 at 命令，其他用户不能使用 at 命令(（注意，/etc/at.allow 文件的优先级更高，也就是说，如果同一个用户既写入 /etc/at.allow 文件，又写入 /etc/at.deny 文件，那么这个用户是可以使用 at 命令的);\n2)如果系统中没有 /etc/at.allow 文件，只有 /etc/at.deny 文件，那么写入 /etc/at.deny 文件（黑名单）中的用户不能使用 at 命令，其他用户可以使用 at 命令。不过这个文件对 root 用户不生效;\n3)如果系统中这两个文件都不存在，那么只有 root 用户可以使用 at 命令;\n4)系统中默认只有 /etc/at.deny 文件，而且这个文件是空的，因此，系统中所有的用户都可以使用 at 命令。如果我们打算控制用户的 at 命令权限，那么只需把用户名写入 /etc/at.deny 文件即可。\n3、at 命令语法添加定时执行任务 基本格式\nat [选项] [时间] or at [option] TIME 选项\n-V 显示版本信息 -t time 时间格式 [[CC]YY]MMDDhhmm[.ss] -l 列出指定队列中等待运行的作业；相当于atq -d N 删除指定的N号作业；相当于atrm -c N 查看具体作业N号任务 -f file 指定的文件中读取任务 -m 当任务被完成之后，将给用户发送邮件，即使没有标准输出 注意：\n作业执行命令的结果中的标准输出和错误以执行任务的用户身份发邮件通知给 root 默认CentOS 8 最小化安装没有安装邮件服务,需要自行安装 TIME：定义出什么时候进行 at 这项任务的时间 此命令中关于时间参数可用的以下格式：\n格式 用法 HH:MM 比如 04:00 AM。 Midnight（midnight） 代表 12:00 AM Noon（noon） 代表 12:00 PM（相当于 12:00） Teatime（teatime） 代表 4:00 PM（相当于 16:00）。 英文月名 日期 年份 比如 January 15 2018 表示 2018 年 1 月 15 号，年份可有可无。 MMDDYY、MM/DD/YY、MM.DD.YY 比如 011518 表示 2018 年 1 月 15 号。 now+时间 以 minutes、hours、days 或 weeks 为单位，例如 now+5 days 表示命令在 5 天之后的此时此刻执行。 具体的使用方法： at命令后想要输入执行程序的确切时间，然后回车，接着在 \u0026gt; 后输入想要执行的命令，最后用 Ctrl+d 组合键退出 at 命令。\n范例\n[root@centos7 ~]# at now+2 min at\u0026gt; ls ./ \u0026gt; a.log 范例: ubuntu at任务存放路径\nroot@ubuntu200404-1:~# ll /var/spool/cron/ total 20 drwxr-xr-x 5 root root 4096 Feb 23 2022 ./ drwxr-xr-x 4 root root 4096 Feb 23 2022 ../ drwxrwx--T 2 daemon daemon 4096 Sep 6 13:32 atjobs/ drwxrwx--T 2 daemon daemon 4096 Nov 12 2018 atspool/ drwx-wx--T 2 root crontab 4096 Feb 13 2020 crontabs/ root@ubuntu200404-1:~# ll /var/spool/cron/atjobs/ total 16 drwxrwx--T 2 daemon daemon 4096 Sep 6 13:32 ./ drwxr-xr-x 5 root root 4096 Feb 23 2022 ../ -rwx------ 1 root daemon 2838 Sep 6 13:33 a0000101a6c9d1* -rw------- 1 daemon daemon 6 Sep 6 13:32 .SEQ root@ubuntu200404-1:~# 范例：centos at任务存放路径\n[root@centos7 ~]# ll /var/spool/at/ total 4 -rwx------. 1 root root 2831 Sep 6 21:37 a0000501a6c9d5 drwx------. 2 root root 19 Sep 6 21:31 spool [root@centos7 ~]# 二、 crontab命令 at 命令：是在指定的时间只能执行一次任务。 crontab 命令：可以循环重复的执行定时任务。\n1、crontab 命令的准备工作 crontab 命令需要 crond 服务支持。crond 是 Linux 下用来周期地执行某种任务或等待处理某些事件的一个守护进程，在安装完成操作系统后，默认会安装 crond 服务工具，且 crond 服务默认就是自启动的。crond 进程每分钟会定期检查是否有要执行的任务，如果有，则会自动执行该任务。\ncrontab 命令和 at 命令类似，也是通过 /etc/cron.allow 和 /etc/cron.deny 文件来限制某些用户是否可以使用 crontab 命令的。\n启动crond服务之后才能使用crontab 命令：\n# systemctl start crond 或者 # systemctl enable crond 2、 crontab 命令语法 命令格式\ncrontab [-u user] [-l | -r | -e] [-i] 常用选项\n-l 列出所有任务 -e 编辑任务 -r 移除所有任务 -i 同-r一同使用，以交互式模式移除指定任务 -u user 指定用户管理cron任务,仅root可运行 crontab 定时任务非常简单，只需执“crontab -e”命令，然后输入想要定时执行的任务即可。注意文件格式如下：\n[root@centos7 ~]## crontab -e #进入 crontab 编辑界面。会打开Vim编辑你的任务 * * * * * 执行的任务 /etc/crontab 格式说明，详情参见 man 5 crontab 注释行以 # 开头\n[root@centos7 ~]# cat /etc/crontab SHELL=/bin/bash PATH=/sbin:/bin:/usr/sbin:/usr/bin MAILTO=root # For details see man 4 crontabs # Example of job definition: # .---------------- minute (0 - 59) # | .------------- hour (0 - 23) # | | .---------- day of month (1 - 31) # | | | .------- month (1 - 12) OR jan,feb,mar,apr ... # | | | | .---- day of week (0 - 6) (Sunday=0 or 7) OR sun,mon,tue,wed,thu,fri,sat # | | | | | # * * * * * user-name command to be executed You have mail in /var/spool/mail/root [root@centos7 ~]# 项目 含义 范围 第一个\u0026quot;*\u0026quot; 一小时当中的第几分钟（minute） 0~59 第二个\u0026quot;*\u0026quot; 一天当中的第几小时（hour） 0~23 第三个\u0026quot;*\u0026quot; 一个月当中的第几天（day） 1~31 第四个\u0026quot;*\u0026quot; 一年当中的第几个月（month） 1~12 第五个\u0026quot;*\u0026quot; 一周当中的星期几（week） 0~7（0和7都代表星期日） 在这个时间的表达式中，还有一些特殊符号如下：\n特殊符号 含义 *（星号） 代表任何时间。比如第一个\u0026quot;*\u0026ldquo;就代表一小时种每分钟都执行一次的意思。 ,（逗号） 代表不连续的时间。比如\u0026quot;0 8，12，16*命令\u0026quot;就代表在每天的 8 点 0 分、12 点 0 分、16 点 0 分都执行一次命令。 -（中杠） 代表连续的时间范围。比如\u0026quot;0 5 1-6命令\u0026rdquo;，代表在周一到周六的凌晨 5 点 0 分执行命令。 /（正斜线） 代表每隔多久执行一次。比如\u0026quot;*/10命令\u0026quot;，代表每隔 10 分钟就执行一次命令。 当“crontab -e”编辑完成之后，一旦保存退出，那么这个定时任务实际就会写入 /var/spool/cron/ 目录中，每个用户的定时任务用自己的用户名进行区分。而且 crontab 命令只要保存就会生效，只要 crond 服务是启动的。\n这里举几个时间的例子来熟悉一下时间字段（星期几和几日最好不要同时出现，非常容易让管理员混淆）：\n时间 含义 1 2 ** * 在每天凌晨 2 点 1 分执行命令 0 17 ** 1 在每周一的 17 点 0 分执行命令 0 5 1,15 ** 在每月 1 日和 15 日的凌晨 5 点 0 分执行命令 40 4 ** 1-5 在每周一到周五的凌晨 4 点 40 分执行命令 */10 4 *** 在每天的凌晨 4 点，每隔 10 分钟执行命令 3,15 8-11 */2 ** 在每隔两天的上午 8 点到 11 点的第 3 和第 15 分钟执行命令。 ","permalink":"https://xyenvy.github.io/posts/linux%E5%AE%9A%E6%97%B6%E6%89%A7%E8%A1%8C%E4%BB%BB%E5%8A%A1/","summary":"一、at命令 1、at命令的准备工作 1）安装 at 软件包 [root@centos7 ~]# yum install -y at 2）需要 atd 服务的支持。atd 服务是独立的服务 查看atd服务状态：# systemctl status atd 开启atd服务：# systemctl start atd 关闭atd服务：# systemctl stop atd 3）查看是否开始开机启动服务：如果弹出enabled，说明开机启动此服务 [root@rocky ~]# systemctl is-enabled atd enabled [root@rocky ~]# 4）安装好","title":"Linux定时执行任务"},{"content":"Linux系统状态的查看及管理工具：\npstree ps pidof pgrep top htop glance pmap vmstat dstat kill pkill job bg fg nohup 1 进程管理和性能相关工具 1.1 进程树pstree pstree 可以用来显示进程的父子关系，以树形结构显示 格式：\npstree [OPTION] [ PID | USER ] 常用选项\n-p 显示PID -T 不显示线程thread,默认显示线程 -u 显示用户切换 -H pid 高亮显示指定进程及其前辈进程 1.2 进程信息PS ps 即 process state，可以进程当前状态的快照，默认显示当前终端中的进程，Linux系统各进程的相关 信息均保存在/proc/PID目录下的各文件中 ps格式：\nps [OPTION]... 常用选项\na 选项包括所有终端中的进程 x 选项包括不链接终端的进程 u 选项显示进程所有者的信息 f 选项显示进程树,相当于 --forest k|--sort 属性 对属性排序,属性前加 - 表示倒序 o 属性… 选项显示定制的信息 pid、cmd、%cpu、%mem L 显示支持的属性列表 -C cmdlist 指定命令，多个命令用，分隔 -L 显示线程 -e 显示所有进程，相当于-A -f 显示完整格式程序信息 -F 显示更完整格式的进程信息 -H 以进程层级格式显示进程相关信息 -u userlist 指定有效的用户ID或名称 -U userlist 指定真正的用户ID或名称 -g gid或groupname 指定有效的gid或组名称 -G gid或groupname 指定真正的gid或组名称 -p pid 显示指pid的进程 --ppid pid 显示属于pid的子进程 -t ttylist 指定tty,相当于 t -M 显示SELinux信息，相当于Z ","permalink":"https://xyenvy.github.io/posts/%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B%E7%9B%B8%E5%85%B3%E6%A6%82%E5%BF%B5/","summary":"Linux系统状态的查看及管理工具： pstree ps pidof pgrep top htop glance pmap vmstat dstat kill pkill job bg fg nohup 1 进程管理和性能相关工具 1.1 进程树pstree pstree 可以用来显示进程的父子关系，以树形结构显示 格式： pstree [OPTION] [ PID | USER ] 常用选项 -p 显示PID -T 不显示线程thread,默认显示线程 -u 显示用户切换 -H pid 高亮显示指定进程及其前辈进程","title":"进程和线程相关概念"},{"content":"1、网络配置 基本网络配置 将Linux主机接入到网络，需要配置网络相关设置 一般包括如下内容：\n主机名 IP/netmask 路由：默认网关 DNS服务器 主DNS服务器 次DNS服务器 第三个DNS服务器 1.1 修改主机名称 CentOs6 及之前的版本 # 修改 /etc/sysconfig/network文件HOSTNAME的值 [root@centos6 sysconfig]# cat /etc/sysconfig/network NETWORKING=yes HOSTNAME=centos6 [root@centos6 sysconfig]# # 修改hostname的值为centos6.mg.du [root@centos6 sysconfig]# vi /etc/sysconfig/network # 修改后不会马上生效,需要使用hostname命令重写一下 [root@centos6 sysconfig]# hostname centos6.mg.du # 重启一下看主机名称是否修改成功 [root@centos6 sysconfig]# reboot # hostname命令查看主机名称 [root@centos6 ~]# hostname centos6.mg.du [root@centos6 ~]# CentOs7 及之后的版本 # centos7 之后的版本主机名称文件 /etc/hostname [root@centos7 ~]# cat /etc/hostname centos7 [root@centos7 ~]# # centos7 之后的版本直接使用命令修改主机名称 [root@centos7 ~]# hostnamectl set-hostname centos7.mg [root@centos7 ~]# hostname centos7.mg [root@centos7 ~]# ubuntu修改主机名称 # 查看主机名称配置文件 root@ubuntu200404-1:~# cat /etc/hostname ubuntu200404-1 root@ubuntu200404-1:~# # 修改主机名称可以直接修改/etc/hostname文件，也可以直接使用命令修改 hostnamectl set-hostname 主机名 1.2 网卡名称 1.2.1 centos 6之前版本的网卡名称 接口命名方式：CentOS 6\n以太网： eth[0,1,2,···] ppp: ppp[0,1,2,···] 网络接口识别并命名相关的udev配置文件 /etc/udev/rules.d/70-persistent-net.rules 查看网卡 dmesg |grep –i eth ethtool -i eth0 卸载网卡驱动 modprobe -r e1000 rmmod e1000 装载网卡驱动 modprobe e1000 范例：临时修改网卡名称 [root@centos6 ~]#ip link set eth0 down [root@centos6 ~]#ip link set eth0 name abc [root@centos6 ~]#ip link set abc up 1.2.2 Centos7 版本之后的网卡配置 参考文档\nhttps://access.redhat.com/documentation/en- us/red_hat_enterprise_linux/8/html/configuring_and_managing_networking/consisten t-network-interface-device-naming_configuring-and-managing-networking CentOS 6之前，网络接口使用连续号码命名：eth0、eth1等,当增加或删除网卡时，名称可能会发生变化 CentOS 7 以上版使用基于硬件，设备拓扑和设置类型命名,可以保持网卡名称的稳定 CentOS 8 中已弃用network.service，采用NetworkManager（NM）为网卡启用命令。CentOS 8 仍可以安装network.service作为网卡服务，只是默认没有安装，具体方法为： dnf install network-scripts ，不过官方已明确在下一个大版本中，将彻底放弃network.service，不建议继续使用network.service管理网络。\nsystemd对网络设备的命名方式\n如果Firmware或BIOS为主板上集成的设备提供的索引信息可用，且可预测则根据此索引进行命 名，如：eno1\n如果Firmware或BIOS为PCI-E扩展槽所提供的索引信息可用，且可预测，则根据此索引进行命名， 如：ens1\n如果硬件接口的物理位置信息可用，则根据此信息命名，如：enp2s0\n如果用户显式启动，也可根据MAC地址进行命名，如：enx2387a1dc56\n上述均不可用时，则使用传统命名机制\n基于BIOS支持启用biosdevname软件\n内置网卡：em1,em2 pci卡：pYpX Y：slot ,X:port 网卡组成格式\nen: Ethernet 有线局域网 wl: wlan 无线局域网 ww: wwan无线广域网 o\u0026lt;index\u0026gt;: 集成设备的设备索引号 s\u0026lt;slot\u0026gt;: 扩展槽的索引号 x\u0026lt;MAC\u0026gt;: 基于MAC地址的命名 p\u0026lt;bus\u0026gt;s\u0026lt;slot\u0026gt;: enp2s1 使用传统方式命名\n（1）编辑/etc/default/grub配置文件\ncentos7 GRUB_CMDLINE_LINUX=\u0026#34;net.ifnames=0 biosdevname=0\u0026#34; ubuntu (2) 为grub2生成其配置文件\ncentos7 [root@centos7 ~]# grub2-mkconfig -o /boot/grub2/grub.cfg ubuntu grub-mkconfig -o /boot/grub/grub.cfg (3) 重启\nreboot 自定义网卡名称\n[root@centos8 ~]# vi /etc/default/grub GRUB_CMDLINE_LINUX=\u0026#34;net.ifnames.prefix=yuankun\u0026#34; [root@centos8 ~]# grub2-mkconfig -o /boot/grub2/grub.cfg [root@centos8 ~]# reboot 1.3 网络配置文件 网络基本配置文件\nIP、MASK、GW、DNS相关的配置文件：\n/etc/sysconfig/network-scripts/ifcfg-IFACE 配置参考文件\n/usr/share/doc/initcripts-*/sysconfig.txt 常用配置\n设置 说明 TYPE 接口类型；常见有的Ethernet, Bridge NAME 此配置文件应用到的设备 DEVICE 设备名 HWADDR 对应的设备的MAC地址 UUID 设备的唯一标识 BOOTPROTO 激活此设备时使用的地址配置协议，常用的dhcp，static, none, bootp IPADDR 指明IP地址 NETMASK 子网掩码,如:255.255.255.0 PREFIX 网络ID的位数, 如:24 GATEWAY 默认网关 DNS1 第一个DNS服务器地址 DNS2 第二个DNS服务器地址 DOMAIN 主机不完整时，自动搜索的域名后缀 ONBOOT 在系统引导时是否激活此设备 USERCTL 普通用户是否可控制此设备 PEERDNS 如果BOOTPROTO的值为“dhcp”，YES将允许dhcp server分配的dns服务器信息直接覆盖至/etc/resolv.conf文件，NO不允许修改resolv.conf NM_CONTROLLED NM是NetworkManager的简写，此网卡是否接受NM控制 **范例\n修改/etc/sysconfig/network-scripts/ifcfg-IFACE 必须以ifcfg-开头，为了规范一般后面跟网卡名 配置文件写入内容 # 动态获取ip地址 DEVICE=eth0 NAME=eth0 BOOTPROTO=dhcp # 静态获取IP地址 DEVICE=eth0 NAME=eth0 BOOTPROTO=static IPADDR=192.168.179.129 PREFIX=24 GATEWAY=192.168.179.1 DNS1=192.168.179.1 DNS2=180.76.76.76 centos8还需要执行以下两条命令才会生效\nCentOS8和rocky nmcli connnection reload nmcli connnettion up eth0 扩展：CentOS网卡配置文件生效方法\nCentOS6 service network restart CentOS7 systemctl restart network # 通用方法 重启 reboot 1.4 ifconfig命令 来自于net-tools包，建议使用 ip 代替\n#清除eth0上面的IP地址 [root@centos8 ~]#ifconfig eth0 0.0.0.0 #启用和禁用网卡 [root@centos8 ~]#ifconfig eth0 down [root@centos8 ~]#ifconfig eth0 up #对一个网卡设置多个IP地址 [root@centos8 ~]#ifconfig eth0:1 172.16.0.8/24 1.5 route命令 路由表管理命令 路由表主要构成:\nDestination: 目标网络ID,表示可以到达的目标网络ID,0.0.0.0/0 表示所有未知网络,又称为默认路由, 优先级最低 Genmask:目标网络对应的netmask Iface: 到达对应网络,应该从当前主机哪个网卡发送出来 Gateway: 到达非直连的网络,将数据发送到临近(下一个)路由器的临近本主机的接口的IP地址,如果 是直连网络,gateway是0.0.0.0 Metric: 开销cost,值越小,路由记录的优先级最高 查看路由表：\n[root@rocky ~]# route -n Kernel IP routing table Destination Gateway Genmask Flags Metric Ref Use Iface 0.0.0.0 192.168.179.1 0.0.0.0 UG 100 0 0 eth0 192.168.179.0 0.0.0.0 255.255.255.0 U 100 0 0 eth0 添加路由：route add\nroute add [-net|-host|default] target [netmask Nm] [gw GW] [[dev] If] 删除路由route del\nroute del [-net|-host] target [gw Gw] [netmask Nm] [[dev] If] 1.6 ubuntu网络配置 1.6.1 修改主机名 方法一 修改配置文件\n# /etc/hostname 方法二 hostnamectl set-hostname 主机名 1.6.2 网卡名称 默认ubuntu的网卡名称和 CentOS 7 类似，如：ens33，ens38等 修改网卡名称为传统命名方式：\n# 修改配置文件 /etc/default/grub GRUB_CMDLINE_LINUX=\u0026#34;net.ifnames=0\u0026#34; 生成新的grub.cfg文件\ngrub-mkconfig -o /boot/grub/grub.cfg #或者 update-grub grep net.ifnames /boot/grub/grub.cfg # 重启生效 reboot 1.6.3 ubuntu网卡配置 配置自动获取IP 网卡配置文件采用YAML格式,必须以 /etc/netplan/XXX.yaml 文件命名方式存放 可以每个网卡对应一个单独的配置文件,也可以将所有网卡都放在一个配置文件里\n范例\nroot@ubuntu200404-1:~# cat /etc/netplan/eth0.yaml # This is the network config written by \u0026#39;subiquity\u0026#39; network: ethernets: eth0: dhcp4: true version: 2 # 修改网卡配置文件后需要执行命令生效 netplan apply 配置静态IP root@ubuntu200404-1:/etc/netplan# cat eth1.yaml # This is the network config written by \u0026#39;subiquity\u0026#39; network: ethernets: eth1: addresses: - 192.168.179.139/24 gateway4: 192.168.179.2 nameservers: search: [] # DNS addresses: [180.76.76.76] version: 2 # 修改网卡配置文件后需要执行命令生效 netplan apply 查看ip和网关\n# 查看IP root@ubuntu200404-1:/etc/netplan# ip address 1: lo: \u0026lt;LOOPBACK,UP,LOWER_UP\u0026gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever 2: eth0: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc fq_codel state UP group default qlen 1000 link/ether 00:0c:29:79:b0:80 brd ff:ff:ff:ff:ff:ff inet 192.168.179.138/24 brd 192.168.179.255 scope global dynamic eth0 valid_lft 1698sec preferred_lft 1698sec inet6 fe80::20c:29ff:fe79:b080/64 scope link valid_lft forever preferred_lft forever 3: eth1: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc fq_codel state UP group default qlen 1000 link/ether 00:0c:29:79:b0:8a brd ff:ff:ff:ff:ff:ff inet 192.168.179.139/24 brd 192.168.179.255 scope global eth1 valid_lft forever preferred_lft forever inet6 fe80::20c:29ff:fe79:b08a/64 scope link valid_lft forever preferred_lft forever root@ubuntu200404-1:/etc/netplan# # 查看网关 root@ubuntu200404-1:/etc/netplan# route -n Kernel IP routing table Destination Gateway Genmask Flags Metric Ref Use Iface 0.0.0.0 192.168.179.2 0.0.0.0 UG 100 0 0 eth0 192.168.179.0 0.0.0.0 255.255.255.0 U 0 0 0 eth1 192.168.179.0 0.0.0.0 255.255.255.0 U 0 0 0 eth0 192.168.179.2 0.0.0.0 255.255.255.255 UH 100 0 0 eth0 root@ubuntu200404-1:/etc/netplan# 查看DNS\nroot@ubuntu2004:~# resolvectl status #Ubuntu 20.04新命令 root@ubuntu1804:~# systemd-resolve --status ","permalink":"https://xyenvy.github.io/posts/network/","summary":"1、网络配置 基本网络配置 将Linux主机接入到网络，需要配置网络相关设置 一般包括如下内容： 主机名 IP/netmask 路由：默认网关 DNS服务器 主DNS服务器 次DNS服务器 第三个DNS服务器 1.1 修改主机名称 CentOs6 及之前的版本 # 修改 /etc/sysconfig/network文件HOSTNAME的值 [root@centos6 sysconfig]# cat /etc/sysconfig/network","title":"计算机网络"},{"content":"1、软件管理简介 Redhat和Centos中软件管理是依靠软件包管理器(RPM)来实现的\nRPM(Redhat Package Manager)软件包管理器提供了在Linux操作系统中安装、升级、卸载的方法，并提供对系统中的软件状态信息的查询；除了这些功能外，RPM软件包管理器还提供了制作软件包的功能\n2、软件包管理器简介 2.1 软件包管理器的职责 将二进制文件、库文件、配置文件、帮助文件打包成一个文件 安装软件时按需将二进制、库文件、配置文件、帮助文件放到相应的位置 生成数据库，追踪所安装的每一个文件 软件卸载时根据安装时生成的数据库将相应的文件删除 2.2 软件包管理器的核心功能 制作软件包 安装软件 卸载软件 升级软件 查询软件 校验软件 3、软件包简介 3.1 软件包组成 软件包的组成清单 文件清单 安装或卸载的运行脚本 数据库 程序包名称及版本 依赖关系 功能说明 安装生成的各个文件的路径及校验码信息 3.2 软件包分类 源码格式 特点：需要编译成二进制格式才能进行\n命名方式：name-VERSION.tar.gz VERSION：主版本号.次版本号.系统发行版本 二进制格式 特点：编译好的，安装之后可以直接运行\n软件的作者下载软件的源码，编译配置为二进制软件包 Redhat和Centos中使用的二进制包为rpm包 源码格式和二进制格式的区别\n源码格式的包编译为二进制包时可以选择需要的特性，如果未选择，则编译后安装后的软件就不会有相应的功能 源码包在编译成为二进制包时可以实现软件功能的定制 二进制包的本版落后于源码包。 4、rpm简介 Redhat和Centos中二进制包的扩展包为.rpm，这是由红帽公司最先发布的一种用来打包软件的文件格式，我们叫做rpm包；RPM软件包管理器就是管理rpm包\n4.1 rpm包命名规范\n5、软件包的获取途径 5.1 系统发行的光盘 Linux的IOS镜像文件自带了非常多的系统扩展RPM安装包，且这些软件版本最适合当前Linux系统 IOS镜像文件自带的扩展RPM安装包的存放目录为：Packages 使用IOS镜像文件自带的扩展RPM安装包前必须先挂载ISO镜像，挂在方法如下：\n# 创建挂载点，挂载光盘镜像到挂载点 [root@jlin ~]# mkdir /mnt/cdrom [root@jlin ~]# mount /dev/sr0 /mnt/cdrom/ # 复制挂载点里面所有的文件到/media/目录，避免光盘断开连接就读取不到扩展RPM安装包 [root@jlin ~]# cp -r /mnt/cdrom/ /media/ [root@jlin ~]# cd /media/cdrom/ [root@jlin cdrom]# ll 总用量 320 -rw-r--r-- 1 root root 14 7月 10 08:27 CentOS_BuildTag drwxr-xr-x 3 root root 35 7月 10 08:27 EFI -rw-r--r-- 1 root root 227 7月 10 08:27 EULA -rw-r--r-- 1 root root 18009 7月 10 08:27 GPL drwxr-xr-x 3 root root 57 7月 10 08:27 images drwxr-xr-x 2 root root 198 7月 10 08:27 isolinux drwxr-xr-x 2 root root 43 7月 10 08:27 LiveOS drwxr-xr-x 2 root root 221184 7月 10 08:29 Packages drwxr-xr-x 2 root root 4096 7月 10 08:29 repodata -rw-r--r-- 1 root root 1690 7月 10 08:29 RPM-GPG-KEY-CentOS-7 -rw-r--r-- 1 root root 1690 7月 10 08:29 RPM-GPG-KEY-CentOS-Testing-7 -r--r--r-- 1 root root 2883 7月 10 08:29 TRANS.TBL 5.2 开源镜像站 开源镜像站上会存放RPM安装包\n阿里巴巴开源镜像站 http://mirrors.aliyun.com 网易开源镜像站 http://mirrors.163.com 清华大学开源镜像站 https://mirrors.tuna.tsinghua.edu.cn 5.3 搜索引擎 有一些搜索引擎直接提供rpm包搜索功能\nrpmfind \u0026gt; http://rpmfind.net rpm pbone \u0026gt; http://rpm.pbone.net pkgs \u0026gt; http://pkgs.org/ 6、rpm包管理 6.1 RPM包安装 // 语法：rpm -ivh /PATH/TO/PACKAGE_FILE ... // 选项： -i：安装 -v：显示详细信息 -h：显示安装进度条 --test：测试安装，但不真正执行安装过程 --nodeps：忽略依赖关系 --force：强行安装，可以实现重装或降级 --replacepkgs：重新安装，替换原有安装 --oldpackage：降级 --nodigest：不检查包的完整性 --nosignature：不检查报的来源合法性 --noscripts：不执行rpm包自带的四类脚本： --nopre：不执行rpm包自带的preinstall脚本 --nopost：不执行rpm包自带的postinstall脚本 --nopreun：不执行rpm包自带的preuninstall脚本 --nopostun：不执行rpm包自带的postuninstall脚本 --preinstall：安装过程开始之前运行的脚本，标记为%pre：--nopre --postinstall：安装过程完成之后运行的脚本，标记为%post：--nopost --preuninstall：卸载过程开始执行之前运行的脚本，标记为%preun：--nopreun --postunistall：写在过程完成之后运行的脚本，标记为%postrun：--nopostun // 安装软件包，需要指定软件包绝对路径 [root@jlin ~]# rpm -ivh /mnt/cdrom/Packages/tree-1.6.0-10.el7.x86_64.rpm // 在软件包所在目录下可以不指定绝对路径 [root@jlin ~]# cd /mnt/cdrom/Packages/ [root@jlin Packages]# rpm -ivh tree-1.6.0-10.el7.x86_64.rpm // 测试一个软件包是否能在该系统上安装 [root@jlin ~]# rpm -ivh --test /mnt/cdrom/Packages/tree-1.6.0-10.el7.x86_64.rpm // 如果软件包已经安装，强制再次安装 [root@jlin ~]# rpm -ivh --force /mnt/cdrom/Packages/tree-1.6.0-10.el7.x86_64.rpm // 安装httpd服务需要依赖其他组件，使用--nodeps可忽略以来强制安装 [root@jlin ~]# rpm -ivh --nodeps /mnt/cdrom/Packages/httpd-2.4.6-80.el7.centos.x86_64.rpm 6.2 RPM包查询 // 查询httpd的rpm包是否安装 [root@jlin ~]# rpm -q httpd // 模糊查找系统已安装的rpm包 [root@jlin ~]# rpm -qa | grep ftp // 查询已安装的httpd软件包相关信息 [root@jlin ~]# rpm -qi httpd // 查询已安装的rpm包生成的文件 [root@jlin ~]# rpm -ql httpd // 查询已安装的rpm包生成的配置文件 所有 [root@jlin ~]# rpm -qc httpd // 查询配置文件或命令来自于哪个rpm包 [root@jlin ~]# rpm -qf /etc/httpd/httpd.conf [root@jlin ~]# rpm -qf /usr/sbin/httpd // 查询未安装的软件包会产生哪些文件 [root@jlin ~]# rpm -qpl / mnt/Packages/httpd-2.4.6-80.el7.centos.x86_64.rpm // 查询未安装的软件包的说明信息 [root@jlin ~]# rpm -qpi /mnt/Packages/httpd-2.4.6-80.el7.centos.x86_64.rpm 6.4 RPM包升级 // 升级tree软件包 [root@jlin ~]# rpm -Uvh /mnt/Packages/httpd-2.4.6-80.el7.centos.x86_64.rpm 6.5 RPM包卸载 // 先查询，然后卸载 [root@jlin ~]# rpm -qa lgrep httpd [root@jlin ~]# rpm -e httpd 6.6 RPM包校验 // 校验已经安装的软件包的文件是否被修改；如果执行以下命令无内容输出说明安装的软件 [root@jlin ~]# rpm -v vsftpd S #文件的容量大小是否被改变 M #文件的类型或者文件的属性是否被修改 5 #MD5加密的内容已经不同 D #装置的主/次代码已经改变 L #路径已经被改变 U #文件的所属主已被修改 G #文件的所属组已被修改 T #文件的创建时间已被改变 6.7 RPM重建数据库 // 数据库信息在/var/lib/rpm目录 // 重建数据库，重建Packages数据库，一定会重建 rpm --rebuilddb // 初始化数据库，重建所有数据库，没有才建立，有就不建立 rpm --initdb 6.8 检查软件包来源合法性 加密类型: - 对称加密 #加密解密使用同一个密钥 - 公钥加密 #一对密钥，公钥和私钥。公钥隐含于私钥中，可以提取出来并公布出去 - 单向加密 #只能加密不能解密 // 红帽官方公钥存放位置 /etc/pki/rpm-gpg/RPM-GPG-KEY-redhat-release // 检查指定rpm包合法性，出现oK字样表示包没问题 rpm -K PACKAGE_FILE // 导入密钥文件 rpm --import /etc/pki/rpm-gpg/RPM-GPG-KEY-redhat-release1 Centos 7发行版光盘提供的密钥文件名为:RPM-GPG-KEY-Centos-7 7、yum和dnf CentOS 使用 yum, dnf 解决rpm的包依赖关系 YUM: Yellowdog Update Modifier，rpm的前端程序，可解决软件包相关依赖性，可在多个库之间定位 软件包，up2date的替代工具，CentOS 8 用dnf 代替了yum ,不过保留了和yum的兼容性，配置也是通 用的\n7.1 yum/dnf 工作原理 yum/dnf 是基于C/S 模式 yum 服务器存放rpm包和相关包的元数据库 yum 客户端访问yum服务器进行安装或查询等 yum 实现过程 先在yum服务器上创建 yum repository（仓库），在仓库中事先存储了众多rpm包，以及包的相关的 元数据文件（放置于特定目录repodata下），当yum客户端利用yum/dnf工具进行安装时包时，会自动 下载repodata中的元数据，查询远数据是否存在相关的包及依赖关系，自动从仓库中找到相关包下载并 安装。\n7.2 yum客户端配置 yum客户端配置文件\n/etc/yum.conf #为所有仓库提供公共配置 /etc/yum.repos.d/*.repo： #为每个仓库的提供配置文件 帮助参考： man 5 yum.conf repo仓库配置文件指向的定义：\n[repositoryID] name=Some name for this repository baseurl=url://path/to/repository/ enabled={1|0} gpgcheck={1|0} gpgkey=URL enablegroups={1|0} failovermethod={roundrobin|priority} roundrobin：意为随机挑选，默认值 priority:按顺序访问 cost= 默认为1000 yum服务器的baseurl形式\nfile:// 本地路径 http:// https:// ftp:// 注意：yum仓库指向的路径一定必须是repodata目录所在目录 相关变量\nyum的repo配置文件中可用的变量： $releasever: 当前OS的发行版的主版本号，如：8，7，6 $arch: CPU架构，如：aarch64, i586, i686，x86_64等 $basearch：系统基础平台；i386, x86_64 $contentdir：表示目录，比如：centos-8，centos-7 $YUM0-$YUM9:自定义变量 7.3 yum命令 yum命令的用法\nyum [options] [command] [package ...] yum的命令行选项\n-y #自动回答为\u0026#34;yes\u0026#34; -q #静默模式 --nogpgcheck #禁止进行gpg check --enablerepo=repoidglob #临时启用此处指定的repo，支持通配符，如：\u0026#34;*\u0026#34; --disablerepo=repoidglob #临时禁用此处指定的repo,和上面语句同时使用，放在后面的生效 7.3.1 显示仓库列表 yum repolist [all|enabled|disabled] 范例\n7.3.2 显示程序包 yum list yum list [all | glob_exp1] [glob_exp2] [...] yum list {available|installed|updates} [glob_exp1] [...] 范例\nyum list yum list [all | glob_exp1] [glob_exp2] [...] yum list {available|installed|updates} [glob_exp1] [...] 范例：只查看安装的包\n[root@rocky ~]# yum list installed|head Installed Packages NetworkManager.x86_64 1:1.32.10-4.el8 @anaconda NetworkManager-config-server.noarch 1:1.32.10-4.el8 @anaconda NetworkManager-libnm.x86_64 1:1.32.10-4.el8 @anaconda NetworkManager-team.x86_64 1:1.32.10-4.el8 @anaconda NetworkManager-tui.x86_64 1:1.32.10-4.el8 @anaconda acl.x86_64 2.2.53-1.el8.1 @anaconda adcli.x86_64 0.8.2-12.el8 @anaconda alsa-sof-firmware.noarch 1.8-1.el8 @anaconda at.x86_64 3.1.20-11.el8 @anaconda [root@rocky ~]# 范例：查看可以安装的包\n[root@rocky ~]# yum list available | head Last metadata expiration check: 2:21:04 ago on Tue 09 Aug 2022 09:50:19 AM CST. Available Packages CUnit.i686 2.1.3-17.el8 appstream CUnit.x86_64 2.1.3-17.el8 appstream GConf2.i686 3.2.6-22.el8 appstream GConf2.x86_64 3.2.6-22.el8 appstream HdrHistogram.noarch 2.1.11-3.module+el8.4.0+405+66dfe7da appstream HdrHistogram-javadoc.noarch 2.1.11-3.module+el8.4.0+405+66dfe7da appstream HdrHistogram_c.i686 0.9.13-2.el8 appstream HdrHistogram_c.x86_64 0.9.13-2.el8 appstream [root@rocky ~]# 范例：查看可以升级的包\nyum list updates 范例：查看指定的包\n[root@centos8 ~]#yum list exim ","permalink":"https://xyenvy.github.io/posts/%E8%BD%AF%E4%BB%B6%E7%AE%A1%E7%90%86/","summary":"1、软件管理简介 Redhat和Centos中软件管理是依靠软件包管理器(RPM)来实现的 RPM(Redhat Package Manager)软件包管理器提供了在Linux操作系统中安装、升级、卸载的方法，并提供对系统中的软件状态信息的查询；除了这些功能外，RPM软件包管理器还提供了制作软件包的功能 2、软件包管理","title":"软件管理"},{"content":"磁盘管理与文件系统 前言 磁盘是计算机主要的存储介质，可以存储大量的二进制数据，并且断电后也能保持数据不丢失，使用磁盘存储数据的时候我们可以将磁盘划分成我们所需要的格式来进行使用\n1. 磁盘结构 1、硬盘的物理结构 盘片：硬盘有多个盘片，每个盘片有2面 磁头：每面有一个磁头\n2.硬盘数据结构 扇区：磁盘上的每个磁道被等分为若干个弧段，这些弧段便是硬盘的扇区。硬盘的第一个扇区，叫做引导扇区 ，盘片被分为多个扇形区域，每个扇区存放512字节的数据，是硬盘最小的存储单元 磁道：当磁盘旋转时，磁头若保持在一个位置上，则每个磁头都会在磁盘表面划出一个圆形轨迹，这些圆形轨迹就叫做磁道 柱面：在有多个盘片构成的盘组中，由不同盘片的面，但处于同一半径圆的多个磁道组成的一个圆柱面\n3、磁盘结构 硬盘存储容量 = 磁头数 x 磁道（柱面）数 x 每道扇区数 x 每扇区字节数（512字节） 可以用柱面/磁头/扇区来唯一定位磁盘上的每一个区域 磁盘的接口类型：IDE、SATA、SCSI、SAS、光纤通道 用 fdisk -l 查看分区信息\n2. 管理存储 2.1 磁盘分区 2.1.1 为什么分区 优化I/O性能 实现磁盘空间配额限制 提高修复速度 隔离系统和程序 安装多个OS 采用不同文件系统 2.1.2 分区方式 两种分区方式：MBR，GPT\nMBR分区\nMBR：Master Boot Record，1982年，使用32位表示扇区数，分区不超过2T 划分分区的单位： CentOS 5 之前按整柱面划分 CentOS 6 版本后可以按Sector划分 0磁道0扇区：512bytes 446bytes: boot loader 启动相关 64bytes：分区表，其中每16bytes标识一个分区 2bytes: 55AA，标识位 MBR分区中一块硬盘最多有4个主分区，也可以3主分区+1扩展(N个逻辑分区) MBR分区：主和扩展分区对应的1\u0026ndash;4，/dev/sda3，逻辑分区从5开始，/dev/sda5\n问题：利用分区策略相同的另一台主机的分区表来还原和恢复当前主机破环的分区表？\nGPT分区 GPT：GUID（Globals Unique Identifiers） partition table 支持128个分区，使用64位，支持8Z（ 512Byte/block ）64Z （ 4096Byte/block） 使用128位UUID(Universally Unique Identifier) 表示磁盘和分区 GPT分区表自动备份在头和尾两份， 并有CRC校验位 UEFI (Unified Extensible Firmware Interface 统一可扩展固件接口)硬件支持GPT，使得操作系统可以 启动\nGPT分区结构分为4个区域：\nGPT头 分区表 GPT分区 备份区域 2.2 管理分区 列出块设备\nlsblk 创建分区命令\nfdisk 管理MBR分区 gdisk 管理GPT分区 parted 高级分区操作，可以是交互或非交互方式 重新设置内存中的内核分区表版本，适合于除了CentOS 6 以外的其它版本 5，7，8\npartprobe 2.2.1 添加并检测新硬盘 1、添加新硬盘使用lsblk命令显示出块设备\nroot@ubuntu200404:~# lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT loop0 7:0 0 61.9M 1 loop /snap/core20/1328 loop1 7:1 0 67.2M 1 loop /snap/lxd/21835 loop2 7:2 0 62M 1 loop /snap/core20/1587 loop3 7:3 0 43.6M 1 loop /snap/snapd/14978 loop4 7:4 0 47M 1 loop /snap/snapd/16292 loop5 7:5 0 67.8M 1 loop /snap/lxd/22753 sda 8:0 0 20G 0 disk ├─sda1 8:1 0 1M 0 part ├─sda2 8:2 0 1.5G 0 part /boot └─sda3 8:3 0 18.5G 0 part └─ubuntu--vg-ubuntu--lv 253:0 0 10G 0 lvm / sr0 11:0 1 1.2G 0 rom 发现并没有检测出来新添加的硬盘\n2、检测新硬盘\n方法1：可以重启电脑\n方法2： 重新扫描存储设备的scsi总线\n# host后面的数字不是固定的，以实际为准 root@ubuntu200404:~# echo \u0026#39;- - -\u0026#39; \u0026gt; /sys/class/scsi_host/host32/scan 再次使用lsblk命令查看发现已经多了sda的硬盘，说明成功了\nroot@ubuntu200404:~# lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT loop0 7:0 0 61.9M 1 loop /snap/core20/1328 loop1 7:1 0 67.2M 1 loop /snap/lxd/21835 loop2 7:2 0 62M 1 loop /snap/core20/1587 loop3 7:3 0 43.6M 1 loop /snap/snapd/14978 loop4 7:4 0 47M 1 loop /snap/snapd/16292 loop5 7:5 0 67.8M 1 loop /snap/lxd/22753 sda 8:0 0 20G 0 disk ├─sda1 8:1 0 1M 0 part ├─sda2 8:2 0 1.5G 0 part /boot └─sda3 8:3 0 18.5G 0 part └─ubuntu--vg-ubuntu--lv 253:0 0 10G 0 lvm / sdb 8:16 0 20G 0 disk # 新添加的硬盘 sr0 11:0 1 1.2G 0 rom 2.2.2 partend命令 注意：parted的操作都是实时生效的，小心使用\n格式:\nparted [选项]... [设备 [命令 [参数]...]...] 范例：\nparted /dev/sdb mklabel gpt|msdos parted /dev/sdb print parted /dev/sdb mkpart primary 1 200 （默认M） parted /dev/sdb rm 1 parted -l 列出所有硬盘分区信息 2.2.3 分区工具fdisk和gdisk fdisk -l [-u] [device...] 查看分区 fdisk [device...] 管理MBR分区 gdisk [device...] 类fdisk 的GPT分区工具 # 范例： fdisk /dev/sdb 子命令：\np 分区列表 t 更改分区类型 n 创建新分区 d 删除分区 v 校验分区 u 转换单位 w 保存并退出 q 不保存并退出 查看内核是否已经识别新的分区\ncat /proc/partitions CentOS 7,8 同步分区表:\npartprobe 2.3 文件系统 2.3.1 文件系统概念 文件系统是操作系统用于明确存储设备或分区上的文件的方法和数据结构；即在存储设备上组织文件的 方法。操作系统中负责管理和存储文件信息的软件结构称为文件管理系统，简称文件系统 从系统角度来看，文件系统是对文件存储设备的空间进行组织和分配，负责文件存储并对存入的文件进 行保护和检索的系统。具体地说，它负责为用户建立文件，存入、读出、修改、转储文件，控制文件的 存取，安全控制，日志，压缩，加密等 支持的文件系统：\n/lib/modules/`uname -r`/kernel/fs 各种文件系统\n帮助：man 5 fs\n2.3.2 文件系统类型 Linux常用文件系统\next2：Extended file system 适用于那些分区容量不是太大，更新也不频繁的情况，例如 /boot 分 区 ext3：是 ext2 的改进版本，其支持日志功能，能够帮助系统从非正常关机导致的异常中恢复 ext4：是 ext 文件系统的最新版。提供了很多新的特性，包括纳秒级时间戳、创建和使用巨型文件 (16TB)、最大1EB的文件系统，以及速度的提升 xfs：SGI，支持最大8EB的文件系统 swap iso9660 光盘 btrfs（Oracle） reiserfs Windows 常用文件系统\nFAT32 NTFS exFAT Unix： FFS（fast） UFS（unix） JFS2 网络文件系统：\nNFS CIFS 集群文件系统：\nGFS2 OCFS2（oracle） 分布式文件系统：\nfastdfs ceph moosefs mogilefs glusterfs Lustre RAW：\n裸文件系统,未经处理或者未经格式化产生的文件系统 常用的文件系统特性：\nFAT32\n最多只能支持16TB的文件系统和4GB的文件 NTFS\n最多只能支持16EB的文件系统和16EB的文件 EXT3\n最多只能支持32TB的文件系统和2TB的文件，实际只能容纳2TB的文件系统和16GB的文件 Ext3目前只支持32000个子目录 Ext3文件系统使用32位空间记录块数量和 inode数量 当数据写入到Ext3文件系统中时，Ext3的数据块分配器每次只能分配一个4KB的块 EXT4：\nEXT4是Linux系统下的日志文件系统，是EXT3文件系统的后继版本 Ext4的文件系统容量达到1EB，而支持单个文件则达到16TB 理论上支持无限数量的子目录 Ext4文件系统使用64位空间记录块数量和 inode数量 Ext4的多块分配器支持一次调用分配多个数据块 修复速度更快 XFS\n根据所记录的日志在很短的时间内迅速恢复磁盘文件内容 用优化算法，日志记录对整体文件操作影响非常小 是一个全64-bit的文件系统，最大可以支持8EB的文件系统，而支持单个文件则达到8EB 能以接近裸设备I/O的性能存储数据 查前支持的文件系统：\ncat /proc/filesystems 2.3.3 文件系统的组成部分 内核中的模块：ext4, xfs, vfat Linux的虚拟文件系统：VFS 用户空间的管理工具：mkfs.ext4, mkfs.xfs,mkfs.vfat\n2.3.4 文件系统选择管理 2.3.4.1 创建文件系统 创建文件管理工具\nmkfs命令： (1) mkfs.FS_TYPE /dev/DEVICE ext4 xfs btrfs vfat (2) mkfs -t FS_TYPE /dev/DEVICE -L \u0026#39;LABEL\u0026#39; 设定卷标 mke2fs：ext系列文件系统专用管理工具 常用选项：\n-t {ext2|ext3|ext4|xfs} 指定文件系统类型 -b {1024|2048|4096} 指定块 block 大小 -L ‘LABEL’ 设置卷标 -j 相当于 -t ext3， mkfs.ext3 = mkfs -t ext3 = mke2fs -j = mke2fs -t ext3 -i # 为数据空间中每多少个字节创建一个inode；不应该小于block大 小 -N # 指定分区中创建多少个inode -I 一个inode记录占用的磁盘空间大小，128---4096 -m # 默认5%,为管理人员预留空间占总空间的百分比 -O FEATURE[,...] 启用指定特性 -O ^FEATURE 案例：mkfs.ext4 /dev/sdb1\nroot@ubuntu200404:~# mkfs.ext4 /dev/sdb1 mke2fs 1.45.5 (07-Jan-2020) Creating filesystem with 2621440 4k blocks and 655360 inodes Filesystem UUID: a7ef4142-26e5-43dd-b9d0-24c4d09155a1 Superblock backups stored on blocks: 32768, 98304, 163840, 229376, 294912, 819200, 884736, 1605632 Allocating group tables: done Writing inode tables: done Creating journal (16384 blocks): done Writing superblocks and filesystem accounting information: done root@ubuntu200404:~# 2.3.4.2 查看和管理分区信息 blkid 可以查看块设备属性信息 格式：\nblkid [OPTION]... [DEVICE] 常用选项：\n-U UUID 根据指定的UUID来查找对应的设备 -L LABEL 根据指定的LABEL来查找对应的设备 e2label：管理ext系列文件系统的LABEL e2label DEVICE [LABEL] 范例\nroot@ubuntu200404:~# blkid /dev/sdb1 /dev/sdb1: UUID=\u0026#34;a7ef4142-26e5-43dd-b9d0-24c4d09155a1\u0026#34; TYPE=\u0026#34;ext4\u0026#34; PARTUUID=\u0026#34;db60ac71-01\u0026#34; root@ubuntu200404:~# 查找分区\nfindfs [options] LABEL=\u0026lt;label\u0026gt; findfs [options] UUID=\u0026lt;uuid\u0026gt; tune2fs：重新设定ext系列文件系统可调整参数的值\n-l 查看指定文件系统超级块信息；super block -L \u0026#39;LABEL’ 修改卷标 -m # 修预留给管理员的空间百分比 -j 将ext2升级为ext3 -O 文件系统属性启用或禁用, -O ^has_journal -o 调整文件系统的默认挂载选项，-o ^acl -U UUID 修改UUID号 dumpe2fs：显示ext文件系统信息，将磁盘块分组管理 -h：查看超级块信息，不显示分组信息\n范例：查看ext文件系统的元数据和块组信息\nroot@ubuntu200404:~# dumpe2fs /dev/sdb1 dumpe2fs 1.45.5 (07-Jan-2020) Filesystem volume name: \u0026lt;none\u0026gt; Last mounted on: \u0026lt;not available\u0026gt; Filesystem UUID: a7ef4142-26e5-43dd-b9d0-24c4d09155a1 Filesystem magic number: 0xEF53 Filesystem revision #: 1 (dynamic) Filesystem features: has_journal ext_attr resize_inode dir_index filetype extent 64bit flex_bg sparse_super large_file huge_file dir_nlink extra_isize metadata_csum Filesystem flags: signed_directory_hash Default mount options: user_xattr acl Filesystem state: clean Errors behavior: Continue Filesystem OS type: Linux Inode count: 655360 Block count: 2621440 Reserved block count: 131072 Free blocks: 2554687 Free inodes: 655349 First block: 0 ...... ...... ...... xfs_info：显示示挂载或已挂载的 xfs 文件系统信息\nxfs_info mountpoint|devname 范例\nxfs_info /dev/sda1 2.3.4.3 文件系统检测和修复 文件系统夹故障常发生于死机或者非正常关机之后，挂载为文件系统标记为“no clean” 注意：一定不要在挂载状态下执行下面命令修复\nfsck: File System Check\nfsck.FS_TYPE fsck -t FS_TYPE 注意：FS_TYPE 一定要与分区上已经文件类型相同\n常用选项\n-a 自动修复 -r 交互式修复错误 e2fsck：ext系列文件专用的检测修复工具\n-y 自动回答为yes -f 强制修复 -p 自动进行安全的修复文件系统问题 用法：\ne2fsck /dev/sdb2 xfs_repair：xfs文件系统专用检测修复工具 常用选项：\n-f 修复文件，而设备 -n 只检查 -d 允许修复只读的挂载设备，在单用户下修复 / 时使用，然后立即reboot 用法：\nxfs_repair /dev/sda1 2.4 挂载 挂载:将额外文件系统与根文件系统某现存的目录建立起关联关系，进而使得此目录做为其它文件访问入 口的行为 卸载:为解除此关联关系的过程 把设备关联挂载点：mount Point 挂载点下原有文件在挂载完成后会被临时隐藏，因此，挂载点目录一般为空 进程正在使用中的设备无法被卸载\n2.4.1 挂载文件系统 mount 格式\nmount [-fnrsvw] [-t vfstype] [-o options] device mountpoint device：指明要挂载的设备\n设备文件：例如:/dev/sda5 卷标：-L \u0026lsquo;LABEL\u0026rsquo;, 例如 -L \u0026lsquo;MYDATA\u0026rsquo; UUID： -U \u0026lsquo;UUID\u0026rsquo;：例如 -U \u0026lsquo;0c50523c-43f1-45e7-85c0-a126711d406e\u0026rsquo; 伪文件系统名称：proc, sysfs, devtmpfs, configfs mountpoint：挂载点目录必须事先存在，建议使用空目录 mount 常用命令选项\n-t fstype 指定要挂载的设备上的文件系统类型,如:ext4,xfs -r readonly，只读挂载 -w read and write, 读写挂载,此为默认设置,可省略 -n 不更新/etc/mtab，mount不可见 -a 自动挂载所有支持自动挂载的设备(定义在了/etc/fstab文件中，且挂载选项中有 auto功能) -L \u0026#39;LABEL\u0026#39; 以卷标指定挂载设备 -U \u0026#39;UUID\u0026#39; 以UUID指定要挂载的设备 -B, --bind 绑定目录到另一个目录上 -o options：(挂载文件系统的选项)，多个选项使用逗号分隔 async 异步模式,内存更改时,写入缓存区buffer,过一段时间再写到磁盘中，效率高，但不安全 sync 同步模式,内存更改时，同时写磁盘，安全，但效率低下 atime/noatime 包含目录和文件 diratime/nodiratime 目录的访问时间戳 auto/noauto 是否支持开机自动挂载，是否支持-a选项 exec/noexec 是否支持将文件系统上运行应用程序 dev/nodev 是否支持在此文件系统上使用设备文件 suid/nosuid 是否支持suid和sgid权限 remount 重新挂载 ro/rw 只读、读写 user/nouser 是否允许普通用户挂载此设备，/etc/fstab使用 acl/noacl 启用此文件系统上的acl功能 loop 使用loop设备 _netdev 当网络可用时才对网络资源进行挂载，如：NFS文件系统 defaults 相当于rw, suid, dev, exec, auto, nouser, async 挂载规则:\n一个挂载点同一时间只能挂载一个设备 一个挂载点同一时间挂载了多个设备，只能看到最后一个设备的数据，其它设备上的数据将被隐藏 一个设备可以同时挂载到多个挂载点 通常挂载点一般是已存在空的目录 范例:挂载案例\nroot@ubuntu200404:/data# mount /dev/sdb1 /data/mysql_mount/ root@ubuntu200404:/data# df 2.4.2 卸载文件系统 umount 卸载时：可使用设备，也可以使用挂载点\numount 设备名|挂载点 2.4.3 查看挂载情况 查看挂载\n#通过查看/etc/mtab文件显示当前已挂载的所有设备 mount #查看内核追踪到的已挂载的所有设备 cat /proc/mounts 查看挂载点情况\nfindmnt MOUNT_POINT|device 查看正在访问指定文件系统的进程\nlsof MOUNT_POINT fuser -v MOUNT_POINT 终止所有在正访问指定的文件系统的进程\nfuser -km MOUNT_POINT 2.4.4 持久挂载 将挂载保存到 /etc/fstab 中可以下次开机时，自动启用挂载 /etc/fstab格式帮助：\nman 5 fstab 每行定义一个要挂载的文件系统,，其中包括共 6 项\n要挂载的设备或伪文件系统设备文件 LABEL：LABEL=\u0026quot;\u0026quot; UUID：UUID=\u0026quot;\u0026quot; 伪文件系统名称：proc, sysfs 挂载点：必须是事先存在的目录 文件系统类型：ext4，xfs，iso9660，nfs，none 挂载选项：defaults ，acl，bind 转储频率：0：不做备份 1：每天转储 2：每隔一天转储 fsck检查的文件系统的顺序：允许的数字是0 1 2 0：不自检 ，1：首先自检；一般只有rootfs才用 2：非rootfs使用 添加新的挂载项，需要执行下面命令生效\nmount -a 范例：centos7, 8 /etc/fstab 的分区UUID错误，无法启动*\n自动进入emergency mode,输入root 密码 #cat /proc/mounts 可以查看到/ 以rw方式挂载 #vim /etc/fstab #reboot 范例：centos 6 /etc/fstab 的分区UUID错误，无法启动\n如果/etc/fstab 的挂载设备出错，比如文件系统故障，并且文件系统检测项（即第6项为非0），将导致无 法启动 自动进入emergency mode,输入root 密码 #cat /proc/mounts 可以查看到/ 以ro方式挂载，无法直接修改配置文件 #mount -o remount,rw / #vim /etc/fstab 将故障行的最后1项，即第6项修改为0，开机不检测此项挂载设备的健康性，从而忽略错误，能实现启动 范例：/etc/fstab格式\nroot@ubuntu200404:/data# cat /etc/fstab # /etc/fstab: static file system information. # # Use \u0026#39;blkid\u0026#39; to print the universally unique identifier for a # device; this may be used with UUID= as a more robust way to name devices # that works even if disks are added and removed. See fstab(5). # # \u0026lt;file system\u0026gt; \u0026lt;mount point\u0026gt; \u0026lt;type\u0026gt; \u0026lt;options\u0026gt; \u0026lt;dump\u0026gt; \u0026lt;pass\u0026gt; # / was on /dev/ubuntu-vg/ubuntu-lv during curtin installation /dev/disk/by-id/dm-uuid-LVM-3aQ0WgB04ZXwNPYVAYy9ssb3Wd06E34ggUUxCcYQaVwAb0L03K40wpOxbnqqqa3f / ext4 defaults 0 1 # /boot was on /dev/sda2 during curtin installation /dev/disk/by-uuid/5e8f9763-2db8-48d0-85e2-a26d76521e2f /boot ext4 defaults 0 1 /swap.img none swap sw 0 0 root@ubuntu200404:/data# 范例：添加新的挂载点后修改/etc/fstab文件\n# /etc/fstab: static file system information. # # Use \u0026#39;blkid\u0026#39; to print the universally unique identifier for a # device; this may be used with UUID= as a more robust way to name devices # that works even if disks are added and removed. See fstab(5). # # \u0026lt;file system\u0026gt; \u0026lt;mount point\u0026gt; \u0026lt;type\u0026gt; \u0026lt;options\u0026gt; \u0026lt;dump\u0026gt; \u0026lt;pass\u0026gt; # / was on /dev/ubuntu-vg/ubuntu-lv during curtin installation /dev/disk/by-id/dm-uuid-LVM-3aQ0WgB04ZXwNPYVAYy9ssb3Wd06E34ggUUxCcYQaVwAb0L03K40wpOxbnqqqa3f / ext4 defaults 0 1 # /boot was on /dev/sda2 during curtin installation /dev/disk/by-uuid/5e8f9763-2db8-48d0-85e2-a26d76521e2f /boot ext4 defaults 0 1 /swap.img none swap sw 0 0 # 添加该行后、重启系统 UUID=0e850a4a-028d-48b2-aa18-dd8b16090aa6 /data/mysql_mount ext4 defaults 0 0 2.5 处理交换文件和分区 2.5.1 swap分区 swap交换分区是系统RAM的补充，swap 分区支持虚拟内存。当没有足够的 RAM 保存系统处理的数据 时会将数据写入 swap 分区，当系统缺乏 swap 空间时，内核会因 RAM 内存耗尽而终止进程。配置过 多 swap 空间会造成存储设备处于分配状态但闲置，造成浪费，过多 swap 空间还会掩盖内存泄露 注意：为优化性能，可以将swap 分布存放，或高性能磁盘存放\n2.5.2 交换分区实现过程 创建交换分区或者文件 使用mkswap写入特殊签名 在/etc/fstab文件中添加适当的条目 使用swapon -a 激活交换空间 启用swap分区\nswapon [OPTION]... [DEVICE] 常用选项\n-a #激活所有的交换分区 -p PRIORITY #指定优先级(-1到32767之间)，值越大,优先级越高.也可在/etc/fstab文件中的第4列指 定：pri=value 范例:创建swap分区\n[root@centos8 ~]#mkswap /dev/sdc1 禁用swap分区\nswapoff [OPTION]... [DEVICE] 范例:禁用swap分区\n[root@centos8 ~]#sed -i.bak \u0026#39;/swap/d\u0026#39; /etc/fstab [root@centos8 ~]#swapoff -a 2.5.3 swap的使用策略 /proc/sys/vm/swappiness 的值决定了当内存占用达到一定的百分比时，会启用swap分区的空间 使用规则\n当内存使用率达到100-swappiness时,会启用交换分区 简单地说这个参数定义了系统对swap的使用倾向，此值越大表示越倾向于使用swap。 可以设为0，这样做并不会禁止对swap的使用，只是最大限度地降低了使用swap的可能性 范例\n#说明：CentOS7和8默认值为30，内存在使用到100-30=70%的时候，就开始出现有交换分区的使用。 [root@centos8 ~]# cat /proc/sys/vm/swappiness 2.6 磁盘常见工具 2.6.1 df 文件系统空间实际真正占用等信息的查看工具 df\ndf [OPTION]... [FILE]... 常用选项\n-H 以10为单位 -T 文件系统类型 -h human-readable -i inodes instead of blocks -P 以Posix兼容的格式输出 2.6.3 du 查看某目录总体空间实际占用状态 du\n显示指定目录下面各个子目录的大小,单位为KB\n常用选项\n-a --all 显示所有文件和目录的大小,默认只显示目录大小 -h human-readable -s summary --max-depth=# 指定最大目录层级 -x, --one-file-system #忽略不在同一个文件系统的目录 面试题\n1.df 和 du 区别?什么时候df \u0026gt;du（空分区的时候) df 查看是文件系统的空间使用，包括元数据和数据，删除文件后，如果此文件正在使用，不会立即释放空间;du 查看是文件数据空间使用，不包括元数据，删除文件后空间立即释放。\n2.什么时候df \u0026lt; du? 目录内挂载有其它分区时的情况\n3.当删除文件但不释放空间时,有什么不同? du 查看文件空间释放,df不释放\n3. RAID ","permalink":"https://xyenvy.github.io/posts/disk/","summary":"磁盘管理与文件系统 前言 磁盘是计算机主要的存储介质，可以存储大量的二进制数据，并且断电后也能保持数据不丢失，使用磁盘存储数据的时候我们可以将磁盘划分成我们所需要的格式来进行使用 1. 磁盘结构 1、硬盘的物理结构 盘片：硬盘有多个盘片，每个盘片有2面 磁头：每面有一个磁头 2.硬盘数据结构 扇区：","title":"磁盘存储和文件系统管理"},{"content":"Docker 详细教程 一、Docker简介 1.1 docker是什么 【问题】：问什么会有docker出现\n​Docker的出现 使得Docker得以打破过去「程序即应用」的观念。透过镜像(images)将作业系统核心除外，运作应用程式所需要的系统环境，由下而上打包，达到应用程式跨平台间的无缝接轨运作。\n【docker理念】：解决了运行环境和配置问题的软件容器，方便持续继承并有助于整体发布的容器虚拟化技术。\n1.2 容器与虚拟机比较 1.2.1 容器发展简史 ￼￼￼\r1.2.2 传统虚拟机技术 虚拟机（virtual machine）就是带环境安装的一种解决方案。\n它可以在一种操作系统里面运行另一种操作系统，比如在Windows10系统里面运行Linux系统CentOS7。应用程序对此毫无感知，因为虚拟机看上去跟真实系统一模一样，而对于底层系统来说，虚拟机就是一个普通文件，不需要了就删掉，对其他部分毫无影响。这类虚拟机完美的运行了另一套系统，能够使应用程序，操作系统和硬件三者之间的逻辑不变。\nWin10 VMWare Centos7 各种cpu、内存网络额配置+各种软件 虚拟机实例 虚拟机的缺点：\n1 资源占用多 2 冗余步骤多 3 启动慢\n1.2.3 容器虚拟化技术 由于前面虚拟机存在某些缺点，Linux发展出了另一种虚拟化技术：\nLinux容器(Linux Containers，缩写为 LXC)\nLinux容器是与系统其他部分隔离开的一系列进程，从另一个镜像运行，并由该镜像提供支持进程所需的全部文件。容器提供的镜像包含了应用的所有依赖项，因而在从开发到测试再到生产的整个过程中，它都具有可移植性和一致性。\nLinux 容器不是模拟一个完整的操作系统 而是对进程进行隔离。有了容器，就可以将软件运行所需的所有资源打包到一个隔离的容器中。 容器与虚拟机不同，不需要捆绑一整套操作系统 ，只需要软件工作所需的库资源和设置。系统因此而变得高效轻量并保证部署在任何环境中的软件都能始终如一地运行。\n1.2.4 对比 比较了 Docker 和传统虚拟化方式的不同之处：\n传统虚拟机技术是虚拟出一套硬件后，在其上运行一个完整操作系统，在该系统上再运行所需应用进程； 容器内的应用进程直接运行于宿主的内核，容器内没有自己的内核 且也没有进行硬件虚拟 。因此容器要比传统虚拟机更为轻便。 每个容器之间互相隔离，每个容器有自己的文件系统 ，容器之间进程不会相互影响，能区分计算资源。\n1.3 能干什么 1.3.1 技术职级变化 coder -\u0026gt; programmer -\u0026gt; software engineer -\u0026gt; DevOps engineer\n1.3.2 开发/运维（Devops)新一代开发工程师 一次构建、随处运行 更快速的应用交付和部署 更便捷的升级和扩缩容 更简单的系统运维 更高效的计算资源利用 1.3.3 Docker应用场景 Docker 借鉴了标砖集装箱的概念。标准集装箱将货物运往世界各地，Docker将这个模型运用到自己的设计中，唯一不同的是：集装箱运输货物，而Docker运输软件。\n1.4 那些企业在使用 新浪\n美团\n蘑菇街 1.5 下载地址 官网：\nDocker Hub 官网：\n二、Docker安装 2.1 前提说明 2.1.1 CentOS Docker 安装 2.1.2 前提条件 目前，CentOS仅发行版本中的内核支持Docker。Docker运行在CentOS 7（64-bit）上，要求系统为64位，Linux系统内核版本为3.8以上，这里选用Centos7.x\n2.1.3 查看自己的内核 uname 命令用于打印当前系统相关信息（内核版本号，硬件架构，主机名称和操作系统类型等）。\n2.2 Docker的基本组成 2.2.1 镜像（image） Docker 镜像（Image）就是一个 只读 的模板。镜像可以用来创建 Docker 容器， 一个镜像可以创建很多容器 。\n它也相当于是一个root文件系统。比如官方镜像 centos:7 就包含了完整的一套 centos:7 最小系统的 root 文件系统。\n相当于容器的“源代码”， docker镜像文件类似于Java的类模板，而docker容器实例类似于java中new出来的实例对象。\n2.2.2 容器（container） 从面向对象角度 Docker 利用容器（Container）独立运行的一个或一组应用，应用程序或服务运行在容器里面，容器就类似于一个虚拟化的运行环境， 容器是用镜像创建的运行实例 。就像是Java中的类和实例对象一样，镜像是静态的定义，容器是镜像运行时的实体。容器为镜像提供了一个标准的和隔离的运行环境 ，它可以被启动、开始、停止、删除。每个容器都是相互隔离的、保证安全的平台\n从镜像容器角度 可以把容器看做是一个简易版的 *Linux* 环境 （包括root用户权限、进程空间、用户空间和网络空间等）和运行在其中的应用程序。\n2.2.3 仓库（repository） 仓库（Repository）是 集中存放镜像 文件的场所。\n类似于\nMaven仓库，存放各种jar包的地方；\ngithub仓库，存放各种git项目的地方；\nDocker公司提供的官方registry被称为Docker Hub，存放各种镜像模板的地方。\n仓库分为公开仓库（Public）和私有仓库（Private）两种形式。\n最大的公开仓库是 Docker Hub ，\n存放了数量庞大的镜像供用户下载。国内的公开仓库包括阿里云 、网易云等\n2.2.4 小总结 需要正确的理解仓库/镜像/容器这几个概念: Docker 本身是一个容器运行载体或称之为管理引擎。我们把应用程序和配置依赖打包好形成一个可交付的运行环境，这个打包好的运行环境就是image镜像文件。只有通过这个镜像文件才能生成Docker容器实例(类似Java中new出来一个对象)。\nimage文件可以看作是容器的模板。Docker 根据 image 文件生成容器的实例。同一个 image 文件，可以生成多个同时运行的容器实例。\n镜像文件 image 文件生成的容器实例，本身也是一个文件，称为镜像文件。\n容器实例 一个容器运行一种服务，当我们需要的时候，就可以通过docker客户端创建一个对应的运行实例，也就是我们的容器 。\n仓库 就是放一堆镜像的地方，我们可以把镜像发布到仓库中，需要的时候再从仓库中拉下来就可以了。\n2.3 Docker平台架构图解（入门版） 2.3.1 Docker工作原理 Docker是一个Client-Server结构的系统，Docker守护进程运行在主机上， 然后通过Socket连接从客户端访问，守护进程从客户端接受命令并管理运行在主机上的容器 。 容器，是一个运行时环境，就是我们前面说到的集装箱。可以对比mysql演示对比讲解\n2.3.2 整体架构及底层通信原理简述 Docker是一个C/S模式的架构，后端是一个松耦合架构，众多模块各司其职\n2.3.3 Docker运行的基本流程为 用户是使用Docker Client 与Docker Daemon 建立通信，并发送请求给后者。 Docker Daemon 作为Docker架构中的主体部分，首先提供Docker Server 的功能时期可以接受 Docker Client的请求。 Docker Engine 执行Docker内部的一些列工作，每一项工作都是以一个Job的形式的存在。 Job的运行过程中，当需要容器镜像是，则从Docker Register中下载镜像，并通过镜像管理驱动Graph driver 将下载镜像以Graph的形式存储。 当需要为Docker创建网络环境时，通过网络驱动Network driver创建并配置Docker容器网络环境。 当需要限制Docker容器运行资源或执行用户指令等操作时，则通过Exec driver来完成。 Libcontainer是一项独立的容器管理包，Network driver以及Exec driver都是通过Libcontainer来实现具体容器进行的操作。 2.4、安装步骤 2.4.1 CentOS7安装Docker 确定你是CentOS7以上版本 # 查看CentOS版本命令 cat /etc/redhat-release 2.卸载旧版本\n# 卸载旧版本docker命令 $ sudo yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-engine 3.yum安装gcc相关命令\n# yum安装gcc相关命令 yum -y install gcc yum -y install gcc-c++ 4.安装需要的软件包\n使用存储库安装\n在新主机上首次安装Docker Engine之前，您需要设置Docker存储库。之后，您可以从存储库安装和更新Docker 设置存储库 安装 yum-utils 包（提供yum-config-manager 实用程序）并设置稳定的存储库 # 官网要求 yum install -y yum-utils 5.设置stable镜像仓库\n# 推荐使用 使用阿里的 docker 镜像仓库，国外的镜像仓库是比较慢的 yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo 6.更新yum软件包索引\n# 更新yum软件包索引 yum makecache fast 7.安装DOCKER CE 引擎\n# 命令 yum -y install docker-ce docker-ce-cli containerd.io 8.启动docker\n# 启动命令 systemctl start docker 9.测试\n# 测试 docker version docker run hello-world 10.卸载\n# 卸载命令 systemctl stop docker yum remove docker-ce docker-ce-cli containerd.io rm -rf /var/lib/docker rm -rf /var/lib/containerd 2.5、阿里云镜像加速 2.5.1 是什么 地址：\n注册一个属于自己的阿里云账户\n获得加速器地址连接：\n登陆阿里云开发者平台 点击控制台 选择容器镜像服务 获取加速器地址 粘贴脚本直接执行\nmkdir -p /etc/docker tee /etc/docker/daemon.json \u0026lt;\u0026lt;-\u0026#39;EOF\u0026#39; { \u0026#34;registry-mirrors\u0026#34;: [\u0026#34;https://aa25jngu.mirror.aliyuncs.com\u0026#34;] } EOF # 或者分开步骤执行 mkdir -p /etc/docker vim /etc/docker/daemon.json 重启服务器 # 重启服务器 systemctl daemon-reload systemctl restart docker 2.5.2 永远的HelloWorld 启动Docker后台容器（测试运行 hello-world）\n# 命令 docker run hello-world 2.5.3 底层原理 为什么Docker会比VM虚拟机快:\n(1)docker有着比虚拟机更少的抽象层 由于docker不需要Hypervisor(虚拟机)实现硬件资源虚拟化,运行在docker容器上的程序直接使用的都是实际物理机的硬件资源。因此在CPU、内存利用率上docker将会在效率上有明显优势。 (2)docker利用的是宿主机的内核,而不需要加载操作系统OS内核 当新建一个容器时,docker不需要和虚拟机一样重新加载一个操作系统内核。进而避免引寻、加载操作系统内核返回等比较费时费资源的过程,当新建一个虚拟机时,虚拟机软件需要加载OS,返回新建过程是分钟级别的。而docker由于直接利用宿主机的操作系统,则省略了返回过程,因此新建一个docker容器只需要几秒钟。 三、Docker常用命令 3.1 帮助启动类命令 # 启动命令 systemctl start docker # 停止命令 systemctl stop docker # 重启命令 systemctl restart docker # 查看docker状态 systemctl status docker # 开机启动 systemctl enable docker # 查看 docker 概要信息 docker info # 查看docker 总体帮助文档 docker --help # 查看docker命令帮助文档： docker 具体命令 --help 3.2 镜像命令 3.2.1 docker images # 列出本地主机上的镜像 docker images 各个选项说明:\nREPOSITORY：表示镜像的仓库源\nTAG：镜像的标签版本号\nIMAGE ID：镜像ID\nCREATED：镜像创建时间\nSIZE：镜像大小\n同一仓库源可以有多个 TAG版本，代表这个仓库源的不同个版本，我们使用 REPOSITORY:TAG 来定义不同的镜像。\n如果你不指定一个镜像的版本标签，例如你只使用 ubuntu，docker 将默认使用 ubuntu:latest 镜像\n3.2.2 OPTIONS 说明 -a : 列出本地所有的镜像（含历史映像层）\n-q：只显示镜像ID\n3.2.3 docker search 某个XXX镜像名字 # 网站 https://hub.docker.com # 命令 docker search [OPTIONS]镜像名字 # OPTIONS说明 # --limit ：只列出N个镜像，默认25个 docker search --limit 5 redis 案例：\n3.2.4 docker pull 某个XXX镜像名字 # 下载镜像 docker pull 镜像名字[:TAG] docker pull 镜像名字 # 没有TAG就是最新版本 等价于 docker pull 镜像名字：latest docker pull ubuntu 3.2.5 docker system df 查看镜像/容器/数据卷所占用的空间 3.2.6 docker rmi 删除镜像 # 删除单个 docker rmi -f 镜像ID # 删除多个 docker rmi -f 镜像名1:TAG 镜像名2:TAG # 删除全部 docker rmi -f $(docker images -qa) 3.2.7 谈谈docker虚悬镜像是什么？ 仓库名称，标签都是\u0026lt;none\u0026gt;的镜像，俗称虚悬镜像dangling image 长什么样子 后续Dockerfile章节在介绍 3.3 容器命令 有镜像才能创建容器，这是根本前提（下载一个CentOS或者ubuntu镜像演示）\n1.说明 2.docker pull centos 3.docker pull ubuntu 4.本次演示用ubuntu演示 3.3.1 新建+启动容器 新建+启动容器 命令 docker run [OPTIONS] IMAGE [COMMAND] [ARG\u0026hellip;]\nOPTIONS说明 OPTIONS说明（常用）：有些是一个减号，有些是两个减号\n\u0026ndash;name=\u0026ldquo;容器新名字\u0026rdquo; 为容器指定一个名称； -d: 后台运行容器并返回容器ID，也即启动守护式容器(后台运行)；\n-i：以交互模式运行容器，通常与 -t 同时使用； -t：为容器重新分配一个伪输入终端，通常与 -i 同时使用； 也即 启动交互式容器(前台有伪终端，等待交互) ； -P: 随机 端口映射，大写P -p: 指定 端口映射，小写p\n启动交互式容器（前台命令行）\n使用镜像centos:latest以 交互模式 启动一个容器,在容器内执行/bin/bash命令。\ndocker run -it centos /bin/bash\n参数说明：\n-i: 交互式操作。\n-t: 终端。\ncentos : centos 镜像。\n/bin/bash：放在镜像名后的是命令，这里我们希望有个交互式 Shell，因此用的是 /bin/bash。 要退出终端，直接输入 exit:\n3.3.2 列出当前所有正在运行的容器 # 列出当前所有正在运行的容器 docker ps [OPTIONS] # OPTIONS说明 -a : 列出当前所有 正在运行 的容器 + 历史上运行过 的 -l :显示最近创建的容器。 -n：显示最近n个创建的容器。 -q :静默模式，只显示容器编号。 3.3.3 退出容器 # 两种退出方式 # 1、run进去容器，exit退出，容器停止 exit # 2、run进去容器，ctrl+p+q退出，容器不停止 ctrl+p+q 3.3.4 启动已停止运行的容器 # 启动已停止运行的容器 docker start 容器ID或者容器名 # 重启容器 docker restart 容器ID或者容器名 # 停止容器 docker stop 容器ID或者容器名 # 强制停止容器 docker kill 容器ID或容器名 # 删除已停止的容器 docker rm 容器ID # 一次性删除多个容器实例 docker rm -rf $(docker ps -a -q) docker ps -a -q | xargs docker rm 3.3.5 重要 启动守护式容器（后台服务器）：\n有镜像才能创建容器，这是根本前提（下载一个Redis6.0.8镜像演示） 在大部分的场景下，我们希望docker的服务是在后台运行的，我们可以通过 -d 指定容器的后台运行模式。 docker run -d 容器名 # 使用镜像centos:latest以后台模式启动一个容器 docker run -d centos 问题：然后docker ps -a 进行查看, 会发现容器已经退出 很重要的要说明的一点: Docker容器后台运行,就必须有一个前台进程. 容器运行的命令如果不是那些 一直挂起的命令 （比如运行top，tail），就是会自动退出的。 这个是docker的机制问题,比如你的web容器,我们以nginx为例，正常情况下, 我们配置启动服务只需要启动响应的service即可。例如service nginx start 但是,这样做,nginx为后台进程模式运行,就导致docker前台没有运行的应用, 这样的容器后台启动后,会立即自杀因为他觉得他没事可做了. 所以，最佳的解决方案是, 将你要运行的程序以前台进程的形式运行， 常见就是命令行模式，表示我还有交互操作，别中断，O(∩_∩)O哈哈~ redis前后台启动演示case\n# 前台交互式启动 docker run -it redis:6.0.8 # 后台交互式启动 docker run -d redis:6.0.8 查看容器日志\n# 查看容器日志 docker logs 容器ID 查看容器内运行的进程\n# 查看容器内运行的进程 docker top 容器ID 查看容器内部细节\n# 查看容器内部细节 docker inspect 容器ID 进入正在运行的容器并以命令行交互\ndocker exec -it 容器ID bashShell 重新进入docker attach 容器ID\n案例演示，用centos或者unbuntu都可以 上述两个区别：\nattach 直接进入容器启动命令的终端，不会启动新的进程用exit退出，会导致容器的停止。 2. exec 是在容器中打开新的终端，并且可以启动新的进程用exit退出，不会导致容器的停止。\n推荐大家使用docker exec 命令，因为退出容器终端，不会导致容器的停止。\n使用之前的redis容器实例进入试试\ndocker exec -it 容器ID /bin/bash docker exec -it 容器ID redis-cli 一般用-d后台启动的程序，在用exec进入对应容器实例 从容器内拷贝文件到主机上\n容器 -\u0026gt; 主机\ndocker cp 容器ID:容器内路径 目的主机路径\n公式： docker cp 容器 ID: 容器内路径 目的主机路径\n导入和导出容器\nExport 导出容器的内容留作为一个tar归档文件[对应import命令]\nimport 从tar 包中的内容创建一个新的文件系统在导入为镜像[对应export]\n【案例】：\ndocker export 容器ID \u0026gt; 文件.tar\ncat 文件名.tar | docker import -镜像用户/镜像名:镜像版本号\n3.4 小总结 attach Attach to a running container # 当前 shell 下 attach 连接指定运行镜像 build Build an image from a Dockerfile # 通过 Dockerfile 定制镜像 commit Create a new image from a container changes # 提交当前容器为新的镜像 cp Copy files/folders from the containers filesystem to the host path #从容器中拷贝指定文件或者目录到宿主机中 create Create a new container # 创建一个新的容器，同 run，但不启动容器 diff Inspect changes on a container\u0026#39;s filesystem # 查看 docker 容器变化 events Get real time events from the server # 从 docker 服务获取容器实时事件 exec Run a command in an existing container # 在已存在的容器上运行命令 export Stream the contents of a container as a tar archive # 导出容器的内容流作为一个 tar 归档文件[对应 import ] history Show the history of an image # 展示一个镜像形成历史 images List images # 列出系统当前镜像 import Create a new filesystem image from the contents of a tarball # 从tar包中的内容创建一个新的文件系统映像[对应export] info Display system-wide information # 显示系统相关信息 inspect Return low-level information on a container # 查看容器详细信息 kill Kill a running container # kill 指定 docker 容器 load Load an image from a tar archive # 从一个 tar 包中加载一个镜像[对应 save] login Register or Login to the docker registry server # 注册或者登陆一个 docker 源服务器 logout Log out from a Docker registry server # 从当前 Docker registry 退出 logs Fetch the logs of a container # 输出当前容器日志信息 port Lookup the public-facing port which is NAT-ed to PRIVATE_PORT # 查看映射端口对应的容器内部源端口 pause Pause all processes within a container # 暂停容器 ps List containers # 列出容器列表 pull Pull an image or a repository from the docker registry server # 从docker镜像源服务器拉取指定镜像或者库镜像 push Push an image or a repository to the docker registry server # 推送指定镜像或者库镜像至docker源服务器 restart Restart a running container # 重启运行的容器 rm Remove one or more containers # 移除一个或者多个容器 rmi Remove one or more images # 移除一个或多个镜像[无容器使用该镜像才可删除，否则需删除相关容器才可继续或 -f 强制删除] run Run a command in a new container # 创建一个新的容器并运行一个命令 save Save an image to a tar archive # 保存一个镜像为一个 tar 包[对应 load] search Search for an image on the Docker Hub # 在 docker hub 中搜索镜像 start Start a stopped containers # 启动容器 stop Stop a running containers # 停止容器 tag Tag an image into a repository # 给源中镜像打标签 top Lookup the running processes of a container # 查看容器中运行的进程信息 unpause Unpause a paused container # 取消暂停容器 version Show the docker version information # 查看 docker 版本号 wait Block until a container stops, then print its exit code # 截取容器停止时的退出状态值 四、Docker镜像 4.1 是什么 【镜像】 是一种轻量级、可执行的独立软件包，它包含运行某个软件所需的所有内容，我们把应用程序和配置依赖打包好形成一个可交付的运行环境(包括代码、运行时需要的库、环境变量和配置文件等)，这个打包好的运行环境就是image镜像文件。 只有通过这个镜像文件才能生成Docker容器实例(类似Java中new出来一个对象)。 【分层镜像】 以我们的pull为例，在下载的过程中我们可以看到docker的镜像好像是在一层一层的在下载 。 【UnionFS（联合文件系统）】 UnionFS（联合文件系统）：Union文件系统（UnionFS）是一种分层、轻量级并且高性能的文件系统，它支持 对文件系统的修改作为一次提交来一层层的叠加， 同时可以将不同目录挂载到同一个虚拟文件系统下(unite several directories into a single virtual filesystem)。Union 文件系统是 Docker 镜像的基础。 镜像可以通过分层来进行继承 ，基于基础镜像（没有父镜像），可以制作各种具体的应用镜像。 特性：一次同时加载多个文件系统，但从外面看起来，只能看到一个文件系统，联合加载会把各层文件系统叠加起来，这样最终的文件系统会包含所有底层的文件和目录 Docker镜像加载原理\nDocker镜像加载原理：\ndocker的镜像实际上由一层一层的文件系统组成，这种层级的文件系统UnionFS。\nbootfs(boot file system)主要包含bootloader和kernel, bootloader主要是引导加载kernel, Linux刚启动时会加载bootfs文件系统， 在Docker镜像的最底层是引导文件系统bootfs。 这一层与我们典型的Linux/Unix系统是一样的，包含boot加载器和内核。当boot加载完成之后整个内核就都在内存中了，此时内存的使用权已由bootfs转交给内核，此时系统也会卸载bootfs。\nrootfs (root file system) ，在bootfs之上 。包含的就是典型 Linux 系统中的 /dev, /proc, /bin, /etc 等标准目录和文件。rootfs就是各种不同的操作系统发行版，比如Ubuntu，Centos等等。\n平时我们安装进虚拟机的CentOS都是好几个G，为什么docker这里才200M？？\n对于一个精简的OS，rootfs可以很小，只需要包括最基本的命令、工具和程序库就可以了，因为底层直接用Host的kernel，自己只需要提供 rootfs 就行了。由此可见对于不同的linux发行版, bootfs基本是一致的, rootfs会有差别, 因此不同的发行版可以公用bootfs。\n为什么Docker镜像要采用这种分层结构呢\n镜像分层最大的一个好处就是共享资源，方便复制迁移，就是为了复用。\n比如说有多个镜像都从相同的 base 镜像构建而来，那么 Docker Host 只需在磁盘上保存一份 base 镜像； 同时内存中也只需加载一份 base 镜像，就可以为所有容器服务了。而且镜像的每一层都可以被共享。\n4.2 重点理解 Docker镜像层都是只读的，容器层是可写的，当容器启动时，一个新的可写层被加载到镜像的顶部。这一层通常被称作\u0026quot;容器层\u0026quot;，\u0026ldquo;容器层\u0026quot;之下的都叫\u0026quot;镜像层\u0026rdquo;。\n所有对容器的改动 - 无论添加、删除、还是修改文件都只会发生在容器层中。只有容器层是可写的，容器层下面的所有镜像层都是只读的。\n4.3 Docker镜像commit操作案例 docker commit 提交容器副本使之成为一个新的镜像\ndocker commit -m=\u0026ldquo;提交的描述信息\u0026rdquo; -a=\u0026ldquo;作者\u0026rdquo; 容器ID 要创建的目标镜像名:[标签名]\n【案例演示】ubuntu安装vim\n从Hub上下ubuntu镜像到笨地并成功运行 原始默认Ubuntu镜像是不带着vim命令的 外网连通情况下，安装vim # 先更新我们的包管理工具 apt-get update # 然后安装我们需要的vim apt-get install vim docker容器内执行上述两条命令：\napt-get update\napt-get -y install vim\n4.安装完成后，commit我们自己的新镜像\n启动我们的新镜像并和原来的对比\n官网是默认下载的Ubuntu没有vim命令\n我们自己commit构建的镜像，新增加了vim功能，可以成功使用。\n总结\nDocker中的镜像分层， 支持通过扩展现有镜像，创建新的镜像 。类似Java继承于一个Base基础类，自己再按需扩展。 新镜像是从 base 镜像一层一层叠加生成的。每安装一个软件，就在现有镜像的基础上增加一层 五、本地镜像发布到阿里云 5.1 本地镜像发布到阿里云流程 5.2 镜像生成的方法 上一讲已经介绍过\n基于当前容器创建一个新的镜像，新功能增强\ndocker commit [OPTIONS]容器ID [REPOSOTORY[:TAG]]\nOPTIONS说明：\n-a :提交的镜像作者；\n-m :提交时的说明文字；\n本次案例centos+ubuntu两个，当堂讲解一个，家庭作业一个，请大家务必动手，亲自实操。\n5.3 将本地镜像推送到阿里云 本地镜像素材原型\n阿里云开发者平台\n地址：\n将镜像推送到阿里云\n将镜像推送到阿里云registry ，管理界面脚本\n脚本实例\ndocker login --username=zzyybuy registry.cn-hangzhou.aliyuncs.com docker tag cea1bb40441c registry.cn-hangzhou.aliyuncs.com/atguiguwh/myubuntu:1.1 docker push registry.cn-hangzhou.aliyuncs.com/atguiguwh/myubuntu:1.1 上面命令是阳哥自己本地的，你自己酌情处理，不要粘贴我的。 5.4 将阿里云上的镜像下载到本地 docker pull registry.cn-hangzhou.aliyuncs.com/atguiguwh/myubuntu:1.1 六、本地镜像发布到私有库 6.1 本地镜像发布到私有库流程 下载镜像Docker Registry\ndocker pull registry\n运行私有库Registry，相当于本地有个私有库Docker hub\ndocker run -d -p 5000:5000 -v /zzyyuse/myregistry/:/tmp/registry \u0026ndash;privileged=true registry\n默认情况，仓库被创建在容器的/var/lib/registry目录下，建议自行用容器卷映射，方便于宿主机联调\n案例演示创建一个新镜像，ubuntu安装ifconfig命令\n从Hub上下载ubuntu镜像到本地并成功运行\n原始Ubuntu镜像是不带着ifconfig命令的\n从Hub上下载ubuntu镜像到本地并成功运行\n原始Ubuntu镜像是不带着ifconfig命令的\n外网连通情况下，安装ifconfig命令通过测试\ndocker容器内 执行上述两条命令：\napt-get update\napt-get install net-tools\n安装完成后，commit我们自己的新镜像\n公式：\ndocker commit -m=\u0026quot; 提交的描述信息 \u0026quot; -a=\u0026quot; 作者 \u0026quot; 容器 ID 要创建的目标镜像名 :[ 标签名 ]\n命令： 在容器外执行，记得\ndocker commit -m=\u0026quot; ifconfig cmd add \u0026quot; -a=\u0026quot; zzyy \u0026quot; a69d7c825c4f zzyyubuntu:1.2\n启动我们的新镜像并和原来的对比\n1.官网是默认下载的Ubuntu没有ifconfig命令\n2.我们自己commit构建的新镜像，新增加了ifconfig功能，可以成功使用。\n4.curl验证私服库上有什么镜像\ncurl -XGET http://192.168.111.162:5000/v2/_catalog 可以看到，目前私服库没有任何镜像上传过\n5.将新镜像zzyyubuntu:1.2修改符合私服规范的Tag\n按照公式： docker tag 镜像:Tag Host:Port/Repository:Tag 自己host主机IP地址，填写同学你们自己的，不要粘贴错误，O(∩_∩)O 使用命令 docker tag 将zzyyubuntu:1.2 这个镜像修改为192.168.111.162:5000/zzyyubuntu:1.2 docker tag zzyyubuntu:1.2 192.168.111.162:5000/zzyyubuntu:1.2 6. 修改配置文件使之支持http\n别无脑照着复制，registry-mirrors 配置的是国内阿里提供的镜像加速地址，不用加速的话访问官网的会很慢。 2个配置中间有个逗号 \u0026#39;,\u0026#39;别漏了 ，这个配置是json格式的。 2个配置中间有个逗号 \u0026#39;,\u0026#39;别漏了 ，这个配置是json格式的。 2个配置中间有个逗号 \u0026#39;,\u0026#39;别漏了 ，这个配置是json格式的。 vim命令新增如下红色内容：vim /etc/docker/daemon.json\n{ \u0026#34;registry-mirrors\u0026#34;: [\u0026#34;https://aa25jngu.mirror.aliyuncs.com\u0026#34;] , \u0026#34;insecure-registries\u0026#34;: [\u0026#34;192.168.111.162:5000\u0026#34;] } 上述理由：docker默认不允许http方式推送镜像，通过配置选项来取消这个限制。====\u0026gt; 修改完后如果不生效，建议重启docker\n7.push推送到私服库\ndocker push 192.168.111.162:5000/zzyyubuntu:1.2 ``` ![65](/docker.images/65.png) 8.curl验证私服库上有什么镜像2 curl -XGET http://192.168.111.162:5000/v2/_catalog ![66](/docker.images/66.png) 9. pull到本地并运行 ```shell docker pull 192.168.111.162:5000/zzyyubuntu:1.2 ``` ![67](/docker.images/67.png) docker run -it 镜像ID /bin/bash ![68](/docker.images/68.png) 七、Docker容器数据卷 7.1 坑：容器卷记得加入 --privileged=true # 原因 Docker挂载主机目录访问 如果出现cannot open directory .: Permission denied 解决办法：在挂载目录后多加一个--privileged=true参数即可 如果是CentOS7安全模块会比之前系统版本加强，不安全的会先禁止，所以目录挂载的情况被默认为不安全的行为， 在SELinux里面挂载目录被禁止掉了额，如果要开启，我们一般使用--privileged=true命令，扩大容器的权限解决挂载目录没有权限的问题，也即 使用该参数，container内的root拥有真正的root权限，否则，container内的root只是外部的一个普通用户权限。 7.2 回顾下上一将的知识点，参数V 还记得蓝色框框中的内容嘛\n7.3 是什么 一句话：有点类似我们Redis里面的rdb和aof文件 将docker容器内的数据保存进宿主机的磁盘中 运行一个带有容器卷存储功能的容器实例 docker run -it --privileged=true -v /宿主机绝对路径目录:/容器内目录 镜像名 7.4 能干什么 将运用与运行的环境打包镜像，run后形成容器实例运行 ，但是我们对数据的要求希望是 持久化的 Docker容器产生的数据，如果不备份，那么当容器实例删除后，容器内的数据自然也就没有了。 为了能保存数据在docker中我们使用卷。 特点： 1：数据卷可在容器之间共享或重用数据 2：卷中的更改可以直接实时生效，爽 3：数据卷中的更改不会包含在镜像的更新中 4：数据卷的生命周期一直持续到没有容器使用它为止 7.5 数据卷案例 7.5.1 宿主vs容器之间映射添加容器卷 直接命令添加\n公式：docker run -it -v /宿主机目录:/容器内目录 ubuntu /bin/bash docker run -it --name myu3 --privileged=true -v /tmp/myHostData:/tmp/myDockerData ubuntu /bin/bash 查看数据卷是否挂成功\ndocker inspect 容器ID 容器和宿主机之间数据共享\n1. docker修改，主机同步获得 2. 主机修改，docker同步获得 3. docker容器stop，主机修改，docker容器重启看数据是否同步。 7.5.2 读写规则映射添加说明 读写(默认)\ndocker run -it --privileged=true -v /宿主机绝对路径目录:/容器内目录:rw 镜像名 默认同上案例，默认就是rw 默认同上案例，默认就是rw 只读\n容器实例内部被限制，只能读取不能写\n/容器目录:ro 镜像名 就能完成功能，此时容器自己只能读取不能写 ro = read only 此时如果宿主机写入内容，可以同步给容器内，容器可以读取到。 docker run -it --privileged=true -v /宿主机绝对路径目录:/容器内目录:ro 镜像名 7.5.3 卷的集成和共享 容器1完成和宿主机的映射\ndocker run -it --privileged=true -v /mydocker/u:/tmp --name u1 ubuntu 容器2集成容器1的卷规则\ndocker run -it --privileged=true --volumes-from 父类 --name u2 ubuntu 八、Docker常规安装简介 8.1 总体步骤 1. 搜索镜像 2. 拉去镜像 3. 查看镜像 4. 查看镜像 5. 启动镜像 服务端口映射 6. 停止容器 8.2 安装tomcat 1、docker hub 上面查找tomcat镜像\n# 命令 docker search tomcat 2、从docker hub 上拉去tomcat镜像到本地\n# 命令 docker pull tomcat 3、docker images 查看是否有拉去到tomcat\n# 命令 docker images tomcat 4、使用tomcat镜像创建容器实例（也叫运行镜像）\n# 命令 docker run -it -p 8080:8080 tomcat -p 小写，主机端口:docker容器端口 -P 大写，随机分配端口 i:交互 t:终端 d:后台 5、访问tomcat首页\n可能出现404 的情况 解决 1、可能没有映射端口或者没有关闭防火墙 2、把webapps.dist 目录换成webapps 先成功启动tomcat 查看webapps文件夹查看为空\n6、免修改版说明\ndocker pull billygoo/tomcat8-jdk8\nDocker run -d -p 8080:8080 \u0026ndash;name mytomcat8 billygoo/tomcat8-djk8\n8.3 安装mysql 1、docker hub上面查找mysql镜像\n# 命令 docker search mysql 2、从docker hub上（阿里云加速器）拉去mysql镜像到本地标签为5.7\n# 命令 docker pull mysql:5.7 3、使用mysql5.7 镜像创建容器（也叫运行镜像）\n# 1、命令出处，哪里来的 地址：https://hub.docker.com/_/mysql # 2、简单版 docker run -p 3306:3306 -e MYSQL_ROOT_PASSWORD=123456 -d mysql:5.7 docker ps docker exec -it 容器ID /bin/bash mysql -uroot -p # 4、 建库建表插入数据 外部Win10也来连接运行在dokcer上的mysql容器实例服务 【问题】 插入中文数据试试，为什么报错？ docker 上默认字符集编码隐患 docker里面的mysql容器实例查看，内容如下： SHOW VARIABLES LIKE \u0026#39;character%\u0026#39; 删除容器后，里面的mysql数据如何办 容器实例一删除，你还有什么？ 删容器到跑路。。。。。？ 【实战版】\n#1、新建mysql容器实例 docker run -d -p 3306:3306 --privileged=true -v /zzyyuse/mysql/log:/var/log/mysql -v /zzyyuse/mysql/data:/var/lib/mysql -v /zzyyuse/mysql/conf:/etc/mysql/conf.d -e MYSQL_ROOT_PASSWORD=123456 --name mysql mysql:5.7 #2、新建my.cnf 通过容器卷同步给MySQL容器实例 [client] default_character_set=utf8 [mysqld] collation_server = utf8_general_ci character_set_server = utf8 #3、重新启动mysql容器实例在重新进入并查看字符编码 docker restart mysql docker exec -it mysql_bash show variables like \u0026#39;character%\u0026#39;; #4、再新建库新建表再插入中文测试 完全正常 #5、结论 之前的DB 无效 修改字符集操作+重启mysql容器实例 之后的DB 有效，需要新建 结论： docker安装完MySQL并run出容器后，建议请先修改完字符集编码后再新建mysql库-表-插数据 #6、假如将当前容器实例删除，再重新来一次，之前建的db01实例还有吗？trytry 8.4 安装redis 1、从docker hub上（阿里云加速器）拉去redis镜像到本地标签6.0.8\n# 拉去镜像 docker pull redis:6.0.8 # 查看镜像 docker images 2、入门命令\n# 启动命令 docker run -d -p 6379:6379 redis:6.0.8 # docker ps # 后台启动 docker exec -it CONTAINER ID /bin/bash 3、命令提醒：容器卷记得加入 \u0026ndash;privileged=true\nDocker挂载主机目录Docker访问出现cannot open directory .: Permission denied 解决办法：在挂载目录后多加一个--privileged=true参数即可 4、在CentOS宿主机下新建目录/app/redis\n# 新建目录 mkdir -p /app/redis 5、将一个redis.conf文件模板拷贝进 /app/redis目录下\nmkdir -p /app/redis cp /myredis/redis.conf /app/redis/ cp /app/redis 6、/app/redis 目录下修改redis.conf\n# 修改redis.conf文件 /app/redis目录下修改redis.conf文件 开启redis验证 可选 requirepass 123 允许redis外地连接 必须 注释掉 # bind 127.0.0.1 # 注释daemonize no daemonize no 将daemonize yes注释起来或者 daemonize no设置，因为该配置和docker run中-d参数冲突，会导致容器一直启动失败 # 开启redis数据持久化 appendonly yes 可选 7、使用redis6.0.8 镜像创建容器(也叫运行镜像)\ndocker run -p 6379:6379 --name myr3 --privileged=true -v /app/redis/redis.conf:/etc/redis/redis.conf -v /app/redis/data:/data -d redis:6.0.8 redis-server /etc/redis/redis.conf 8、测试redis-cli连接上\ndocker exec -it 运行着Rediis服务的容器ID redis-cli\n9、请证明docker启动使用了我们自己指定的配置文件\n【修改前】\n【修改后】\n10、测试redis-cli连接上来第2次\n","permalink":"https://xyenvy.github.io/posts/docker/","summary":"Docker 详细教程 一、Docker简介 1.1 docker是什么 【问题】：问什么会有docker出现 ​Docker的出现 使得Docker得以打破过去「程序即应用」的观念。透过镜像(images)将作业系统核心除外，运作应用程式所需要的系统环境，由下而上打包，达到应用程式跨平台间的无缝接轨运作。","title":"Docker基础详细教程"},{"content":"内容简述 shell 是操作系统的最外层。shell 合并编程语言以控制进程和文件，以及启动和控制其它程序。shell 通过提示您输入，向操作系统解释该输入，然后处理来自操作系统的任何结果输出来管理您与操作系统之间的交互。\n1.编程基础 Linus：Talk is cheap, show me the code\n1.1 程序组成 程序：算法+数据结构 算法：处理数据的方式 数据结构：数据在计算机中的类型和组织方式 数据：是程序的核心，程序为数据提供服务 1.2 程序编程风格 面向过程语言 做一件事情，排出个步骤，第一步干什么，第二步干什么，如果出现情况A，做什么处理，如果出现了情况B，做什么处理 问题规模小，可以步骤化，按部就班处理 以指令为中心，数据服务于指令 C，shell 面向对象语言 将编程看成是一个事物，对外界来说，事物是直接使用的,不用关心事物内部的情况。而编程就是设置事物能够完成功能。 一种认识世界、分析世界的方法论。将万事万物抽象为各种对象 类是抽象的概念，是万事万物的抽象，是一类事物的共同特征的集合 对象是类的具体实现，是一个实体 问题规模大，复杂系统 以数据为中心，指令服务于数据 java，C#，python，golang等 1.3 编程语言 编程语言排行榜链接\nhttps://www.tiobe.com/tiobe-index/ 计算机：运行二进制指令\n编程语言：人与计算机之间交互的语言。分为两种：低级语言和高级语言\n低级编程语言： 机器：二进制的0和1的序列，称为机器指令。与自然语言差异太大，难懂、难写 汇编：用一些助记符号替代机器指令，称为汇编语言\n如：ADD A,B 将寄存器A的数与寄存器B的数相加得到的数放到寄存器A中\n汇编语言写好的程序需要汇编程序转换成机器指令\n汇编语言稍微好理解，即机器指令对应的助记符，助记符更接近自然语言 高级编程语言： 编译：高级语言\u0026ndash;\u0026gt;编译器\u0026ndash;\u0026gt;机器代码文件\u0026ndash;\u0026gt;执行，如：C，C++ 解释：高级语言\u0026ndash;\u0026gt;执行\u0026ndash;\u0026gt;解释器\u0026ndash;\u0026gt;机器代码，如：shell，python，php，JavaScript，perl 编译和解释型语言 1.4 编程逻辑处理方式 三种处理逻辑\n顺序执行：程序按从上到下顺序执行 选择执行：程序执行过程中，根据条件的不同，进行选择不同分支继续执行 循环执行：程序执行过程中需要重复执行多次某段语句 2.shell 脚本语言的基本用法 2.1 shell 脚本的用途 将简单的命令组合完成复杂的工作,自动化执行命令,提高工作效率 减少手工命令的输入，一定程度上避免人为错误 将软件或应用的安装及配置实现标准化 用于实现日常性的,重复性的,非交互式的运维工作,如:文件打包压缩备份,监控系统运行状态并实现告警等 2.2 shell脚本基本结构 shell脚本编程：是基于过程式、解释执行的语言\n编程语言的基本结构：\n各种系统命令的组合 数据存储：变量、数组 表达式：a + b 控制语句：if shell脚本：包含一些命令或声明，并符合一定格式的文本文件 格式要求：首行shebang机制\n#!/bin/bash #!/usr/bin/python #!/usr/bin/perl #!/usr/bin/ruby #!/usr/bin/lua 2.3 shell脚本创建过程 第一步：使用文本编编辑器来创建文本文件\n第一行必须包括shell声明序列：#! 示例：\n#!/bin/bash # 使用bash，添加注释,注释以#开头 第二步：加执行权限 给予执行权限，在命令行上指定脚本的绝对或相对路径 第三步：运行脚本 直接运行解释器，将脚本作为解释器程序的参数运行\n扩展：查看当前使用的是何种shell，终端输入：echo $SHELL\nroot@ubuntu200404:~# echo $SHELL /bin/bash root@ubuntu200404:~# 2.4 shell脚本注释规范 第一行一般为调用使用的语言 程序名，避免更改文件名为无法找到正确的文件 版本号 更改后的时间 作者相关信息 该程序的作用，及注意事项 最后是各版本的更新简要说明 2.5 第一个shell脚本 范例：第一个shell脚本hello world\n参考文档：\nhttps://zh.wikipedia.org/wiki/Hello_World https://zh.wikipedia.org/wiki/Hello_World%E7%A8%8B%E5%BA%8F%E6%A0%B7%E4%BE%8B 程序样例\n第一步：vim创建hello.sh文本\nroot@ubuntu200404:~# vim hello.sh 第二步：声明序列和添加脚本名称、日期等\n#!/bin/bash #****************** #filename:hello.sh #Data:2022-08-06 #author:admin #****************** 第三步：编写代码\n#经典写法 echo \u0026#34;hello, world\u0026#34; #流行写法 echo \u0026#39;Hello, world!\u0026#39; 第四步：执行shell脚本\n方法一：\nroot@ubuntu200404:~# bash hello.sh hello world! ****************** hello world! root@ubuntu200404:~# 方法二：\nroot@ubuntu200404:/data/scripts# cat /data/scripts/hello.sh | bash hello world! ****************** hello world! root@ubuntu200404:/data/scripts# 方法三：\nroot@ubuntu200404:/data/scripts# bash \u0026lt; /data/scripts/hello.sh hello world! ****************** hello world! root@ubuntu200404:/data/scripts# 方法四：添加执行权限使用绝对路径和相对路径\n# 绝对路径 root@ubuntu200404:/data/scripts# /data/scripts/hello.sh hello world! ****************** hello world! root@ubuntu200404:/data/scripts# # 相对路径 root@ubuntu200404:/data/scripts# pwd /data/scripts root@ubuntu200404:/data/scripts# ./hello.sh hello world! ****************** hello world! root@ubuntu200404:/data/scripts# 方法五：将脚本添加到path变量中\n# 当前path位置 root@ubuntu200404:/data/scripts# echo $PATH /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin root@ubuntu200404:/data/scripts# # 给hello.sh文件创建软链接放到/usr/local/bin目录下 root@ubuntu200404:/data/scripts# ln -s /data/scripts/hello.sh /usr/local/bin/ root@ubuntu200404:/data/scripts# ls /usr/local/bin/ hello.sh root@ubuntu200404:/data/scripts# # 执行shell脚本 root@ubuntu200404:/data/scripts# hello.sh hello world! ****************** hello world! root@ubuntu200404:/data/scripts# 方法六：本方法可以实现执行远程主机的shell脚本\n# 扩展：curl加-s选项不显示下载信息 root@ubuntu200404:/data# curl -s http://wangxiaochun.com/testdir/hello.sh |bash hello, world Hello, world! root@ubuntu200404:/data# 案例：备份脚本\n# 脚本内容 root@ubuntu200404:/data/scripts# cat -n bacup.sh 1#!/bin/bash 2#------------------ 3#filename:bacup.sh 4#备份脚本 5#------------------ 6 7 8tar zcf /data/scripts-`date +%F_%s`.tar.gz /data/ \u0026amp;\u0026gt; /dev/null 9 10echo -e \u0026#34;\\E[1;32mbacup is success!\\E[0m\u0026#34; # 执行脚本 root@ubuntu200404:/data/scripts# bash bacup.sh bacup is success! root@ubuntu200404:/data/scripts# 2.6 shell脚本调试 只检测脚本中的语法错误，但无法检查出命令错误，但不真正执行脚本\nbash -n /path/to/some_script 调试并执行\nbash -x /path/to/some_script 案例1：\nroot@ubuntu200404:/data/scripts# bash -x hello.sh + echo \u0026#39;hello world!\u0026#39; hello world! + echo \u0026#39;******************\u0026#39; ****************** + echo \u0026#39;hello world!\u0026#39; hello world! root@ubuntu200404:/data/scripts# 案例2:多行重定向\n脚本内容：\n#!/bin/bash # 多行重定向 #data:2022-08-06 #author:admin #-------------------------------------------- echo start cat \u0026gt;/data/demo.conf \u0026lt;\u0026lt;EOF line 1 line 2 line 3 EOF echo end root@ubuntu200404:/data/scripts# 检查错误：\nroot@ubuntu200404:/data/scripts# bash -n demo1.sh demo1.sh: line 17: warning: here-document at line 11 delimited by end-of-file (wanted `EOF\u0026#39;) root@ubuntu200404:/data/scripts# 检查出第十七行有错误，肉眼观察没有错误，这是因为有些错误不显示在屏幕上的，可以通过cat -A filename或者在vi命令行模式下输入：set list\n使用cat -A filename命令后发现EOF后面多了个空格导致错误。删除掉空格脚本即可成功运行。\n在vi命令行模式下输入set list\n总结：脚本错误常见的有三种\n语法错误，会导致后续的命令不继续执行，可以用bash -n 检查错误，提示的出错行数不一定是准 确的 命令错误，默认后续的命令还会继续执行，用bash -n 无法检查出来 ，可以使用 bash -x 进行观察 逻辑错误：只能使用 bash -x 进行观察 2.7 变量 2.7.1 变量 变量表示命名的内存空间，将数据放在内存空间中，通过变量名引用，获取数据\n2.7.2 变量类型 变量类型：\n内置变量，如：PS1，PATH，UID，HOSTNAME，$$，BASHPID，PPID，$?，HISTSIZE 用户自定义变量 不同的变量存放的数据不同，决定了以下\n数据存储方式 参与的运算 表示的数据范围 变量数据类型：\n字符 数值：整型、浮点型,bash 不支持浮点数 2.7.3 shell中变量命令规则 2.7.3.1 命名要求 区分大小写\n不能使程序中的保留字和内置变量：如：if, for 只能使用数字、字母及下划线，且不能以数字开头，注意：不支持短横线 “ - ”，和主机名相反\n只能使用数字、字母及下划线，且不能以数字开头，注意：不支持短横线 “ - ”，和主机名相反\n2.7.3.2 命令习惯 见名知义，用英文单词命名，并体现出实际作用，不要用简写，如：ATM 变量名大写 局部变量小写 函数名小写 大驼峰StudentFirstName,由多个单词组成，且每个单词的首字母是大写，其它小写 小驼峰studentFirstName ,由多个单词组成，第一个单词的首字母小写，后续每个单词的首字母是大写，其它小写 下划线: student_name 2.7.4 变量定义和引用 变量的生效范围等标准划分变量类型\n普通变量：生效范围为当前shell进程；对当前shell之外的其它shell进程，包括当前shell的子shell进程均无效 环境变量：生效范围为当前shell进程及其子进程 本地变量：生效范围为当前shell进程中某代码片断，通常指函数 变量赋值：\nname=\u0026#39;value\u0026#39; value 可以是以下多种形式\n直接字串：name=\u0026#39;root\u0026#39; 变量引用：name=\u0026#34;$USER\u0026#34; 命令引用：name=`COMMAND` 或者 name=$(COMMAND) **注意：**变量赋值是临时生效，当退出终端后，变量会自动删除，无法持久保存，脚本中的变量会随着脚本结束，也会自动删除\n变量引用：\n$name ${name} 弱引用和强引用\n\u0026ldquo;$name\u0026rdquo; 弱引用，其中的变量引用会被替换为变量值 \u0026lsquo;$name\u0026rsquo; 强引用，其中的变量引用不会被替换为变量值，而保持原字符串 范例：变量的各种赋值方式和引用\n方式1： root@ubuntu200404:/data/scripts# TITLE=cto root@ubuntu200404:/data/scripts# echo $TITLE cto root@ubuntu200404:/data/scripts# 方式二： root@ubuntu200404:/data/scripts# T=ceo root@ubuntu200404:/data/scripts# NAME=$T root@ubuntu200404:/data/scripts# echo $NAME ceo root@ubuntu200404:/data/scripts# 方式三： root@ubuntu200404:/data/scripts# NAME=`whoami` root@ubuntu200404:/data/scripts# echo $NAME root root@ubuntu200404:/data/scripts# 方式四： root@ubuntu200404:/data/scripts# seq 10 1 2 3 4 5 6 7 8 9 10 root@ubuntu200404:/data/scripts# # 弱引用 root@ubuntu200404:/data/scripts# echo \u0026#34;$NUM\u0026#34; 1 2 3 4 5 6 7 8 9 10 root@ubuntu200404:/data/scripts# 删除变量： unset name\nunset \u0026lt;name\u0026gt; 案例： root@ubuntu200404:/data/scripts# NUM=`seq 10` root@ubuntu200404:/data/scripts# echo $NUM 1 2 3 4 5 6 7 8 9 10 root@ubuntu200404:/data/scripts# unset NUM root@ubuntu200404:/data/scripts# echo $NUM root@ubuntu200404:/data/scripts# 显示已有的变量\nset 2.7.5 环境变量 环境变量：\n可以使子进程（包括孙子进程）继承父进程的变量，但是无法让父进程使用子进程的变量 一旦子进程修改从父进程继承的变量，将会新的值传递给孙子进 一般只在系统配置文件中使用，在脚本中较少使用 变量声明和赋值：\n#声明并赋值 export name=VALUE declare -x name=VALUE #或者分两步实现 name=VALUE export name 变量引用：\n$name ${name} 显示所有环境变量：\nenv printenv export declare -x 查看指定进程的环境变量\ncat /proc/$PID/environ 删除变量\nunset name bash内建的环境变量\nPATH SHELL USER UID HOME PWD SHLVL #shell的嵌套层数，即深度 LANG MAIL HOSTNAME HISTSIZE _ #下划线,表示前一命令的最后一个参数 扩展：pstree -p\nroot@ubuntu200404:/data/scripts# pstree -p systemd(1)─┬─VGAuthService(757) ├─accounts-daemon(811)─┬─{accounts-daemon}(818) │ └─{accounts-daemon}(864) ├─atd(837) ├─cron(815) ├─dbus-daemon(817) ├─irqbalance(824)───{irqbalance}(853) ├─login(1206)───bash(1402)───sudo(1413)───bash(1420) ├─multipathd(702)─┬─{multipathd}(703) │ ├─{multipathd}(704) │ ├─{multipathd}(705) │ ├─{multipathd}(706) │ ├─{multipathd}(707) │ └─{multipathd}(708) ├─networkd-dispat(825) ├─polkitd(872)─┬─{polkitd}(875) │ └─{polkitd}(877) ├─rsyslogd(826)─┬─{rsyslogd}(839) │ ├─{rsyslogd}(840) │ └─{rsyslogd}(841) ├─snapd(828)─┬─{snapd}(915) │ ├─{snapd}(916) │ ├─{snapd}(917) │ ├─{snapd}(918) │ ├─{snapd}(919) │ ├─{snapd}(945) │ ├─{snapd}(946) │ ├─{snapd}(952) │ ├─{snapd}(954) │ └─{snapd}(975) ├─sshd(859)─┬─sshd(3292)───bash(3421)───pstree(13708) │ └─sshd(6603)───bash(6736) ├─systemd(1477)───(sd-pam)(1478) ├─systemd(1392)───(sd-pam)(1393) ├─systemd-journal(495) ├─systemd-logind(830) ├─systemd-network(2826) ├─systemd-resolve(799) ├─systemd-timesyn(746)───{systemd-timesyn}(778) ├─systemd-udevd(525) ├─udisksd(836)─┬─{udisksd}(863) │ ├─{udisksd}(866) │ ├─{udisksd}(883) │ └─{udisksd}(906) ├─unattended-upgr(878)───{unattended-upgr}(908) ├─upowerd(2940)─┬─{upowerd}(2942) │ └─{upowerd}(2943) └─vmtoolsd(758)─┬─{vmtoolsd}(781) └─{vmtoolsd}(2774) ```bash ### 2.7.6 只读变量 **只读变量：只能声明定义，但后续不能修改和删除，即常量** **声明只读变量：** ```shell readonly name declare -r name 查看只读变量：\nreadonly [-p] declare -r 范例：\nroot@ubuntu200404:/data/scripts# readonly PI=3.14159 root@ubuntu200404:/data/scripts# echo $PI 3.14159 root@ubuntu200404:/data/scripts# PI=3.14 -bash: PI: readonly variable root@ubuntu200404:/data/scripts# 2.7.7 位置变量 位置变量：在bash shell中内置的变量, 在脚本代码中调用通过命令行传递给脚本的参数\n$1, $2, ... 对应第1个、第2个等参数，shift [n]换位置 $0 命令本身,包括路径 $* 传递给脚本的所有参数，全部参数合为一个字符串 $@ 传递给脚本的所有参数，每个参数为独立字符串 $# 传递给脚本的参数的个数 注意：$@ $* 只在被双引号包起来的时候才会有差异 清空所有位置变量\nset -- 范例：\n#!/bin/bash echo \u0026#34;1st arg is $1\u0026#34; echo \u0026#34;2st arg is $2\u0026#34; echo \u0026#34;3st arg is $3\u0026#34; echo \u0026#34;10st arg is ${10}\u0026#34; echo \u0026#34;11st arg is ${11}\u0026#34; echo \u0026#34;The number of arg is $#\u0026#34; echo \u0026#34;All args are $*\u0026#34; echo \u0026#34;All args are $@\u0026#34; echo \u0026#34;The scriptname is `basename $0`\u0026#34; root@ubuntu200404:/data/scripts# bash args.sh {a..z} 1st arg is a 2st arg is b 3st arg is c 10st arg is j 11st arg is k The number of arg is 26 All args are a b c d e f g h i j k l m n o p q r s t u v w x y z All args are a b c d e f g h i j k l m n o p q r s t u v w x y z The scriptname is args.sh root@ubuntu200404:/data/scripts# 范例：删库跑路之安全命令\n# 查看命令 root@ubuntu200404:/data/scripts# cat /data/scripts/rm.sh #!/bin/bash #----------------- #删库跑路之安全命令 #----------------- #filename:rm.sh #data:2022-08-06 #author:admin #----------------- WARNING_COLOR=\u0026#34;echo -e \\E[1;31m\u0026#34; END=\u0026#34;\\E[0m\u0026#34; DIR=/tmp/`date +%F_%H-%M-%S` mkdir ${DIR} mv $* ${DIR} ${WARNING_COLOR}Move $* to ${END} root@ubuntu200404:/data/scripts# # 给/data/scripts/rm.sh添加执行权限 root@ubuntu200404:/data/scripts# chmod a+x /data/scripts/rm.sh # 添加别名 root@ubuntu200404:/data/scripts#alias rm=\u0026#39;/data/scripts/rm.sh\u0026#39; root@ubuntu200404:/data/scripts# touch {1..9}.TXT root@ubuntu200404:/data/scripts# rm *.TXT Move 1.TXT 2.TXT 3.TXT 4.TXT 5.TXT 6.TXT 7.TXT 8.TXT 9.TXT to *范例：$和$@的区别\n当 $* 和 $@ 不带双引号时它们两个是没有区别的，都是接收所有参数然后分别单独处理每个参数！而当$*带双引号的时候，会把接收的所有参数当成一个字段处理 将$@与$赋值给变量之后，结果跟不带引号是一样的！这是我们需要注意的地方，当$ 赋值给变量的时候还是跟不带引号的作用是一样的！ 2.7.8 利用软链接实现同一个脚本不同功能 范例：\n[root@centos8 ~]#cat test.sh #!/bin/bash #******************************************************************** echo $0 [root@centos8 ~]#ln -s test.sh a.sh [root@centos8 ~]#ln -s test.sh b.sh [root@centos8 ~]#./a.sh ./a.sh [root@centos8 ~]#./b.sh ./b.sh 2.7.9 退出状态码变量 进程执行后，将使用变量 $? 保存状态码的相关数字，不同的值反应成功或失败，$?取值范例 0-255\n$?的值为0 #代表成功 $?的值是1到255 #代表失败 范例：状态码为0\nroot@ubuntu200404:/data/scripts# ll total 40 drwxr-xr-x 2 root root 4096 Aug 6 07:29 ./ drwxr-xr-x 3 root root 4096 Aug 6 02:41 ../ -rw-r--r-- 1 root root 241 Aug 6 06:48 args.sh -rw-r--r-- 1 root root 192 Aug 6 02:40 bacup.sh -rw-r--r-- 1 root root 185 Aug 6 03:38 demo1.sh -rw-r--r-- 1 root root 85 Aug 6 07:26 f1.sh -rw-r--r-- 1 root root 41 Aug 6 07:29 file.sh -rwxr-xr-x 1 root root 208 Aug 6 01:42 hello.sh* -rwxr-xr-x 1 root root 285 Aug 6 07:20 rm.sh* -rwxr-xr-x 1 root root 284 Aug 6 07:01 rm.sh.bak* root@ubuntu200404:/data/scripts# echo $? 0 root@ubuntu200404:/data/scripts# 范例：状态码不是0\nroot@ubuntu200404:/data/scripts# ls ajdksh ls: cannot access \u0026#39;ajdksh\u0026#39;: No such file or directory root@ubuntu200404:/data/scripts# echo $? 2 root@ubuntu200404:/data/scripts# 用户可以在脚本中使用以下命令自定义退出状态码\nexit [n] 案例：\nroot@ubuntu200404:/data/scripts# cat exit.sh #!/bin/bash echo -e `hostname` exit 200 echo -e \u0026#39;success\u0026#39; root@ubuntu200404:/data/scripts# root@ubuntu200404:/data/scripts# bash exit.sh ubuntu200404 exit.sh: line 4: exit: 200: numeric argument required root@ubuntu200404:/data/scripts# 注意：\n脚本中一旦遇到exit命令，脚本会立即终止；终止退出状态取决于exit命令后面的数字 如果exit后面无数字,终止退出状态取决于exit命令前面命令执行结果 如果没有exit命令, 即未给脚本指定退出状态码，整个脚本的退出状态码取决于脚本中执行的最后一条命令的状态码 2.7.10 脚本安全和 set set 命令：可以用来定制 shell 环境 $- 变量 h：hashall，打开选项后，Shell 会将命令所在的路径hash下来，避免每次都要查询。通过set +h将h选 项关闭 i：interactive-comments，包含这个选项说明当前的 shell 是一个交互式的 shell。所谓的交互式shell, 在脚本中，i选项是关闭的 m：monitor，打开监控模式，就可以通过Job control来控制进程的停止、继续，后台或者前台执行等 B：braceexpand，大括号扩展 H：history，H选项打开，可以展开历史列表中的命令，可以通过!感叹号来完成，例如“!!”返回上最近的 一个历史命令，“!n”返回第 n 个历史命令\nset 命令实现脚本安全 -u 在扩展一个没有设置的变量时，显示错误信息， 等同set -o nounset -e 如果一个命令返回一个非0退出状态值(失败)就退出， 等同set -o errexit -o option 显示，打开或者关闭选项 显示选项：set -o 打开选项：set -o 选项 关闭选项：set +o 选项 -x 当执行命令时，打印命令及其参数,类似 bash -x 范例：-e -u\n#!/bin/bash #****************** #filename:hello.sh #Data:2022-08-06 #author:admin #****************** set -e -u #echo \u0026#34;经典写法\u0026#34; echo \u0026#34;hello world!\u0026#34; echo \u0026#39;******************\u0026#39; # 流行写法 echo \u0026#39;hello world!\u0026#39; 2.8 算术运算 Shell允许在某些情况下对算术表达式进行求值，比如：let和declare 内置命令，(( ))复合命令和算术扩 展。求值以固定宽度的整数进行，不检查溢出，尽管除以0 被困并标记为错误。运算符及其优先级，关联性和值与C语言相同。以下运算符列表分组为等优先级运算符级别。级别按降序排列优先。 注意：bash 只支持整数，不支持小数\n+ - addition, subtraction * / % multiplication, division, remainder, %表示取模，即取余数，示例：9%4=1，5%3=2 i++ i-- variable post-increment and post-decrement ++i --i variable pre-increment and pre-decrement = *= /= %= += -= \u0026lt;\u0026lt;= \u0026gt;\u0026gt;= \u0026amp;= ^= |= assignment - + unary minus and plus ! ~ logical and bitwise negation ** exponentiation 乘方,即指数运算 \u0026lt;\u0026lt; \u0026gt;\u0026gt; left and right bitwise shifts \u0026lt;= \u0026gt;= \u0026lt; \u0026gt; comparison == != equality and inequality \u0026amp; bitwise AND | bitwise OR ^ bitwise exclusive OR \u0026amp;\u0026amp; logical AND || logical OR expr?expr:expr conditional operator expr1 , expr2 comma 乘法符号有些场景中需要转义 实现算术运算：\n(1) let var=算术表达式 (2) ((var=算术表达式)) 和上面等价 (3) var=$[算术表达式] (4) var=$((算术表达式)) (5) var=$(expr arg1 arg2 arg3 ...) (6) declare -i var = 数值 (7) echo \u0026#39;算术表达式\u0026#39; | bc 内建的随机数生成器变量：\n$RANDOM 取值范围：0-32767 范例：\n#生成 0 - 49 之间随机数 echo $[$RANDOM%50] #随机字体颜色 [root@centos8 ~]#echo -e \u0026#34;\\033[1;$[RANDOM%7+31]mhello\\033[0m\u0026#34; magedu 2.9 逻辑运算 1,真 0,假 #注意,以上为二进制 与或非符号：\u0026amp; | ！\n异或：^\n异或：^ 异或的两个值，相同为假，不同为真。两个数字X,Y异或得到结果Z，Z再和任意两者之一X异或，将得出另一个值Y\n0 ^ 0 = 0 0 ^ 1 = 1 1 ^ 0 = 1 1 ^ 1 = 0 2.10 条件测试命令 条件测试：判断某需求是否满足，需要由测试机制来实现，专用的测试表达式需要由测试命令辅助完成 测试过程，实现评估布尔声明，以便用在条件性环境下进行执行 若真，则状态码变量 $? 返回0 若假，则状态码变量 $? 返回1 条件测试命令\ntest EXPRESSIO [ EXPRESSION ] #和test 等价，建议使用 [[ EXPRESSION ]] 相关于增强版的 , 支持[]的用法,且支持扩展正则表达式和通配 注意：EXPRESSION前后必须有空白字符\n帮助：\nroot@ubuntu200404:/data/scripts# type [ [ is a shell builtin root@ubuntu200404:/data/scripts# root@ubuntu200404:/data/scripts# help test test: test [expr] Evaluate conditional expression. Exits with a status of 0 (true) or 1 (false) depending on the evaluation of EXPR. Expressions may be unary or binary. Unary expressions are often used to examine the status of a file. There are string operators and numeric comparison operators as well. The behavior of test depends on the number of arguments. Read the bash manual page for the complete specification. File operators: -a FILE True if file exists. -b FILE True if file is block special. -c FILE True if file is character special. -d FILE True if file is a directory. -e FILE True if file exists. -f FILE True if file exists and is a regular file. -g FILE True if file is set-group-id. -h FILE True if file is a symbolic link. -L FILE True if file is a symbolic link. -k FILE True if file has its `sticky\u0026#39; bit set. -p FILE True if file is a named pipe. -r FILE True if file is readable by you. -s FILE True if file exists and is not empty. -S FILE True if file is a socket. -t FD True if FD is opened on a terminal. -u FILE True if the file is set-user-id. -w FILE True if the file is writable by you. -x FILE True if the file is executable by you. -O FILE True if the file is effectively owned by you. -G FILE True if the file is effectively owned by your group. -N FILE True if the file has been modified since it was last read. FILE1 -nt FILE2 True if file1 is newer than file2 (according to modification date). FILE1 -ot FILE2 True if file1 is older than file2. FILE1 -ef FILE2 True if file1 is a hard link to file2. All file operators except -h and -L are acting on the target of a symbolic link, not on the symlink itself, if FILE is a symbolic link. String operators: -z STRING True if string is empty. -n STRING STRING True if string is not empty. STRING1 = STRING2 True if the strings are equal. STRING1 != STRING2 True if the strings are not equal. STRING1 \u0026lt; STRING2 True if STRING1 sorts before STRING2 lexicographically. STRING1 \u0026gt; STRING2 True if STRING1 sorts after STRING2 lexicographically. Other operators: -o OPTION True if the shell option OPTION is enabled. -v VAR True if the shell variable VAR is set. -R VAR True if the shell variable VAR is set and is a name reference. ! EXPR True if expr is false. EXPR1 -a EXPR2 True if both expr1 AND expr2 are true. EXPR1 -o EXPR2 True if either expr1 OR expr2 is true. arg1 OP arg2 Arithmetic tests. OP is one of -eq, -ne, -lt, -le, -gt, or -ge. Arithmetic binary operators return true if ARG1 is equal, not-equal, less-than, less-than-or-equal, greater-than, or greater-than-or-equal than ARG2. See the bash manual page bash(1) for the handling of parameters (i.e. missing parameters). Exit Status: Returns success if EXPR evaluates to true; fails if EXPR evaluates to false or an invalid argument is given. root@ubuntu200404:/data/scripts# 2.10.1 变量测试 #判断 NAME 变量是否定义 [ -v NAME ] 范例：\nroot@ubuntu200404:/data/scripts# NAME=\u0026#39;tom\u0026#39; root@ubuntu200404:/data/scripts# [ -v NAME ] root@ubuntu200404:/data/scripts# echo $? 0 root@ubuntu200404:/data/scripts# [ -v AGE ] root@ubuntu200404:/data/scripts# echo $? 1 root@ubuntu200404:/data/scripts# 2.10.2 数值测试 -eq 是否等于 -ne 是否不等于 -gt 是否大于 -ge 是否大于等于 -lt 是否小于 -le 是否小于等于 范例：\n[root@centos8 ~]#i=10 [root@centos8 ~]#j=8 [root@centos8 ~]#[ $i -lt $j ] [root@centos8 ~]#echo $? 1 2.10.3 算术表达式比较 == 相等 != 不相等 \u0026lt;= \u0026gt;= \u0026lt; \u0026gt; 范例：\n[root@centos8 ~]#x=10;y=10;(( x == y ));echo $? 0 [root@centos8 ~]#x=10;y=20;(( x == y ));echo $? 1 [root@centos8 ~]#x=10;y=20;(( x != y ));echo $? 0 [root@centos8 ~]#x=10;y=10;(( x != y ));echo $? 1 2.10.4 字符窜测试 test和 [ ] 字符串测试用法\n-z STRING 字符串是否为空，没定义或空为真，不空为假， -n STRING 字符串是否不空，不空为真，空为假 STRING 同上 STRING1 = STRING2 是否等于，注意 = 前后有空格 STRING1 != STRING2 是否不等于 \u0026gt; ascii码是否大于ascii码 \u0026lt; 是否小于 [[]] 字符串测试用法\n[[ expression ]] 用法 == 左侧字符串是否和右侧的PATTERN相同 注意:此表达式用于[[ ]]中，PATTERN为通配符 =~ 左侧字符串是否能够被右侧的正则表达式的PATTERN所匹配 注意: 此表达式用于[[ ]]中为扩展的正则表达式 建议：当使用正则表达式或通配符使用[[ ]]，其它情况一般使用 [ ]\n范例：使用 [ ]\n[root@centos8 ~]#unset str [root@centos8 ~]#[ -z \u0026#34;$str\u0026#34; ] [root@centos8 ~]#echo $? 0 范例：在比较字符串时，建议变量放在“ ”中\n[root@centos8 ~]#[ \u0026#34;$NAME\u0026#34; ] [root@centos8 ~]#NAME=\u0026#34;I love linux\u0026#34; [root@centos8 ~]#[ $NAME ] -bash: [: love: binary operator expected [root@centos8 ~]#[ \u0026#34;$NAME\u0026#34; ] [root@centos8 ~]#echo $? 0 [[]]中如果不想使用通配符,只想表达*本身,可以用\u0026quot; \u0026ldquo;引起来*\n*#[[]]中如果不想使用通配符,只想表达本身,也可以使用转义符*\n2.10.5 文件测试 存在性测试\n-a FILE：同 -e -e FILE: 文件存在性测试，存在为真，否则为假 -b FILE：是否存在且为块设备文件 -c FILE：是否存在且为字符设备文件 -d FILE：是否存在且为目录文件 -f FILE：是否存在且为普通文件 -h FILE 或 -L FILE：存在且为符号链接文件 -p FILE：是否存在且为命名管道文件 -S FILE：是否存在且为套接字文件 案例：\nroot@ubuntu200404:/data/scripts# [ -e /data/scripts/rm.sh ] root@ubuntu200404:/data/scripts# echo $? 0 root@ubuntu200404:/data/scripts# 文件权限测试\n-r FILE：是否存在且可读 -w FILE: 是否存在且可写 -x FILE: 是否存在且可执行 -u FILE：是否存在且拥有suid权限 -g FILE：是否存在且拥有sgid权限 -k FILE：是否存在且拥有sticky权限 注意：最终结果由用户对文件的实际权限决定，而非文件属性决定\n范例:\nroot@ubuntu200404:/data/scripts# [ -w /data/scripts/rm.sh ] root@ubuntu200404:/data/scripts# echo $? 0 root@ubuntu200404:/data/scripts# 文件属性测试\n-s FILE #是否存在且非空 -t fd #fd 文件描述符是否在某终端已经打开 -N FILE #文件自从上一次被读取之后是否被修改过 -O FILE #当前有效用户是否为文件属主 -G FILE #当前有效用户是否为文件属组 FILE1 -ef FILE2 #FILE1是否是FILE2的硬链接 FILE1 -nt FILE2 #FILE1是否新于FILE2（mtime） FILE1 -ot FILE2 #FILE1是否旧于FILE2 案例：\nroot@ubuntu200404:/data/scripts# [ -s /data/scripts/rm.sh ] root@ubuntu200404:/data/scripts# echo $? 0 root@ubuntu200404:/data/scripts# 2.11 关于（）和 （CMD1;CMD2;\u0026hellip;）和 { CMD1;CMD2;\u0026hellip;; } 都可以将多个命令组合在一起，批量执行**\n( list ) 会开启子shell,并且list中变量赋值及内部命令执行后,将不再影响后续的环境 帮助参看:man bash 搜索(list) { list; } 不会启子shell, 在当前shell中运行,会影响当前shell环境 帮助参看:man bash 搜索{ list; } ( list ) 会开启子shell,并且list中变量赋值及内部命令执行后,将不再影响后续的环境 帮助参看:man bash 搜索(list) { list; } 不会启子shell, 在当前shell中运行,会影响当前shell环境 帮助参看:man bash 搜索{ list; } #（）会开启子shell [root@centos8 ~]#echo $BASHPID 1920 [root@centos8 ~]#( echo $BASHPID;sleep 100) 1979 [root@centos8 ~]#pstree -p ├─sshd(719)───sshd(1906)───sshd(1919)─┬─bash(1920)───bash(1979)───sleep(1980) #{ } 不会开启子shell [root@centos8 ~]#echo $BASHPID 1920 2.12 组合测试 2.12.1 第一种方式 [ EXPRESSION1 -a EXPRESSION2 ] #并且，EXPRESSION1和EXPRESSION2都是真，结果才为真 [ EXPRESSION1 -o EXPRESSION2 ] #或者，EXPRESSION1和EXPRESSION2只要有一个真，结果就为 真 [ ! EXPRESSION ] #取反 说明： -a 和 -o 需要使用测试命令进行，[[ ]] 不支持\n2.12.2 第二种方式 COMMAND1 \u0026amp;\u0026amp; COMMAND2 #并且，短路与，代表条件性的AND THEN 如果COMMAND1 成功,将执行COMMAND2,否则,将不执行COMMAND2 COMMAND1 || COMMAND2 #或者，短路或，代表条件性的OR ELSE 如果COMMAND1 成功,将不执行COMMAND2,否则,将执行COMMAND2 ! COMMAND #非,取反 如果\u0026amp;\u0026amp; 和 || 混合使用，\u0026amp;\u0026amp; 要在前，|| 放在后\n练习 1、编写脚本 argsnum.sh，接受一个文件路径作为参数；如果参数个数小于1，则提示用户“至少应该给一个参数”，并立即退出；如果参数个数不小于1，则显示第一个参数所指向的文件中的空白行数 2、编写脚本 hostping.sh，接受一个主机的IPv4地址做为参数，测试是否可连通。如果能ping通，则提示用户“该IP地址可访问”；如果不可ping通，则提示用户“该IP地址不可访问” 3、编写脚本 checkdisk.sh，检查磁盘分区空间和inode使用率，如果超过80%，就发广播警告空间将满 4、编写脚本 per.sh，判断当前用户对指定参数文件，是否不可读并且不可写 5、编写脚本 excute.sh ，判断参数文件是否为sh后缀的普通文件，如果是，添加所有人可执行权限，否则提示用户非脚本文件 6、编写脚本 nologin.sh和 login.sh，实现禁止和允许普通用户登录系统\n2.13 使用read命令来接受输入 使用read来把输入值分配给一个或多个shell变量，read从标准输入中读取值，给每个单词分配一个变量，所有剩余单词都被分配给最后一个变量，如果变量名没有指定，默认标准输入的值赋值给系统内置变量REPLY 格式：\nread [options] [name ...] 常用选项：\n-p 指定要显示的提示 -s 静默输入，一般用于密码 -n N 指定输入的字符长度N -d \u0026#39;字符\u0026#39; 输入结束符 -t N TIMEOUT为N秒 范例：\n[root@rocky ~]# read -p \u0026#39;请输入任意内容\u0026#39; NAME 请输入任意内容yuan [root@rocky ~]# echo ${NAME} yuan [root@rocky ~]# 3 条件选择if 格式：\nif COMMANDS; then COMMANDS; [ elif COMMANDS; then COMMANDS; ]... [ else COMMANDS; ] fi 单分支：\nif 判断条件;then 条件为真的分支代码 fi 双分支：\nif 判断条件; then 条件为真的分支代码 else 条件为假的分支代码 fi 多分支：\nif 判断条件1; then 条件1为真的分支代码 elif 判断条件2; then 条件2为真的分支代码 elif 判断条件3; then 条件3为真的分支代码 ... else 以上条件都为假的分支代码 fi 4 循环 4.1 for循环 帮助：\nhelp for 格式：\nfor NAME [in WORDS ... ] ; do COMMANDS; done #方式1 for 变量名 in 列表;do 循环体 done #方式2 for 变量名 in 列表 do 循环体 done 执行机制：\n依次将列表中的元素赋值给“变量名”; 每次赋值后即执行一次循环体; 直到列表中的元素耗尽，循环结束 如果省略 [in WORDS \u0026hellip; ] ，此时使用位置参数变量 in \u0026ldquo;$@\u0026rdquo; for 循环列表生成方式：\n直接给出列表 整数列表： {start..end} $(seq [start [step]] end) 返回列表的命令 $(COMMAND) 使用glob，如：.sh 变量引用，如：$@，$，$# 范例：计算1+···+100的值\n[root@centos8 ~]#sum=0;for i in {1..100};do let sum+=i;done ;echo sum=$sum sum=5050 [root@centos8 ~]#seq -s+ 100|bc5050 5050 [root@centos8 ~]#echo {1..100}|tr \u0026#39; \u0026#39; +|bc 5050 [root@centos8 ~]#seq 100|paste -sd +|bc 5050 4.2 while循环 格式\nwhile COMMANDS; do COMMANDS; done while CONDITION; do 循环体 done 扩展:nc命令\nnc命令 全称netcat，用于设置路由器。它能通过 TCP 和 UDP 在网络中读写数据。通过与其他工具结合和重定向，你可以在脚本中以多种方式使用它。使用 netcat 命令所能完成的事情令人惊讶。\n选项\n-g\u0026lt;网关\u0026gt; 设置路由器跃程通信网关，最多可设置8个。 -G\u0026lt;指向器数目\u0026gt; 设置来源路由指向器，其数值为4的倍数。 -h 在线帮助。 -i\u0026lt;延迟秒数\u0026gt; 设置时间间隔，以便传送信息及扫描通信端口。 -l 使用监听模式，管控传入的资料。 -n 直接使用IP地址，而不通过域名服务器。 -o\u0026lt;输出文件\u0026gt; 指定文件名称，把往来传输的数据以16进制字码倾倒成该文件保存。 -p\u0026lt;通信端口\u0026gt; 设置本地主机使用的通信端口。 -r 乱数指定本地与远端主机的通信端口。 -s\u0026lt;来源位址\u0026gt; 设置本地主机送出数据包的IP地址。 -u 使用UDP传输协议。 -v 显示指令执行过程。 -w\u0026lt;超时秒数\u0026gt; 设置等待连线的时间。 -z 使用0输入/输出模式，只在扫描通信端口时使用。 范例\n# TCP端口扫描 [root@rocky ~]# nc -zv 192.168.179.129 80 Ncat: Version 7.70 ( https://nmap.org/ncat ) Ncat: Connected to 192.168.179.129:80. Ncat: 0 bytes sent, 0 bytes received in 0.01 seconds. [root@rocky ~]# 范例:写一个扫描某个主机端口的状态的脚本\n#!/bin/bash # 变量 i=1 # 主机IP host=192.168.179.138 # 清空文件内容 cat /dev/null \u0026gt;port.TXT # 循环端口1-100 while [ $i -le 100 ];do # 扫描端口并将信息放入垃圾箱 if nc -z ${host} ${i} \u0026amp;\u0026gt; /dev/null;then # 屏幕打印IP+port,输出重定向到port.TXT echo ${host}:${i} | tee -a port.TXT fi # i++ let i++ done 5 其他脚本相关工具 5.1 trap命令 trap命令可以捕捉信号，修改信号原有的功能，实现自定义功能\n# 查看信号trap -l 或者kill -l root@ubuntu200404-1:/data/scripts# kill -l 1) SIGHUP 2) SIGINT 3) SIGQUIT 4) SIGILL 5) SIGTRAP 6) SIGABRT 7) SIGBUS 8) SIGFPE 9) SIGKILL 10) SIGUSR1 11) SIGSEGV 12) SIGUSR2 13) SIGPIPE 14) SIGALRM 15) SIGTERM 16) SIGSTKFLT 17) SIGCHLD 18) SIGCONT 19) SIGSTOP 20) SIGTSTP 21) SIGTTIN 22) SIGTTOU 23) SIGURG 24) SIGXCPU 25) SIGXFSZ 26) SIGVTALRM 27) SIGPROF 28) SIGWINCH 29) SIGIO 30) SIGPWR 31) SIGSYS 34) SIGRTMIN 35) SIGRTMIN+1 36) SIGRTMIN+2 37) SIGRTMIN+3 38) SIGRTMIN+4 39) SIGRTMIN+5 40) SIGRTMIN+6 41) SIGRTMIN+7 42) SIGRTMIN+8 43) SIGRTMIN+9 44) SIGRTMIN+10 45) SIGRTMIN+11 46) SIGRTMIN+12 47) SIGRTMIN+13 48) SIGRTMIN+14 49) SIGRTMIN+15 50) SIGRTMAX-14 51) SIGRTMAX-13 52) SIGRTMAX-12 53) SIGRTMAX-11 54) SIGRTMAX-10 55) SIGRTMAX-9 56) SIGRTMAX-8 57) SIGRTMAX-7 58) SIGRTMAX-6 59) SIGRTMAX-5 60) SIGRTMAX-4 61) SIGRTMAX-3 62) SIGRTMAX-2 63) SIGRTMAX-1 64) SIGRTMAX root@ubuntu200404-1:/data/scripts# # 进程收到系统发出的制定信号后，将执行自定义指令，而不会执原操作 trap \u0026#39;触发指令\u0026#39; 信号 # 忽略信号的操作 trap \u0026#39;\u0026#39; 信号 # 恢复原信号的操作 trap \u0026#39;-\u0026#39; 信号 # 列出自定义的操作 trap -p # 当脚本退出时，执行finish函数 trap finish exit 范例\n#!/bin/bash # 打印press ctrl+c or ctrl+\\ replace int quit trap \u0026#34;echo \u0026#39;press ctrl+c or ctrl+\\ \u0026#39;\u0026#34; 2 3 # 列出 自定义的操作 trap -p # 循环并打印1-10 # 打印1-10键盘按ctrl+c打印press ctrl+c or ctrl for ((i=1;i\u0026lt;=10;i++)) do sleep 1 echo ${i} done # 忽略2 3信号操作 trap \u0026#39;\u0026#39; 2 3 # 打印出自定义操作 trap -p # 打印11-20 # 打印11-20的时候键盘按ctrl+c没有任何操作 for((i=11;i\u0026lt;=20;i++)) do sleep 1 echo ${i} done # 恢复原信号操作 trap \u0026#39;-\u0026#39; int # 列出信号操作 trap -p # 打印21-30键盘按ctrl+c 退出 for((i=21;i\u0026lt;=30;i++)) do sleep 1 echo ${i} done 范例\n#!/bin/bash finsh(){ echo `date +%F-%T`-finsh | tee -a /data/finsh.log } # 捕捉到退出执行finsh trap或者exit trap finsh exit while true;do echo running sleep 1 done 创建临时文件\n# mktemp testXXXX root@ubuntu200404-1:/data/scripts# mktemp testXXXXXX.log testdnlqM9.log root@ubuntu200404-1:/data/scripts# # 创建临时目录 root@ubuntu200404-1:/data/scripts# mktemp -d testXXX testGio root@ubuntu200404-1:/data/scripts# 5. 2 except实现自动化的非交互操作 expect 是由Don Libes基于 Tcl（ Tool Command Language ）语言开发的，主要应用于自动化交互式 操作的场景，借助 expect 处理交互的命令，可以将交互过程如：ssh登录，ftp登录等写在一个脚本 上，使之自动化完成。尤其适用于需要对多台服务器执行相同操作的环境中，可以大大提高系统管理人 员的工作效率。\nexpect语法\nexpect [选项] [ -c cmds ] [ [ -[f|b] ] cmdfile ] [ args ] 常见选项\n-c：从命令行执行expect脚本，默认expect是交互地执行的 -d：可以调试信息 expect中相关命令\nspawn 启动新的进程 expect 从进程接收字符串 send 用于向进程发送字符串 interact 允许用户交互 exp_continue 匹配多个字符串在执行动作后加此命令 范例1:自动登录\n# 创建文件 vim filename # 脚本内容 #!/usr/bin/expect # 启动新的进程 spawn ssh 192.168.179.138 # 从进程接收字符串 expect { # 匹配到yse/no，输入yes \u0026#34;yes/no\u0026#34; {send \u0026#34;yes\\n\u0026#34;;exp_continue } \u0026#34;password\u0026#34; { send \u0026#34;123456\\n\u0026#34; } } # 允许用户交互 interact # 添加可执行权限 chmod +x filename # 执行 ./filename 扩展：scp命令\n语法\nscp 选项 参数 选项\n-1：使用ssh协议版本1； -2：使用ssh协议版本2； -4：使用ipv4； -6：使用ipv6； -B：以批处理模式运行； -C：使用压缩； -F：指定ssh配置文件； -i：identity_file 从指定文件中读取传输时使用的密钥文件（例如亚马逊云pem），此参数直接传递给ssh； -l：指定宽带限制； -o：指定使用的ssh选项； -P：指定远程主机的端口号； -p：保留文件的最后修改时间，最后访问时间和权限模式； -q：不显示复制进度； -r：以递归方式复制。 实例 从远程复制到本地的scp命令与上面的命令雷同，只要将从本地复制到远程的命令后面2个参数互换顺序就行了。\n从远程机器复制文件到本地目录\nscp root@10.10.10.10:/opt/soft/nginx-0.5.38.tar.gz /opt/soft/ 从10.10.10.10机器上的/opt/soft/的目录中下载nginx-0.5.38.tar.gz 文件到本地/opt/soft/目录中。\n从远程机器复制目录到本地\nscp -r root@10.10.10.10:/opt/soft/mongodb /opt/soft/ 从10.10.10.10机器上的/opt/soft/中下载mongodb目录到本地的/opt/soft/目录来。\n上传本地文件到远程机器指定目录\nscp /opt/soft/nginx-0.5.38.tar.gz root@10.10.10.10:/opt/soft/scptest # 指定端口 2222 scp -rp -P 2222 /opt/soft/nginx-0.5.38.tar.gz root@10.10.10.10:/opt/soft/scptest 复制本地/opt/soft/目录下的文件nginx-0.5.38.tar.gz到远程机器10.10.10.10的opt/soft/scptest目录。\n上传本地目录到远程机器指定目录\nscp -r /opt/soft/mongodb root@10.10.10.10:/opt/soft/scptest 上传本地目录/opt/soft/mongodb到远程机器10.10.10.10上/opt/soft/scptest的目录中去。\n范例2:非交互式复制文件\n#!/usr/bin/expect # 开启新的进程,复制当前主机下的/root/hello.sh到远程主机 spawn scp /root/hello.sh root@192.168.179.129:/root expect { # 匹配到yes/no，输入yes \u0026#34;yes/no\u0026#34; { send \u0026#34;yes\\n\u0026#34;;exp_continue} \u0026#34;password\u0026#34; { send \u0026#34;123456\\n\u0026#34;} } expect eof 范例3:变量\n#!/usr/bin/expect # 添加变量 set ip 192.168.179.138 set user root set passwd 123456 set timeout 10 # 启动新的进程 spawn ssh ${user}@${ip} expect { \u0026#34;yes/no\u0026#34; { send \u0026#34;yes\\n\u0026#34;;exp_continue} \u0026#34;password\u0026#34; { send \u0026#34;$passwd\\n\u0026#34; } } # 允许交互式操作 interact 范例4:位置参数\n#!/usr/bin/expect # 添加变量 set ip [lindex $argv 0] set user [lindex $argv 1] set passwd [lindex $argv 2] set timeout 10 # 启动新的进程 spawn ssh ${user}@${ip} expect { \u0026#34;yes/no\u0026#34; { send \u0026#34;yes\\n\u0026#34;;exp_continue} \u0026#34;password\u0026#34; { send \u0026#34;$passwd\\n\u0026#34; } } # 允许交互式操作 interact # 添加执行权限 [root@centos7 ~]# chmmod +x expect3 # 后面跟三个参数 [root@centos7 ~]# ./expect3 192.168.179.138 root 123456 范例5:执行多个命令\n#!/usr/bin/expect # 添加变量 set ip [lindex $argv 0] set user [lindex $argv 1] set passwd [lindex $argv 2] set timeout 10 # 启动新的进程 spawn ssh ${user}@${ip} expect { \u0026#34;yes/no\u0026#34; { send \u0026#34;yes\\n\u0026#34;;exp_continue} \u0026#34;password\u0026#34; { send \u0026#34;$passwd\\n\u0026#34; } } # adduser haha expect \u0026#34;]#\u0026#34; { send \u0026#34;useradd haha\\n\u0026#34; } # passwd set 123456 expect \u0026#34;]#\u0026#34; { send \u0026#34;echo 123456 |passwd --stdin haha\\n\u0026#34; } # logout send \u0026#34;exit\\n\u0026#34; expect eof [root@centos7 ~]# ./expect4 192.168.179.141 root 123456 范例6:shell脚本调用expect\n#!/bin/bash ip=$1 user=$2 password=$3 expect \u0026lt;\u0026lt;EOF set timeout 20 # 开启新的进程，登录远程主机 spawn ssh $user@$ip expect { \u0026#34;yes/no\u0026#34; { send \u0026#34;yes\\n\u0026#34;;exp_continue } \u0026#34;password\u0026#34; { send \u0026#34;$password\\n\u0026#34; } } # 添加新的用户 expect \u0026#34;]#\u0026#34; { send \u0026#34;useradd hehe\\n\u0026#34; } # 设置新密码 expect \u0026#34;]#\u0026#34; { send \u0026#34;echo 123456 |passwd --stdin hehe\\n\u0026#34; } # logout expect \u0026#34;]#\u0026#34; { send \u0026#34;exit\\n\u0026#34; } expect eof EOF [root@centos7 ~]# bash expect5.sh 192.168.179.141 root 123456 范例7: shell脚本利用循环调用expect在CentOS和Ubuntu上批量创建用户\nNET=10.0.0 user=root password=magedu IPLIST=\u0026#34; 7 18 101 \u0026#34; for ID in $IPLIST;do ip=$NET.$ID expect \u0026lt;\u0026lt;EOF set timeout 20 spawn ssh $user@$ip expect { \u0026#34;yes/no\u0026#34; { send \u0026#34;yes\\n\u0026#34;;exp_continue } \u0026#34;password\u0026#34; { send \u0026#34;$password\\n\u0026#34; } } expect \u0026#34;#\u0026#34; { send \u0026#34;useradd test\\n\u0026#34; } expect \u0026#34;#\u0026#34; { send \u0026#34;exit\\n\u0026#34; } expect eof EOF done 6 数组 6.1 数组介绍 变量：存储单个元素的内存空间 数组：存储多个元素的连续的内存空间，相当于多个变量的集合 数组名和索引\n索引的编号从0开始，属于数值索引 索引可支持使用自定义的格式，而不仅是数值格式，即为关联索引，bash 4.0版本之后开始支持 bash的数组支持稀疏格式（索引不连续） 6.2 声明数组 #普通数组可以不事先声明,直接使用 declare -a ARRAY_NAME #关联数组必须先声明,再使用 declare -A ARRAY_NAME 注:两者不可相互转换\n6.3 数组赋值 数组元素的赋值 (1) 一次只赋值一个元素\nARRAY_NAME[INDEX]=VALUE 范例：\nweekdays[0]=\u0026#34;Sunday\u0026#34; weekdays[4]=\u0026#34;Thursday\u0026#34; (2) 一次赋值全部元素\nARRAY_NAME=(\u0026#34;VAL1\u0026#34; \u0026#34;VAL2\u0026#34; \u0026#34;VAL3\u0026#34; ...) 范例:\ntitle=(\u0026#34;ceo\u0026#34; \u0026#34;coo\u0026#34; \u0026#34;cto\u0026#34;) num=({0..10}) alpha=({a..g}) file=( *.sh ) (3)只赋值特定元素\nARRAY_NAME=([0]=\u0026#34;VAL1\u0026#34; [3]=\u0026#34;VAL2\u0026#34; ...) (4)交互式赋值元素\nread -a ARRAY 6.4 显示所有数组 显示所有数组\ndeclare -a 范例\n[root@centos7 ~]# declare -a declare -a BASH_ARGC=\u0026#39;()\u0026#39; declare -a BASH_ARGV=\u0026#39;()\u0026#39; declare -a BASH_LINENO=\u0026#39;()\u0026#39; declare -a BASH_SOURCE=\u0026#39;()\u0026#39; declare -ar BASH_VERSINFO=\u0026#39;([0]=\u0026#34;4\u0026#34; [1]=\u0026#34;2\u0026#34; [2]=\u0026#34;46\u0026#34; [3]=\u0026#34;2\u0026#34; [4]=\u0026#34;release\u0026#34; [5]=\u0026#34;x86_64-redhat-linux-gnu\u0026#34;)\u0026#39; declare -a DIRSTACK=\u0026#39;()\u0026#39; declare -a FUNCNAME=\u0026#39;()\u0026#39; declare -a GROUPS=\u0026#39;()\u0026#39; declare -a PIPESTATUS=\u0026#39;([0]=\u0026#34;0\u0026#34;)\u0026#39; [root@centos7 ~]# 6.5 引用数组 引用特定的数组元素\n${ARRAY_NAME[INDEX]} #如果省略[INDEX]表示引用下标为0的元素 引用所有数组元素\n${ARRAY_NAME[*]} ${ARRAY_NAME[@]} 数组的长度，即数组的元素的个数\n${#ARRAY_NAME[*]} ${#ARRAY_NAME[@]} 范例\n[root@centos7 ~]# title[0]=1 [root@centos7 ~]# title[1]=1 [root@centos7 ~]# title[2]=1 [root@centos7 ~]# echo ${#title[*]} 3 [root@centos7 ~]# 数组的所有下标\n${!ARRAY_NAME[*]} ${!ARRAY_NAME[@]} 范例\n[root@centos7 ~]# title[0]=1 [root@centos7 ~]# title[1]=1 [root@centos7 ~]# title[2]=1 [root@centos7 ~]# echo ${!title[*]} 0 1 2 [root@centos7 ~]# 6.6 删除数组 删除数组中的某个元素\nunset ARRAY[INDEX] 删除整个数组\nunset ARRAY 6.7 数组数据处理 数据切片\n${ARRAY[@]:offset:number} ${ARRAY[*]:offset:number} offset #要跳过的元素个数 number #要取出的元素个数 #取偏移量之后的所有元素 {ARRAY[@]:offset} {ARRAY[*]:offset} 范例\n[root@centos8 ~]#num=({0..10}) [root@centos8 ~]#echo ${num[*]:2:3} 2 3 4 [root@centos8 ~]#echo ${num[*]:6} 6 7 8 9 10 向数组中追加元素\nARRAY[${#ARRAY[*]}]=value ARRAY[${#ARRAY[@]}]=value 范例\n[root@centos8 ~]#num[${#num[@]}]=11 [root@centos8 ~]#echo ${#num[@]} 12 [root@centos8 ~]#echo ${num[@]} 0 1 2 3 4 5 6 7 8 9 10 11 范例：生成10个随机数保存于数组中，并找出其最大值和最小值\n#!/bin/bash declare -i min max declare -a nums for ((i=0;i\u0026lt;10;i++));do nums[$i]=$RANDOM [ $i -eq 0 ] \u0026amp;\u0026amp; min=${nums[0]} \u0026amp;\u0026amp; max=${nums[0]}\u0026amp;\u0026amp; continue [ ${nums[$i]} -gt $max ] \u0026amp;\u0026amp; max=${nums[$i]} \u0026amp;\u0026amp; continue [ ${nums[$i]} -lt $min ] \u0026amp;\u0026amp; min=${nums[$i]} done echo \u0026#34;All numbers are ${nums[*]}\u0026#34; echo Max is $max echo Min is $min 7 字符串处理 7.1 字符串切片 #返回字符串变量var的字符的长度,一个汉字算一个字符 ${#var} #返回字符串变量var中从第offset个字符后（不包括第offset个字符）的字符开始，到最后的部分， offset的取值在0 到 ${#var}-1 之间(bash4.2后，允许为负值) ${var:offset} #返回字符串变量var中从第offset个字符后（不包括第offset个字符）的字符开始，长度为number的部分 ${var:offset:number} #取字符串的最右侧几个字符,取字符串的最右侧几个字符, 注意：冒号后必须有一空白字符 ${var: -length} #从最左侧跳过offset字符，一直向右取到距离最右侧lengh个字符之前的内容,即:掐头去尾 ${var:offset:-length} #先从最右侧向左取到length个字符开始，再向右取到距离最右侧offset个字符之间的内容,注意：- length前空格,并且length必须大于offset ${var: -length:-offset} 范例\n[root@centos8 script40]#str=abcdef我你他 [root@centos8 script40]#echo ${#str} 9 [root@centos8 script40]#echo ${str:2} cdef我你他 [root@centos8 script40]#echo ${str:2:3} cde [root@centos8 script40]#echo ${str:-3} abcdef我你他 [root@centos8 script40]#echo ${str: -3} 我你他 [root@centos8 script40]#echo ${str:2:-3} cdef [root@centos8 script40]#echo ${str: -2:-3} -bash: -3: substring expression \u0026lt; 0 [root@centos8 script40]#echo ${str: -3:-2} 我 [root@centos8 script40]#echo ${str:-3:-2} abcdef我你他 [root@centos8 script40]#echo ${str: -3:-2} 我 [root@centos8 script40]#echo ${str: -5:-2} ef我 7.2 基于模式取子串 #其中word可以是指定的任意字符,自左而右，查找var变量所存储的字符串中，第一次出现的word, 删除字 符串开头至第一次出现word字符串（含）之间的所有字符,即懒惰模式,以第一个word为界删左留右 ${var#*word} #从var变量的值中删除以word开头的部分 ${var#word} #同上，贪婪模式，不同的是，删除的是字符串开头至最后一次由word指定的字符之间的所有内容,即贪婪模 式,以最后一个word为界删左留右 ${var##*word} ${var##word} 范例\n[root@centos8 ~]#file=\u0026#34;var/log/messages\u0026#34; [root@centos8 ~]#echo ${file#*/} log/messages [root@centos8 ~]#echo ${file##*/} messages #其中word可以是指定的任意字符,功能：自右而左，查找var变量所存储的字符串中，第一次出现的word, 删除字符串最后一个字符向左至第一次出现word字符串（含）之间的所有字符,即懒惰模式,以从右向左的第 一个word为界删右留左 ${var%word*} ${var%word} #同上，只不过删除字符串最右侧的字符向左至最后一次出现word字符之间的所有字符,即贪婪模式,以从右向 左的最后一个word为界删右留左 ${var%%word*} ${var%%word} 7.3 查找和替换 #查找var所表示的字符串中，第一次被pattern所匹配到的字符串，以substr替换之 ${var/pattern/substr} #查找var所表示的字符串中，所有能被pattern所匹配到的字符串，以substr替换之 ${var//pattern/substr} #查找var所表示的字符串中，行首被pattern所匹配到的字符串，以substr替换之 ${var/#pattern/substr} #查找var所表示的字符串中，行尾被pattern所匹配到的字符串，以substr替换之 ${var/%pattern/substr} 7.4 查找和删除 #删除var表示的字符串中第一次被pattern匹配到的字符串 ${var/pattern} #删除var表示的字符串中所有被pattern匹配到的字符串 ${var//pattern} #删除var表示的字符串中所有以pattern为行首匹配到的字符串 ${var/#pattern} #删除var所表示的字符串中所有以pattern为行尾所匹配到的字符串 ${var/%pattern} 7.5 字符大小写转换 #把var中的所有小写字母转换为大写 ${var^^} #把var中的所有大写字母转换为小写 ${var,,} ","permalink":"https://xyenvy.github.io/posts/shell%E7%BC%96%E7%A8%8B/","summary":"内容简述 shell 是操作系统的最外层。shell 合并编程语言以控制进程和文件，以及启动和控制其它程序。shell 通过提示您输入，向操作系统解释该输入，然后处理来自操作系统的任何结果输出来管理您与操作系统之间的交互。 1.编程基础 Linus：Talk is cheap, show me the code 1.1 程序组成 程序：算法+数据结构","title":"shell编程"},{"content":"文件查找和打包压缩 内容概述\n- locate - find - xargs - compress和uncompress - gzip和gunzip - bzip2和bunzip2 - xz和unxz - zip和unzip - tar 1 查找工具 在文件系统上查找符合条件的文件 文件查找：\n非实时查找(数据库查找)：locate 实时查找：find 1.1 locate locate 查询系统上预建的文件索引数据库/var/lib/mlocate/mlocate.db 索引的构建是在系统较为空闲时自动进行(周期性任务)，执行updatedb可以更新数据库 索引构建过程需要遍历整个根文件系统，很消耗资源 locate和updatedb命令来自于mlocate包 工作特点:\n查找速度快 模糊查找 非实时查找 搜索的是文件的全路径，不仅仅是文件名 可能只搜索用户具备读取和执行权限的目录 格式：\nlocate [OPTION]... [PATTERN]... 常用选项：\n-i 不区分大小写的搜索 -n N 只列举前N个匹配项目 -r 使用基本正则表达式 范例：\n#搜索名称或路径中包含“conf\u0026#34;的文件 locate conf #使用Regex来搜索以“.conf\u0026#34;结尾的文件 locate -r \u0026#39;\\.conf$\u0026#39; 范例：创建locatedb数据库\n[root@rocky8 data]# updatedb [root@rocky8 data]# locate -n 3 conf /boot/config-4.18.0-372.13.1.el8_6.x86_64 /boot/config-4.18.0-372.9.1.el8.x86_64 /boot/grub2/i386-pc/configfile.mod [root@rocky8 data]# 范例: 文件新创建和删除,无法马上更新locate数据库\n# 创建yuankun.txt文件查找没有结果 [root@rocky8 data]# touch yuankun.txt [root@rocky8 data]# locate yuankun.txt [root@rocky8 data]# # 已经删除/data/a.txt文件，查找a.txt文件还能找到 [root@rocky8 data]# ll total 8 -rw-r--r-- 1 root root 22 Jul 30 04:07 a.txt -rw-r--r-- 1 root root 1511 Jul 30 05:11 passwd -rw-r--r-- 1 root root 0 Aug 1 22:06 yuankun.txt [root@rocky8 data]# rm -rf a.txt [root@rocky8 data]# locate a.txt /data/a.txt /home/yuankun/a.txt /root/a.txt /root/data.txt /usr/lib/firmware/brcm/brcmfmac43340-sdio.pov-tab-p1006w-data.txt /usr/lib/firmware/brcm/brcmfmac43430-sdio.sinovoip,bpi-m2-ultra.txt /usr/share/crypto-policies/DEFAULT/java.txt /usr/share/crypto-policies/EMPTY/java.txt /usr/share/crypto-policies/FIPS/java.txt /usr/share/crypto-policies/FUTURE/java.txt /usr/share/crypto-policies/LEGACY/java.txt /usr/share/doc/perl-CPAN-Meta/t/README-data.txt /usr/share/doc/vim-common/README_extra.txt /usr/share/gnupg/help.ca.txt /usr/share/gnupg/help.da.txt /usr/share/gnupg/help.ja.txt /usr/share/vim/vim80/doc/ft_ada.txt /usr/share/vim/vim80/doc/if_lua.txt /usr/share/vim/vim80/doc/os_amiga.txt /usr/share/vim/vim80/doc/uganda.txt /www/server/panel/pyenv/lib/python3.7/test/test_email/data/msg_12a.txt [root@rocky8 data]# 1.2 find find 是实时查找工具，通过遍历指定路径完成文件查找。 工作特点：\n查找速度略慢 精确查找 实时查找 查找条件丰富 可能只搜索用户具备读取和执行权限的目录 格式：\nfind [OPTION]... [查找路径] [查找条件] [处理动作] 查找路径：指定具体目标路径；默认为当前目录 查找条件：指定的查找标准，可以文件名、大小、类型、权限等标准进行；默认为找出指定路径下的所 有文件 处理动作：对符合条件的文件做操作，默认输出至屏幕\n1.2.1 指定搜索目录层级 -maxdepth level 最大搜索目录深度,指定目录下的文件为第1级 -mindepth level 最小搜索目录深度 范例：\nfind /etc -maxdepth 2 -mindepth 2 1.2.2 对每个目录先处理目录内的文件，再处理目录本身 -depth -d #warning: the -d option is deprecated; please use -depth instead, because the latter is a POSIX-compliant feature 范例：\n[root@centos8 data]#tree /data/test /data/test ├── f1.txt ├── f2.txt └── test2 └── test3 ├── f3.txt └── f4.txt 4 directories, 2 files [root@centos8 data]#find /data/test /data/test /data/test/f1.txt /data/test/f2.txt /data/test/test2 /data/test/test2/test3 /data/test/test2/test3/f3.txt /data/test/test2/test3/f4.txt [root@centos8 data]#find /data/test -depth /data/test/f1.txt /data/test/f2.txt /data/test/test2/test3/f3.txt /data/test/test2/test3/f4.txt /data/test/test2/test3 /data/test/test2 /data/test 1.2.3 根据文件名和inode查找 -name \u0026#34;文件名称\u0026#34; #支持使用glob，如：*, ?, [], [^],通配符要加双引号引起来 -iname \u0026#34;文件名称\u0026#34; #不区分字母大小写 -inum n #按inode号查找 -samefile name #相同inode号的文件 -links n #链接数为n的文件 -regex “PATTERN\u0026#34; #以PATTERN匹配整个文件路径，而非文件名称 1.2.4 根据属主、属组查找 -user USERNAME #查找属主为指定用户(UID)的文件 -group GRPNAME #查找属组为指定组(GID)的文件 -uid UserID #查找属主为指定的UID号的文件 -gid GroupID #查找属组为指定的GID号的文件 -nouser #查找没有属主的文件 -nogroup #查找没有属组的文件 1.2.5 根据文件类型查找 -type TYPE TYPE可以是以下形式： f: 普通文件 d: 目录文件 l: 符号链接文件 s：套接字文件 b: 块设备文件 c: 字符设备文件 p: 管道文件 范例：\n#查看/home的目录 find /home –type d -ls 1.2.6 空文件或目录 -empty 范例：\n[root@centos8 ~]#find /app -type d -empty 1.2.7 组合条件 与：-a ，默认多个条件是与关系，所以可以省略-a 或：-o 非：-not ! 范例：\n[root@centos8 ~]#find /etc/ -type d -o -type l |wc -l 307 [root@centos8 ~]#find /etc/ -type d -o -type l -ls |wc -l 101 [root@centos8 ~]#find /etc/ \\( -type d -o -type l \\) -ls |wc -l 30 德·摩根定律：\n非 A) 且 (非 B) = 非(A 或 B) (非 A) 或 (非 B) = 非(A 且 B) 示例：\n!A -a !B = !(A -o B) !A -o !B = !(A -a B) 范例：\n#找出/tmp目录下，属主不是root，且文件名不以f开头的文件 find /tmp \\( -not -user root -a -not -name \u0026#39;f*\u0026#39; \\) -ls find /tmp -not \\( -user root -o -name \u0026#39;f*\u0026#39; \\) –ls 1.2.8 排除目录 #查找/etc/下，除/etc/security目录的其它所有.conf后缀的文件 find /etc -path \u0026#39;/etc/security\u0026#39; -a -prune -o -name \u0026#34;*.conf\u0026#34; #查找/etc/下，除/etc/security和/etc/systemd,/etc/dbus-1三个目录的所有.conf后缀的文件 find /etc \\( -path \u0026#34;/etc/security\u0026#34; -o -path \u0026#34;/etc/systemd\u0026#34; -o -path \u0026#34;/etc/dbus- 1\u0026#34; \\) -a -prune -o -name \u0026#34;*.conf\u0026#34; #排除/proc和/sys目录 find / \\( -path \u0026#34;/sys\u0026#34; -o -path \u0026#34;/proc\u0026#34; \\) -a -prune -o -type f -a -mmin -1 范例:\nfind / -size +10G [root@centos8 ~]#find / -size +10G /proc/kcore find: ‘/proc/25229/task/25229/fd/6’: No such file or directory find: ‘/proc/25229/task/25229/fdinfo/6’: No such file or directory find: ‘/proc/25229/fd/5’: No such file or directory find: ‘/proc/25229/fdinfo/5’: No such file or directory [root@centos8 ~]#ll -h /proc/kcore -r-------- 1 root root 128T Dec 14 2020 /proc/kcore [root@centos8 ~]#du -sh /proc/kcore 0 /proc/kcore 1.2.9 根据时间戳 #以“天\u0026#34;为单位 -atime [+|-]# # #表示[#,#+1) +# #表示[#+1,∞] -# #表示[0,#) -mtime -ctime #以“分钟\u0026#34;为单位 -amin -mmin -cmin 1.2.10 根据权限查找 -perm [/|-]MODE MODE #精确权限匹配 /MODE #任何一类(u,g,o)对象的权限中只要有一位匹配即可，或关系，+ 从CentOS 7开始淘汰 -MODE #每一类对象都必须同时拥有指定权限，与关系 0 表示不关注 说明： find -perm 755 会匹配权限模式恰好是755的文件 只要当任意人有写权限时，find -perm /222就会匹配 只有当每个人都有写权限时，find -perm -222才会匹配 只有当其它人（other）有写权限时，find -perm -002才会匹配\n1.2.11 处理动作 -print：默认的处理动作，显示至屏幕 -ls：类似于对查找到的文件执行\u0026#34;ls -dils\u0026#34;命令格式输出 -fls file：查找到的所有文件的长格式信息保存至指定文件中，相当于 -ls \u0026gt; file -delete：删除查找到的文件，慎用！ -ok COMMAND {} \\; 对查找到的每个文件执行由COMMAND指定的命令，对于每个文件执行命令之前，都会 交互式要求用户确认 -exec COMMAND {} \\; 对查找到的每个文件执行由COMMAND指定的命令 {}: 用于引用查找到的文件名称自身 关于 {} ;\nhttps://askubuntu.com/questions/339015/what-does-mean-in-the-find-command 范例：\n#备份配置文件，添加.orig这个扩展名 [root@rocky8 data]# ll total 4 -rw-r--r-- 1 root root 0 Aug 2 21:02 file1.conf -rw-r--r-- 1 root root 0 Aug 2 21:02 file2.conf -rw-r--r-- 1 root root 0 Aug 2 21:02 file3.conf -rw-r--r-- 1 root root 0 Aug 2 21:02 file4.conf -rw-r--r-- 1 root root 1511 Jul 30 05:11 passwd -rw-r--r-- 1 root root 0 Aug 1 22:06 yuankun.txt [root@rocky8 data]# find ./ -name \u0026#39;file*.conf\u0026#39; ./file1.conf ./file2.conf ./file3.conf ./file4.conf [root@rocky8 data]# find ./ -name \u0026#39;file*.conf\u0026#39; -exec cp {} {}.orig \\; [root@rocky8 data]# ll total 4 -rw-r--r-- 1 root root 0 Aug 2 21:02 file1.conf -rw-r--r-- 1 root root 0 Aug 2 21:07 file1.conf.orig -rw-r--r-- 1 root root 0 Aug 2 21:02 file2.conf -rw-r--r-- 1 root root 0 Aug 2 21:07 file2.conf.orig -rw-r--r-- 1 root root 0 Aug 2 21:02 file3.conf -rw-r--r-- 1 root root 0 Aug 2 21:07 file3.conf.orig -rw-r--r-- 1 root root 0 Aug 2 21:02 file4.conf -rw-r--r-- 1 root root 0 Aug 2 21:07 file4.conf.orig -rw-r--r-- 1 root root 1511 Jul 30 05:11 passwd -rw-r--r-- 1 root root 0 Aug 1 22:06 yuankun.txt [root@rocky8 data]# #提示删除存在时间超过３天以上的joe的临时文件 find /tmp -ctime +3 -user joe -ok rm {} \\; #在主目录中寻找可被其它用户写入的文件 find ~ -perm -002 -exec chmod o-w {} \\; #查找/data下的权限为644，后缀为sh的普通文件，增加执行权限 find /data –type f -perm 644 -name \u0026#34;*.sh\u0026#34; –exec chmod 755 {} \\; 1.3 参数替换xargs 由于很多命令不支持管道|来传递参数，xargs用于产生某个命令的参数，xargs 可以读入 stdin 的数 据，并且以空格符或回车符将 stdin 的数据分隔成为参数 另外，许多命令不能接受过多参数，命令执行可能会失败，xargs 可以解决 注意：文件名或者是其他意义的名词内含有空格符的情况 find 经常和 xargs 命令进行组合,形式如下：\nfind | xargs COMMAND 范例：\n#显示10个数字 [root@centos8 ~]#seq 10 | xargs 1 2 3 4 5 6 7 8 9 10 #删除当前目录下的大量文件 ls | xargs rm # find -name \u0026#34;*.sh\u0026#34; | xargs ls -Sl [root@centos8 data]#echo {1..10} |xargs 1 2 3 4 5 6 7 8 9 10 [root@centos8 data]#echo {1..10} |xargs -n1 1 2 3 4 5 6 7 8 9 10 [root@centos8 data]#echo {1..10} |xargs -n2 1 2 3 4 5 6 7 8 9 10 #批量创建和删除用户 echo user{1..10} |xargs -n1 useradd echo user{1..100} | xargs -n1 userdel -r #这个命令是错误的 find /sbin/ -perm /700 | ls -l #查找有特殊权限的文件，并排序 find /bin/ -perm /7000 | xargs ls -Sl #此命令和上面有何区别？ find /bin/ -perm -7000 | xargs ls -Sl #以字符nul分隔 find -type f -name \u0026#34;*.txt\u0026#34; -print0 | xargs -0 rm #并发执行多个进程 seq 100 |xargs -i -P10 wget -P /data http://10.0.0.8/{}.html #并行下载bilibili视频 yum install python3-pip -y pip3 install you-get seq 60 | xargs -i -P3 you-get https://www.bilibili.com/video/BV14K411W7UF?p={} 练习 1、查找/var目录下属主为root，且属组为mail的所有文件 2、查找/var目录下不属于root、lp、gdm的所有文件 3、查找/var目录下最近一周内其内容修改过，同时属主不为root，也不是postfix的文件 4、查找当前系统上没有属主或属组，且最近一个周内曾被访问过的文件 5、查找/etc目录下大于1M且类型为普通文件的所有文件 6、查找/etc目录下所有用户都没有写权限的文件 7、查找/etc目录下至少有一类用户没有执行权限的文件 8、查找/etc/init.d目录下，所有用户都有执行权限，且其它用户有写权限的文件\n2 压缩和解压缩 主要针对单个文件压缩，而非目录\n2.1 compress和uncompress 此工具来自于ncompress包,此工具目前已经很少使用 对应的文件是 .Z 后缀\n常用选项\n-d 解压缩，相当于uncompress -c 结果输出至标准输出,不删除原文件 -v 显示详情 范例：\ncompress filename #压缩 uncompress filename # 解压缩 zcat file.Z 不显式解压缩的前提下查看文本文件内容\nzcat file.Z \u0026gt;file 2.2 gzip和gunzip 来自于 gzip 包 对应的文件是 .gz 后缀 格式：\ngzip [OPTION] ···file··· 常用选项：\n-k keep, 保留原文件,CentOS 8 新特性 -d 解压缩，相当于gunzip -c 结果输出至标准输出，保留原文件不改变 -# 指定压缩比，#取值为1-9，值越大压缩比越大 范例：\n# 压缩 gzip filename # 解压缩 gunzip file.gz #不显式解压缩的前提下查看文本文件内容 zcat file.gz 范例:\ngzip -c messages \u0026gt;messages.gz gzip -c -d messages.gz \u0026gt; messages zcat messages.gz \u0026gt; messages cat messages | gzip \u0026gt; m.gz 2.3 bzip2和bunzip2 来自于 bzip2 包 对应的文件是 .bz2 后缀 格式：\nbzip2 [OPTION]... FILE ... 常用选项：\n-k keep, 保留原文件 -d 解压缩 -c 结果输出至标准输出，保留原文件不改变 -# 1-9，压缩比，默认为9 范例：\nbzip2 file # 压缩 bunzip2 file.bz2 解压缩 bzcat file.bz2 不显式解压缩的前提下查看文本文件内容 2.4 xz和unxz 来自于 xz 包 对应的文件是 .xz 后缀 格式:\nxz [OPTION]... FILE ... 常用选项：\n-k keep, 保留原文件 -d 解压缩 -c 结果输出至标准输出，保留原文件不改变 -# 压缩比，取值1-9，默认为6 范例：\nunxz file.xz #解压缩 xzcat file.xz #不显式解压缩的前提下查看文本文件内容 2.5 zip和unzip zip 可以实现打包目录和多个文件成一个文件并压缩，但可能会丢失文件属性信息，如：所有者和组信 息，一般建议使用 tar 代替 分别来自于 zip 和 unzip 包 对应的文件是 .zip 后缀 范例: zip帮助\n#打包并压缩 zip -r /backup/sysconfig.zip /etc/sysconfig/ #不包括目录本身，只打包目录内的文件和子目录 cd /etc/sysconfig; zip -r /root/sysconfig.zip * #默认解压缩至当前目录 unzip /backup/sysconfig.zip #解压缩至指定目录,如果指定目录不存在，会在其父目录（必须事先存在）下自动生成 unzip /backup/sysconfig.zip -d /tmp/config cat /var/log/messages | zip messages - #-p 表示管道 unzip -p message.zip \u0026gt; message 范例: 交互式加密和解密\n[root@rocky8 data]# zip -e file1.conf.zip file1.conf Enter password: Verify password: adding: file1.conf (stored 0%) [root@rocky8 data]# unzip file1.conf.zip Archive: file1.conf.zip [file1.conf.zip] file1.conf password: replace file1.conf? [y]es, [n]o, [A]ll, [N]one, [r]ename: y extracting: file1.conf [root@rocky8 data]# ll total 8 -rw-r--r-- 1 root root 0 Aug 2 21:02 file1.conf -rw-r--r-- 1 root root 0 Aug 2 21:07 file1.conf.orig -rw-r--r-- 1 root root 198 Aug 2 22:06 file1.conf.zip -rw-r--r-- 1 root root 0 Aug 2 21:02 file2.conf -rw-r--r-- 1 root root 0 Aug 2 21:07 file2.conf.orig -rw-r--r-- 1 root root 0 Aug 2 21:02 file3.conf -rw-r--r-- 1 root root 0 Aug 2 21:07 file3.conf.orig -rw-r--r-- 1 root root 0 Aug 2 21:02 file4.conf -rw-r--r-- 1 root root 0 Aug 2 21:07 file4.conf.orig -rw-r--r-- 1 root root 1511 Jul 30 05:11 passwd -rw-r--r-- 1 root root 0 Aug 1 22:06 yuankun.txt [root@rocky8 data]# 范例: 非交互式加密和解密\n[root@rocky8 data]# zip -P 123456 file2.conf.zip file2.conf # p是大P adding: file2.conf (stored 0%) # 解压 [root@rocky8 data]# unzip file2.conf.zip Archive: file2.conf.zip [file2.conf.zip] file2.conf password: replace file2.conf? [y]es, [n]o, [A]ll, [N]one, [r]ename: y extracting: file2.conf [root@rocky8 data]# 3 打包和解包 3.1 tar tar 即 Tape ARchive 磁带归档，可以对目录和多个文件打包一个文件，并且可以压缩，保留文件属性不 丢失，常用于备份功能，推荐使用 对应的文件是 .tar 后缀 格式\ntar [-ABcdgGhiklmMoOpPrRsStuUvwWxzZ][-b \u0026lt;区块数目\u0026gt;][-C \u0026lt;目的目录\u0026gt;][-f \u0026lt;备份文件\u0026gt;][-F \u0026lt;Script文件\u0026gt;][-K \u0026lt;文件\u0026gt;][-L \u0026lt;媒体容量\u0026gt;][-N \u0026lt;日期时间\u0026gt;][-T \u0026lt;范本文件\u0026gt;][-V \u0026lt;卷册名称\u0026gt;][-X \u0026lt;范本文件\u0026gt;][-\u0026lt;设备编号\u0026gt;\u0026lt;存储密度\u0026gt;][--after-date=\u0026lt;日期时间\u0026gt;][--atime-preserve][-- backuup=\u0026lt;备份方式\u0026gt;][--checkpoint][--concatenate][--confirmation][--delete][-- exclude=\u0026lt;范本样式\u0026gt;][--force-local][--group=\u0026lt;群组名称\u0026gt;][--help][--ignore-failed- read][--new-volume-script=\u0026lt;Script文件\u0026gt;][--newer-mtime][--no-recursion][--null][-- numeric-owner][--owner=\u0026lt;用户名称\u0026gt;][--posix][--erve][--preserve-order][--preserve- permissions][--record-size=\u0026lt;区块数目\u0026gt;][--recursive-unlink][--remove-files][--rsh- command=\u0026lt;执行指令\u0026gt;][--same-owner][--suffix=\u0026lt;备份字尾字符串\u0026gt;][--totals][--use- compress-program=\u0026lt;执行指令\u0026gt;][--version][--volno-file=\u0026lt;编号文件\u0026gt;][文件或目录...] 常用选项：\n-A或--catenate 新增文件到已存在的备份文件。 -b\u0026lt;区块数目\u0026gt;或--blocking-factor=\u0026lt;区块数目\u0026gt; 设置每笔记录的区块数目，每个区块大小为12Bytes。 -B或--read-full-records 读取数据时重设区块大小。 -c或--create 建立新的备份文件。 -C\u0026lt;目的目录\u0026gt;或--directory=\u0026lt;目的目录\u0026gt; 切换到指定的目录。 -d或--diff或--compare 对比备份文件内和文件系统上的文件的差异。 -f\u0026lt;备份文件\u0026gt;或--file=\u0026lt;备份文件\u0026gt; 指定备份文件。 -F\u0026lt;Script文件\u0026gt;或--info-script=\u0026lt;Script文件\u0026gt; 每次更换磁带时，就执行指定的Script文件。 -g或--listed-incremental 处理GNU格式的大量备份。 -G或--incremental 处理旧的GNU格式的大量备份。 -h或--dereference 不建立符号连接，直接复制该连接所指向的原始文件。 -i或--ignore-zeros 忽略备份文件中的0 Byte区块，也就是EOF。 -k或--keep-old-files 解开备份文件时，不覆盖已有的文件。 -K\u0026lt;文件\u0026gt;或--starting-file=\u0026lt;文件\u0026gt; 从指定的文件开始还原。 -l或--one-file-system 复制的文件或目录存放的文件系统，必须与tar指令执行时所处的文件系统相 同，否则不予复制。 -L\u0026lt;媒体容量\u0026gt;或-tape-length=\u0026lt;媒体容量\u0026gt; 设置存放每体的容量，单位以1024 Bytes计算。 -m或--modification-time 还原文件时，不变更文件的更改时间。 -M或--multi-volume 在建立，还原备份文件或列出其中的内容时，采用多卷册模式。 -N\u0026lt;日期格式\u0026gt;或--newer=\u0026lt;日期时间\u0026gt; 只将较指定日期更新的文件保存到备份文件里。 -o或--old-archive或--portability 将资料写入备份文件时使用V7格式。 -O或--stdout 把从备份文件里还原的文件输出到标准输出设备。 -p或--same-permissions 用原来的文件权限还原文件。 -P或--absolute-names 文件名使用绝对名称，不移除文件名称前的\u0026#34;/\u0026#34;号。 -r或--append 新增文件到已存在的备份文件的结尾部分。 -R或--block-number 列出每个信息在备份文件中的区块编号。 -s或--same-order 还原文件的顺序和备份文件内的存放顺序相同。 -S或--sparse 倘若一个文件内含大量的连续0字节，则将此文件存成稀疏文件。 -t或--list 列出备份文件的内容。 -T\u0026lt;范本文件\u0026gt;或--files-from=\u0026lt;范本文件\u0026gt; 指定范本文件，其内含有一个或多个范本样式，让tar解开或 建立符合设置条件的文件。 -u或--update 仅置换较备份文件内的文件更新的文件。 -U或--unlink-first 解开压缩文件还原文件之前，先解除文件的连接。 -v或--verbose 显示指令执行过程。 -V\u0026lt;卷册名称\u0026gt;或--label=\u0026lt;卷册名称\u0026gt; 建立使用指定的卷册名称的备份文件。 -w或--interactive 遭遇问题时先询问用户。 -W或--verify 写入备份文件后，确认文件正确无误。 -x或--extract或--get 从备份文件中还原文件。 -X\u0026lt;范本文件\u0026gt;或--exclude-from=\u0026lt;范本文件\u0026gt; 指定范本文件，其内含有一个或多个范本样式，让ar排除 符合设置条件的文件。 -z或--gzip或--ungzip 通过gzip指令处理备份文件。 -Z或--compress或--uncompress 通过compress指令处理备份文件。 -\u0026lt;设备编号\u0026gt;\u0026lt;存储密度\u0026gt; 设置备份用的外围设备编号及存放数据的密度。 --after-date=\u0026lt;日期时间\u0026gt; 此参数的效果和指定\u0026#34;-N\u0026#34;参数相同。 --atime-preserve 不变更文件的存取时间。 --backup=\u0026lt;备份方式\u0026gt;或--backup 移除文件前先进行备份。 --checkpoint 读取备份文件时列出目录名称。 --concatenate 此参数的效果和指定\u0026#34;-A\u0026#34;参数相同。 --confirmation 此参数的效果和指定\u0026#34;-w\u0026#34;参数相同。 --delete 从备份文件中删除指定的文件。 --exclude=\u0026lt;范本样式\u0026gt; 排除符合范本样式的文件。 --group=\u0026lt;群组名称\u0026gt; 把加入设备文件中的文件的所属群组设成指定的群组。 --help 在线帮助。 --ignore-failed-read 忽略数据读取错误，不中断程序的执行。 --new-volume-script=\u0026lt;Script文件\u0026gt; 此参数的效果和指定\u0026#34;-F\u0026#34;参数相同。 --newer-mtime 只保存更改过的文件。 --no-recursion 不做递归处理，也就是指定目录下的所有文件及子目录不予处理。 --null 从null设备读取文件名称。 --numeric-owner 以用户识别码及群组识别码取代用户名称和群组名称。 --owner=\u0026lt;用户名称\u0026gt; 把加入备份文件中的文件的拥有者设成指定的用户。 --posix 将数据写入备份文件时使用POSIX格式。 --preserve 此参数的效果和指定\u0026#34;-ps\u0026#34;参数相同。 --preserve-order 此参数的效果和指定\u0026#34;-A\u0026#34;参数相同。 --preserve-permissions 此参数的效果和指定\u0026#34;-p\u0026#34;参数相同。 --record-size=\u0026lt;区块数目\u0026gt; 此参数的效果和指定\u0026#34;-b\u0026#34;参数相同。 --recursive-unlink 解开压缩文件还原目录之前，先解除整个目录下所有文件的连接。 --remove-files 文件加入备份文件后，就将其删除。 --rsh-command=\u0026lt;执行指令\u0026gt; 设置要在远端主机上执行的指令，以取代rsh指令。 --same-owner 尝试以相同的文件拥有者还原文件。 --suffix=\u0026lt;备份字尾字符串\u0026gt; 移除文件前先行备份。 --totals 备份文件建立后，列出文件大小。 --use-compress-program=\u0026lt;执行指令\u0026gt; 通过指定的指令处理备份文件。 --version 显示版本信息。 --volno-file=\u0026lt;编号文件\u0026gt; 使用指定文件内的编号取代预设的卷册编号。 范例：打包并压缩\ntar zcvf filename.tar.gz filename 范例：解压缩\ntar xf filename.tar.gz 3.2 split split 命令可以分割一个文件为多个文件 范例：\n#分割大的 tar 文件为多份小文件 split -b Size –d tar-file-name prefix-name 示例: split -b 1M mybackup.tgz mybackup-parts #切换成的多个小分文件使用数字后缀 split -b 1M –d mybackup.tgz mybackup-parts 将多个切割的小文件合并成一个大文件\ncat mybackup-parts* \u0026gt; mybackup.tar.gz ","permalink":"https://xyenvy.github.io/posts/%E6%96%87%E4%BB%B6%E6%9F%A5%E6%89%BE%E5%92%8C%E6%89%93%E5%8C%85%E5%8E%8B%E7%BC%A9/","summary":"文件查找和打包压缩 内容概述 - locate - find - xargs - compress和uncompress - gzip和gunzip - bzip2和bunzip2 - xz和unxz - zip和unzip - tar 1 查找工具 在文件系统上查找符合条件的文件 文件查找： 非实时查找(数据库查找)：locate 实时查找：find 1.1 locate","title":"文件查找和打包压缩"},{"content":"1.文本编辑工具之神VIM 1.1使用vim初步 1.1.1vim命令格式 vim [option]··· FILE ··· 常用选项：\n+# 打开文件后，让光标处于第#行的行首，+默认行尾 范例：\nvim +10 passwd +/PATTERN 让光标处于第一个被PATTERN匹配到的行行首 -b file 二进制方式打开文件 -d file1 file2… 比较多个文件，相当于 vimdiff -m file 只读打开文件 -e file 直接进入ex模式，相当于执行ex file -y file Easy mode (like \u0026#34;evim\u0026#34;, modeless)，直接可以操作文件，ctrl+o:wq|q! 保存和不 保存退出 说明：\n如果该文件存在，文件被打开并显示内容 如果该文件不存在，当编辑后第一次存盘时创建它 1.1.2三种主要模式 三种常见模式：\n命令或普通(Normal)模式：默认模式，可以实现移动光标，剪切/粘贴文本\n插入(Insert)或编辑模式：用于修改文本\n扩展命令(extended command )或命令(末)行模式：保存，退出等\n命令模式\u0026ndash;》插入模式\ni insert, 在光标所在处输入 I 在当前光标所在行的行首输入 a append, 在光标所在处后面输入 A 在当前光标所在行的行尾输入 o 在当前光标所在行的下方打开一个新行 O 在当前光标所在行的上方打开一个新行 插入模式 \u0026mdash; ESC\u0026mdash;\u0026ndash;\u0026gt; 命令模式 命令模式 \u0026mdash;- : \u0026mdash;-\u0026gt; 扩展命令模式 扩展命令模式 \u0026mdash;-ESC,enter\u0026mdash;-\u0026gt; 命令模式 范例: 插入颜色字符\n1 切换至插入模式 2 按ctrl+v+[ 三个键,显示^[ 3 后续输入颜色信息,如:^[[32mhello^[[0m 4 切换至扩展命令模式,保存退出 5 cat 文件可以看到下面显示 1.2扩展命令模式 按“:\u0026quot;（冒号）进入Ex模式，创建一个命令提示符：处于底部的屏幕左侧\n1.2.1扩展模式基本命令 w 写（存）磁盘文件 wq 写入并退出 x 写入并退出 X 加密 q 退出 q！ 不存盘退出，即使更改都将丢失 读取文件内容到当前文件中 用法：\nr filename # 读文件内容到当前文件中 范例：\n# 将当前目录下的b文件的内容读取到当前文件中 vim a.txt :r b.txt 将当前文件内容写入另一个文件 用法：\nw filename # 将当前文件内容写入另一个文件 范例：\n# 将当前文件(a.txt文件)内容写入到b.txt中去 vim a.txt w c.txt 执行命令 用法：\n!command #执行命令 范例：\n读入命令的输入 用法：\nr!command #读入命令的输入 范例：执行hostname命令输入到当前文件中\n1.2.2地址定界 格式：\n:start_pos,end_pos CMD 1.2.2.1地址定界格式 # #具体第#行，例如2表示第2行 #,# #从左侧#表示起始行，到右侧#表示结尾行 #,+# #从左侧#表示的起始行，加上右侧#表示的行数，范例：2,+3 表示2到5行 . #当前行 $ #最后一行 .,$-1 #当前行到倒数第二行 % #全文, 相当于1,$ /pattern/ #从当前行向下查找，直到匹配pattern的第一行,即:正则表达式 /pat1/,/pat2/ #从第一次被pat1模式匹配到的行开始，一直到第一次被pat2匹配到的行结束 #,/pat/ #从指定行开始，一直找到第一个匹配pattern的行结束 /pat/,$ #向下找到第一个匹配patttern的行到整个文件的结尾的所有行 1.2.2.2地址定界后跟一个编辑命令 d #删除 y #复制 w file #将范围内的行另存至指定文件中 r file #在指定位置插入指定文件中的所有内容 t#行号 将前面指定的行复制到#行后 m#行号 将前面指定的行移动到#行后 范例：\n删除文件内容第几行到第几行 :1,3d #删除第一行到第三行 复制文件全部内容 :.,$y # 通过键盘上下键选择要复制在什么地方，选择后位置后按p键复制 删除文件全部内容 :%d 1.2.3查找和替换 格式：\ns/查找的内容/替换为内容/修饰符 说明：\n要查找的内容：可使用基本正则表达式模式 替换为的内容：不能使用模式，但可以使用\\1, \\2, ...等后向引用符号；还可以使用“\u0026amp;”引用前面查找时查 找到的整个内容 修饰符：\ni #忽略大小写 g #全局替换，默认情况下，每一行只替换第一次出现 gc #全局替换，每次替换前询问 查找替换中的分隔符/可替换为其它字符，如：#,@ 范例：\ns@/etc@/var@g s#/boot#/#i 复制/etc/passwd到家目录下，将文件内的root全部替换为ROOT :%s/root/ROOT/g 1.2.4定制vim的工作特性 扩展命令模式的配置只是对当前vim进程有效，可将配置存放在文件中持久保存 配置文件：\n/etc/vimrc #全局 ~/.vimrc #个人 1.2.4.1行号 显示：set number，简写 set nu 取消显示：set nonumber, 简写 set nonu 1.2.4.2忽略字符的大小写 启用：set ignorecase，简写 set ic 不忽略：set noic 1.2.4.3自动缩进 启用：set autoindent，简写 set ai 禁用：set noai 1.2.4.4复制保留格式 启用：set paste 禁用：set nopaste 1.2.4.5显示Tab ^I和换行符 和$显示 启用：set list 禁用：set nolist 1.2.4.6高亮搜索 启用：set hlsearch 禁用：set nohlsearch 简写：nohl 1.2.4.7语法高亮 启用：syntax on 禁用：syntax off 1.2.4.8文件格式 启用windows格式：set fileformat=dos 启用unix格式：set fileformat=unix 简写 set ff=dos|unix 1.2.4.9Tab 用空格代替 启用：set expandtab 默认为8个空格代替Tab 禁用：set noexpandtab 简写：set et 1.2.4.10Tab用指定空格的个数代替 启用：set tabstop=# 指定#个空格代替Tab 简写：set ts=4 1.2.4.11设置缩进宽度 #向右缩进 命令模式\u0026gt;\u0026gt; #向左缩进 命令模式\u0026lt;\u0026lt; #设置缩进为4个字符 set shiftwidth=4 1.2.4.12设置文本宽度 set textwidth=65 (vim only) #从左向右计数 set wrapmargin=15 #从右到左计数 1.2.4.13 设置光标所在行的标识线 启用：set cursorline，简写 set cul 禁用：set nocursorline 1.2.4.14加密 启用： set key=password 禁用： set key= 1.2.4.15了解更多 set帮助\n:help option-list :set or :set all 1.3命令模式 1.3.1退出vim ZZ 保存退出 ZQ 不保存退出 1.3.2光标跳转 字符间跳转 h: 左 l: 右 j: 下 k: 上 #COMMAND：跳转由#指定的个数的字符 如：3l 单词间跳转 w：下一个单词的词首 e：当前或下一单词的词尾 b：当前或前一个单词的词首 #COMMAND：由#指定一次跳转的单词数 当前页跳转 H：页首 M：页中间行 L：页底 zt：将光标所在当前行移到屏幕顶端 zz：将光标所在当前行移到屏幕中间 zb：将光标所在当前行移到屏幕底端 行首行尾 ^ 跳转至行首的第一个非空白字符 0 跳转至行首 $ 跳转至行尾 行间移动 #G 或者扩展命令模式下 :# 跳转至由第#行 G 最后一行 1G, gg 第一行 句间移动 ) 下一句 ( 上一句 段落间移动 } 下一段 { 上一段 命令模式翻屏操作 Ctrl+f 向文件尾部翻一屏,相当于Pagedown Ctrl+b 向文件首部翻一屏,相当于Pageup Ctrl+d 向文件尾部翻半屏 Ctrl+u 向文件首部翻半屏 1.3.3字符编辑 x 剪切光标处的字符 # p键可复制剪切的字符 #x 剪切光标处起始的#个字符 xp 交换光标所在处的字符及其后面字符的位置 ~ 转换大小写 J 删除当前行后的换行符 1.3.4替换 r 只替换光标所在处的一个字符 R 切换成REPLACE模式（在末行出现-- REPLACE -- 提示）,按ESC回到命令模式 1.3.5删除命令 d 删除命令，可结合光标跳转字符，实现范围删除 d$ 删除到行尾 d^ 删除到非空行首 d0 删除到行首 dw de db #COMMAND dd： 剪切光标所在的行 #dd 多行删除 D：从当前光标位置一直删除到行尾，等同于d$ 1.3.6复制命令 y 复制，行为相似于d命令 y$ y0 y^ ye yw yb #COMMAND yy：复制行 #yy 复制多行 Y：复制整行 1.3.7粘贴命令 p 缓冲区存的如果为整行，则粘贴当前光标所在行的下方；否则，则粘贴至当前光标所在处的后面 P 缓冲区存的如果为整行，则粘贴当前光标所在行的上方；否则，则粘贴至当前光标所在处的前面 1.3.8查找 /PATTERN：从当前光标所在处向文件尾部查找 ?PATTERN：从当前光标所在处向文件首部查找 n：与命令同方向 N：与命令反方向 1.3.9撤销更改 u 撤销最近的更改，相当于windows中ctrl+z #u 撤销之前多次更改 U 撤消光标落在这行后所有此行的更改 Ctrl-r 重做最后的“撤消”更改，相当于windows中crtl+y . 重复前一个操作 #. 重复前一个操作#次 1.3.10高级用法 常见Command：y 复制、d 删除、gU 变大写、gu 变小写 范例：\n0y$ 命令 0 → 先到行头 y → 从这里开始拷贝 $ → 拷贝到本行最后一个字符 范例：粘贴“wang”100次\n100iwang [ESC] di\u0026#34; 光标在” “之间，则删除” “之间的内容 yi( 光标在()之间，则复制()之间的内容 vi[ 光标在[]之间，则选中[]之间的内容 dtx 删除字符直到遇见光标之后的第一个 x 字符 ytx 复制字符直到遇见光标之后的第一个 x 字符 1.4可视化模式 在末行有”\u0026ndash; VISUAL \u0026ndash; “指示，表示在可视化模式 允许选择的文本块\nv 面向字符，\u0026ndash; VISUAL \u0026ndash; V 面向整行，\u0026ndash; VISUAL LINE \u0026ndash; ctrl-v 面向块，\u0026ndash; VISUAL BLOCK \u0026ndash; 可视化键可用于与移动键结合使用 w ) } 箭头等 突出显示的文字可被删除，复制，变更，过滤，搜索，替换等 范例：在文件指定行的行首插入# 1、先将光标移动到指定的第一行的行首 2、输入ctrl+v 进入可视化模式 3、向下移动光标，选中希望操作的每一行的第一个字符 4、输入大写字母 I 切换至插入模式 5、输入 # 6、按 ESC 键 范例：在指定的块位置插入相同的内容\n1、光标定位到要操作的地方 2、CTRL+v 进入“可视块”模式，选取这一列操作多少行 3、SHIFT+i(I) 4、输入要插入的内容 5、按 ESC 键 1.5多文件模式 vim FILE1 FILE2 FILE3 ... :next 下一个 :prev 前一个 :first 第一个 :last 最后一个 :wall 保存所有 :qall 不保存退出所有 :wqall保存退出所有 1.6多窗口模式 1.6.1多文件分割 vim -o|-O FILE1 FILE2 ... -o: 水平或上下分割 -O: 垂直或左右分割（vim only） 在窗口间切换：Ctrl+w, Arrow 1.6.2单文件窗口 Ctrl+w,s：split, 水平分割，上下分屏 Ctrl+w,v：vertical, 垂直分割，左右分屏 ctrl+w,q：取消相邻窗口 ctrl+w,o：取消全部窗口 :wqall 退出 1.7帮助 :help :help topic Use :q to exit help #vimtutor 2.常见文本处理工具 2.1文件内容查看命令 2.1.1查看文本文件内容 2.1.1.1 cat cat可以查看文本内容\n格式：\ncat [OPTION]... [FILE]... 常见选项：\n-E：显示行结束符$ -A：显示所有控制符 -n：对显示出的每一行进行编号 -b：非空行编号 -s：压缩连续的空行成一行 2.1.1.2 nl 显示行号，相当于cat -b\n[root@rocky8 ~]# nl data.txt 1 1 2 2 3 3 4 4 5 5 [root@rocky8 ~]# 2.1.1.3 tac 逆向显示文本内容\n[root@rocky8 ~]# cat data.txt 1 2 3 4 5 [root@rocky8 ~]# tac data.txt 5 4 3 2 1 [root@rocky8 ~]# 2.1.1.4 rev 将同一行的内容逆向显示\n[root@rocky8 ~]# cat readme.txt 1 2 3 4 5 6 a b c d e f [root@rocky8 ~]# rev readme.txt 6 5 4 3 2 1 f e d c b a [root@rocky8 ~]# 2.1.2查看非文本文件内容 范例：hexdump\nhexdump -C -n 512 /dev/sda 00000000 eb 63 90 10 8e d0 bc 00 b0 b8 00 00 8e d8 8e c0 |.c..............| echo {a..z} | tr -d \u0026#39; \u0026#39;|hexdump -C 00000000 61 62 63 64 65 66 67 68 69 6a 6b 6c 6d 6e 6f 70 |abcdefghijklmnop| 00000010 71 72 73 74 75 76 77 78 79 7a 0a |qrstuvwxyz.| 0000001b 2.2. 分页查看文件内容 2.2.1 more 可以实现分页查看文件，可以配合管道符实现输出信息的分页\n格式：\nmore [OPTIONS...] FILE... 选项：\n-d: 显示翻页及退出提示 范例：\nmore passwd 使用空格键往下查看，可显示进度百分比，“q\u0026quot;退出\n2.2.2 less less 也可以实现分页查看文件或STDIN输出，less 命令是man命令使用的分页器 查看时有用的命令包括：\n/文本 搜索 文本 n/N 跳到下一个 或 上一个匹配 范例：#less 配合管道对其它命令的执行结果进行分页显示\ncat passwd |less 2.3显示文本前面的或后面的内容 2.3.1 head 可以显示文件或标准输入的前面行 格式：\nhead [OPTION]... [FILE]... 选项：\n-c # 指定获取前#字节 -n # 指定获取前#行,#如果为负数,表示从文件头取到倒数第#前 -# 同上 范例：查看passwd文件前三行\n[root@rocky8 ~]# head -n 3 passwd root❌0:0:root:/root:/bin/bash root❌0:0:root:/root:/bin/bash root❌0:0:root:/root:/bin/bash [root@rocky8 ~]# 范例：查看倒数三行\n[root@rocky8 ~]# head -3 passwd root❌0:0:root:/root:/bin/bash root❌0:0:root:/root:/bin/bash root❌0:0:root:/root:/bin/bash [root@rocky8 ~]# 范例：查看首行到倒数第三行内容\nhead -n -3 passwd 2.3.2 tail tail 和head 相反，查看文件或标准输入的倒数行 格式:\ntail [OPTION]... [FILE]... 常用选项：\n-c # 指定获取后#字节 -n # 指定获取后#行,如果#是负数,表示从第#行开始到文件结束 -# 同上 -f 跟踪显示文件fd新追加的内容,常用日志监控，相当于 --follow=descriptor,当文件删除再新 建同名文件,将无法继续跟踪文件 -F 跟踪文件名，相当于--follow=name --retry，当文件删除再新建同名文件,将可以继续跟踪文 件 tailf 类似 tail –f，当文件不增长时并不访问文件,节约资源,CentOS8已经无此工具 2.4按列抽取文本 cut cut 命令可以提取文本文件或STDIN数据的指定列 格式:\ncut [OPTION]... [FILE]... 常用选项\n-d DELIMITER: 指明分隔符，默认tab -f FILEDS: #: 第#个字段,例如:3 #,#[,#]：离散的多个字段，例如:1,3,6 #-#：连续的多个字段, 例如:1-6 混合使用：1-3,7 -c 按字符切割 --output-delimiter=STRING指定输出分隔符 2.5合并多个文件 paste paste 合并多个文件同行号的列到一行 格式\npaste [OPTION]... [FILE]... 常用选项：\n-d #分隔符：指定分隔符，默认用TAB -s #所有行合成一行显示 范例：\n[root@rocky8 ~]# echo {a..d}\u0026gt;alpha.log [root@rocky8 ~]# cat alpha.log a b c d [root@rocky8 ~]# echo {1..4}\u0026gt;seq.log [root@rocky8 ~]# cat seq.log 1 2 3 4 [root@rocky8 ~]# paste alpha.log seq.log a b c d 1 2 3 4 [root@rocky8 ~]# [root@rocky8 ~]# cat alpha.log a b c d [root@rocky8 ~]# echo {1..4} |tr \u0026#34; \u0026#34; \u0026#34;\\n\u0026#34;\u0026gt;seq.log [root@rocky8 ~]# cat seq.log 1 2 3 4 [root@rocky8 ~]# paste -d: alpha.log seq.log a:1 b:2 c:3 d:4 [root@rocky8 ~]# 2.6分析文本的工具 文本数据统计：wc 整理文本：sort 比较文件：diff和patch\n2.6.1 收集文本统计数据 wc wc 命令可用于统计文件的行总数、单词总数、字节总数和字符总数 可以对文件或STDIN中的数据统计 常用选项\n-l 只计数行数 -w 只计数单词总数 -c 只计数字节总数 -m 只计数字符总数 -L 显示文件中最长行的长度 范例：\n[root@rocky8 ~]# wc /etc/passwd 30 58 1511 /etc/passwd 行数 单词数 字节数 [root@rocky8 ~]# wc -l /etc/passwd 30 /etc/passwd [root@rocky8 ~]# wc -w /etc/passwd 58 /etc/passwd [root@rocky8 ~]# wc -c /etc/passwd 1511 /etc/passwd [root@rocky8 ~]# wc -m /etc/passwd 1511 /etc/passwd [root@rocky8 ~]# wc -L /etc/passwd 85 /etc/passwd [root@rocky8 ~]# 2.6.2 文本排序 sort 把整理过的文本显示在STDOUT，不改变原始文件 格式：\nsort [options] file(s) 常用选项:\n-r 执行反方向（由上至下）整理 -R 随机排序 -n 执行按数字大小整理 -h 人类可读排序,如: 2K 1G -f 选项忽略（fold）字符串中的字符大小写 -u 选项（独特，unique），合并重复项，即去重 -t c 选项使用c做为字段界定符 -k # 选项按照使用c字符分隔的 # 列来整理能够使用多次 范例:\n#统计日志访问量 [root@centos8 data]#cut -d\u0026#34; \u0026#34; -f1 /var/log/nginx/access_log |sort -u|wc -l 201 范例：统计分区利用率\ndf| tr -s \u0026#39; \u0026#39; \u0026#39;%\u0026#39;|cut -d% -f5|sort -nr|head -n1 2.6.3 去重 uniq命令从输入中删除前后相接的重复的行 格式：\nuniq [OPTION]... [FILE]... 常见选项：\n-c: 显示每行重复出现的次数 -d: 仅显示重复过的行 -u: 仅显示不曾重复的行 uniq常和sort 命令一起配合使用： 范例：\nsort userlist.txt | uniq -c 范例：统计日志访问量最多的请求\n[root@centos8 data]#cut -d\u0026#34; \u0026#34; -f1 access_log |sort |uniq -c|sort -nr |head -3 4870 172.20.116.228 3429 172.20.116.208 2834 172.20.0.222 [root@centos8 data]#lastb -f btmp-34 | tr -s \u0026#39; \u0026#39; |cut -d \u0026#39; \u0026#39; -f3|sort |uniq -c |sort -nr | head -3 86294 58.218.92.37 43148 58.218.92.26 18036 112.85.42.201 范例：并发连接最多的远程主机IP\n[root@centos8 ~]#ss -nt|tail -n+2 |tr -s \u0026#39; \u0026#39; : |cut -d: -f6|sort|uniq -c|sort - nr |head -n2 7 10.0.0.1 2 10.0.0.7 范例：取两个文件的相同和不同的行\n[root@centos8 data]#cat test1.txt a b 1 c [root@centos8 data]#cat test2.txt b e f c 1 2 #取文件的共同行 [root@centos8 data]#cat test1.txt test2.txt | sort |uniq -d 1 b c #取文件的不同行 [root@centos8 data]#cat test1.txt test2.txt | sort |uniq -u 2 a e f 2.6.4 比较文件 2.6.4.1 diff diff命令比较两个文件之间的区别\n-u 选项来输出\u0026#34;统一的(unified)\u0026#34;diff格式文件，最适用于补丁文件 范例：\n[root@rocky8 data]# cat a.txt a b c d [root@rocky8 data]# cat b.txt a 2 c d [root@rocky8 data]# diff a.txt b.txt 2c2 \u0026lt; b --- \u0026gt; 2 [root@rocky8 data]# 2.6.4.2 patch patch 复制在其它文件中进行的改变（要谨慎使用\n-b 选项来自动备份改变了的文件 范例：\ndiff -u foo.conf foo2.conf \u0026gt; foo.patch patch -b foo.conf foo.patch 2.6.4.3vimdiff 相当于 vim -d\n范例：\n[root@rocky8 data]# cat a.txt a 2 c d [root@rocky8 data]# cat b.txt a 2 c d [root@rocky8 data]# vimdiff a.txt b.txt 2 files to edit [root@rocky8 data]# 2.6.4.3cmp 范例：查看二进制文件的不同\n[root@centos8 data]#ll /usr/bin/dir /usr/bin/ls -rwxr-xr-x. 1 root root 166448 May 12 2019 /usr/bin/dir -rwxr-xr-x. 1 root root 166448 May 12 2019 /usr/bin/ls [root@centos8 data]#ll /usr/bin/dir /usr/bin/ls -i 201839444 -rwxr-xr-x. 1 root root 166448 May 12 2019 /usr/bin/dir 201839465 -rwxr-xr-x. 1 root root 166448 May 12 2019 /usr/bin/ls [root@centos8 data]#diff /usr/bin/dir /usr/bin/ls Binary files /usr/bin/dir and /usr/bin/ls differ [root@centos8 ~]#cmp /bin/dir /bin/ls /bin/dir /bin/ls differ: byte 737, line 2 #跳过前735个字节,观察后面30个字节 [root@centos8 ~]#hexdump -s 735 -Cn 30 /bin/ls 000002df 00 05 6d da 3f 1b 77 91 91 63 a7 de 55 63 a2 b9 |..m.?.w..c..Uc..| 000002ef d9 d2 45 55 4c 00 00 00 00 03 00 00 00 7d |..EUL........}| 000002fd [root@centos8 ~]#hexdump -s 735 -Cn 30 /bin/dir 000002df 00 f1 21 4e f2 19 7e ef 38 0d 9b 3e d7 54 08 39 |..!N..~.8..\u0026gt;.T.9| 000002ef e4 74 4d 69 25 00 00 00 00 03 00 00 00 7d |.tMi%........}| 000002fd 练习 1、找出ifconfig “网卡名” 命令结果中本机的IPv4地址\n[root@rocky8 data]# ifconfig | tail -n +2 |head -n1|tr -s \u0026#34; \u0026#34;|cut -d \u0026#34; \u0026#34; -f3 192.168.37.13 2、查出分区空间使用率的最大百分比值\n[root@rocky8 data]# df |tr -s \u0026#34; \u0026#34; | cut -d \u0026#34; \u0026#34; -f5|sort -nr|head -n1 26% 3、查出用户UID最大值的用户名、UID及shell类型 4、查出/tmp的权限，以数字方式显示 5、统计当前连接本机的每个远程主机IP的连接数，并按从大到小排序\n3 正则表达式 REGEXP： Regular Expressions，由一类特殊字符及文本字符所编写的模式，其中有些字符（元字符） 不表示字符字面意义，而表示控制或通配的功能，类似于增强版的通配符功能，但与通配符不同，通配 符功能是用来处理文件名，而正则表达式是处理文本内容中字符 正则表达式被很多程序和开发语言所广泛支持：vim, less,grep,sed,awk, nginx,mysql 等 正则表达式分两类\n基本正则表达式：BRE Basic Regular Expressions\n扩展正则表达式：ERE Extended Regular Expressions\n正则表达式引擎： 采用不同算法，检查处理正则表达式的软件模块，如：PCRE（Perl Compatible Regular Expressions） 正则表达式的元字符分类：字符匹配、匹配次数、位置锚定、分组 帮助：man 7 regex\n3.1基本正则表达式元字符 3.1 .1字符匹配 . 匹配任意单个字符(除了\\n)，可以是一个汉字或其它国家的文字 [] 匹配指定范围内的任意单个字符，示例：[wang] [0-9] [a-z] [a-zA-Z] [^] 匹配指定范围外的任意单个字符,示例：[^wang] [:alnum:] 字母和数字 [:alpha:] 代表任何英文大小写字符，亦即 A-Z, a-z [:lower:] 小写字母,示例:[[:lower:]],相当于[a-z] [:upper:] 大写字母 [:blank:] 空白字符（空格和制表符） [:space:] 包括空格、制表符(水平和垂直)、换行符、回车符等各种类型的空白,比[:blank:]包含的范围 广 [:cntrl:] 不可打印的控制字符（退格、删除、警铃...） [:digit:] 十进制数字 [:xdigit:]十六进制数字 [:graph:] 可打印的非空白字符 [:print:] 可打印字符 [:punct:] 标点符号 ----------------- \\s #匹配任何空白字符，包括空格、制表符、换页符等等。等价于 [\\f\\r\\t\\v]。注意 Unicode 正则表达式会匹配全角空格符 \\S #匹配任何非空白字符。等价于 [^\\f\\r\\t\\v] \\w #匹配一个字母,数字,下划线,汉字,其它国家文字的字符，等价于[_[:alnum:]字] \\W #匹配一个非字母,数字,下划线,汉字,其它国家文字的字符，等价于[^_[:alnum:]字] 案例：\n[root@rocky8 data]# ls /etc/ | grep \u0026#39;rc[.0-6]\u0026#39; rc0.d rc1.d rc2.d rc3.d rc4.d rc5.d rc6.d rc.d rc.local [root@rocky8 data]# 3.1.2 匹配次数 用在要指定次数的字符后面，用于指定前面的字符要出现的次数\n* #匹配前面的字符任意次，包括0次，贪婪模式：尽可能长的匹配 .* #任意长度的任意字符 \\? #匹配其前面的字符出现0次或1次,即:可有可无 \\+ #匹配其前面的字符出现最少1次,即:肯定有且 \u0026gt;=1 次 \\{n\\} #匹配前面的字符n次 \\{m,n\\} #匹配前面的字符至少m次，至多n次 \\{,n\\} #匹配前面的字符至多n次,\u0026lt;=n \\{n,\\} #匹配前面的字符至少n次 范例: 取IP地址\n[root@rocky8 data]# ifconfig ens160 | grep -o \u0026#34;[0-9]\\{1,3\\}\\.[0-9]\\{1,3\\}\\.[0-9]\\{1,3\\}\\.[0-9]\\{1,3\\}\u0026#34; | head -n1 192.168.37.130 3.1.3 位置锚定 ^ 行首 $ 行尾 \\\u0026lt;或者\\b 语首 \\\u0026gt;,或者\\b 语尾 案例： 行首\n[root@rocky8 data]# grep \u0026#34;^root\u0026#34; passwd root❌0:0:root:/root:/bin/bash [root@rocky8 data]# 案例： 行尾\n[root@rocky8 data]# grep \u0026#34;bash$\u0026#34; passwd root❌0:0:root:/root:/bin/bash yuankun❌1000:1000:yuankun:/home/yuankun:/bin/bash test❌1002:1001::/home/test:/bin/bash test1❌1003:1003::/home/test1:/bin/bash [root@rocky8 data]# 案例：语首\n[root@rocky8 data]# echo \u0026#39;yuankunsir\u0026#39; | grep \u0026#34;\\\u0026lt;yuan\u0026#34; yuankunsir [root@rocky8 data]# 案例： 语尾\n[root@rocky8 data]# echo \u0026#39;yuankunsir\u0026#39; | grep \u0026#34;sir\\\u0026gt;\u0026#34; yuankunsir [root@rocky8 data]# 3.1.4 分组其他 () 分组 后向引用：\\1, \\2, ... 注意: \\0 表示正则表达式匹配的所有字符 | 或者 a|b #a或b C|cat #C或cat (C|c)at #Cat或cat 案例：分组\n# abc至少出现三次 [root@rocky8 data]# echo \u0026#39;abcabcabc\u0026#39; | grep \u0026#34;\\(abc\\)\\{3,\\}\u0026#34; abcabcabc 案例：或者\n[root@rocky8 data]# echo \u0026#39;abc\u0026#39; |grep \u0026#39;a\\|b\u0026#39; abc 4 文本处理三剑客 grep 命令主要对文本的（正则表达式）行基于模式进行过滤 sed：stream editor，文本编辑工具 awk：Linux上的实现gawk，文本报告生成器\n4.1 文本处理三剑客之grep grep: Global search REgular expression and Print out the line 作用：文本搜索工具，根据用户指定的“模式”对目标文本逐行进行匹配检查；打印匹配到的行 模式：由正则表达式字符及文本字符所编写的过滤条件 帮助:\nhttps://man7.org/linux/man-pages/man1/grep.1.html 格式：\ngrep [OPTIONS] PATTERN [FILE...] 常见选项：\n--color=auto 对匹配到的文本着色显示 -m # 匹配#次后停止 -v 显示不被pattern匹配到的行,即取反 -i 忽略字符大小写 -n 显示匹配的行号 -c 统计匹配的行数 -o 仅显示匹配到的字符串 -q 静默模式，不输出任何信息 -A # after, 后#行 -B # before, 前#行 -C # context, 前后各#行 -e 实现多个选项间的逻辑or关系,如：grep –e ‘cat \u0026#39; -e ‘dog\u0026#39; file -w 匹配整个单词 -E 使用ERE，相当于egrep -F 不支持正则表达式，相当于fgrep -P 支持Perl格式的正则表达式 -f file 根据模式文件处理 -r 递归目录，但不处理软链接 -R 递归目录，但处理软链接 案例：-m\n[root@rocky8 data]# grep -m1 root passwd root❌0:0:root:/root:/bin/bash [root@rocky8 data]# 案例：-v\ngrep -v root passwd 案例：-i\n[root@rocky8 data]# grep -i root passwd root❌0:0:root:/root:/bin/bash operator❌11:0:operator:/root:/sbin/nologin [root@rocky8 data]# 案例：-n\n[root@rocky8 data]# grep -n root passwd 1:root:x:0:0:root:/root:/bin/bash 10:operator:x:11:0:operator:/root:/sbin/nologin [root@rocky8 data]# 案例：-o\n[root@rocky8 data]# grep -o bash passwd bash bash bash bash [root@rocky8 data]# 案例：-q\n[root@rocky8 data]# grep -q root passwd [root@rocky8 data]# echo $? 0 [root@rocky8 data]# 案例：-A\n[root@rocky8 data]# cat a.txt a b c d e f g h j k l [root@rocky8 data]# grep -A3 a a.txt a b c d [root@rocky8 data]# 案例: -B\n[root@rocky8 data]# cat a.txt a b c d e f g h j k l [root@rocky8 data]# grep -B3 f a.txt c d e f [root@rocky8 data]# 案例： -C\n[root@rocky8 data]# cat a.txt a b c d e f g h j k l [root@rocky8 data]# grep -C2 f a.txt d e f g h [root@rocky8 data]# 案例： -e\n[root@rocky8 data]# grep -e root -e yuankun passwd root❌0:0:root:/root:/bin/bash operator❌11:0:operator:/root:/sbin/nologin yuankun❌1000:1000:yuankun:/home/yuankun:/bin/bash [root@rocky8 data]# 案例： -w\n[root@rocky8 data]# grep -w root passwd root❌0:0:root:/root:/bin/bash operator❌11:0:operator:/root:/sbin/nologin [root@rocky8 data]# 案例： -f\n# 取两个文件的相同行 grep -f a.txt b.txt 4.2 文本处理工具之sed 4.2.1 sed基本用法 格式:\nsed [option]... \u0026#39;script;script;...\u0026#39; [inputfile...] 常用选项\n-n 不输出模式空间内容到屏幕，即不自动打印 -e 多点编辑 -f FILE 从指定文件中读取编辑脚本 -r, -E 使用扩展正则表达式 -i.bak 备份文件并原处编辑 -s 将多个文件视为独立文件，而不是单个连续的长文件流 #说明: -ir 不支持 -i -r 支持 -ri 支持 -ni 危险选项,会清空文件 script格式：\n\u0026#39;地址命令\u0026#39; 地址格式：\n1. 不给地址：对全文进行处理 2. 单地址： #：指定的行，$：最后一行 /pattern/：被此处模式所能够匹配到的每一行 3. 地址范围： #,# #从#行到第#行，3，6 从第3行到第6行 #,+# #从#行到+#行，3,+4 表示从3行到第7行 /pat1/,/pat2/ #,/pat/ /pat/,# 4. 步进：~ 1~2 奇数行 2~2 偶数行 命令：\np 打印当前模式空间内容，追加到默认输出之后 Ip 忽略大小写输出 d 删除模式空间匹配的行，并立即启用下一轮循环 a [\\]text 在指定行后面追加文本，支持使用\\n实现多行追加 i [\\]text 在行前面插入文本 c [\\]text 替换行为单行或多行文本 w file 保存模式匹配的行至指定文件 r file 读取指定文件的文本至模式空间中匹配到的行后 = 为模式空间中的行打印行号 ! 模式空间中匹配行取反处理 q 结束或退出sed 查找和替换：\ns/pattern/string/修饰符 查找替换,支持使用其它分隔符，可以是其它形式：s@@@，s### 替换修饰符： g 行内全局替换 p 显示替换成功的行 w /PATH/FILE 将替换成功的行保存至文件中 I,i 忽略大小写 范例：\n# sed默认会将输入信息输出到屏幕 [root@rocky8 data]# sed \u0026#34;\u0026#34; hello hello yuan yuan data data 案例：\n# 打印第三行，默认会输出所有，-n选项不输出模式空间内容到屏幕，即不自动打印 [root@rocky8 data]# seq 10 | sed \u0026#39;3p\u0026#39; 1 2 3 3 4 5 6 7 8 9 10 # p 打印当前模式空间内容，追加到默认输出之后 [root@rocky8 data]# seq 10 | sed -n \u0026#39;3p\u0026#39; 3 [root@rocky8 data]# # 删除第三行 [root@rocky8 data]# seq 10 | sed \u0026#39;3d\u0026#39; 1 2 4 5 6 7 8 9 10 [root@rocky8 data]# # 输出第三行至最后一行 [root@rocky8 data]# seq 10 | sed -n \u0026#39;3,$p\u0026#39; 3 4 5 6 7 8 9 10 [root@rocky8 data]# # 输出奇数行 [root@rocky8 etc]# seq 10 | sed -n \u0026#39;1~2p\u0026#39; 1 3 5 7 9 # 输出偶数行 [root@rocky8 etc]# seq 10 | sed -n \u0026#39;2~2p\u0026#39; 2 4 6 8 10 [root@rocky8 etc]# # 追加，在偶数行追加hello [root@rocky8 etc]# seq 10 | sed \u0026#39;2~2ahello\u0026#39; 1 2 hello 3 4 hello 5 6 hello 7 8 hello 9 10 hello 案例：行前和行首添加文本\n[root@rocky8 data]# cat data.txt hello my name is lihua [root@rocky8 data]# sed -i \u0026#39;/hello/a12138\u0026#39; data.txt [root@rocky8 data]# cat data.txt hello my name is lihua 12138 [root@rocky8 data]# sed -i \u0026#39;/hello/i12138\u0026#39; data.txt [root@rocky8 data]# cat data.txt 12138 hello my name is lihua 12138 案例：替换行为单行或多行文本\n[root@rocky8 data]# cat data.txt 852 a 852 b 852 c [root@rocky8 data]# sed -i \u0026#39;/852/c hello\u0026#39; data.txt [root@rocky8 data]# cat data.txt hello hello hello [root@rocky8 data]# 案例：保存模式匹配的行至指定文件\n[root@rocky8 data]# cat a.txt [root@rocky8 data]# seq 10 | sed -n \u0026#39;1~2w a.txt\u0026#39; [root@rocky8 data]# cat a.txt 1 3 5 7 9 [root@rocky8 data]# 案例：读取指定文件的文本至模式空间中匹配到的行后\n[root@rocky8 data]# seq 10 | sed \u0026#39;1~2r /etc/issue\u0026#39; 1 \\S Kernel \\r on an \\m 2 3 \\S Kernel \\r on an \\m 4 5 \\S Kernel \\r on an \\m 6 7 \\S Kernel \\r on an \\m 8 9 \\S Kernel \\r on an \\m 10 [root@rocky8 data]# 案例：! 模式空间中匹配行取反处理\n# 1~2奇数行，加上！取反就是偶数行 [root@rocky8 data]# seq 10 | sed -n \u0026#39;1~2!p\u0026#39; 2 4 6 8 10 [root@rocky8 data]# 4.3 文本处理工具之awk ","permalink":"https://xyenvy.github.io/posts/%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E5%B7%A5%E5%85%B7%E5%92%8C%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/","summary":"1.文本编辑工具之神VIM 1.1使用vim初步 1.1.1vim命令格式 vim [option]··· FILE ··· 常用选项： +# 打开文件后，让光标处于第#行的行首，+默认行尾 范例： vim +10 passwd +/PATTERN 让光标处于第一个被PATTERN匹配到的行行首 -b file 二进制方式打开文件 -d file1 file2… 比较多个文件，相当于 vimdiff","title":"文本处理工具和正则表达式"},{"content":"1.新建文件和目录的默认权限 umask 的值可以用来保留在创建文件权限 实现方式：\n新建文件的默认权限: 666-umask，如果所得结果某位存在执行（奇数）权限，则将其权限+1,偶 数不变 新建目录的默认权限: 777-umask 非特权用户umask默认是002\nroot的umask默认是022\n查看umask\numask #模式方式显示 umask –S #输出可被调用 umask –p 修改umask\numask #bash 范例：\nbash umask 002 umask u=rw,g=r,o= 持久保存umask:\n全局设置：/etc/bashrc 用户设置：~/.bashrc 创建临时权限为000的文件三种方法：\n方法一 touch a.txt;chmod 000 a.txt 方法二 umask 777;touch a.txt;umask 022 方法三 (umask 777;touch a.txt) ","permalink":"https://xyenvy.github.io/posts/%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86%E5%8F%8A%E6%96%87%E6%9C%AC%E7%BC%96%E8%BE%91%E5%B7%A5%E5%85%B7/","summary":"1.新建文件和目录的默认权限 umask 的值可以用来保留在创建文件权限 实现方式： 新建文件的默认权限: 666-umask，如果所得结果某位存在执行（奇数）权限，则将其权限+1,偶 数不变 新建目录的默认权限: 777-umask 非特权用户umask默认是002 root的umask默认是022 查看umask umask #模式","title":"权限管理及文本编辑工具"},{"content":"1.文件系统目录结构 1.1常见的文件系统目录功能 /boot：引导文件存放目录，内核文件(vmlinuz)、引导加载器(bootloader, grub)都存放于此目录 /bin：所有用户使用的基本命令；不能关联至独立分区，OS启动即会用到的程序 /sbin：管理类的基本命令；不能关联至独立分区，OS启动即会用到的程序 /lib：启动时程序依赖的基本共享库文件以及内核模块文件(/lib/modules) /lib64：专用于x86_64系统上的辅助共享库文件存放位置 /etc：配置文件目录 /home/USERNAME：普通用户家目录 /root：管理员的家目录 /media：便携式移动设备挂载点 /mnt：临时文件系统挂载点 /dev：设备文件及特殊文件存储位置 b: block device，随机访问 c: character device，线性访问 /opt：第三方应用程序的安装位置 /srv：系统上运行的服务用到的数据 /tmp：临时文件存储位置 /usr: universal shared, read-only data bin: 保证系统拥有完整功能而提供的应用程序 sbin: lib：32位使用 lib64：只存在64位系统 include: C程序的头文件(header files) share：结构化独立的数据，例如doc, man等 local：第三方应用程序的安装位置 bin, sbin, lib, lib64, etc, share /var: variable data files cache: 应用程序缓存数据目录 lib: 应用程序状态信息数据 local：专用于为/usr/local下的应用程序存储可变数据 lock: 锁文件 log: 日志目录及文件 opt: 专用于为/opt下的应用程序存储可变数据 run: 运行中的进程相关数据,通常用于存储进程pid文件 spool: 应用程序数据池 tmp: 保存系统两次重启之间产生的临时数据 /proc: 用于输出内核与进程信息相关的虚拟文件系统 /sys：用于输出当前系统上硬件设备相关信息虚拟文件系统 /selinux: security enhanced Linux，selinux相关的安全策略等信息的存储位置 1.2Linux下的文件类型 -普通文件 d 目录文件directory I 符号链接文件link b 块设备block c 字符设备character p 管道文件pipe s 套接字文件socket 注意:面试题目容易出现\n2.文件操作命令 2.1相对路径和绝对路径 绝对路径 以正斜杠/ 即根目录开始 完整的文件的位置路径 可用于任何想指定一个文件名的时候 相对路径名 不以斜线开始 一般情况下，是指相对于当前工作目录的路径，特殊场景下，是相对于某目录的位置 可以作为一个简短的形式指定一个文件名 基名：basename，只取文件名而不要路径 目录名：dirname，只取路径，不要文件名 范例: 2.2更改目录 命令 cd ： change directory 改变目录 选项：-P 切换至物理路径，而非软链接目录 可以使用绝对或相对路径 切换至父目录： cd .. 切换至当前用户主目录： cd 切换至以前的工作目录： cd -\n2.3列出目录内容 ls 命令可以列出当前目录的内容或指定目录 用法：\nls [options] [files_or_dirs] 常见选项：\n-a 包含隐藏文件 -l 显示额外的信息 -R 目录递归 -ld 目录和符号链接信息 -1 文件分行显示 -S 按从大到小排序 -t 按mtime排序 -u 配合-t选项，显示并按atime从新到旧排序 -U 按目录存放顺序显示 -X 按文件后缀排序 -F 对不同类型文件显示时附加不同的符号：*/=\u0026gt;@| -C 文件多时，以多列的方式显示文件，默认是一列（标准输出） 说明：\nls 查看不同后缀文件时的颜色由 /etc/DIR_COLORS 和@LS_COLORS变量定义 ls -l 看到文件的大小,不一定是实际文件真正占用空间的大小 2.4查看文件状态 用法：\nstat filename 每个文件有三个时间戳：\naccess time 访问时间，atime，读取文件内容 modify time 修改时间，mtime，改变文件内容（数据） change time 改变时间，ctime，元数据发生改变 2.5查看文件内容 用法：\nfile [options] filename 常用选项：\n-b 列出文件辨识结果时，不显示文件名称 -f filelist 列出文件filelist中文件名的文件类型 -F 使用指定分隔符号替换输出文件名后默认的”:”分隔符 -L 查看对应软链接对应文件的文件类型 \u0026ndash;help 显示命令在线帮助 2.6文件通配符模式 常见的通配符如下\n* 匹配零个或多个字符，但不匹配 \u0026#34;.\u0026#34; 开头的文件，即隐藏文件 ? 匹配任何单个字符,一个汉字也算一个字符 ~ 当前用户家目录 ~mage 用户mage家目录 [0-9] 匹配数字范围 [a-z] 一个字母 [A-Z] 一个字母 [wang] 匹配列表中的任何的一个字符 [^wang] 匹配列表中的所有字符以外的字符 [^a-z] 匹配列表中的所有字符以外的字符 . 和 ~+ 当前工作目录 ~- 前一个工作目录 2.7批量修改文件名 利用 rename 可以批量修改文件名 格式：\nrename [options] \u0026lt;expression\u0026gt; \u0026lt;replacement\u0026gt; \u0026lt;file\u0026gt;... 范例：\n#为所有的f开头包含conf的文件加上.bak后缀： rename \u0026#39;conf\u0026#39; \u0026#39;conf.bak\u0026#39; f* #去掉所有的bak后缀： rename \u0026#39;.bak\u0026#39; \u0026#39;\u0026#39; *.bak 3.硬链接和软链接 3.1硬链接 硬链接本质上就给一个文件起一个新的名称，实质是同一个文件 硬链接特性\n创建硬链接会在对应的目录中增加额外的记录项以引用文件 对应于同一文件系统上一个物理文件 每个目录引用相同的inode号 创建时链接数递增 删除文件时：rm命令递减计数的链接，文件要存在，至少有一个链接数，当链接数为零时，该文件被删除 不能跨越驱动器或分区 不支持对目录创建硬链接 格式：\nln filename [linkname] 3.2软链接 一个符号链接指向另一个文件,就像 windows 中快捷方式，软链接文件和原文件本质上不是同一个文件 软链接特点\n一个符号链接的内容是它引用文件的名称 可以对目录创建软链接 可以跨分区的文件实现 指向的是另一个文件的路径；其大小为指向的路径字符串的长度；不增加或减少目标文件inode的引用计数 在创建软链接时, 如果源文件使用相对路径，是相对于软链接文件的路径，而非相对于当前工作目录,但是软链接的路径如果是相对路径,则是相对于当前工作目录 格式 ln -s filename [linkname] 范例： 查看软链接\nrm -rf /data/dirlink #只删除软链接本身,不会删除源目录内容 rm -rf /data/dirlink/ #删除源目录的文件,但不会删除链接文件,此方法非常危险 #注意: 删除此软链接务必不要加-r选项 4.硬链接和软链接区别 本质： 硬链接：本质是同一个文件 软链接：本质不是同一个文件 跨设备 硬链接：不支持 软链接：支持 inode 硬链接：相同 软链接：不同 链接数 硬链接：创建新的硬链接,链接数会增加,删除硬链接,链接数减少 软链接：创建或删除,链接数不会变化 文件夹 硬链接：不支持 软链接：支持 相对路径 硬链接：原始文件相对路径是相对于当前工作目录 软链接：原始文件的相对路径是相对于链接文件的相对路径 删除源文件 硬链接：只是链接数减一,但链接文件的访问不受影响 软链接：链接文件将无法访问 文件类型 硬链接：和源文件相同 软链接：链接文件,和源文件无关 文件大小 硬链接: 和源文件相同 软链接: 源文件的路径的长度 5.生产案例 案例1：提示空间满 No space left on device，但 df 可以看到空间很多，为什么 解决方法：节点编号用完了，增加节点编号增加不了，说明你的磁盘上的文件都是小文件； 1、删除不用的文件和文件夹释放inode 2、迁移数据到新磁盘然后格式化重新指定inode 知识点： 1.Linux下一个文件夹或者一个文件就会占用一个inode资源 2.inode资源数量是在格式化磁盘的时候就指定的（可以不指定，但也会有一个值），要更改这个 数量必须格式化磁盘 3.如果某个磁盘的inode资源用尽，即便磁盘有空间，也不能进行任何文件或者文件夹的新增 4.删除一个文件夹或者文件就能释放一个inode资源 案例2：提示空间快满，使用 rm 删除了很大的无用文件后，df仍然看到空间不足，为什么？如何解决 有其他程序在使用该文件，可以清空该文件内容。使用\u0026gt;清空文件内容 \u0026gt; filename # \u0026gt; test.log 6.重定向和管道 6.1 标准输入和输出 程序：指令+数据 读入数据：Input 输出数据：Output 打开的文件都有一个fd: file descriptor (文件描述符) Linux给程序提供三种 I/O 设备\n标准输入（STDIN） －0 默认接受来自终端窗口的输入 标准输出（STDOUT）－1 默认输出到终端窗口 标准错误（STDERR） －2 默认输出到终端窗口 6.2标准的输出和错误重定向 格式：\n命令 操作符号 文件名 支持的操作符号包括：\n1\u0026gt; 或 \u0026gt; 把STDOUT重定向到文件 2\u0026gt; 把STDERR重定向到文件 \u0026amp;\u0026gt; 把标准输出和错误都重定向 \u0026gt;\u0026amp; 和上面功能一样，建议使用上面方式 以上的文件如果已经存在，文件内容则会覆盖\n# \u0026gt;\u0026gt; 可以在原有的基础内容上追加内容 \u0026gt;\u0026gt; 追加标准输出重定向至文件 2\u0026gt;\u0026gt; 追加标准错误重定向至文件 6.3将标准输出和错误输出指定向不同的文件 格式：\nCOMMAND \u0026gt; /path/to/file.log 2\u0026gt; /path/to/error.log 6.4合并标准输出和错误输出为同一个数据流进行重定向 \u0026amp;\u0026gt; 覆盖重定向 \u0026amp;\u0026gt;\u0026gt; 追加重定向 COMMAND \u0026gt; /path/to/file.out 2\u0026gt;\u0026amp;1 （顺序很重要） COMMAND \u0026gt;\u0026gt; /path/to/file.out 2\u0026gt;\u0026amp;1 错误案例 6.5标准输入重定向 实现标准输入重定向的符号\nCOMMAND 0\u0026lt; FILE COMMAND \u0026lt; FILE 面试题： # 求1+2+···+10的和 seq -s+ 10 \u0026gt; seq.log bc \u0026lt; seq.log 扩展：求1*2*···*10的值： seq -s* 10 \u0026gt;seq.log bc \u0026lt; seq.log 6.5.1tr命令 tr 转换和删除字符\ntr [option] ··· SET1 [SET2] 选项：\n-d --delete：删除所有属于第一字符集的字符 -s --squeeze-repeats：把连续重复的字符以单独一个字符表示,即去重 -t --truncate-set1：将第一个字符集对应字符转化为第二字符集对应的字符 -c –C --complement：取字符集的补集 \\NNN character with octal value NNN (1 to 3 octal digits) \\\\ backslash \\a audible BEL \\b backspace \\f form feed \\n new line \\r return \\t horizontal tab \\v vertical tab [:alnum:]：字母和数字 [:alpha:]：字母 [:digit:]：数字 [:lower:]：小写字母 [:upper:]：大写字母 [:space:]：空白字符 [:print:]：可打印字符 [:punct:]：标点符号 [:graph:]：图形字符 [:cntrl:]：控制（非打印）字符 [:xdigit:]：十六进制字符 范例：\n删除字符,删除\u0026rsquo;abcd\u0026rsquo;中的\u0026rsquo;a' echo abcd | tr -d \u0026#39;a\u0026#39; 将’aaabbbccc‘中字符去重 echo aaabbbccc |tr -s \u0026#39;abc\u0026#39; 输入df将空格用\u0026quot;+\u0026ldquo;替换 df | tr -s \u0026#39; \u0026#39; + 6.5.2多行重定向 使用 \u0026ldquo;\u0026laquo;终止词\u0026rdquo; 命令从键盘把多行重导向给STDIN，直到终止词位置之前的所有文本都发送给 STDIN，有时被称为就地文本（here documents） 其中终止词可以是任何一个或多个符号，比如：!，@，$，EOF（End Of File），magedu等，其中EOF 比较常用\n范例：\n6.5.3高级重定向 6.5.3.1 cmd1 \u0026lt; \u0026lt;(cmd2) 名称为 Process substitution ,是由两个部分组成 \u0026lt;(cmd2) 表示把cmd2的输出写入一个临时文件, 注意：\u0026lt;和（之间无空格 cmd1 \u0026lt; 这是一个标准的stdin重定向 把两个合起来，就是把cmd2的输出stdout传递给cmd1作为输入stdin, 中间通过临时文件做传递\n6.5.3.2cmd1\u0026laquo;\u0026lt;\u0026lsquo;string\u0026rsquo; 含义是 here-string ，表示传给给cmd的stdin的内容从这里开始是一个字符串。 范例：\nbc \u0026lt;\u0026lt;\u0026lt;\u0026#39;2+4\u0026#39; 6.6 tee命令 tee命令用于读取标准输入的数据，并将其内容输出成文件。\ntee指令会从标准输入设备读取数据，将其内容输出到标准输出设备，同时保存成文件。\n选项：\n-a 追加 7.用户和组相关概念 7.1 用户 Linux中每个用户是通过 User Id （UID）来唯一标识的\n管理员：root, 0\n普通用户：1-60000 自动分配\n系统用户：1-499 （CentOS 6以前）, 1-999 （CentOS 7以后） 对守护进程获取资源进行权限分配 登录用户：500+ （CentOS6以前）, 1000+（CentOS7以后） 给用户进行交互式登录使用 7.2 用户组 Linux中可以将一个或多个用户加入用户组中，用户组是通过Group ID（GID） 来唯一标识的。\n管理员组：root, 0 普通组： 系统组：1-499（CentOS 6以前）, 1-999（CentOS7以后）, 对守护进程获取资源进行权限分配 普通组：500+（CentOS 6以前）, 1000+（CentOS7以后）, 给用户使用 7.3 用户和组的关系 用户的主要组(primary group)：用户必须属于一个且只有一个主组，默认创建用户时会自动创建和用户名同名的组，做为用户的主要组，由于此组中只有一个用户，又称为私有组 用户的附加组(supplementary group)： 一个用户可以属于零个或多个辅助组，附属组 范例：\n[root@rocky8 home]# id yuankun uid=1000(yuankun) gid=1000(yuankun) groups=1000(yuankun) 7.4用户和组的配置文件 7.4.1用户和组的主要配置文件 /etc/passwd：用户及其属性信息(名称、UID、主组ID等） /etc/shadow：用户密码及其相关属性 /etc/group：组及其属性信息 /etc/gshadow：组密码及其相关属性 7.4.2 passwd文件格式 login name：登录用名（yuankun） passwd：密码 (x) UID：用户身份编号 (1000) GID：登录默认所在组编号 (1000) GECOS：用户全名或注释 home directory：用户主目录 (/home/wang) shell：用户默认使用shell (/bin/bash) 7.4.3shadow文件格式 登录用名 用户密码:一般用sha512加密 从1970年1月1日起到密码最近一次被更改的时间 密码再过几天可以被变更（0表示随时可被变更） 密码再过几天必须被变更（99999表示永不过期） 密码过期前几天系统提醒用户（默认为一周） 密码过期几天后帐号会被锁定 从1970年1月1日算起，多少天后帐号失效 7.4.4group文件格式 群组名称：就是群组名称 群组密码：通常不需要设定，密码是被记录在 /etc/gshadow GID：就是群组的 ID 以当前组为附加组的用户列表(分隔符为逗号) 7.4.5gshadow文件格式 群组名称：就是群的名称 群组密码： 组管理员列表：组管理员的列表，更改组密码和成员 以当前组为附加组的用户列表：多个用户间用逗号分隔 7.5 用户和组管理命令 用户管理命令 useradd(添加用户) usermod(修改用户) userdel(删除用户) 组账号维护命令 groupadd groupmod groupdel 面试题：添加新用户后家目录下的文件来源什么地方？\n来源于/etc/skel,进入/etc/skel下查看文件和进入test用户的家目录下查看文件是一致的\n7.5.1用户创建 useradd命令可以创建新的linux用户\n格式：\nuseradd [options] login 常见的选项：\n-u UID -o 配合-u 选项，不检查UID的唯一性 -g GID 指明用户所属基本组，可为组名，也可以GID -c \u0026#34;COMMENT“ 用户的注释信息 -d HOME_DIR 以指定的路径(不存在)为家目录 -s SHELL 指明用户的默认shell程序，可用列表在/etc/shells文件中 -G GROUP1[,GROUP2,...] 为用户指明附加组，组须事先存在 -N 不创建私用组做主组，使用users组做主组 -r 创建系统用户 CentOS 6之前: ID\u0026lt;500，CentOS7 以后: ID\u0026lt;1000 -m 创建家目录，用于系统用户 -M 不创建家目录，用于非系统用户 -p 指定加密的密码 范例:\n[root@rocky8 home]# groupadd apache [root@rocky8 home]# useradd -r -u 48 -g apache -s /sbin/nologin -d /var/www -c \u0026#34;Apache\u0026#34; apache useradd命令默认值设置由/etc/default/useradd定义\n[root@centos8 ~]#cat /etc/default/useradd # useradd defaults file GROUP=100 HOME=/home INACTIVE=-1 #对应/etc/shadow文件第7列，即用户密码过期后的帐号锁定的宽限期,-1表示不锁定 EXPIRE= #对应/etc/shadow文件第8列，即用户帐号的有效期 SHELL=/bin/bash SKEL=/etc/skel #用于生成新建用户家目录的模版文件 CREATE_MAIL_SPOOL=yes 7.5.2用户属性修改 usermod命令可以修改用户属性\n格式：\nusermod [options] login 常见选项：\n-u UID: 新UID -g GID: 新主组 -G GROUP1[,GROUP2,...[,GROUPN]]]：新附加组，原来的附加组将会被覆盖；若保留原有，则要同时使 用-a选项 -s SHELL：新的默认SHELL -c \u0026#39;COMMENT\u0026#39;：新的注释信息 -d HOME: 新家目录不会自动创建；若要创建新家目录并移动原家数据，同时使用-m选项 -l login_name: 新的名字 -L: lock指定用户,在/etc/shadow 密码栏的增加 ! -U: unlock指定用户,将 /etc/shadow 密码栏的 ! 拿掉 -e YYYY-MM-DD: 指明用户账号过期日期 -f INACTIVE: 设定非活动期限，即宽限期 范例：创建test用户，使用id username查看用户的uid,然后修改其uid\n[root@rocky8 home]# useradd test #添加tes用户 [root@rocky8 home]# id test #查看用户信息 uid=1001(test) gid=1001(test) groups=1001(test) [root@rocky8 home]# usermod -u 1002 test # 将uid修改为1002 [root@rocky8 home]# id test #查看用户信息修改成功 uid=1002(test) gid=1001(test) groups=1001(test) 7.5.4删除用户 userdel可以删除用户\n格式：\nuserdel [options] login 常见的选项：\n-f, --force 强制 -r, --remove 删除用户家目录和邮箱 范例：\nuserdel -f test #强制删除 userdel -rf test # 删除家目录和邮箱 7.5.5查看用户相关ID id命令可以查看用户的UID、GID等信息\nid [options] [username] 常见选项：\n-u: 显示UID -g: 显示GID -G: 显示用户所属的组的ID -n: 显示名称，需配合ugG使用 范例：\n[root@rocky8 home]# id test uid=1002(test) gid=1001(test) groups=1001(test) [root@rocky8 home]# id -u test 1002 [root@rocky8 home]# id -g test 1001 [root@rocky8 home]# id -G test 1001 [root@rocky8 home]# 7.5.6查看linux所有用户 查看/etc/passwd getent passwd 7.5.7切换用户 su: 即 switch user，命令可以切换用户身份，并且以指定用户的身份执行命令 格式：\nsu [options...] [-] [user [args...]] 常见的选项\n-l --login su -l UserName 相当于 su - UserName -c, --command \u0026lt;command\u0026gt; pass a single command to the shell with -c 切换用户的方式：\nsu UserName：非登录式切换，即不会读取目标用户的配置文件，不改变当前工作目录，即不完全切换 su - UserName：登录式切换，会读取目标用户的配置文件，切换至自已的家目录，即完全切换 说明：root su至其他用户无须密码；非root用户切换时需要密码 注意：su 切换新用户后，使用 exit 退回至旧的用户身份，而不要再用 su 切换至旧用户，否则会生成很多的bash子进程，环境可能会混乱。 换个身份执行命令：\nsu - username -c \u0026#39;command\u0026#39; 范例：\n[root@rocky8 skel]# su - test -c \u0026#39;touch test.log\u0026#39; [root@rocky8 skel]# su test [test@rocky8 skel]$ ll total 0 [test@rocky8 skel]$ ls -a . .. .bash_logout .bash_profile .bashrc [test@rocky8 skel]$ cd /home/ [test@rocky8 home]$ ll total 0 drwx------. 2 test test 99 Jul 24 11:38 test drwx------. 2 test1 test1 78 Jul 24 11:24 test1 drwx------. 2 yuankun yuankun 114 Jul 23 08:24 yuankun [test@rocky8 home]$ cd test [test@rocky8 ~]$ ll total 0 -rw-rw-r--. 1 test test 0 Jul 24 11:38 test.log [test@rocky8 ~]$ 7.5.8设置密码 passwd 可以修改用户密码\n格式：\npasswd [options] username 常见选项：\n-d：删除指定用户密码 -l：锁定指定用户 -u：解锁指定用户 -e：强制用户下次登录修改密码 -f：强制操作 -n mindays：指定最短使用期限 -x maxdays：最大使用期限 -w warndays：提前多少天开始警告 -i inactivedays：非活动期限 --stdin：从标准输入接收用户密码,Ubuntu无此选项 范例：非交互式修改用户密码\n#此方式更通用，适用于各种Linux版本，如:ubuntu root@ununtu2004:/home# echo -e \u0026#39;123456\\n123456\u0026#39; | passwd test New password: Retype new password: passwd: password updated successfully root@ununtu2004:/home# #适用于红帽系列的Linux版本 [root@rocky8 home]# echo -e \u0026#39;123456\u0026#39;| passwd --stdin test Changing password for user test. passwd: all authentication tokens updated successfully. [root@rocky8 home]# 7.6文件权限管理 7.6.1文件所有者和属组属性操作 7.6.1.1设置文件的所有者chown chown 命令可以修改文件的属主，也可以修改文件属组 格式：\nchown [OPTION]... [OWNER][:[GROUP]] FILE... chown [OPTION]... --reference=RFILE FILE... 用法说明：\nOWNER #只修改所有者 OWNER:GROUP #同时修改所有者和属组 :GROUP #只修改属组，冒号也可用 . 替换 --reference=RFILE #参考指定的的属性，来修改 -R #递归，此选项慎用，非常危险！ 范例：\n修改所有者 [root@rocky8 home]# touch data.log [root@rocky8 home]# ll # data.log所有者为root total 0 -rw-r--r--. 1 root root 0 Jul 24 13:16 data.log drwx------. 2 gentoo gentoo 62 Jul 24 12:39 gentoo drwx------. 2 test test 99 Jul 24 11:38 test drwx------. 2 test1 test1 78 Jul 24 11:24 test1 drwx------. 2 yuankun yuankun 114 Jul 23 08:24 yuankun [root@rocky8 home]# chown yuankun data.log # 修改所有者为yuankun [root@rocky8 home]# ll total 0 -rw-r--r--. 1 yuankun root 0 Jul 24 13:16 data.log drwx------. 2 gentoo gentoo 62 Jul 24 12:39 gentoo drwx------. 2 test test 99 Jul 24 11:38 test drwx------. 2 test1 test1 78 Jul 24 11:24 test1 drwx------. 2 yuankun yuankun 114 Jul 23 08:24 yuankun [root@rocky8 home]# 修改所属组 chown :bin data.log 同时修改所有者和所属组 [root@rocky8 home]# touch test.log [root@rocky8 home]# [root@rocky8 home]# [root@rocky8 home]# chown yuankun:bin test.log # 冒号用.替换也可以 [root@rocky8 home]# ll total 0 -rw-r--r--. 1 yuankun bin 0 Jul 24 13:16 data.log drwx------. 2 gentoo gentoo 62 Jul 24 12:39 gentoo drwx------. 2 test test 99 Jul 24 11:38 test drwx------. 2 test1 test1 78 Jul 24 11:24 test1 -rw-r--r--. 1 yuankun bin 0 Jul 24 13:22 test.log drwx------. 2 yuankun yuankun 114 Jul 23 08:24 yuankun [root@rocky8 home]# 修改为参考的所有者户所属组 chown --reference=root.log data.log 递归修改 chown -R yuankun:yuankun ./data/mysql/ 7.6.1.2设置文件的属组信息chgrp chgrp 命令可以只修改文件的属组 格式:\nchgrp [OPTION]... GROUP FILE... chgrp [OPTION]... --reference=RFILE FILE... -R 递归\n范例：\nchgrp yuankun data.log 7.6.2文件权限 每个文件针对每类访问者都定义了三种权限\nr Readable 4 w Writable 2 x eXcutable 1 对文件的权限\nr 可使用文件查看类工具，比如：cat，可以获取其内容 w 可修改其内容,文件的是否被删除和文件的权限无关 x 可以把此文件提请内核启动为一个进程，即可以执行（运行）此文件（此文件的内容必须是可执行） 文件权限常见组合 --- 0 r 4 r-x 5 rw 6 rwx 7 对目录的权限\nr 可以使用ls查看此目录中文件名列表,但无法看到文件的属性meta信息,包括inode号,不能查看文件的 内容 w 可在此目录中创建文件，也可删除此目录中的文件，而和此被删除的文件的权限无关 x 可以cd进入此目录，可以使用ls -l file或stat file 查看此目录中指定文件的元数据，当预先知 道文件名称时,也可以查看文件的内容,属于目录的可访问的最小权限 X 分配给目录或有部分x权限的文件的x权限，对无任意x权限的文件则不会分配x权限 目录权限常见组合 - 不能访问目录 r-x 只读目录 rwx 可读也可写目录 面试题：Linux中的目录和文件的权限区别？分别说明读，写和执行权限的区别?\n修改文件权限chmod\n面试题：执行 cp /etc/issue /data/dir/ 所需要的最小权限?\n","permalink":"https://xyenvy.github.io/posts/%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86/","summary":"1.文件系统目录结构 1.1常见的文件系统目录功能 /boot：引导文件存放目录，内核文件(vmlinuz)、引导加载器(bootloader, grub)都存放于此目录 /bin：所有用户使用的基本命令；不能关联至独立分区，OS启动即会用到的程序 /sbin：管理类的基本命令；不能关联至","title":"文件管理"},{"content":"1.冯诺依曼体系 1946年美籍匈牙利数学家冯·诺依曼于提出存储程序原理，把程序本身当作数据来对待，程序和该程序处 理的数据用同样的方式储存。 冯·诺依曼体系的要点是：\n数字计算机的数制采用二进制，bit 位, byte 字节 1 byte =8 bit\n计算机应该按照程序顺序执行\n计算机硬件由运算器、控制器、存储器、输入设备和输出设备五大部分组成\n计算机的硬件五个组件\n控制器: 指挥系统\n运算器: 数学和逻辑运算\n存储器: 存储信息\n输入设备: 接收外部信息\n输出设备: 输出计算机内部信息到外部设备\n2.服务器按外观类型分类 PC服务器常见的三种外观\n塔式服务器\n刀片式服务器\n机架式服务器\n3.操作系统和Linux安装 操作系统的作用\n主要作用\n硬件驱动\n进程管理\n内存管理\n网络管理\n安全管理\n文件管理\nunix哲学思想\n一切都是一个文件(包括硬件) 小型，单一用途的程序 链接程序，共同完成复杂的任务(shell脚本) 避免令人困惑的用户界面 配置数据存储在文本中 4.常见面试题 5 .基础使用命令 5.1 查看网络ip地址 ip a 5.2 重启 reboot 5.3 ubuntu roo账户进行远程登录修改方法 切换到root账户 sudo -i 设置密码 passwd 用户名 修改/etc/ssh/sshd_config ,PermitRootlogin yes\n重启sshd systemctl restart sshd 5.4 查看当前所在终端 tty 5.5 查看当前账户 whoami who am i who 5.6 查看当前时间 date 5.7 修改时区 ,修改为北京时间 timedatectl set-timezone Asia/Shanghai date # 查看当前时间 5.8 查看当前系统使用的shell 5.9 查看当前主机名 hostname 5.10修改当前主机名称，永久修改 hostnamectl set-hostname 名称 # 临时修改，重启后变为修改前的主机名称 hostname 主机名 5.11 查看所有内部命令 help 5.12 查看命令为内部还是外部命令 type 命令名称 # 示例 type cd 5.13 查看系统中所有别名 alias 5.14 设置别名 alias 别名名称 = \u0026#39;被设置别名的行为\u0026#39; # 示例 alias cdnt = \u0026#39;cd /root\u0026#39; 5.15 删除别名 unalisa 别名名称 命令种类\nalias(优先级最高) 内部命令(优先级低于alias) 外部命令(优先级最低) whatis\nwhatis使用数据库来显示命令的简短描述\n此工具在系统刚安装后不可立即使用，需要制作数据库后才可使用\n执行下面的命令生成数据库\n# centos7版本以后 mandb # centos6版本之前 makewhatis 5.16 内部命令查看帮助 # 使用type命令查看是否为内部命令，不是内部命令不能使用该命令 help history 范例\n5.17 外部命令使用帮助 COMMAND \u0026ndash;help 或者 COMMAND -h\n范例\ndate --help 5.18 man man date man 1 date 6.查看硬件信息 6.1查看CPU信息 lscpu # 该命令也可以 cat /proc/cpuinfo 6.2 查看内存信息 free -h # 或者 cat /proc/meminfo 6.3 查看硬盘信息和分区情况 lsblk 7.查看系统信息 7.1 查看系统架构 arch 7.2 查看内核版本 uname -r 7.3 查看操作系统发行版本 cat /etc/os-releases cat /etc/issue 7.4 修改登录后显示的内容 # 修改/etc/motd文件内容 vi /etc/motd 7.5 查看硬件时间 clock 7.6重启和关机 7.6.1重启 halt\nreboot\n7.6.2 关机或重启 shutdown - r :重启 - h :关机 指定时间关机或重启 shutdown -r 15:00 # 15:00重启 shutdown -h 15:00 # 15:00关机 shutdown -c # 取消 ","permalink":"https://xyenvy.github.io/posts/linux%E5%9F%BA%E7%A1%80%E5%92%8C%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/","summary":"1.冯诺依曼体系 1946年美籍匈牙利数学家冯·诺依曼于提出存储程序原理，把程序本身当作数据来对待，程序和该程序处 理的数据用同样的方式储存。 冯·诺依曼体系的要点是： 数字计算机的数制采用二进制，bit 位, byte 字节 1 byte =8 bit 计算机应该按照程序顺序执行 计算机硬件由运算器、控制器、存储器、输入","title":"linux基础和常用命令"},{"content":" 注：以下命令全部在git bash完成 1.查看是否配置邮箱和用户名 git config --global --list 如图所示，则代表已经配置完成\n2.配置用户名和邮箱 git config --global user.name \u0026#34;这里换上你的用户名\u0026#34; git config --global user.email \u0026#34;这里换上你的邮箱\u0026#34; 3.查看是否已经生成密钥 cd ~/.ssh ls -a 如图所示，代表已经生成密钥\nid_rsa文件是私钥，要保存好，放在本地，私钥可以生产公钥，反之不行。 id_rsa.pub文件是公钥，可以用于发送到其他服务器，或者git上 4.生成密钥 执行ssh-keygen -t rsa -c ssh-keygen -t rsa -c \u0026#34;这是你的邮箱\u0026#34; 点击enter,输入密码 点击enter，确认密码 如图，创建成功 ","permalink":"https://xyenvy.github.io/posts/git-ssh/","summary":"注：以下命令全部在git bash完成 1.查看是否配置邮箱和用户名 git config --global --list 如图所示，则代表已经配置完成 2.配置用户名和邮箱 git config --global user.name \u0026#34;这里换上你的用户名\u0026#34; git config --global user.email \u0026#34;这里换上你的邮箱\u0026#34; 3.查看是否已经生成密钥 cd ~/.ssh ls -a 如图所示，代表已经生成密钥 id_rsa","title":"git-ssh"},{"content":"\rSulv\u0026#39;s Blog\r一个记录技术、阅读、生活的博客\r👉友链格式\r名称： Sulv\u0026rsquo;s Blog 网址： https://www.sulvblog.cn 图标： https://www.sulvblog.cn/img/Q.gif 描述： 一个记录技术、阅读、生活的博客 👉友链申请要求\r秉承互换友链原则、文章定期更新、不能有太多广告、个人描述字数控制在15字内\n👉Hugo博客交流群\r787018782\n","permalink":"https://xyenvy.github.io/links/","summary":"Sulv\u0026#39;s Blog 一个记录技术、阅读、生活的博客 👉友链格式 名称： Sulv\u0026rsquo;s Blog 网址： https://www.sulvblog.cn 图标： https://www.sulvblog.cn/img/Q.gif 描述： 一个记录技术、阅读、生活的博客 👉友链申请要求 秉承互换友链原则、文章定期更新、不能有太多广告、个人描述字数控制在15字内 👉Hugo博客交流群 787018782","title":"🤝友链"},{"content":"关于博客\n为什么我要搭建这个博客呢？ 因为生命在于折腾 因为平时学习查找资料的时候，偶尔会发现一些非常精致的个人网站，那个时候就在想，什么时候俺也要整一个，然后用来写博客 。无奈由于各种原因 (懒)，一直没有捡起来，后来总算是找到一个不错的应用，折腾着建起来了，也打算督促自己克服懒癌，来记录一些东西。\n","permalink":"https://xyenvy.github.io/about/","summary":"关于博客 为什么我要搭建这个博客呢？ 因为生命在于折腾 因为平时学习查找资料的时候，偶尔会发现一些非常精致的个人网站，那个时候就在想，什么时候俺也要整一个，然后用来写博客 。无奈由于各种原因 (懒)，一直没有捡起来，后来总算是找到一个不错的应用，折腾着建起来了，也打算督促自己克服懒癌，来记","title":"🙋🏻‍♂️关于"}]